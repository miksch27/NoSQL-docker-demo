[error_logger:info,2021-04-19T19:45:43.269Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.121.0>},
                       {name,timer_server},
                       {mfargs,{timer,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:45:43.756Z,nonode@nohost:<0.88.0>:ns_server:init_logging:151]Started & configured logging
[ns_server:info,2021-04-19T19:45:43.772Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]Static config terms:
[{error_logger_mf_dir,"/opt/couchbase/var/lib/couchbase/logs"},
 {path_config_bindir,"/opt/couchbase/bin"},
 {path_config_etcdir,"/opt/couchbase/etc/couchbase"},
 {path_config_libdir,"/opt/couchbase/lib"},
 {path_config_datadir,"/opt/couchbase/var/lib/couchbase"},
 {path_config_tmpdir,"/opt/couchbase/var/lib/couchbase/tmp"},
 {path_config_secdir,"/opt/couchbase/etc/security"},
 {nodefile,"/opt/couchbase/var/lib/couchbase/couchbase-server.node"},
 {loglevel_default,debug},
 {loglevel_couchdb,info},
 {loglevel_ns_server,debug},
 {loglevel_error_logger,debug},
 {loglevel_user,debug},
 {loglevel_menelaus,debug},
 {loglevel_ns_doctor,debug},
 {loglevel_stats,debug},
 {loglevel_rebalance,debug},
 {loglevel_cluster,debug},
 {loglevel_views,debug},
 {loglevel_mapreduce_errors,debug},
 {loglevel_xdcr,debug},
 {loglevel_xdcr_trace,error},
 {loglevel_access,info},
 {disk_sink_opts,
     [{rotation,
          [{compress,true},
           {size,41943040},
           {num_files,10},
           {buffer_size_max,52428800}]}]},
 {disk_sink_opts_xdcr_trace,
     [{rotation,[{compress,false},{size,83886080},{num_files,5}]}]},
 {net_kernel_verbosity,10}]
[ns_server:warn,2021-04-19T19:45:43.772Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter error_logger_mf_dir, which is given from command line
[ns_server:warn,2021-04-19T19:45:43.772Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter path_config_bindir, which is given from command line
[ns_server:warn,2021-04-19T19:45:43.772Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter path_config_etcdir, which is given from command line
[ns_server:warn,2021-04-19T19:45:43.772Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter path_config_libdir, which is given from command line
[ns_server:warn,2021-04-19T19:45:43.773Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter path_config_datadir, which is given from command line
[ns_server:warn,2021-04-19T19:45:43.773Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter path_config_tmpdir, which is given from command line
[ns_server:warn,2021-04-19T19:45:43.773Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter path_config_secdir, which is given from command line
[ns_server:warn,2021-04-19T19:45:43.773Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter nodefile, which is given from command line
[ns_server:warn,2021-04-19T19:45:43.773Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_default, which is given from command line
[ns_server:warn,2021-04-19T19:45:43.773Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_couchdb, which is given from command line
[ns_server:warn,2021-04-19T19:45:43.773Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_ns_server, which is given from command line
[ns_server:warn,2021-04-19T19:45:43.773Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_error_logger, which is given from command line
[ns_server:warn,2021-04-19T19:45:43.773Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_user, which is given from command line
[ns_server:warn,2021-04-19T19:45:43.773Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_menelaus, which is given from command line
[ns_server:warn,2021-04-19T19:45:43.773Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_ns_doctor, which is given from command line
[ns_server:warn,2021-04-19T19:45:43.773Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_stats, which is given from command line
[ns_server:warn,2021-04-19T19:45:43.773Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_rebalance, which is given from command line
[ns_server:warn,2021-04-19T19:45:43.774Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_cluster, which is given from command line
[ns_server:warn,2021-04-19T19:45:43.774Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_views, which is given from command line
[ns_server:warn,2021-04-19T19:45:43.774Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_mapreduce_errors, which is given from command line
[ns_server:warn,2021-04-19T19:45:43.774Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_xdcr, which is given from command line
[ns_server:warn,2021-04-19T19:45:43.774Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_xdcr_trace, which is given from command line
[ns_server:warn,2021-04-19T19:45:43.774Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_access, which is given from command line
[ns_server:warn,2021-04-19T19:45:43.774Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter disk_sink_opts, which is given from command line
[ns_server:warn,2021-04-19T19:45:43.774Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter disk_sink_opts_xdcr_trace, which is given from command line
[ns_server:warn,2021-04-19T19:45:43.774Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter net_kernel_verbosity, which is given from command line
[error_logger:info,2021-04-19T19:45:43.782Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.128.0>},
                       {name,local_tasks},
                       {mfargs,{local_tasks,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:45:43.789Z,nonode@nohost:ns_server_cluster_sup<0.127.0>:log_os_info:start_link:25]OS type: {unix,linux} Version: {4,19,128}
Runtime info: [{otp_release,"R16B03-1"},
               {erl_version,"5.10.4.0.0.1"},
               {erl_version_long,
                   "Erlang R16B03-1 (erts-5.10.4.0.0.1) [source-00852da] [64-bit] [smp:8:8] [async-threads:16] [kernel-poll:true]\n"},
               {system_arch_raw,"x86_64-unknown-linux-gnu"},
               {system_arch,"x86_64-unknown-linux-gnu"},
               {localtime,{{2021,4,19},{19,45,43}}},
               {memory,
                   [{total,111059640},
                    {processes,9511584},
                    {processes_used,9510096},
                    {system,101548056},
                    {atom,331249},
                    {atom_used,310220},
                    {binary,70984},
                    {code,7693333},
                    {ets,2240656}]},
               {loaded,
                   [ns_info,log_os_info,local_tasks,restartable,
                    ns_server_cluster_sup,'ale_logger-metakv',
                    'ale_logger-rebalance','ale_logger-xdcr_trace',
                    'ale_logger-menelaus','ale_logger-stats',
                    'ale_logger-access',calendar,ale_default_formatter,
                    io_lib_fread,'ale_logger-ns_server','ale_logger-user',
                    'ale_logger-ns_doctor','ale_logger-cluster',
                    'ale_logger-xdcr',otp_internal,ns_log_sink,ale_disk_sink,
                    misc,couch_util,ns_server,filelib,cpu_sup,memsup,disksup,
                    os_mon,io,release_handler,overload,alarm_handler,sasl,
                    timer,tftp_sup,httpd_sup,httpc_handler_sup,httpc_cookie,
                    inets_trace,httpc_manager,httpc,httpc_profile_sup,
                    httpc_sup,ftp_sup,inets_sup,inets_app,ssl,lhttpc_manager,
                    lhttpc_sup,lhttpc,tls_connection_sup,ssl_session_cache,
                    ssl_pkix_db,ssl_manager,ssl_sup,ssl_app,crypto_server,
                    crypto_sup,crypto_app,ale_error_logger_handler,
                    'ale_logger-ale_logger','ale_logger-error_logger',
                    beam_opcodes,beam_dict,beam_asm,beam_validator,beam_z,
                    beam_flatten,beam_trim,beam_receive,beam_bsm,beam_peep,
                    beam_dead,beam_split,beam_type,beam_bool,beam_except,
                    beam_clean,beam_utils,beam_block,beam_jump,beam_a,
                    v3_codegen,v3_life,v3_kernel,sys_core_dsetel,erl_bifs,
                    sys_core_fold,cerl_trees,sys_core_inline,core_lib,cerl,
                    v3_core,erl_bits,erl_expand_records,sys_pre_expand,sofs,
                    erl_internal,sets,ordsets,erl_lint,compile,
                    dynamic_compile,ale_utils,io_lib_pretty,io_lib_format,
                    io_lib,ale_codegen,dict,ale,ale_dynamic_sup,ale_sup,
                    ale_app,epp,ns_bootstrap,child_erlang,file_io_server,
                    orddict,erl_eval,file,c,kernel_config,user_sup,
                    supervisor_bridge,standard_error,code_server,unicode,
                    hipe_unified_loader,gb_sets,ets,binary,code,file_server,
                    net_kernel,global_group,erl_distribution,filename,
                    inet_gethost_native,os,inet_parse,inet,inet_udp,
                    inet_config,inet_db,global,gb_trees,rpc,supervisor,kernel,
                    application_master,sys,application,gen_server,erl_parse,
                    proplists,erl_scan,lists,application_controller,proc_lib,
                    gen,gen_event,error_logger,heart,error_handler,
                    erts_internal,erlang,erl_prim_loader,prim_zip,zlib,
                    prim_file,prim_inet,prim_eval,init,otp_ring0]},
               {applications,
                   [{lhttpc,"Lightweight HTTP Client","1.3.0"},
                    {os_mon,"CPO  CXC 138 46","2.2.14"},
                    {public_key,"Public key infrastructure","0.21"},
                    {asn1,"The Erlang ASN1 compiler version 2.0.4","2.0.4"},
                    {kernel,"ERTS  CXC 138 10","2.16.4"},
                    {ale,"Another Logger for Erlang","4.6.0-3573-enterprise"},
                    {inets,"INETS  CXC 138 49","5.9.8"},
                    {ns_server,"Couchbase server","4.6.0-3573-enterprise"},
                    {crypto,"CRYPTO version 2","3.2"},
                    {ssl,"Erlang/OTP SSL application","5.3.3"},
                    {sasl,"SASL  CXC 138 11","2.3.4"},
                    {stdlib,"ERTS  CXC 138 10","1.19.4"}]},
               {pre_loaded,
                   [erts_internal,erlang,erl_prim_loader,prim_zip,zlib,
                    prim_file,prim_inet,prim_eval,init,otp_ring0]},
               {process_count,94},
               {node,nonode@nohost},
               {nodes,[]},
               {registered,
                   [ftp_sup,'sink-disk_xdcr',code_server,sasl_sup,
                    'sink-disk_debug',application_controller,
                    'sink-disk_error',local_tasks,'sink-disk_default',
                    ale_stats_events,kernel_safe_sup,inets_sup,ale,
                    standard_error,error_logger,lhttpc_sup,ale_sup,
                    lhttpc_manager,timer_server,standard_error_sup,
                    release_handler,httpd_sup,ale_dynamic_sup,overload,
                    alarm_handler,init,inet_db,rex,kernel_sup,'sink-ns_log',
                    global_name_server,sasl_safe_sup,crypto_server,crypto_sup,
                    file_server_2,tftp_sup,global_group,os_mon_sup,
                    'sink-disk_metakv',cpu_sup,tls_connection_sup,memsup,
                    ssl_sup,'sink-disk_access_int',disksup,'sink-disk_access',
                    ns_server_cluster_sup,httpc_sup,ssl_manager,
                    'sink-xdcr_trace',erl_prim_loader,'sink-disk_reports',
                    httpc_profile_sup,'sink-disk_stats',httpc_manager,
                    httpc_handler_sup,'sink-disk_xdcr_errors']},
               {cookie,nocookie},
               {wordsize,8},
               {wall_clock,3}]
[ns_server:info,2021-04-19T19:45:43.800Z,nonode@nohost:ns_server_cluster_sup<0.127.0>:log_os_info:start_link:27]Manifest:
["<?xml version=\"1.0\" encoding=\"UTF-8\"?>","<manifest>",
 "  <remote fetch=\"git://github.com/blevesearch/\" name=\"blevesearch\"/>",
 "  <remote fetch=\"git://github.com/couchbase/\" name=\"couchbase\" review=\"review.couchbase.org\"/>",
 "  <remote fetch=\"ssh://git@github.com/couchbase/\" name=\"couchbase-priv\" review=\"review.couchbase.org\"/>",
 "  <remote fetch=\"git://github.com/couchbasedeps/\" name=\"couchbasedeps\" review=\"review.couchbase.org\"/>",
 "  <remote fetch=\"git://github.com/couchbaselabs/\" name=\"couchbaselabs\" review=\"review.couchbase.org\"/>",
 "  ","  <default remote=\"couchbase\" revision=\"master\"/>","  ",
 "  <project groups=\"notdefault,enterprise\" name=\"backup\" path=\"goproj/src/github.com/couchbase/backup\" remote=\"couchbase-priv\" revision=\"469a5e8cc8661f35ab4af74fe45e92a3d89febed\"/>",
 "  <project name=\"bitset\" path=\"godeps/src/github.com/willf/bitset\" remote=\"couchbasedeps\" revision=\"28a4168144bb8ac95454e1f51c84da1933681ad4\"/>",
 "  <project name=\"blance\" path=\"godeps/src/github.com/couchbase/blance\" revision=\"5ce14d13954e04262b7eabfc6978776a4018402b\"/>",
 "  <project name=\"bleve\" path=\"godeps/src/github.com/blevesearch/bleve\" remote=\"blevesearch\" revision=\"f531835d5c212ee5f95c49d2debc28e65e6d1693\"/>",
 "  <project name=\"bleve-mapping-ui\" path=\"godeps/src/github.com/blevesearch/bleve-mapping-ui\" remote=\"blevesearch\" revision=\"b0453426dc1d59918cc763a970f1ad147b22ad6a\"/>",
 "  <project name=\"blevex\" path=\"godeps/src/github.com/blevesearch/blevex\" remote=\"blevesearch\" revision=\"918d980b0d244c8230c7d8c8ee40919f8d55ef88\"/>",
 "  <project name=\"bolt\" path=\"godeps/src/github.com/boltdb/bolt\" remote=\"couchbasedeps\" revision=\"51f99c862475898df9773747d3accd05a7ca33c1\"/>",
 "  <project name=\"buffer\" path=\"godeps/src/github.com/tdewolff/buffer\" remote=\"couchbasedeps\" revision=\"43cef5ba7b6ce99cc410632dad46cf1c6c97026e\"/>",
 "  <project groups=\"notdefault,build\" name=\"build\" path=\"cbbuild\" revision=\"ccd3ae52bbf0ade5fd59adcedba2b8cbbd16cd9b\">",
 "    <annotation name=\"VERSION\" value=\"4.6.0\"/>",
 "    <annotation name=\"BLD_NUM\" value=\"3573\"/>",
 "    <annotation name=\"RELEASE\" value=\"@RELEASE@\"/>",
 "    <annotation name=\"EDITION\" value=\"@EDITION@\"/>","  </project>",
 "  <project name=\"cbauth\" path=\"godeps/src/github.com/couchbase/cbauth\" revision=\"4a6d537777f57b291a8126f94dfbe3201c1d4efc\"/>",
 "  <project name=\"cbflag\" path=\"godeps/src/github.com/couchbase/cbflag\" revision=\"ce5c10adbb78c1212aefda73a85f8cfd1c3ae7e9\"/>",
 "  <project name=\"cbft\" path=\"goproj/src/github.com/couchbase/cbft\" revision=\"99f44266178dbe423890d8dd5bb9439ef2a71318\"/>",
 "  <project name=\"cbgt\" path=\"goproj/src/github.com/couchbase/cbgt\" revision=\"10790963d9cbada17ebfff728ea9298c1c97b7c5\"/>",
 "  <project groups=\"notdefault,enterprise\" name=\"cbq-gui\" path=\"goproj/src/github.com/couchbase/cbq-gui\" remote=\"couchbase-priv\" revision=\"1e19e5e34b64ca6b43a37de6166dac6e76803848\"/>",
 "  <project name=\"clog\" path=\"godeps/src/github.com/couchbase/clog\" revision=\"eebc98233c3e032eb6b9036575d51324ab5932e6\"/>",
 "  <project name=\"context\" path=\"godeps/src/github.com/gorilla/context\" remote=\"couchbasedeps\" revision=\"215affda49addc4c8ef7e2534915df2c8c35c6cd\"/>",
 "  <project name=\"couchbase-cli\" revision=\"951668b6b2fcaa5386b31d59df5004ff667e91e8\"/>",
 "  <project name=\"couchbase-examples\" revision=\"39ee1c2451ac2f2e86a6ff308e21e1201c49cafe\"/>",
 "  <project name=\"couchdb\" revision=\"7b950cfaa3ad30c75a7fcc7f4eb30b2df1a8bd5b\"/>",
 "  <project groups=\"notdefault,packaging\" name=\"couchdbx-app\" revision=\"be5f6ebaa12ac7c0b5382deb9b1b0efa7bf80497\"/>",
 "  <project groups=\"kv\" name=\"couchstore\" revision=\"9cf71ba60cf95f8b835b1040c68c85a4ddc653ee\"/>",
 "  <project name=\"crypto\" path=\"godeps/src/golang.org/x/crypto\" remote=\"couchbasedeps\" revision=\"f23ba3a5ee43012fcb4b92e1a2a405a92554f4f2\"/>",
 "  <project name=\"cznic-b\" path=\"godeps/src/github.com/cznic/b\" remote=\"couchbasedeps\" revision=\"b96e30f1b7bd34b0b9d8760798d67eca83d7f09e\"/>",
 "  <project name=\"dparval\" path=\"godeps/src/github.com/couchbase/dparval\" revision=\"9def03782da875a2477c05bf64985db3f19f59ae\"/>",
 "  <project groups=\"kv\" name=\"ep-engine\" revision=\"e4c8bcbbf20b52b11e93665901597875e10b2070\"/>",
 "  <project groups=\"kv\" name=\"forestdb\" revision=\"1d169510a5102e81547b1d3dc423eb37db908076\"/>",
 "  <project name=\"geocouch\" revision=\"74b4bab07713b233ca2780f9a9a3f7daa1a1dff4\"/>",
 "  <project name=\"go-bindata-assetfs\" path=\"godeps/src/github.com/elazarl/go-bindata-assetfs\" remote=\"couchbasedeps\" revision=\"57eb5e1fc594ad4b0b1dbea7b286d299e0cb43c2\"/>",
 "  <project name=\"go-couchbase\" path=\"godeps/src/github.com/couchbase/go-couchbase\" revision=\"e06e5adaf45e189d4cf3e471341af0bf80bcc312\"/>",
 "  <project name=\"go-jsonpointer\" path=\"godeps/src/github.com/dustin/go-jsonpointer\" remote=\"couchbasedeps\" revision=\"75939f54b39e7dafae879e61f65438dadc5f288c\"/>",
 "  <project name=\"go-metrics\" path=\"godeps/src/github.com/rcrowley/go-metrics\" remote=\"couchbasedeps\" revision=\"dee209f2455f101a5e4e593dea94872d2c62d85d\"/>",
 "  <project name=\"go-porterstemmer\" path=\"godeps/src/github.com/blevesearch/go-porterstemmer\" remote=\"blevesearch\" revision=\"23a2c8e5cf1f380f27722c6d2ae8896431dc7d0e\"/>",
 "  <project name=\"go-slab\" path=\"godeps/src/github.com/couchbase/go-slab\" revision=\"1f5f7f282713ccfab3f46b1610cb8da34bcf676f\"/>",
 "  <project name=\"go-zookeeper\" path=\"godeps/src/github.com/samuel/go-zookeeper\" remote=\"couchbasedeps\" revision=\"fa6674abf3f4580b946a01bf7a1ce4ba8766205b\"/>",
 "  <project name=\"go_json\" path=\"godeps/src/github.com/couchbase/go_json\" revision=\"f5a178ab380eb9a1911cf9c45b4159115b564169\"/>",
 "  <project name=\"go_n1ql\" path=\"godeps/src/github.com/couchbase/go_n1ql\" revision=\"6cf4e348b127e21f56e53eb8c3faaea56afdc588\"/>",
 "  <project name=\"gocb\" path=\"godeps/src/github.com/couchbase/gocb\" revision=\"d5b1a13c1e81f1255ca8155007b470db37ddeb25\"/>",
 "  <project name=\"godbc\" path=\"godeps/src/github.com/couchbase/godbc\" revision=\"adc62033c392ca9df8b5b42c0dda237576b39f9f\"/>",
 "  <project name=\"goforestdb\" path=\"godeps/src/github.com/couchbase/goforestdb\" revision=\"0b501227de0e8c55d99ed14e900eea1a1dbaf899\"/>",
 "  <project name=\"gojson\" path=\"godeps/src/github.com/dustin/gojson\" remote=\"couchbasedeps\" revision=\"af16e0e771e2ed110f2785564ae33931de8829e4\"/>",
 "  <project name=\"golang-snappy\" path=\"godeps/src/github.com/golang/snappy\" remote=\"couchbasedeps\" revision=\"723cc1e459b8eea2dea4583200fd60757d40097a\"/>",
 "  <project name=\"goleveldb\" path=\"godeps/src/github.com/syndtr/goleveldb\" remote=\"couchbasedeps\" revision=\"fa5b5c78794bc5c18f330361059f871ae8c2b9d6\"/>",
 "  <project name=\"gomemcached\" path=\"godeps/src/github.com/couchbase/gomemcached\" revision=\"4604300463c4a379d36d1427b17d3284a93f7621\"/>",
 "  <project name=\"gometa\" path=\"goproj/src/github.com/couchbase/gometa\" revision=\"7da5634cce1de744293acf27bb2aecc13ee50cc5\"/>",
 "  <project groups=\"kv\" name=\"googletest\" remote=\"couchbasedeps\" revision=\"f397fa5ec6365329b2e82eb2d8c03a7897bbefb5\"/>",
 "  <project name=\"goskiplist\" path=\"godeps/src/github.com/ryszard/goskiplist\" remote=\"couchbasedeps\" revision=\"2dfbae5fcf46374f166f8969cb07e167f1be6273\"/>",
 "  <project name=\"gosnappy\" path=\"godeps/src/github.com/syndtr/gosnappy\" remote=\"couchbasedeps\" revision=\"156a073208e131d7d2e212cb749feae7c339e846\"/>",
 "  <project name=\"goutils\" path=\"godeps/src/github.com/couchbase/goutils\" revision=\"5823a0cbaaa9008406021dc5daf80125ea30bba6\"/>",
 "  <project name=\"goxdcr\" path=\"goproj/src/github.com/couchbase/goxdcr\" revision=\"0f66d74c38453d0c1a620588edb4ee6a8fc22577\"/>",
 "  <project name=\"gtreap\" path=\"godeps/src/github.com/steveyen/gtreap\" remote=\"couchbasedeps\" revision=\"0abe01ef9be25c4aedc174758ec2d917314d6d70\"/>",
 "  <project name=\"indexing\" path=\"goproj/src/github.com/couchbase/indexing\" revision=\"1811cdbff66216861320b7657590e961b10b2c0a\"/>",
 "  <project name=\"levigo\" path=\"godeps/src/github.com/jmhodges/levigo\" remote=\"couchbasedeps\" revision=\"1ddad808d437abb2b8a55a950ec2616caa88969b\"/>",
 "  <project name=\"liner\" path=\"godeps/src/github.com/peterh/liner\" remote=\"couchbasedeps\" revision=\"ad1edfd30321d8f006ccf05f1e0524adeb943060\"/>",
 "  <project name=\"liner\" path=\"godeps/src/github.com/sbinet/liner\" remote=\"couchbasedeps\" revision=\"d9335eee40a45a4f5d74524c90040d6fe6013d50\"/>",
 "  <project groups=\"kv\" name=\"memcached\" revision=\"45a464250e1358593fa9f11ec010ddd992f0a717\"/>",
 "  <project name=\"minify\" path=\"godeps/src/github.com/tdewolff/minify\" remote=\"couchbasedeps\" revision=\"ede45cc53f43891267b1fe7c689db9c76d4ce0fb\"/>",
 "  <project name=\"mmap-go\" path=\"godeps/src/github.com/edsrzf/mmap-go\" remote=\"couchbasedeps\" revision=\"935e0e8a636ca4ba70b713f3e38a19e1b77739e8\"/>",
 "  <project name=\"moss\" path=\"godeps/src/github.com/couchbase/moss\" revision=\"c7cc82a67cf3fe50faf9a0697516b885e4fa34b9\"/>",
 "  <project groups=\"kv\" name=\"moxi\" revision=\"363c250e6087a61bf2d4bc8d6eff3325956be731\"/>",
 "  <project name=\"mux\" path=\"godeps/src/github.com/gorilla/mux\" remote=\"couchbasedeps\" revision=\"8a875a034c69b940914d83ea03d3f1299b4d094b\"/>",
 "  <project name=\"net\" path=\"godeps/src/golang.org/x/net\" remote=\"couchbasedeps\" revision=\"8968c61983e8f51a91b8c0ef25bf739278c89634\"/>",
 "  <project name=\"npipe\" path=\"godeps/src/github.com/natefinch/npipe\" remote=\"couchbasedeps\" revision=\"272c8150302e83f23d32a355364578c9c13ab20f\"/>",
 "  <project name=\"ns_server\" revision=\"b6c99dc71308f44261bbcc80688de02942d69f19\"/>",
 "  <project name=\"parse\" path=\"godeps/src/github.com/tdewolff/parse\" remote=\"couchbasedeps\" revision=\"0334a869253aca4b3a10c56c3f3139b394aec3a9\"/>",
 "  <project groups=\"kv\" name=\"platform\" revision=\"a80097d53c779b548d8c78b0a1886b8d44591b23\"/>",
 "  <project name=\"protobuf\" path=\"godeps/src/github.com/golang/protobuf\" remote=\"couchbasedeps\" revision=\"655cdfa588ea190e901bc5590e65d5621688847c\"/>",
 "  <project name=\"query\" path=\"goproj/src/github.com/couchbase/query\" revision=\"2012f9b883199299df53dec638a2b91c21907a53\"/>",
 "  <project name=\"query-ui\" revision=\"ff1f502b2f0c544ca68d2bda60d80fc3a01d573a\"/>",
 "  <project name=\"retriever\" path=\"godeps/src/github.com/couchbase/retriever\" revision=\"e3419088e4d3b4fe3aad3b364fdbe9a154f85f17\"/>",
 "  <project name=\"segment\" path=\"godeps/src/github.com/blevesearch/segment\" remote=\"blevesearch\" revision=\"db70c57796cc8c310613541dfade3dce627d09c7\"/>",
 "  <project groups=\"kv\" name=\"sigar\" revision=\"83bd88595f558987731a1baa3330f641bc36554c\"/>",
 "  <project name=\"strconv\" path=\"godeps/src/github.com/tdewolff/strconv\" remote=\"couchbasedeps\" revision=\"9b189f5be77f33c46776f24dbddb2a7ab32af214\"/>",
 "  <project groups=\"kv\" name=\"subjson\" revision=\"65d3f053e2d968aea00b60234a42e1d1c5b9f6d2\"/>",
 "  <project groups=\"solaris,notdefault\" name=\"sys\" path=\"godeps/src/golang.org/x/sys\" remote=\"couchbasedeps\" revision=\"9d4e42a20653790449273b3c85e67d6d8bae6e2e\"/>",
 "  <project name=\"testrunner\" revision=\"d63ed33d4130ecac236711b4156d41328728e42e\"/>",
 "  <project name=\"text\" path=\"godeps/src/golang.org/x/text\" remote=\"couchbasedeps\" revision=\"601048ad6acbab6cedd582db09b8c4839ff25b15\"/>",
 "  <project groups=\"kv\" name=\"tlm\" revision=\"29fafd6b365e58e9fc43fad749ce20c900890a6b\">",
 "    <copyfile dest=\"GNUmakefile\" src=\"GNUmakefile\"/>",
 "    <copyfile dest=\"Makefile\" src=\"Makefile\"/>",
 "    <copyfile dest=\"CMakeLists.txt\" src=\"CMakeLists.txt\"/>",
 "  </project>",
 "  <project name=\"ts\" path=\"godeps/src/github.com/olekukonko/ts\" remote=\"couchbasedeps\" revision=\"ecf753e7c962639ab5a1fb46f7da627d4c0a04b8\"/>",
 "  <project groups=\"notdefault,packaging\" name=\"voltron\" remote=\"couchbase-priv\" revision=\"876e25cffb99e0ae89078a0443b179bcb5d639c2\"/>",
 "</manifest>"]

[error_logger:info,2021-04-19T19:45:43.805Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.129.0>},
                       {name,timeout_diag_logger},
                       {mfargs,{timeout_diag_logger,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:45:43.808Z,nonode@nohost:dist_manager<0.130.0>:dist_manager:read_address_config_from_path:86]Reading ip config from "/opt/couchbase/var/lib/couchbase/ip_start"
[ns_server:info,2021-04-19T19:45:43.809Z,nonode@nohost:dist_manager<0.130.0>:dist_manager:read_address_config_from_path:86]Reading ip config from "/opt/couchbase/var/lib/couchbase/ip"
[ns_server:info,2021-04-19T19:45:43.810Z,nonode@nohost:dist_manager<0.130.0>:dist_manager:init:163]ip config not found. Looks like we're brand new node
[error_logger:info,2021-04-19T19:45:43.811Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,inet_gethost_native_sup}
             started: [{pid,<0.132.0>},{mfa,{inet_gethost_native,init,[[]]}}]

[error_logger:info,2021-04-19T19:45:43.811Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.131.0>},
                       {name,inet_gethost_native_sup},
                       {mfargs,{inet_gethost_native,start_link,[]}},
                       {restart_type,temporary},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:45:44.597Z,nonode@nohost:dist_manager<0.130.0>:dist_manager:bringup:214]Attempting to bring up net_kernel with name 'ns_1@127.0.0.1'
[error_logger:info,2021-04-19T19:45:44.605Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.134.0>},
                       {name,erl_epmd},
                       {mfargs,{erl_epmd,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:44.606Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.135.0>},
                       {name,auth},
                       {mfargs,{auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:44.606Z,ns_1@127.0.0.1:dist_manager<0.130.0>:dist_manager:configure_net_kernel:255]Set net_kernel vebosity to 10 -> 0
[error_logger:info,2021-04-19T19:45:44.606Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.136.0>},
                       {name,net_kernel},
                       {mfargs,
                           {net_kernel,start_link,
                               [['ns_1@127.0.0.1',longnames]]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:44.606Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_sup}
             started: [{pid,<0.133.0>},
                       {name,net_sup_dynamic},
                       {mfargs,
                           {erl_distribution,start_link,
                               [['ns_1@127.0.0.1',longnames]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,supervisor}]

[ns_server:info,2021-04-19T19:45:44.609Z,ns_1@127.0.0.1:dist_manager<0.130.0>:dist_manager:save_node:147]saving node to "/opt/couchbase/var/lib/couchbase/couchbase-server.node"
[ns_server:debug,2021-04-19T19:45:44.624Z,ns_1@127.0.0.1:dist_manager<0.130.0>:dist_manager:bringup:228]Attempted to save node name to disk: ok
[ns_server:debug,2021-04-19T19:45:44.624Z,ns_1@127.0.0.1:dist_manager<0.130.0>:dist_manager:wait_for_node:235]Waiting for connection to node 'babysitter_of_ns_1@127.0.0.1' to be established
[error_logger:info,2021-04-19T19:45:44.624Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'babysitter_of_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:45:44.633Z,ns_1@127.0.0.1:dist_manager<0.130.0>:dist_manager:wait_for_node:244]Observed node 'babysitter_of_ns_1@127.0.0.1' to come up
[error_logger:info,2021-04-19T19:45:44.641Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.130.0>},
                       {name,dist_manager},
                       {mfargs,{dist_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:44.644Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.141.0>},
                       {name,ns_cookie_manager},
                       {mfargs,{ns_cookie_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:44.645Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.142.0>},
                       {name,ns_cluster},
                       {mfargs,{ns_cluster,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:45:44.647Z,ns_1@127.0.0.1:ns_config_sup<0.143.0>:ns_config_sup:init:32]loading static ns_config from "/opt/couchbase/etc/couchbase/config"
[error_logger:info,2021-04-19T19:45:44.647Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.144.0>},
                       {name,ns_config_events},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_config_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:44.647Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.145.0>},
                       {name,ns_config_events_local},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,ns_config_events_local}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:45:44.699Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_config:load_config:1083]Loading static config from "/opt/couchbase/etc/couchbase/config"
[ns_server:info,2021-04-19T19:45:44.706Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_config:load_config:1097]Loading dynamic config from "/opt/couchbase/var/lib/couchbase/config/config.dat"
[ns_server:info,2021-04-19T19:45:44.708Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_config:load_config:1102]No dynamic config file found. Assuming we're brand new node
[ns_server:debug,2021-04-19T19:45:44.711Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_config:load_config:1105]Here's full dynamic config we loaded:
[[]]
[ns_server:info,2021-04-19T19:45:44.714Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_config:load_config:1126]Here's full dynamic config we loaded + static & default config:
[{roles_definitions,
  [{admin,[],
    [{name,<<"Admin">>},
     {desc,<<"Can manage ALL cluster features including security.">>}],
    [{[],all}]},
   {ro_admin,[],
    [{name,<<"Read Only Admin">>},{desc,<<"Can view ALL cluster features.">>}],
    [{[{bucket,any},password],none},
     {[{bucket,any},data],none},
     {[admin,security],[read]},
     {[admin],none},
     {[],[read]}]},
   {cluster_admin,[],
    [{name,<<"Cluster Admin">>},
     {desc,<<"Can manage all cluster features EXCEPT security.">>}],
    [{[admin],none},{[],all}]},
   {bucket_admin,
    [bucket_name],
    [{name,<<"Bucket Admin">>},
     {desc,
      <<"Can manage ALL bucket features for specified buckets (incl. start/stop XDCR)">>}],
    [{[{bucket,bucket_name},xdcr],[read,execute]},
     {[{bucket,bucket_name}],all},
     {[{bucket,any},settings],[read]},
     {[{bucket,any}],none},
     {[xdcr],none},
     {[admin],none},
     {[],[read]}]},
   {bucket_sasl,
    [bucket_name],
    [],
    [{[{bucket,bucket_name},data],all},
     {[{bucket,bucket_name},views],all},
     {[{bucket,bucket_name}],[read,flush]},
     {[pools],[read]}]},
   {views_admin,
    [bucket_name],
    [{name,<<"Views Admin">>},
     {desc,<<"Can manage views for specified buckets">>}],
    [{[{bucket,bucket_name},views],all},
     {[{bucket,bucket_name},data],[read]},
     {[{bucket,any},settings],[read]},
     {[{bucket,any}],none},
     {[xdcr],none},
     {[admin],none},
     {[],[read]}]},
   {replication_admin,[],
    [{name,<<"Replication Admin">>},
     {desc,<<"Can manage ONLY XDCR features (cluster AND bucket level)">>}],
    [{[{bucket,any},xdcr],all},
     {[{bucket,any},data],[read]},
     {[{bucket,any},settings],[read]},
     {[{bucket,any}],none},
     {[xdcr],all},
     {[admin],none},
     {[],[read]}]}]},
 {drop_request_memory_threshold_mib,undefined},
 {{request_limit,capi},undefined},
 {{request_limit,rest},undefined},
 {auto_failover_cfg,[{enabled,false},{timeout,120},{max_nodes,1},{count,0}]},
 {replication,[{enabled,true}]},
 {alert_limits,
  [{max_overhead_perc,50},{max_disk_used,90},{max_indexer_ram,75}]},
 {email_alerts,
  [{recipients,["root@localhost"]},
   {sender,"couchbase@localhost"},
   {enabled,false},
   {email_server,
    [{user,[]},{pass,"*****"},{host,"localhost"},{port,25},{encrypt,false}]},
   {alerts,
    [auto_failover_node,auto_failover_maximum_reached,
     auto_failover_other_nodes_down,auto_failover_cluster_too_small,
     auto_failover_disabled,ip,disk,overhead,ep_oom_errors,
     ep_item_commit_failed,audit_dropped_events,indexer_ram_max_usage,
     ep_clock_cas_drift_threshold_exceeded]}]},
 {{node,'ns_1@127.0.0.1',ns_log},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
   {filename,"/opt/couchbase/var/lib/couchbase/ns_log"}]},
 {{node,'ns_1@127.0.0.1',port_servers},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}]},
 {{node,'ns_1@127.0.0.1',moxi},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
   {port,11211},
   {verbosity,[]}]},
 {buckets,[{configs,[]}]},
 {fts_memory_quota,512},
 {memory_quota,7582},
 {{node,'ns_1@127.0.0.1',memcached_config},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   {[{interfaces,
      {memcached_config_mgr,omit_missing_mcd_ports,
       [{[{host,<<"*">>},{port,port},{maxconn,maxconn}]},
        {[{host,<<"*">>},
          {port,dedicated_port},
          {maxconn,dedicated_port_maxconn}]},
        {[{host,<<"*">>},
          {port,ssl_port},
          {maxconn,maxconn},
          {ssl,
           {[{key,
              <<"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem">>},
             {cert,
              <<"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem">>}]}}]}]}},
     {ssl_cipher_list,{"~s",[ssl_cipher_list]}},
     {ssl_minimum_protocol,{memcached_config_mgr,ssl_minimum_protocol,[]}},
     {connection_idle_time,connection_idle_time},
     {breakpad,
      {[{enabled,breakpad_enabled},
        {minidump_dir,{memcached_config_mgr,get_minidump_dir,[]}}]}},
     {extensions,
      [{[{module,<<"/opt/couchbase/lib/memcached/stdin_term_handler.so">>},
         {config,<<>>}]},
       {[{module,<<"/opt/couchbase/lib/memcached/file_logger.so">>},
         {config,
          {"cyclesize=~B;sleeptime=~B;filename=~s/~s",
           [log_cyclesize,log_sleeptime,log_path,log_prefix]}}]}]},
     {admin,{"~s",[admin_user]}},
     {verbosity,verbosity},
     {audit_file,{"~s",[audit_file]}},
     {dedupe_nmvb_maps,dedupe_nmvb_maps}]}]},
 {{node,'ns_1@127.0.0.1',memcached},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
   {port,11210},
   {dedicated_port,11209},
   {ssl_port,11207},
   {admin_user,"_admin"},
   {admin_pass,"*****"},
   {engines,
    [{membase,
      [{engine,"/opt/couchbase/lib/memcached/ep.so"},
       {static_config_string,"failpartialwarmup=false"}]},
     {memcached,
      [{engine,"/opt/couchbase/lib/memcached/default_engine.so"},
       {static_config_string,"vb0=true"}]}]},
   {config_path,"/opt/couchbase/var/lib/couchbase/config/memcached.json"},
   {audit_file,"/opt/couchbase/var/lib/couchbase/config/audit.json"},
   {log_path,"/opt/couchbase/var/lib/couchbase/logs"},
   {log_prefix,"memcached.log"},
   {log_generations,20},
   {log_cyclesize,10485760},
   {log_sleeptime,19},
   {log_rotation_period,39003}]},
 {{node,'ns_1@127.0.0.1',memcached_defaults},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
   {maxconn,30000},
   {dedicated_port_maxconn,5000},
   {ssl_cipher_list,"HIGH"},
   {connection_idle_time,0},
   {verbosity,0},
   {breakpad_enabled,true},
   {breakpad_minidump_dir_path,"/opt/couchbase/var/lib/couchbase/crash"},
   {dedupe_nmvb_maps,false}]},
 {memcached,[]},
 {{node,'ns_1@127.0.0.1',audit},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}]},
 {audit,
  [{auditd_enabled,false},
   {rotate_interval,86400},
   {rotate_size,20971520},
   {disabled,[]},
   {sync,[]},
   {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]},
 {{node,'ns_1@127.0.0.1',isasl},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
   {path,"/opt/couchbase/var/lib/couchbase/isasl.pw"}]},
 {remote_clusters,[]},
 {rest_creds,[{creds,[]}]},
 {{node,'ns_1@127.0.0.1',ssl_proxy_upstream_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   11215]},
 {{node,'ns_1@127.0.0.1',ssl_proxy_downstream_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   11214]},
 {{node,'ns_1@127.0.0.1',fts_http_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   8094]},
 {{node,'ns_1@127.0.0.1',indexer_stmaint_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   9105]},
 {{node,'ns_1@127.0.0.1',indexer_stcatchup_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   9104]},
 {{node,'ns_1@127.0.0.1',indexer_stinit_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   9103]},
 {{node,'ns_1@127.0.0.1',indexer_http_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   9102]},
 {{node,'ns_1@127.0.0.1',indexer_scan_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   9101]},
 {{node,'ns_1@127.0.0.1',indexer_admin_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   9100]},
 {{node,'ns_1@127.0.0.1',xdcr_rest_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   9998]},
 {{node,'ns_1@127.0.0.1',projector_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   9999]},
 {{node,'ns_1@127.0.0.1',ssl_query_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   18093]},
 {{node,'ns_1@127.0.0.1',query_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   8093]},
 {{node,'ns_1@127.0.0.1',ssl_capi_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   18092]},
 {{node,'ns_1@127.0.0.1',capi_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   8092]},
 {{node,'ns_1@127.0.0.1',ssl_rest_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   18091]},
 {{node,'ns_1@127.0.0.1',rest},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
   {port,8091},
   {port_meta,global}]},
 {{couchdb,max_parallel_replica_indexers},2},
 {{couchdb,max_parallel_indexers},4},
 {rest,[{port,8091}]},
 {{node,'ns_1@127.0.0.1',membership},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   active]},
 {server_groups,
  [[{uuid,<<"0">>},{name,<<"Group 1">>},{nodes,['ns_1@127.0.0.1']}]]},
 {nodes_wanted,['ns_1@127.0.0.1']},
 {{node,'ns_1@127.0.0.1',compaction_daemon},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
   {check_interval,30},
   {min_db_file_size,131072},
   {min_view_file_size,20971520}]},
 {set_view_update_daemon,
  [{update_interval,5000},
   {update_min_changes,5000},
   {replica_update_min_changes,5000}]},
 {autocompaction,
  [{database_fragmentation_threshold,{30,undefined}},
   {view_fragmentation_threshold,{30,undefined}}]},
 {max_bucket_count,10},
 {index_aware_rebalance_disabled,false},
 {{node,'ns_1@127.0.0.1',ldap_enabled},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   true]},
 {{node,'ns_1@127.0.0.1',is_enterprise},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   true]},
 {{node,'ns_1@127.0.0.1',config_version},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   {4,5}]},
 {{node,'ns_1@127.0.0.1',uuid},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   <<"dbb8bee8b38705437e7f5ebc78107bfa">>]}]
[error_logger:info,2021-04-19T19:45:44.717Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.146.0>},
                       {name,ns_config},
                       {mfargs,
                           {ns_config,start_link,
                               ["/opt/couchbase/etc/couchbase/config",
                                ns_config_default]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:44.719Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.149.0>},
                       {name,ns_config_remote},
                       {mfargs,
                           {ns_config_replica,start_link,
                               [{local,ns_config_remote}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:44.723Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.150.0>},
                       {name,ns_config_log},
                       {mfargs,{ns_config_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:44.723Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.143.0>},
                       {name,ns_config_sup},
                       {mfargs,{ns_config_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:45:44.725Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.152.0>},
                       {name,vbucket_filter_changes_registry},
                       {mfargs,
                           {ns_process_registry,start_link,
                               [vbucket_filter_changes_registry,
                                [{terminate_command,shutdown}]]}},
                       {restart_type,permanent},
                       {shutdown,100},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:44.727Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.153.0>},
                       {name,json_rpc_connection_sup},
                       {mfargs,{json_rpc_connection_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:45:44.741Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.156.0>},
                       {name,remote_monitors},
                       {mfargs,{remote_monitors,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:44.743Z,ns_1@127.0.0.1:menelaus_barrier<0.157.0>:one_shot_barrier:barrier_body:58]Barrier menelaus_barrier has started
[error_logger:info,2021-04-19T19:45:44.744Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.157.0>},
                       {name,menelaus_barrier},
                       {mfargs,{menelaus_sup,barrier_start_link,[]}},
                       {restart_type,temporary},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:44.744Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.158.0>},
                       {name,rest_lhttpc_pool},
                       {mfargs,
                           {lhttpc_manager,start_link,
                               [[{name,rest_lhttpc_pool},
                                 {connection_timeout,120000},
                                 {pool_size,20}]]}},
                       {restart_type,{permanent,1}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:45:44.773Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.160.0>:ns_ssl_services_setup:init:370]Used ssl options:
[{keyfile,"/opt/couchbase/var/lib/couchbase/config/ssl-cert-key.pem"},
 {certfile,"/opt/couchbase/var/lib/couchbase/config/ssl-cert-key.pem"},
 {versions,[tlsv1,'tlsv1.1','tlsv1.2']},
 {cacertfile,undefined},
 {dh,<<48,130,1,8,2,130,1,1,0,152,202,99,248,92,201,35,238,246,5,77,93,120,10,
       118,129,36,52,111,193,167,220,49,229,106,105,152,133,121,157,73,158,
       232,153,197,197,21,171,140,30,207,52,165,45,8,221,162,21,199,183,66,
       211,247,51,224,102,214,190,130,96,253,218,193,35,43,139,145,89,200,250,
       145,92,50,80,134,135,188,205,254,148,122,136,237,220,186,147,187,104,
       159,36,147,217,117,74,35,163,145,249,175,242,18,221,124,54,140,16,246,
       169,84,252,45,47,99,136,30,60,189,203,61,86,225,117,255,4,91,46,110,
       167,173,106,51,65,10,248,94,225,223,73,40,232,140,26,11,67,170,118,190,
       67,31,127,233,39,68,88,132,171,224,62,187,207,160,189,209,101,74,8,205,
       174,146,173,80,105,144,246,25,153,86,36,24,178,163,64,202,221,95,184,
       110,244,32,226,217,34,55,188,230,55,16,216,247,173,246,139,76,187,66,
       211,159,17,46,20,18,48,80,27,250,96,189,29,214,234,241,34,69,254,147,
       103,220,133,40,164,84,8,44,241,61,164,151,9,135,41,60,75,4,202,133,173,
       72,6,69,167,89,112,174,40,229,171,2,1,2>>},
 {ciphers,[{dhe_rsa,aes_256_cbc,sha256},
           {dhe_dss,aes_256_cbc,sha256},
           {rsa,aes_256_cbc,sha256},
           {dhe_rsa,aes_128_cbc,sha256},
           {dhe_dss,aes_128_cbc,sha256},
           {rsa,aes_128_cbc,sha256},
           {dhe_rsa,aes_256_cbc,sha},
           {dhe_dss,aes_256_cbc,sha},
           {rsa,aes_256_cbc,sha},
           {dhe_rsa,'3des_ede_cbc',sha},
           {dhe_dss,'3des_ede_cbc',sha},
           {rsa,'3des_ede_cbc',sha},
           {dhe_rsa,aes_128_cbc,sha},
           {dhe_dss,aes_128_cbc,sha},
           {rsa,aes_128_cbc,sha}]}]
[ns_server:debug,2021-04-19T19:45:46.623Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.160.0>:ns_server_cert:generate_cert_and_pkey:78]Generated certificate and private key in 1846526 us
[ns_server:debug,2021-04-19T19:45:46.624Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
cert_and_pkey ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080746}}]}|
 {<<"-----BEGIN CERTIFICATE-----\nMIIDAjCCAeqgAwIBAgIIFndZ/+GzDYAwDQYJKoZIhvcNAQELBQAwJDEiMCAGA1UE\nAxMZQ291Y2hiYXNlIFNlcnZlciA4ODFmOWE4YzAeFw0xMzAxMDEwMDAwMDBaFw00\nOTEyMzEyMzU5NTlaMCQxIjAgBgNVBAMTGUNvdWNoYmFzZSBTZXJ2ZXIgODgxZjlh\nOGMwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCz0vvVTMTWH8JLsYfx\nMZ+egYFMFORYbynBjyuWB7+ltQbKZKtnruph7r3agBX8qzQLo1fbuaNJIkb2/TYZ\n7q61KM7aIxCPKBtKs0ms85z8gseSLb3"...>>,
  <<"*****">>}]
[ns_server:debug,2021-04-19T19:45:46.624Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{local_changes_count,<<"dbb8bee8b38705437e7f5ebc78107bfa">>} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080746}}]}]
[error_logger:info,2021-04-19T19:45:46.675Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_ssl_services_sup}
             started: [{pid,<0.160.0>},
                       {name,ns_ssl_services_setup},
                       {mfargs,{ns_ssl_services_setup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:45:46.706Z,ns_1@127.0.0.1:<0.165.0>:menelaus_pluggable_ui:validate_plugin_spec:117]Loaded pluggable UI specification for fts

[ns_server:info,2021-04-19T19:45:46.707Z,ns_1@127.0.0.1:<0.165.0>:menelaus_pluggable_ui:validate_plugin_spec:117]Loaded pluggable UI specification for n1ql

[ns_server:debug,2021-04-19T19:45:46.729Z,ns_1@127.0.0.1:<0.165.0>:restartable:start_child:98]Started child process <0.167.0>
  MFA: {ns_ssl_services_setup,start_link_rest_service,[]}
[error_logger:info,2021-04-19T19:45:46.730Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_ssl_services_sup}
             started: [{pid,<0.165.0>},
                       {name,ns_rest_ssl_service},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_ssl_services_setup,
                                    start_link_rest_service,[]},
                                1000]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:46.730Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.159.0>},
                       {name,ns_ssl_services_sup},
                       {mfargs,{ns_ssl_services_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2021-04-19T19:45:46.743Z,ns_1@127.0.0.1:wait_link_to_couchdb_node<0.185.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:126]Waiting for ns_couchdb node to start
[error_logger:info,2021-04-19T19:45:46.743Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.184.0>},
                       {name,start_couchdb_node},
                       {mfargs,{ns_server_nodes_sup,start_couchdb_node,[]}},
                       {restart_type,{permanent,5}},
                       {shutdown,86400000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:46.743Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:45:46.744Z,ns_1@127.0.0.1:<0.186.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:45:46.744Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.188.0>,shutdown}}
[error_logger:info,2021-04-19T19:45:46.744Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:45:46.945Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:45:46.946Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.191.0>,shutdown}}
[ns_server:debug,2021-04-19T19:45:46.946Z,ns_1@127.0.0.1:<0.186.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:45:46.946Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:45:47.147Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:45:47.147Z,ns_1@127.0.0.1:<0.186.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:45:47.147Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.194.0>,shutdown}}
[error_logger:info,2021-04-19T19:45:47.148Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:45:47.349Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:45:47.350Z,ns_1@127.0.0.1:<0.186.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:45:47.350Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.197.0>,shutdown}}
[error_logger:info,2021-04-19T19:45:47.350Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:45:47.551Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:45:47.552Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.200.0>,shutdown}}
[error_logger:info,2021-04-19T19:45:47.552Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:45:47.552Z,ns_1@127.0.0.1:<0.186.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:45:47.753Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:45:47.754Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.203.0>,shutdown}}
[ns_server:debug,2021-04-19T19:45:47.754Z,ns_1@127.0.0.1:<0.186.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:45:47.754Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:45:47.956Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:45:47.957Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.206.0>,shutdown}}
[error_logger:info,2021-04-19T19:45:47.957Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:45:47.958Z,ns_1@127.0.0.1:<0.186.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:45:48.159Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:45:48.160Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.209.0>,shutdown}}
[ns_server:debug,2021-04-19T19:45:48.160Z,ns_1@127.0.0.1:<0.186.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:45:48.160Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:45:48.361Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:45:48.362Z,ns_1@127.0.0.1:<0.186.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:45:48.362Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.212.0>,shutdown}}
[error_logger:info,2021-04-19T19:45:48.362Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:45:48.563Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:45:48.564Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.215.0>,shutdown}}
[ns_server:debug,2021-04-19T19:45:48.564Z,ns_1@127.0.0.1:<0.186.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:45:48.564Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:45:48.765Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:45:48.767Z,ns_1@127.0.0.1:<0.186.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:45:48.767Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.218.0>,shutdown}}
[error_logger:info,2021-04-19T19:45:48.768Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:45:48.969Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:45:48.969Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.221.0>,shutdown}}
[ns_server:debug,2021-04-19T19:45:48.969Z,ns_1@127.0.0.1:<0.186.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:45:48.970Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:45:49.171Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:45:49.172Z,ns_1@127.0.0.1:<0.186.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:45:49.172Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.224.0>,shutdown}}
[error_logger:info,2021-04-19T19:45:49.172Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:45:49.373Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:45:49.508Z,ns_1@127.0.0.1:<0.186.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:45:49.714Z,ns_1@127.0.0.1:<0.186.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:45:49.917Z,ns_1@127.0.0.1:<0.186.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:45:50.118Z,ns_1@127.0.0.1:<0.186.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:45:50.319Z,ns_1@127.0.0.1:<0.186.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:45:50.521Z,ns_1@127.0.0.1:<0.186.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:45:50.722Z,ns_1@127.0.0.1:<0.186.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:45:50.924Z,ns_1@127.0.0.1:<0.186.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:45:51.126Z,ns_1@127.0.0.1:<0.186.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:45:51.328Z,ns_1@127.0.0.1:<0.186.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:45:51.529Z,ns_1@127.0.0.1:<0.186.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[error_logger:info,2021-04-19T19:45:52.046Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.240.0>},
                       {name,timer2_server},
                       {mfargs,{timer2,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:45:52.247Z,ns_1@127.0.0.1:ns_couchdb_port<0.184.0>:ns_port_server:log:210]ns_couchdb<0.184.0>: Apache CouchDB  (LogLevel=info) is starting.

[error_logger:info,2021-04-19T19:45:52.681Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.185.0>},
                       {name,wait_for_couchdb_node},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<ns_server_nodes_sup.0.8580514>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:52.690Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.155.0>:ns_storage_conf:setup_db_and_ix_paths:53]Initialize db_and_ix_paths variable with [{db_path,
                                           "/opt/couchbase/var/lib/couchbase/data"},
                                          {index_path,
                                           "/opt/couchbase/var/lib/couchbase/data"}]
[error_logger:info,2021-04-19T19:45:52.707Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.243.0>},
                       {name,ns_disksup},
                       {mfargs,{ns_disksup,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:52.711Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.244.0>},
                       {name,diag_handler_worker},
                       {mfargs,{work_queue,start_link,[diag_handler_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:45:52.713Z,ns_1@127.0.0.1:ns_couchdb_port<0.184.0>:ns_port_server:log:210]ns_couchdb<0.184.0>: Apache CouchDB has started. Time to relax.
ns_couchdb<0.184.0>: 145: Booted. Waiting for shutdown request

[ns_server:info,2021-04-19T19:45:52.715Z,ns_1@127.0.0.1:ns_server_sup<0.242.0>:dir_size:start_link:39]Starting quick version of dir_size with program name: godu
[error_logger:info,2021-04-19T19:45:52.717Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.245.0>},
                       {name,dir_size},
                       {mfargs,{dir_size,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:52.722Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.246.0>},
                       {name,request_throttler},
                       {mfargs,{request_throttler,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:warn,2021-04-19T19:45:52.737Z,ns_1@127.0.0.1:ns_log<0.247.0>:ns_log:read_logs:128]Couldn't load logs from "/opt/couchbase/var/lib/couchbase/ns_log" (perhaps it's first startup): {error,
                                                                                                 enoent}
[error_logger:info,2021-04-19T19:45:52.739Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.247.0>},
                       {name,ns_log},
                       {mfargs,{ns_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:52.741Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.248.0>},
                       {name,ns_crash_log_consumer},
                       {mfargs,{ns_log,start_link_crash_consumer,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:52.760Z,ns_1@127.0.0.1:ns_config_isasl_sync<0.249.0>:ns_config_isasl_sync:init:65]isasl_sync init: ["/opt/couchbase/var/lib/couchbase/isasl.pw","_admin"]
[ns_server:debug,2021-04-19T19:45:52.760Z,ns_1@127.0.0.1:ns_config_isasl_sync<0.249.0>:ns_config_isasl_sync:init:73]isasl_sync init buckets: []
[ns_server:debug,2021-04-19T19:45:52.762Z,ns_1@127.0.0.1:ns_config_isasl_sync<0.249.0>:ns_config_isasl_sync:writeSASLConf:145]Writing isasl passwd file: "/opt/couchbase/var/lib/couchbase/isasl.pw"
[ns_server:warn,2021-04-19T19:45:52.796Z,ns_1@127.0.0.1:ns_config_isasl_sync<0.249.0>:ns_memcached:connect:1307]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[error_logger:info,2021-04-19T19:45:53.797Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.249.0>},
                       {name,ns_config_isasl_sync},
                       {mfargs,{ns_config_isasl_sync,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:53.797Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.251.0>},
                       {name,ns_log_events},
                       {mfargs,{gen_event,start_link,[{local,ns_log_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:53.800Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.253.0>},
                       {name,ns_node_disco_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,ns_node_disco_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:53.801Z,ns_1@127.0.0.1:ns_node_disco<0.254.0>:ns_node_disco:init:138]Initting ns_node_disco with []
[ns_server:debug,2021-04-19T19:45:53.801Z,ns_1@127.0.0.1:ns_cookie_manager<0.141.0>:ns_cookie_manager:do_cookie_sync:115]ns_cookie_manager do_cookie_sync
[user:info,2021-04-19T19:45:53.801Z,ns_1@127.0.0.1:ns_cookie_manager<0.141.0>:ns_cookie_manager:do_cookie_init:93]Initial otp cookie generated: {sanitized,
                                  <<"Gldz+3QHYFD9UMWZ6D/7VCdFO4es4rvk9HPUTz5soFw=">>}
[ns_server:debug,2021-04-19T19:45:53.802Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{local_changes_count,<<"dbb8bee8b38705437e7f5ebc78107bfa">>} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{2,63786080753}}]}]
[ns_server:debug,2021-04-19T19:45:53.802Z,ns_1@127.0.0.1:<0.255.0>:ns_node_disco:do_nodes_wanted_updated_fun:224]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"Gldz+3QHYFD9UMWZ6D/7VCdFO4es4rvk9HPUTz5soFw=">>}
[ns_server:debug,2021-04-19T19:45:53.802Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
otp ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080753}}]},
 {cookie,{sanitized,<<"Gldz+3QHYFD9UMWZ6D/7VCdFO4es4rvk9HPUTz5soFw=">>}}]
[ns_server:debug,2021-04-19T19:45:53.807Z,ns_1@127.0.0.1:<0.255.0>:ns_node_disco:do_nodes_wanted_updated_fun:230]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"Gldz+3QHYFD9UMWZ6D/7VCdFO4es4rvk9HPUTz5soFw=">>}
[error_logger:info,2021-04-19T19:45:53.807Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.254.0>},
                       {name,ns_node_disco},
                       {mfargs,{ns_node_disco,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:53.818Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.257.0>},
                       {name,ns_node_disco_log},
                       {mfargs,{ns_node_disco_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:53.822Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.258.0>},
                       {name,ns_node_disco_conf_events},
                       {mfargs,{ns_node_disco_conf_events,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:53.830Z,ns_1@127.0.0.1:ns_config_rep<0.260.0>:ns_config_rep:init:68]init pulling
[ns_server:debug,2021-04-19T19:45:53.831Z,ns_1@127.0.0.1:ns_config_rep<0.260.0>:ns_config_rep:init:70]init pushing
[error_logger:info,2021-04-19T19:45:53.830Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.259.0>},
                       {name,ns_config_rep_merger},
                       {mfargs,{ns_config_rep,start_link_merger,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:53.832Z,ns_1@127.0.0.1:ns_config_rep<0.260.0>:ns_config_rep:init:74]init reannouncing
[ns_server:debug,2021-04-19T19:45:53.832Z,ns_1@127.0.0.1:ns_config_events<0.144.0>:ns_node_disco_conf_events:handle_event:50]ns_node_disco_conf_events config on otp
[ns_server:debug,2021-04-19T19:45:53.832Z,ns_1@127.0.0.1:ns_config_events<0.144.0>:ns_node_disco_conf_events:handle_event:44]ns_node_disco_conf_events config on nodes_wanted
[ns_server:debug,2021-04-19T19:45:53.832Z,ns_1@127.0.0.1:ns_cookie_manager<0.141.0>:ns_cookie_manager:do_cookie_sync:115]ns_cookie_manager do_cookie_sync
[ns_server:debug,2021-04-19T19:45:53.832Z,ns_1@127.0.0.1:ns_cookie_manager<0.141.0>:ns_cookie_manager:do_cookie_sync:115]ns_cookie_manager do_cookie_sync
[ns_server:debug,2021-04-19T19:45:53.832Z,ns_1@127.0.0.1:<0.264.0>:ns_node_disco:do_nodes_wanted_updated_fun:224]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"Gldz+3QHYFD9UMWZ6D/7VCdFO4es4rvk9HPUTz5soFw=">>}
[ns_server:debug,2021-04-19T19:45:53.832Z,ns_1@127.0.0.1:<0.265.0>:ns_node_disco:do_nodes_wanted_updated_fun:224]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"Gldz+3QHYFD9UMWZ6D/7VCdFO4es4rvk9HPUTz5soFw=">>}
[ns_server:debug,2021-04-19T19:45:53.832Z,ns_1@127.0.0.1:<0.264.0>:ns_node_disco:do_nodes_wanted_updated_fun:230]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"Gldz+3QHYFD9UMWZ6D/7VCdFO4es4rvk9HPUTz5soFw=">>}
[ns_server:debug,2021-04-19T19:45:53.832Z,ns_1@127.0.0.1:<0.265.0>:ns_node_disco:do_nodes_wanted_updated_fun:230]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"Gldz+3QHYFD9UMWZ6D/7VCdFO4es4rvk9HPUTz5soFw=">>}
[ns_server:debug,2021-04-19T19:45:53.832Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
otp ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080753}}]},
 {cookie,{sanitized,<<"Gldz+3QHYFD9UMWZ6D/7VCdFO4es4rvk9HPUTz5soFw=">>}}]
[ns_server:debug,2021-04-19T19:45:53.833Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
cert_and_pkey ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080746}}]}|
 {<<"-----BEGIN CERTIFICATE-----\nMIIDAjCCAeqgAwIBAgIIFndZ/+GzDYAwDQYJKoZIhvcNAQELBQAwJDEiMCAGA1UE\nAxMZQ291Y2hiYXNlIFNlcnZlciA4ODFmOWE4YzAeFw0xMzAxMDEwMDAwMDBaFw00\nOTEyMzEyMzU5NTlaMCQxIjAgBgNVBAMTGUNvdWNoYmFzZSBTZXJ2ZXIgODgxZjlh\nOGMwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCz0vvVTMTWH8JLsYfx\nMZ+egYFMFORYbynBjyuWB7+ltQbKZKtnruph7r3agBX8qzQLo1fbuaNJIkb2/TYZ\n7q61KM7aIxCPKBtKs0ms85z8gseSLb3"...>>,
  <<"*****">>}]
[ns_server:debug,2021-04-19T19:45:53.833Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
alert_limits ->
[{max_overhead_perc,50},{max_disk_used,90},{max_indexer_ram,75}]
[ns_server:debug,2021-04-19T19:45:53.833Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
audit ->
[{auditd_enabled,false},
 {rotate_interval,86400},
 {rotate_size,20971520},
 {disabled,[]},
 {sync,[]},
 {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]
[ns_server:debug,2021-04-19T19:45:53.834Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
auto_failover_cfg ->
[{enabled,false},{timeout,120},{max_nodes,1},{count,0}]
[ns_server:debug,2021-04-19T19:45:53.834Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
autocompaction ->
[{database_fragmentation_threshold,{30,undefined}},
 {view_fragmentation_threshold,{30,undefined}}]
[ns_server:debug,2021-04-19T19:45:53.834Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
buckets ->
[[],{configs,[]}]
[ns_server:debug,2021-04-19T19:45:53.834Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
drop_request_memory_threshold_mib ->
undefined
[ns_server:debug,2021-04-19T19:45:53.834Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
email_alerts ->
[{recipients,["root@localhost"]},
 {sender,"couchbase@localhost"},
 {enabled,false},
 {email_server,[{user,[]},
                {pass,"*****"},
                {host,"localhost"},
                {port,25},
                {encrypt,false}]},
 {alerts,[auto_failover_node,auto_failover_maximum_reached,
          auto_failover_other_nodes_down,auto_failover_cluster_too_small,
          auto_failover_disabled,ip,disk,overhead,ep_oom_errors,
          ep_item_commit_failed,audit_dropped_events,indexer_ram_max_usage,
          ep_clock_cas_drift_threshold_exceeded]}]
[ns_server:debug,2021-04-19T19:45:53.834Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
fts_memory_quota ->
512
[ns_server:debug,2021-04-19T19:45:53.834Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
index_aware_rebalance_disabled ->
false
[ns_server:debug,2021-04-19T19:45:53.834Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
max_bucket_count ->
10
[ns_server:debug,2021-04-19T19:45:53.835Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
memcached ->
[]
[ns_server:debug,2021-04-19T19:45:53.835Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
memory_quota ->
7582
[ns_server:debug,2021-04-19T19:45:53.835Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
nodes_wanted ->
['ns_1@127.0.0.1']
[ns_server:debug,2021-04-19T19:45:53.835Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
remote_clusters ->
[]
[ns_server:debug,2021-04-19T19:45:53.835Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
replication ->
[{enabled,true}]
[error_logger:info,2021-04-19T19:45:53.835Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.260.0>},
                       {name,ns_config_rep},
                       {mfargs,{ns_config_rep,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:53.835Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
rest ->
[{port,8091}]
[error_logger:info,2021-04-19T19:45:53.835Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.252.0>},
                       {name,ns_node_disco_sup},
                       {mfargs,{ns_node_disco_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2021-04-19T19:45:53.835Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
rest_creds ->
[{creds,[]}]
[ns_server:debug,2021-04-19T19:45:53.835Z,ns_1@127.0.0.1:ns_config_rep<0.260.0>:ns_config_rep:do_push_keys:321]Replicating some config keys ([alert_limits,audit,auto_failover_cfg,
                               autocompaction,buckets,cert_and_pkey,
                               drop_request_memory_threshold_mib,email_alerts,
                               fts_memory_quota,
                               index_aware_rebalance_disabled,
                               max_bucket_count,memcached,memory_quota,
                               nodes_wanted,otp,remote_clusters,replication,
                               rest,rest_creds,roles_definitions,
                               server_groups,set_view_update_daemon,
                               {couchdb,max_parallel_indexers},
                               {couchdb,max_parallel_replica_indexers},
                               {local_changes_count,
                                   <<"dbb8bee8b38705437e7f5ebc78107bfa">>},
                               {request_limit,capi},
                               {request_limit,rest},
                               {node,'ns_1@127.0.0.1',audit},
                               {node,'ns_1@127.0.0.1',capi_port},
                               {node,'ns_1@127.0.0.1',compaction_daemon},
                               {node,'ns_1@127.0.0.1',config_version},
                               {node,'ns_1@127.0.0.1',fts_http_port},
                               {node,'ns_1@127.0.0.1',indexer_admin_port},
                               {node,'ns_1@127.0.0.1',indexer_http_port},
                               {node,'ns_1@127.0.0.1',indexer_scan_port},
                               {node,'ns_1@127.0.0.1',indexer_stcatchup_port},
                               {node,'ns_1@127.0.0.1',indexer_stinit_port},
                               {node,'ns_1@127.0.0.1',indexer_stmaint_port},
                               {node,'ns_1@127.0.0.1',is_enterprise},
                               {node,'ns_1@127.0.0.1',isasl},
                               {node,'ns_1@127.0.0.1',ldap_enabled},
                               {node,'ns_1@127.0.0.1',membership},
                               {node,'ns_1@127.0.0.1',memcached},
                               {node,'ns_1@127.0.0.1',memcached_config},
                               {node,'ns_1@127.0.0.1',memcached_defaults},
                               {node,'ns_1@127.0.0.1',moxi},
                               {node,'ns_1@127.0.0.1',ns_log},
                               {node,'ns_1@127.0.0.1',port_servers},
                               {node,'ns_1@127.0.0.1',projector_port},
                               {node,'ns_1@127.0.0.1',query_port},
                               {node,'ns_1@127.0.0.1',rest},
                               {node,'ns_1@127.0.0.1',ssl_capi_port},
                               {node,'ns_1@127.0.0.1',
                                   ssl_proxy_downstream_port},
                               {node,'ns_1@127.0.0.1',ssl_proxy_upstream_port},
                               {node,'ns_1@127.0.0.1',ssl_query_port},
                               {node,'ns_1@127.0.0.1',ssl_rest_port},
                               {node,'ns_1@127.0.0.1',uuid},
                               {node,'ns_1@127.0.0.1',xdcr_rest_port}]..)
[ns_server:debug,2021-04-19T19:45:53.836Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
roles_definitions ->
[{admin,[],
        [{name,<<"Admin">>},
         {desc,<<"Can manage ALL cluster features including security.">>}],
        [{[],all}]},
 {ro_admin,[],
           [{name,<<"Read Only Admin">>},
            {desc,<<"Can view ALL cluster features.">>}],
           [{[{bucket,any},password],none},
            {[{bucket,any},data],none},
            {[admin,security],[read]},
            {[admin],none},
            {[],[read]}]},
 {cluster_admin,[],
                [{name,<<"Cluster Admin">>},
                 {desc,<<"Can manage all cluster features EXCEPT security.">>}],
                [{[admin],none},{[],all}]},
 {bucket_admin,[bucket_name],
               [{name,<<"Bucket Admin">>},
                {desc,<<"Can manage ALL bucket features for specified buckets (incl. start/stop XDCR)">>}],
               [{[{bucket,bucket_name},xdcr],[read,execute]},
                {[{bucket,bucket_name}],all},
                {[{bucket,any},settings],[read]},
                {[{bucket,any}],none},
                {[xdcr],none},
                {[admin],none},
                {[],[read]}]},
 {bucket_sasl,[bucket_name],
              [],
              [{[{bucket,bucket_name},data],all},
               {[{bucket,bucket_name},views],all},
               {[{bucket,bucket_name}],[read,flush]},
               {[pools],[read]}]},
 {views_admin,[bucket_name],
              [{name,<<"Views Admin">>},
               {desc,<<"Can manage views for specified buckets">>}],
              [{[{bucket,bucket_name},views],all},
               {[{bucket,bucket_name},data],[read]},
               {[{bucket,any},settings],[read]},
               {[{bucket,any}],none},
               {[xdcr],none},
               {[admin],none},
               {[],[read]}]},
 {replication_admin,[],
                    [{name,<<"Replication Admin">>},
                     {desc,<<"Can manage ONLY XDCR features (cluster AND bucket level)">>}],
                    [{[{bucket,any},xdcr],all},
                     {[{bucket,any},data],[read]},
                     {[{bucket,any},settings],[read]},
                     {[{bucket,any}],none},
                     {[xdcr],all},
                     {[admin],none},
                     {[],[read]}]}]
[ns_server:debug,2021-04-19T19:45:53.837Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
server_groups ->
[[{uuid,<<"0">>},{name,<<"Group 1">>},{nodes,['ns_1@127.0.0.1']}]]
[ns_server:debug,2021-04-19T19:45:53.837Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
set_view_update_daemon ->
[{update_interval,5000},
 {update_min_changes,5000},
 {replica_update_min_changes,5000}]
[ns_server:debug,2021-04-19T19:45:53.837Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{couchdb,max_parallel_indexers} ->
4
[ns_server:debug,2021-04-19T19:45:53.837Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{couchdb,max_parallel_replica_indexers} ->
2
[ns_server:debug,2021-04-19T19:45:53.837Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{request_limit,capi} ->
undefined
[ns_server:debug,2021-04-19T19:45:53.838Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{request_limit,rest} ->
undefined
[ns_server:debug,2021-04-19T19:45:53.838Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',audit} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}]
[ns_server:debug,2021-04-19T19:45:53.838Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',capi_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|8092]
[ns_server:debug,2021-04-19T19:45:53.838Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',compaction_daemon} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
 {check_interval,30},
 {min_db_file_size,131072},
 {min_view_file_size,20971520}]
[ns_server:debug,2021-04-19T19:45:53.839Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',config_version} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|{4,5}]
[ns_server:debug,2021-04-19T19:45:53.839Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',fts_http_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|8094]
[ns_server:debug,2021-04-19T19:45:53.839Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',indexer_admin_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|9100]
[ns_server:debug,2021-04-19T19:45:53.839Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',indexer_http_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|9102]
[ns_server:debug,2021-04-19T19:45:53.839Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',indexer_scan_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|9101]
[ns_server:debug,2021-04-19T19:45:53.839Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',indexer_stcatchup_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|9104]
[error_logger:info,2021-04-19T19:45:53.839Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.268.0>},
                       {name,vbucket_map_mirror},
                       {mfargs,{vbucket_map_mirror,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:53.839Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',indexer_stinit_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|9103]
[ns_server:debug,2021-04-19T19:45:53.840Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',indexer_stmaint_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|9105]
[ns_server:debug,2021-04-19T19:45:53.840Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',is_enterprise} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|true]
[ns_server:debug,2021-04-19T19:45:53.840Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',isasl} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
 {path,"/opt/couchbase/var/lib/couchbase/isasl.pw"}]
[ns_server:debug,2021-04-19T19:45:53.840Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ldap_enabled} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|true]
[ns_server:debug,2021-04-19T19:45:53.841Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',membership} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
 active]
[ns_server:debug,2021-04-19T19:45:53.841Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',memcached} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
 {port,11210},
 {dedicated_port,11209},
 {ssl_port,11207},
 {admin_user,"_admin"},
 {admin_pass,"*****"},
 {engines,[{membase,[{engine,"/opt/couchbase/lib/memcached/ep.so"},
                     {static_config_string,"failpartialwarmup=false"}]},
           {memcached,[{engine,"/opt/couchbase/lib/memcached/default_engine.so"},
                       {static_config_string,"vb0=true"}]}]},
 {config_path,"/opt/couchbase/var/lib/couchbase/config/memcached.json"},
 {audit_file,"/opt/couchbase/var/lib/couchbase/config/audit.json"},
 {log_path,"/opt/couchbase/var/lib/couchbase/logs"},
 {log_prefix,"memcached.log"},
 {log_generations,20},
 {log_cyclesize,10485760},
 {log_sleeptime,19},
 {log_rotation_period,39003}]
[ns_server:debug,2021-04-19T19:45:53.842Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',memcached_config} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
 {[{interfaces,
    {memcached_config_mgr,omit_missing_mcd_ports,
     [{[{host,<<"*">>},{port,port},{maxconn,maxconn}]},
      {[{host,<<"*">>},
        {port,dedicated_port},
        {maxconn,dedicated_port_maxconn}]},
      {[{host,<<"*">>},
        {port,ssl_port},
        {maxconn,maxconn},
        {ssl,
         {[{key,
            <<"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem">>},
           {cert,
            <<"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem">>}]}}]}]}},
   {ssl_cipher_list,{"~s",[ssl_cipher_list]}},
   {ssl_minimum_protocol,{memcached_config_mgr,ssl_minimum_protocol,[]}},
   {connection_idle_time,connection_idle_time},
   {breakpad,
    {[{enabled,breakpad_enabled},
      {minidump_dir,{memcached_config_mgr,get_minidump_dir,[]}}]}},
   {extensions,
    [{[{module,<<"/opt/couchbase/lib/memcached/stdin_term_handler.so">>},
       {config,<<>>}]},
     {[{module,<<"/opt/couchbase/lib/memcached/file_logger.so">>},
       {config,
        {"cyclesize=~B;sleeptime=~B;filename=~s/~s",
         [log_cyclesize,log_sleeptime,log_path,log_prefix]}}]}]},
   {admin,{"~s",[admin_user]}},
   {verbosity,verbosity},
   {audit_file,{"~s",[audit_file]}},
   {dedupe_nmvb_maps,dedupe_nmvb_maps}]}]
[ns_server:debug,2021-04-19T19:45:53.842Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',memcached_defaults} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
 {maxconn,30000},
 {dedicated_port_maxconn,5000},
 {ssl_cipher_list,"HIGH"},
 {connection_idle_time,0},
 {verbosity,0},
 {breakpad_enabled,true},
 {breakpad_minidump_dir_path,"/opt/couchbase/var/lib/couchbase/crash"},
 {dedupe_nmvb_maps,false}]
[ns_server:debug,2021-04-19T19:45:53.842Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',moxi} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
 {port,11211},
 {verbosity,[]}]
[ns_server:debug,2021-04-19T19:45:53.842Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ns_log} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
 {filename,"/opt/couchbase/var/lib/couchbase/ns_log"}]
[ns_server:debug,2021-04-19T19:45:53.843Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',port_servers} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}]
[ns_server:debug,2021-04-19T19:45:53.843Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',projector_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|9999]
[ns_server:debug,2021-04-19T19:45:53.843Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',query_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|8093]
[ns_server:debug,2021-04-19T19:45:53.843Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',rest} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
 {port,8091},
 {port_meta,global}]
[ns_server:debug,2021-04-19T19:45:53.843Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ssl_capi_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|18092]
[ns_server:debug,2021-04-19T19:45:53.843Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ssl_proxy_downstream_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|11214]
[ns_server:debug,2021-04-19T19:45:53.843Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ssl_proxy_upstream_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|11215]
[ns_server:debug,2021-04-19T19:45:53.843Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ssl_query_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|18093]
[ns_server:debug,2021-04-19T19:45:53.843Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ssl_rest_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|18091]
[ns_server:debug,2021-04-19T19:45:53.843Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',uuid} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
 <<"dbb8bee8b38705437e7f5ebc78107bfa">>]
[ns_server:debug,2021-04-19T19:45:53.843Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',xdcr_rest_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|9998]
[ns_server:debug,2021-04-19T19:45:53.844Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{local_changes_count,<<"dbb8bee8b38705437e7f5ebc78107bfa">>} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{2,63786080753}}]}]
[error_logger:info,2021-04-19T19:45:53.846Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.270.0>},
                       {name,bucket_info_cache},
                       {mfargs,{bucket_info_cache,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:53.846Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.273.0>},
                       {name,ns_tick_event},
                       {mfargs,{gen_event,start_link,[{local,ns_tick_event}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:53.847Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.274.0>},
                       {name,buckets_events},
                       {mfargs,
                           {gen_event,start_link,[{local,buckets_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:53.852Z,ns_1@127.0.0.1:ns_log_events<0.251.0>:ns_mail_log:init:44]ns_mail_log started up
[error_logger:info,2021-04-19T19:45:53.852Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_mail_sup}
             started: [{pid,<0.276.0>},
                       {name,ns_mail_log},
                       {mfargs,{ns_mail_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:53.852Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.275.0>},
                       {name,ns_mail_sup},
                       {mfargs,{ns_mail_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:45:53.852Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.277.0>},
                       {name,ns_stats_event},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_stats_event}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:53.854Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.278.0>},
                       {name,samples_loader_tasks},
                       {mfargs,{samples_loader_tasks,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:53.861Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_heart_sup}
             started: [{pid,<0.280.0>},
                       {name,ns_heart},
                       {mfargs,{ns_heart,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:53.861Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_heart_sup}
             started: [{pid,<0.282.0>},
                       {name,ns_heart_slow_updater},
                       {mfargs,{ns_heart,start_link_slow_updater,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:53.862Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.279.0>},
                       {name,ns_heart_sup},
                       {mfargs,{ns_heart_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:45:53.864Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_doctor_sup}
             started: [{pid,<0.286.0>},
                       {name,ns_doctor_events},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_doctor_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:53.868Z,ns_1@127.0.0.1:ns_heart<0.280.0>:ns_heart:grab_latest_stats:259]Ignoring failure to grab "@system" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,117}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,255}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,249}]},
                 {ns_heart,update_current_status,1,
                           [{file,"src/ns_heart.erl"},{line,186}]},
                 {ns_heart,handle_info,2,
                           [{file,"src/ns_heart.erl"},{line,118}]}]}}

[ns_server:debug,2021-04-19T19:45:53.869Z,ns_1@127.0.0.1:ns_heart<0.280.0>:ns_heart:grab_latest_stats:259]Ignoring failure to grab "@system-processes" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-processes-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,117}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,255}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,249}]},
                 {ns_heart,update_current_status,1,
                           [{file,"src/ns_heart.erl"},{line,186}]}]}}

[error_logger:info,2021-04-19T19:45:53.874Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_doctor_sup}
             started: [{pid,<0.287.0>},
                       {name,ns_doctor},
                       {mfargs,{ns_doctor,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:53.874Z,ns_1@127.0.0.1:<0.283.0>:restartable:start_child:98]Started child process <0.285.0>
  MFA: {ns_doctor_sup,start_link,[]}
[error_logger:info,2021-04-19T19:45:53.874Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.283.0>},
                       {name,ns_doctor_sup},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_doctor_sup,start_link,[]},infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:45:53.888Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.290.0>},
                       {name,remote_clusters_info},
                       {mfargs,{remote_clusters_info,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:53.888Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.291.0>},
                       {name,master_activity_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,master_activity_events}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:53.894Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.293.0>},
                       {name,xdcr_ckpt_store},
                       {mfargs,{simple_store,start_link,[xdcr_ckpt_data]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:53.895Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.294.0>},
                       {name,metakv_worker},
                       {mfargs,{work_queue,start_link,[metakv_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:53.895Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.295.0>},
                       {name,index_events},
                       {mfargs,{gen_event,start_link,[{local,index_events}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:53.900Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.296.0>},
                       {name,index_settings_manager},
                       {mfargs,{index_settings_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:53.904Z,ns_1@127.0.0.1:ns_heart<0.280.0>:ns_heart:grab_local_xdcr_replications:460]Ignoring exception getting xdcr replication infos
{exit,{noproc,{gen_server,call,[xdc_replication_sup,which_children,infinity]}},
      [{gen_server,call,3,[{file,"gen_server.erl"},{line,188}]},
       {xdc_replication_sup,all_local_replication_infos,0,
                            [{file,"src/xdc_replication_sup.erl"},{line,58}]},
       {ns_heart,grab_local_xdcr_replications,0,
                 [{file,"src/ns_heart.erl"},{line,439}]},
       {ns_heart,current_status_slow_inner,0,
                 [{file,"src/ns_heart.erl"},{line,317}]},
       {ns_heart,current_status_slow,1,[{file,"src/ns_heart.erl"},{line,249}]},
       {ns_heart,update_current_status,1,
                 [{file,"src/ns_heart.erl"},{line,186}]},
       {ns_heart,handle_info,2,[{file,"src/ns_heart.erl"},{line,118}]},
       {gen_server,handle_msg,5,[{file,"gen_server.erl"},{line,604}]}]}
[error_logger:info,2021-04-19T19:45:53.907Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.299.0>},
                       {name,menelaus_ui_auth},
                       {mfargs,{menelaus_ui_auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:53.910Z,ns_1@127.0.0.1:ns_heart<0.280.0>:cluster_logs_collection_task:maybe_build_cluster_logs_task:43]Ignoring exception trying to read cluster_logs_collection_task_status table: error:badarg
[error_logger:info,2021-04-19T19:45:53.912Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.302.0>},
                       {name,menelaus_local_auth},
                       {mfargs,{menelaus_local_auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:53.917Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.303.0>},
                       {name,menelaus_web_cache},
                       {mfargs,{menelaus_web_cache,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:53.924Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.304.0>},
                       {name,menelaus_stats_gatherer},
                       {mfargs,{menelaus_stats_gatherer,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:53.924Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.305.0>},
                       {name,json_rpc_events},
                       {mfargs,
                           {gen_event,start_link,[{local,json_rpc_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:53.928Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.282.0>:ns_heart:grab_latest_stats:259]Ignoring failure to grab "@system" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,117}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,255}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,249}]},
                 {ns_heart,slow_updater_loop,0,
                           [{file,"src/ns_heart.erl"},{line,243}]},
                 {proc_lib,init_p_do_apply,3,
                           [{file,"proc_lib.erl"},{line,239}]}]}}

[ns_server:info,2021-04-19T19:45:53.928Z,ns_1@127.0.0.1:menelaus_sup<0.298.0>:menelaus_pluggable_ui:validate_plugin_spec:117]Loaded pluggable UI specification for fts

[ns_server:debug,2021-04-19T19:45:53.928Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.282.0>:ns_heart:grab_latest_stats:259]Ignoring failure to grab "@system-processes" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-processes-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,117}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,255}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,249}]},
                 {ns_heart,slow_updater_loop,0,
                           [{file,"src/ns_heart.erl"},{line,243}]}]}}

[ns_server:info,2021-04-19T19:45:53.929Z,ns_1@127.0.0.1:menelaus_sup<0.298.0>:menelaus_pluggable_ui:validate_plugin_spec:117]Loaded pluggable UI specification for n1ql

[ns_server:debug,2021-04-19T19:45:53.929Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.282.0>:ns_heart:grab_local_xdcr_replications:460]Ignoring exception getting xdcr replication infos
{exit,{noproc,{gen_server,call,[xdc_replication_sup,which_children,infinity]}},
      [{gen_server,call,3,[{file,"gen_server.erl"},{line,188}]},
       {xdc_replication_sup,all_local_replication_infos,0,
                            [{file,"src/xdc_replication_sup.erl"},{line,58}]},
       {ns_heart,grab_local_xdcr_replications,0,
                 [{file,"src/ns_heart.erl"},{line,439}]},
       {ns_heart,current_status_slow_inner,0,
                 [{file,"src/ns_heart.erl"},{line,317}]},
       {ns_heart,current_status_slow,1,[{file,"src/ns_heart.erl"},{line,249}]},
       {ns_heart,slow_updater_loop,0,[{file,"src/ns_heart.erl"},{line,243}]},
       {proc_lib,init_p_do_apply,3,[{file,"proc_lib.erl"},{line,239}]}]}
[ns_server:debug,2021-04-19T19:45:53.929Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.282.0>:cluster_logs_collection_task:maybe_build_cluster_logs_task:43]Ignoring exception trying to read cluster_logs_collection_task_status table: error:badarg
[error_logger:info,2021-04-19T19:45:53.929Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.310.0>},
                       {name,menelaus_web},
                       {mfargs,{menelaus_web,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:53.933Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.328.0>},
                       {name,menelaus_event},
                       {mfargs,{menelaus_event,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:53.937Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.329.0>},
                       {name,hot_keys_keeper},
                       {mfargs,{hot_keys_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:53.947Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.330.0>},
                       {name,menelaus_web_alerts_srv},
                       {mfargs,{menelaus_web_alerts_srv,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:53.950Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.331.0>},
                       {name,menelaus_cbauth},
                       {mfargs,{menelaus_cbauth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[user:info,2021-04-19T19:45:53.951Z,ns_1@127.0.0.1:ns_server_sup<0.242.0>:menelaus_sup:start_link:46]Couchbase Server has started on web port 8091 on node 'ns_1@127.0.0.1'. Version: "4.6.0-3573-enterprise".
[error_logger:info,2021-04-19T19:45:53.951Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.298.0>},
                       {name,menelaus},
                       {mfargs,{menelaus_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:45:53.951Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.335.0>},
                       {name,ns_ports_setup},
                       {mfargs,{ns_ports_setup,start,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:53.954Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_agent_sup}
             started: [{pid,<0.338.0>},
                       {name,service_agent_children_sup},
                       {mfargs,
                           {supervisor,start_link,
                               [{local,service_agent_children_sup},
                                service_agent_sup,child]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:45:53.955Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_agent_sup}
             started: [{pid,<0.339.0>},
                       {name,service_agent_worker},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<service_agent_sup.0.29791682>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:53.955Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.337.0>},
                       {name,service_agent_sup},
                       {mfargs,{service_agent_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:45:53.965Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.341.0>},
                       {name,ns_memcached_sockets_pool},
                       {mfargs,{ns_memcached_sockets_pool,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:53.966Z,ns_1@127.0.0.1:ns_audit_cfg<0.342.0>:ns_audit_cfg:write_audit_json:158]Writing new content to "/opt/couchbase/var/lib/couchbase/config/audit.json" : [{auditd_enabled,
                                                                                false},
                                                                               {disabled,
                                                                                []},
                                                                               {log_path,
                                                                                "/opt/couchbase/var/lib/couchbase/logs"},
                                                                               {rotate_interval,
                                                                                86400},
                                                                               {rotate_size,
                                                                                20971520},
                                                                               {sync,
                                                                                []},
                                                                               {version,
                                                                                1},
                                                                               {descriptors_path,
                                                                                "/opt/couchbase/etc/security"}]
[ns_server:debug,2021-04-19T19:45:53.968Z,ns_1@127.0.0.1:ns_ports_setup<0.335.0>:ns_ports_manager:set_dynamic_children:54]Setting children [memcached,saslauthd_port,xdcr_proxy]
[ns_server:debug,2021-04-19T19:45:53.977Z,ns_1@127.0.0.1:ns_ports_setup<0.335.0>:ns_ports_setup:set_children:72]Monitor ns_child_ports_sup <11632.72.0>
[ns_server:debug,2021-04-19T19:45:53.985Z,ns_1@127.0.0.1:ns_audit_cfg<0.342.0>:ns_audit_cfg:handle_info:107]Instruct memcached to reload audit config
[error_logger:info,2021-04-19T19:45:53.985Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.342.0>},
                       {name,ns_audit_cfg},
                       {mfargs,{ns_audit_cfg,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:warn,2021-04-19T19:45:53.986Z,ns_1@127.0.0.1:<0.345.0>:ns_memcached:connect:1307]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[ns_server:debug,2021-04-19T19:45:53.990Z,ns_1@127.0.0.1:memcached_config_mgr<0.347.0>:memcached_config_mgr:init:44]waiting for completion of initial ns_ports_setup round
[ns_server:debug,2021-04-19T19:45:53.991Z,ns_1@127.0.0.1:memcached_config_mgr<0.347.0>:memcached_config_mgr:init:46]ns_ports_setup seems to be ready
[error_logger:info,2021-04-19T19:45:53.991Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.347.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:45:53.995Z,ns_1@127.0.0.1:<0.348.0>:ns_memcached_log_rotator:init:28]Starting log rotator on "/opt/couchbase/var/lib/couchbase/logs"/"memcached.log"* with an initial period of 39003ms
[error_logger:info,2021-04-19T19:45:53.995Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.348.0>},
                       {name,ns_memcached_log_rotator},
                       {mfargs,{ns_memcached_log_rotator,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:53.999Z,ns_1@127.0.0.1:memcached_config_mgr<0.347.0>:memcached_config_mgr:find_port_pid_loop:119]Found memcached port <11632.79.0>
[error_logger:info,2021-04-19T19:45:54.002Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.351.0>},
                       {name,memcached_clients_pool},
                       {mfargs,{memcached_clients_pool,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:54.007Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.352.0>},
                       {name,proxied_memcached_clients_pool},
                       {mfargs,{proxied_memcached_clients_pool,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:54.008Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.353.0>},
                       {name,xdc_lhttpc_pool},
                       {mfargs,
                           {lhttpc_manager,start_link,
                               [[{name,xdc_lhttpc_pool},
                                 {connection_timeout,120000},
                                 {pool_size,200}]]}},
                       {restart_type,{permanent,1}},
                       {shutdown,10000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:54.013Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.354.0>},
                       {name,ns_null_connection_pool},
                       {mfargs,
                           {ns_null_connection_pool,start_link,
                               [ns_null_connection_pool]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:45:54.016Z,ns_1@127.0.0.1:ns_couchdb_port<0.184.0>:ns_port_server:log:210]ns_couchdb<0.184.0>: working as port

[error_logger:info,2021-04-19T19:45:54.021Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {<0.355.0>,xdcr_sup}
             started: [{pid,<0.356.0>},
                       {name,xdc_stats_holder},
                       {mfargs,
                           {proc_lib,start_link,
                               [xdcr_sup,link_stats_holder_body,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:54.022Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {<0.355.0>,xdcr_sup}
             started: [{pid,<0.357.0>},
                       {name,xdc_replication_sup},
                       {mfargs,{xdc_replication_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2021-04-19T19:45:54.026Z,ns_1@127.0.0.1:xdc_rep_manager<0.358.0>:ns_couchdb_api:wait_for_doc_manager:298]Start waiting for doc manager
[error_logger:info,2021-04-19T19:45:54.026Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {<0.355.0>,xdcr_sup}
             started: [{pid,<0.358.0>},
                       {name,xdc_rep_manager},
                       {mfargs,{xdc_rep_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,30000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:54.026Z,ns_1@127.0.0.1:memcached_config_mgr<0.347.0>:memcached_config_mgr:init:77]wrote memcached config to /opt/couchbase/var/lib/couchbase/config/memcached.json. Will activate memcached port server
[ns_server:debug,2021-04-19T19:45:54.029Z,ns_1@127.0.0.1:memcached_config_mgr<0.347.0>:memcached_config_mgr:init:80]activated memcached port server
[ns_server:debug,2021-04-19T19:45:54.034Z,ns_1@127.0.0.1:xdcr_doc_replicator<0.360.0>:ns_couchdb_api:wait_for_doc_manager:298]Start waiting for doc manager
[ns_server:debug,2021-04-19T19:45:54.035Z,ns_1@127.0.0.1:xdc_rdoc_replication_srv<0.361.0>:ns_couchdb_api:wait_for_doc_manager:298]Start waiting for doc manager
[error_logger:info,2021-04-19T19:45:54.035Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {<0.355.0>,xdcr_sup}
             started: [{pid,<0.360.0>},
                       {name,xdc_rdoc_replicator},
                       {mfargs,{doc_replicator,start_link_xdcr,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:54.035Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {<0.355.0>,xdcr_sup}
             started: [{pid,<0.361.0>},
                       {name,xdc_rdoc_replication_srv},
                       {mfargs,{doc_replication_srv,start_link_xdcr,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:54.039Z,ns_1@127.0.0.1:<0.355.0>:xdc_rdoc_manager:start_link_remote:42]Starting xdc_rdoc_manager on 'couchdb_ns_1@127.0.0.1' with following links: [<0.360.0>,
                                                                             <0.361.0>,
                                                                             <0.358.0>]
[ns_server:debug,2021-04-19T19:45:54.043Z,ns_1@127.0.0.1:xdcr_doc_replicator<0.360.0>:ns_couchdb_api:wait_for_doc_manager:301]Received doc manager registration from <11633.254.0>
[ns_server:debug,2021-04-19T19:45:54.043Z,ns_1@127.0.0.1:xdc_rdoc_replication_srv<0.361.0>:ns_couchdb_api:wait_for_doc_manager:301]Received doc manager registration from <11633.254.0>
[ns_server:debug,2021-04-19T19:45:54.044Z,ns_1@127.0.0.1:xdc_rep_manager<0.358.0>:ns_couchdb_api:wait_for_doc_manager:301]Received doc manager registration from <11633.254.0>
[error_logger:info,2021-04-19T19:45:54.044Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {<0.355.0>,xdcr_sup}
             started: [{pid,<11633.254.0>},
                       {name,xdc_rdoc_manager},
                       {mfargs,
                           {xdc_rdoc_manager,start_link_remote,
                               ['couchdb_ns_1@127.0.0.1']}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:54.044Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.355.0>},
                       {name,xdcr_sup},
                       {mfargs,{xdcr_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:45:54.048Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.363.0>},
                       {name,xdcr_dcp_sockets_pool},
                       {mfargs,{xdcr_dcp_sockets_pool,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:54.052Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_worker_sup}
             started: [{pid,<0.365.0>},
                       {name,ns_bucket_worker},
                       {mfargs,{work_queue,start_link,[ns_bucket_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:54.056Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_sup}
             started: [{pid,<0.367.0>},
                       {name,buckets_observing_subscription},
                       {mfargs,{ns_bucket_sup,subscribe_on_config_events,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:54.057Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_worker_sup}
             started: [{pid,<0.366.0>},
                       {name,ns_bucket_sup},
                       {mfargs,{ns_bucket_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:45:54.057Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.364.0>},
                       {name,ns_bucket_worker_sup},
                       {mfargs,{ns_bucket_worker_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:45:54.063Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.368.0>},
                       {name,system_stats_collector},
                       {mfargs,{system_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:54.065Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.372.0>},
                       {name,{stats_archiver,"@system"}},
                       {mfargs,{stats_archiver,start_link,["@system"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:54.074Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.374.0>},
                       {name,{stats_reader,"@system"}},
                       {mfargs,{stats_reader,start_link,["@system"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:54.083Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.375.0>},
                       {name,{stats_archiver,"@system-processes"}},
                       {mfargs,
                           {stats_archiver,start_link,["@system-processes"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:54.086Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.377.0>},
                       {name,{stats_reader,"@system-processes"}},
                       {mfargs,
                           {stats_reader,start_link,["@system-processes"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:54.092Z,ns_1@127.0.0.1:xdcr_doc_replicator<0.360.0>:doc_replicator:loop:64]doing replicate_newnodes_docs
[error_logger:info,2021-04-19T19:45:54.101Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.378.0>},
                       {name,{stats_archiver,"@query"}},
                       {mfargs,{stats_archiver,start_link,["@query"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:54.102Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.380.0>},
                       {name,{stats_reader,"@query"}},
                       {mfargs,{stats_reader,start_link,["@query"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:54.118Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.381.0>},
                       {name,query_stats_collector},
                       {mfargs,{query_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:54.131Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.383.0>},
                       {name,{stats_archiver,"@global"}},
                       {mfargs,{stats_archiver,start_link,["@global"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:54.131Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.385.0>},
                       {name,{stats_reader,"@global"}},
                       {mfargs,{stats_reader,start_link,["@global"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:54.135Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.386.0>},
                       {name,global_stats_collector},
                       {mfargs,{global_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:54.141Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.388.0>},
                       {name,goxdcr_status_keeper},
                       {mfargs,{goxdcr_status_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:54.149Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_stats_sup}
             started: [{pid,<0.390.0>},
                       {name,index_stats_children_sup},
                       {mfargs,
                           {supervisor,start_link,
                               [{local,index_stats_children_sup},
                                index_stats_sup,child]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:45:54.153Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_status_keeper_sup}
             started: [{pid,<0.392.0>},
                       {name,index_status_keeper_worker},
                       {mfargs,
                           {work_queue,start_link,
                               [index_status_keeper_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:54.164Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_status_keeper_sup}
             started: [{pid,<0.393.0>},
                       {name,index_status_keeper},
                       {mfargs,{indexer_gsi,start_keeper,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:54.167Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_status_keeper_sup}
             started: [{pid,<0.396.0>},
                       {name,index_status_keeper_fts},
                       {mfargs,{indexer_fts,start_keeper,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:54.168Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_stats_sup}
             started: [{pid,<0.391.0>},
                       {name,index_status_keeper_sup},
                       {mfargs,{index_status_keeper_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:45:54.168Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_stats_sup}
             started: [{pid,<0.399.0>},
                       {name,index_stats_worker},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<index_stats_sup.0.21142793>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:54.168Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.389.0>},
                       {name,index_stats_sup},
                       {mfargs,{index_stats_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:45:54.176Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.401.0>},
                       {name,compaction_daemon},
                       {mfargs,{compaction_daemon,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:54.194Z,ns_1@127.0.0.1:<0.404.0>:new_concurrency_throttle:init:113]init concurrent throttle process, pid: <0.404.0>, type: kv_throttle# of available token: 1
[ns_server:debug,2021-04-19T19:45:54.199Z,ns_1@127.0.0.1:compaction_new_daemon<0.402.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:45:54.199Z,ns_1@127.0.0.1:compaction_new_daemon<0.402.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:45:54.199Z,ns_1@127.0.0.1:compaction_new_daemon<0.402.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:45:54.200Z,ns_1@127.0.0.1:compaction_new_daemon<0.402.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[error_logger:info,2021-04-19T19:45:54.199Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.402.0>},
                       {name,compaction_new_daemon},
                       {mfargs,{compaction_new_daemon,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,86400000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:54.200Z,ns_1@127.0.0.1:compaction_new_daemon<0.402.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_master. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:45:54.200Z,ns_1@127.0.0.1:compaction_new_daemon<0.402.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_master too soon. Next run will be in 3600s
[error_logger:info,2021-04-19T19:45:54.204Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,cluster_logs_sup}
             started: [{pid,<0.406.0>},
                       {name,ets_holder},
                       {mfargs,
                           {cluster_logs_collection_task,
                               start_link_ets_holder,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:54.205Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.405.0>},
                       {name,cluster_logs_sup},
                       {mfargs,{cluster_logs_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:45:54.207Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.407.0>},
                       {name,remote_api},
                       {mfargs,{remote_api,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:54.210Z,ns_1@127.0.0.1:<0.408.0>:mb_master:check_master_takeover_needed:141]Sending master node question to the following nodes: []
[ns_server:debug,2021-04-19T19:45:54.211Z,ns_1@127.0.0.1:<0.408.0>:mb_master:check_master_takeover_needed:143]Got replies: []
[ns_server:debug,2021-04-19T19:45:54.211Z,ns_1@127.0.0.1:<0.408.0>:mb_master:check_master_takeover_needed:149]Was unable to discover master, not going to force mastership takeover
[user:info,2021-04-19T19:45:54.211Z,ns_1@127.0.0.1:mb_master<0.410.0>:mb_master:init:86]I'm the only node, so I'm the master.
[ns_server:debug,2021-04-19T19:45:54.227Z,ns_1@127.0.0.1:mb_master_sup<0.412.0>:misc:start_singleton:1097]start_singleton(gen_server, ns_tick, [], []): started as <0.413.0> on 'ns_1@127.0.0.1'

[error_logger:info,2021-04-19T19:45:54.227Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.413.0>},
                       {name,ns_tick},
                       {mfargs,{ns_tick,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,10},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:54.241Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_config:do_upgrade_config:716]Upgrading config by changes:
[{set,cluster_compat_version,[2,5]}]

[ns_server:info,2021-04-19T19:45:54.241Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_online_config_upgrader:upgrade_config_from_2_5_to_3_0:62]Performing online config upgrade to 3.0 version
[ns_server:debug,2021-04-19T19:45:54.242Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_config:do_upgrade_config:716]Upgrading config by changes:
[{set,cluster_compat_version,[3,0]},
 {set,rest_creds,null},
 {set,read_only_user_creds,null}]

[ns_server:info,2021-04-19T19:45:54.242Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_online_config_upgrader:upgrade_config_from_3_0_to_4_0:67]Performing online config upgrade to 4.0 version
[ns_server:debug,2021-04-19T19:45:54.242Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_config:do_upgrade_config:716]Upgrading config by changes:
[{set,cluster_compat_version,[4,0]},
 {delete,goxdcr_upgrade},
 {set,{node,'ns_1@127.0.0.1',stop_xdcr},true},
 {set,{metakv,<<"/indexing/settings/config">>},
      <<"{\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.log_level\":\"info\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\":200,\"indexer.settings.max_cpu_percent\":0,\"indexer.settings.recovery.max_rollbacks\":5,\"indexer.settings.memory_quota\":536870912}">>}]

[ns_server:info,2021-04-19T19:45:54.243Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_online_config_upgrader:upgrade_config_from_4_0_to_4_1:72]Performing online config upgrade to 4.1 version
[ns_server:debug,2021-04-19T19:45:54.243Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_config:do_upgrade_config:716]Upgrading config by changes:
[{set,cluster_compat_version,[4,1]},
 {set,{service_map,n1ql},[]},
 {set,{service_map,index},[]}]

[ns_server:info,2021-04-19T19:45:54.243Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_online_config_upgrader:upgrade_config_from_4_1_to_4_5:76]Performing online config upgrade to 4.5 version
[ns_server:debug,2021-04-19T19:45:54.244Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_config:do_upgrade_config:716]Upgrading config by changes:
[{set,cluster_compat_version,[4,5]},
 {set,{metakv,<<"/indexing/settings/config">>},
      <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.log_level\":\"info\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\":200,\"indexer.settings.max_cpu_percent\":0,\"indexer.settings.storage_mode\":\"\",\"indexer.settings.recovery.max_rollbacks\":5,\"indexer.settings.memory_quota\":536870912,\"indexer.settings.compaction.abort_exceed_interval\":false}">>},
 {set,{service_map,fts},[]}]

[ns_server:debug,2021-04-19T19:45:54.244Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_config:do_upgrade_config:716]Upgrading config by changes:
[{set,cluster_compat_version,[4,6]}]

[ns_server:debug,2021-04-19T19:45:54.246Z,ns_1@127.0.0.1:menelaus_ui_auth<0.299.0>:menelaus_ui_auth:handle_cast:194]Revoke tokens [] for role ro_admin
[ns_server:debug,2021-04-19T19:45:54.246Z,ns_1@127.0.0.1:menelaus_ui_auth<0.299.0>:menelaus_ui_auth:handle_cast:194]Revoke tokens [] for role admin
[ns_server:info,2021-04-19T19:45:54.247Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.160.0>:ns_ssl_services_setup:handle_info:434]Got certificate and pkey change
[ns_server:debug,2021-04-19T19:45:54.247Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{service_map,fts} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080754}}]}]
[ns_server:debug,2021-04-19T19:45:54.247Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{service_map,index} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080754}}]}]
[ns_server:debug,2021-04-19T19:45:54.247Z,ns_1@127.0.0.1:ns_config_rep<0.260.0>:ns_config_rep:do_push_keys:321]Replicating some config keys ([cluster_compat_version,goxdcr_upgrade,
                               read_only_user_creds,rest_creds,
                               {local_changes_count,
                                   <<"dbb8bee8b38705437e7f5ebc78107bfa">>},
                               {metakv,<<"/indexing/settings/config">>},
                               {service_map,fts},
                               {service_map,index},
                               {service_map,n1ql},
                               {node,'ns_1@127.0.0.1',stop_xdcr}]..)
[ns_server:debug,2021-04-19T19:45:54.248Z,ns_1@127.0.0.1:ns_config_rep<0.260.0>:ns_config_rep:do_push_keys:321]Replicating some config keys ([{local_changes_count,
                                   <<"dbb8bee8b38705437e7f5ebc78107bfa">>},
                               {node,'ns_1@127.0.0.1',stop_xdcr}]..)
[ns_server:debug,2021-04-19T19:45:54.249Z,ns_1@127.0.0.1:ns_config_rep<0.260.0>:ns_config_rep:handle_call:115]Got full synchronization request from 'ns_1@127.0.0.1'
[ns_server:debug,2021-04-19T19:45:54.249Z,ns_1@127.0.0.1:ns_config_rep<0.260.0>:ns_config_rep:handle_call:121]Fully synchronized config in 12 us
[user:warn,2021-04-19T19:45:54.249Z,ns_1@127.0.0.1:<0.415.0>:ns_orchestrator:consider_switching_compat_mode:1205]Changed cluster compat mode from undefined to [4,6]
[ns_server:debug,2021-04-19T19:45:54.249Z,ns_1@127.0.0.1:ns_orchestrator_sup<0.414.0>:misc:start_singleton:1097]start_singleton(gen_fsm, ns_orchestrator, [], []): started as <0.415.0> on 'ns_1@127.0.0.1'

[error_logger:info,2021-04-19T19:45:54.250Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_sup}
             started: [{pid,<0.415.0>},
                       {name,ns_orchestrator},
                       {mfargs,{ns_orchestrator,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:54.248Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{service_map,n1ql} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080754}}]}]
[ns_server:debug,2021-04-19T19:45:54.252Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{metakv,<<"/indexing/settings/config">>} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{2,63786080754}}]}|
 <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.log_level\":\"info\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\""...>>]
[ns_server:debug,2021-04-19T19:45:54.252Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',stop_xdcr} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080754}}]}|true]
[ns_server:debug,2021-04-19T19:45:54.253Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
goxdcr_upgrade ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080754}}]}|
 '_deleted']
[ns_server:debug,2021-04-19T19:45:54.254Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
read_only_user_creds ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080754}}]}|null]
[ns_server:debug,2021-04-19T19:45:54.254Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
cluster_compat_version ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{6,63786080754}}]},4,6]
[ns_server:debug,2021-04-19T19:45:54.255Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
rest_creds ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080754}}]}|null]
[ns_server:debug,2021-04-19T19:45:54.255Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{local_changes_count,<<"dbb8bee8b38705437e7f5ebc78107bfa">>} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{3,63786080754}}]}]
[ns_server:debug,2021-04-19T19:45:54.255Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{local_changes_count,<<"dbb8bee8b38705437e7f5ebc78107bfa">>} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{4,63786080754}}]}]
[ns_server:debug,2021-04-19T19:45:54.255Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',stop_xdcr} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{2,63786080754}}]}|
 '_deleted']
[ns_server:info,2021-04-19T19:45:54.258Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.160.0>:ns_ssl_services_setup:maybe_generate_local_cert:523]Failed to read node certificate. Perhaps it wasn't created yet. Error: {error,
                                                                        {badmatch,
                                                                         {error,
                                                                          enoent}}}
[ns_server:debug,2021-04-19T19:45:54.265Z,ns_1@127.0.0.1:<0.426.0>:auto_failover:init:147]init auto_failover.
[ns_server:debug,2021-04-19T19:45:54.266Z,ns_1@127.0.0.1:ns_orchestrator_sup<0.414.0>:misc:start_singleton:1097]start_singleton(gen_server, auto_failover, [], []): started as <0.426.0> on 'ns_1@127.0.0.1'

[error_logger:info,2021-04-19T19:45:54.266Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_sup}
             started: [{pid,<0.426.0>},
                       {name,auto_failover},
                       {mfargs,{auto_failover,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:54.266Z,ns_1@127.0.0.1:<0.408.0>:restartable:start_child:98]Started child process <0.410.0>
  MFA: {mb_master,start_link,[]}
[error_logger:info,2021-04-19T19:45:54.267Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.414.0>},
                       {name,ns_orchestrator_sup},
                       {mfargs,{ns_orchestrator_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:45:54.267Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.408.0>},
                       {name,mb_master},
                       {mfargs,
                           {restartable,start_link,
                               [{mb_master,start_link,[]},infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:45:54.267Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.427.0>},
                       {name,master_activity_events_ingress},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,master_activity_events_ingress}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:54.268Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.428.0>},
                       {name,master_activity_events_timestamper},
                       {mfargs,
                           {master_activity_events,start_link_timestamper,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:54.283Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.430.0>},
                       {name,master_activity_events_pids_watcher},
                       {mfargs,
                           {master_activity_events_pids_watcher,start_link,
                               []}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:54.306Z,ns_1@127.0.0.1:ns_ports_setup<0.335.0>:ns_ports_manager:set_dynamic_children:54]Setting children [memcached,saslauthd_port,goxdcr,xdcr_proxy]
[ns_server:debug,2021-04-19T19:45:54.329Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.155.0>:one_shot_barrier:notify:27]Notifying on barrier menelaus_barrier
[ns_server:debug,2021-04-19T19:45:54.329Z,ns_1@127.0.0.1:menelaus_barrier<0.157.0>:one_shot_barrier:barrier_body:62]Barrier menelaus_barrier got notification from <0.155.0>
[ns_server:debug,2021-04-19T19:45:54.329Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.155.0>:one_shot_barrier:notify:32]Successfuly notified on barrier menelaus_barrier
[ns_server:debug,2021-04-19T19:45:54.329Z,ns_1@127.0.0.1:<0.154.0>:restartable:start_child:98]Started child process <0.155.0>
  MFA: {ns_server_nodes_sup,start_link,[]}
[error_logger:info,2021-04-19T19:45:54.329Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.431.0>},
                       {name,master_activity_events_keeper},
                       {mfargs,{master_activity_events_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:54.331Z,ns_1@127.0.0.1:<0.2.0>:child_erlang:child_loop:116]98: Entered child_loop
[error_logger:info,2021-04-19T19:45:54.331Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.242.0>},
                       {name,ns_server_sup},
                       {mfargs,{ns_server_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:45:54.331Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.154.0>},
                       {name,ns_server_nodes_sup},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_server_nodes_sup,start_link,[]},
                                infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:45:54.332Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
         application: ns_server
          started_at: 'ns_1@127.0.0.1'

[ns_server:warn,2021-04-19T19:45:54.987Z,ns_1@127.0.0.1:<0.345.0>:ns_memcached:connect:1307]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[ns_server:warn,2021-04-19T19:45:55.236Z,ns_1@127.0.0.1:<0.433.0>:ns_memcached:connect:1307]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[ns_server:debug,2021-04-19T19:45:55.398Z,ns_1@127.0.0.1:json_rpc_connection-saslauthd-saslauthd-port<0.436.0>:json_rpc_connection:init:74]Observed revrpc connection: label "saslauthd-saslauthd-port", handling process <0.436.0>
[error_logger:error,2021-04-19T19:45:55.399Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.436.0>,{ok,<0.436.0>}}

[ns_server:debug,2021-04-19T19:45:55.809Z,ns_1@127.0.0.1:json_rpc_connection-goxdcr-cbauth<0.439.0>:json_rpc_connection:init:74]Observed revrpc connection: label "goxdcr-cbauth", handling process <0.439.0>
[error_logger:error,2021-04-19T19:45:55.809Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.439.0>,{ok,<0.439.0>}}

[ns_server:debug,2021-04-19T19:45:55.809Z,ns_1@127.0.0.1:menelaus_cbauth<0.331.0>:menelaus_cbauth:handle_cast:87]Observed json rpc process {"goxdcr-cbauth",<0.439.0>} started
[ns_server:debug,2021-04-19T19:45:55.810Z,ns_1@127.0.0.1:json_rpc_connection-goxdcr-cbauth<0.439.0>:json_rpc_connection:handle_call:157]sending jsonrpc call:{[{jsonrpc,<<"2.0">>},
                       {id,0},
                       {method,<<"AuthCacheSvc.UpdateDB">>},
                       {params,
                        [{[{specialUser,<<"@goxdcr-cbauth">>},
                           {nodes,
                            [{[{host,<<"127.0.0.1">>},
                               {user,<<"_admin">>},
                               {password,"*****"},
                               {ports,
                                [8091,18091,18092,8092,11207,9999,11210,
                                 11211]},
                               {local,true}]}]},
                           {buckets,[]},
                           {authCheckURL,<<"http://127.0.0.1:8091/_cbauth">>},
                           {permissionCheckURL,
                            <<"http://127.0.0.1:8091/_cbauth/checkPermission">>},
                           {ldapEnabled,true},
                           {permissionsVersion,125619376}]}]}]}
[ns_server:debug,2021-04-19T19:45:55.812Z,ns_1@127.0.0.1:json_rpc_connection-goxdcr-cbauth<0.439.0>:json_rpc_connection:handle_info:93]got response: [{<<"id">>,0},{<<"result">>,true},{<<"error">>,null}]
[stats:warn,2021-04-19T19:45:56.238Z,ns_1@127.0.0.1:<0.386.0>:base_stats_collector:latest_tick:69](Collector: global_stats_collector) Dropped 1 ticks
[ns_server:info,2021-04-19T19:45:56.320Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.160.0>:ns_ssl_services_setup:do_generate_local_cert:511]Saved local cert for node 'ns_1@127.0.0.1'
[ns_server:info,2021-04-19T19:45:56.404Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.160.0>:ns_ssl_services_setup:handle_info:437]Wrote new pem file
[ns_server:debug,2021-04-19T19:45:56.404Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.160.0>:ns_ssl_services_setup:handle_info:463]Going to notify following services: [ssl_service,capi_ssl_service,xdcr_proxy,
                                     query_svc,memcached]
[ns_server:info,2021-04-19T19:45:56.405Z,ns_1@127.0.0.1:<0.459.0>:ns_ssl_services_setup:notify_service:556]Successfully notified service query_svc
[ns_server:debug,2021-04-19T19:45:56.405Z,ns_1@127.0.0.1:<0.165.0>:restartable:loop:71]Restarting child <0.167.0>
  MFA: {ns_ssl_services_setup,start_link_rest_service,[]}
  Shutdown policy: 1000
  Caller: {<0.456.0>,#Ref<0.0.0.1618>}
[ns_server:debug,2021-04-19T19:45:56.405Z,ns_1@127.0.0.1:<0.458.0>:ns_ports_manager:restart_port_by_name:43]Requesting restart of port xdcr_proxy
[ns_server:debug,2021-04-19T19:45:56.405Z,ns_1@127.0.0.1:<0.165.0>:restartable:shutdown_child:120]Successfully terminated process <0.167.0>
[ns_server:info,2021-04-19T19:45:56.408Z,ns_1@127.0.0.1:<0.460.0>:ns_ssl_services_setup:notify_service:556]Successfully notified service memcached
[ns_server:info,2021-04-19T19:45:56.413Z,ns_1@127.0.0.1:<0.165.0>:menelaus_pluggable_ui:validate_plugin_spec:117]Loaded pluggable UI specification for fts

[ns_server:info,2021-04-19T19:45:56.413Z,ns_1@127.0.0.1:<0.165.0>:menelaus_pluggable_ui:validate_plugin_spec:117]Loaded pluggable UI specification for n1ql

[ns_server:debug,2021-04-19T19:45:56.414Z,ns_1@127.0.0.1:<0.165.0>:restartable:start_child:98]Started child process <0.461.0>
  MFA: {ns_ssl_services_setup,start_link_rest_service,[]}
[ns_server:info,2021-04-19T19:45:56.414Z,ns_1@127.0.0.1:<0.456.0>:ns_ssl_services_setup:notify_service:556]Successfully notified service ssl_service
[ns_server:info,2021-04-19T19:45:56.421Z,ns_1@127.0.0.1:<0.457.0>:ns_ssl_services_setup:notify_service:556]Successfully notified service capi_ssl_service
[user:debug,2021-04-19T19:45:58.302Z,ns_1@127.0.0.1:<0.248.0>:ns_log:crash_consumption_loop:70]Service 'xdcr_proxy' exited with status 0. Restarting. Messages: 199: Booted. Waiting for shutdown request
199: got shutdown request. Exiting
[ns_server:info,2021-04-19T19:45:58.304Z,ns_1@127.0.0.1:<0.458.0>:ns_ssl_services_setup:notify_service:556]Successfully notified service xdcr_proxy
[ns_server:info,2021-04-19T19:45:58.304Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.160.0>:ns_ssl_services_setup:handle_info:479]Succesfully notified services [memcached,query_svc,xdcr_proxy,
                               capi_ssl_service,ssl_service]
[ns_server:debug,2021-04-19T19:45:59.627Z,ns_1@127.0.0.1:<0.500.0>:ns_audit:put:248]Audit cluster_settings: [{cluster_name,<<>>},
                         {fts_memory_quota,512},
                         {index_memory_quota,512},
                         {memory_quota,300},
                         {real_userid,{[{source,anonymous},{user,<<>>}]}},
                         {remote,{[{ip,<<"127.0.0.1">>},{port,35766}]}},
                         {timestamp,<<"2021-04-19T19:45:59.627Z">>}]
[ns_server:debug,2021-04-19T19:45:59.627Z,ns_1@127.0.0.1:ns_config_rep<0.260.0>:ns_config_rep:do_push_keys:321]Replicating some config keys ([memory_quota,
                               {local_changes_count,
                                   <<"dbb8bee8b38705437e7f5ebc78107bfa">>},
                               {metakv,<<"/indexing/settings/config">>}]..)
[ns_server:debug,2021-04-19T19:45:59.627Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{metakv,<<"/indexing/settings/config">>} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{3,63786080759}}]}|
 <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.log_level\":\"info\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\""...>>]
[ns_server:debug,2021-04-19T19:45:59.628Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
memory_quota ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080759}}]}|300]
[ns_server:debug,2021-04-19T19:45:59.628Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{local_changes_count,<<"dbb8bee8b38705437e7f5ebc78107bfa">>} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{5,63786080759}}]}]
[ns_server:debug,2021-04-19T19:45:59.639Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{local_changes_count,<<"dbb8bee8b38705437e7f5ebc78107bfa">>} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{6,63786080759}}]}]
[ns_server:debug,2021-04-19T19:45:59.640Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',services} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080759}}]},
 index,kv,n1ql]
[ns_server:debug,2021-04-19T19:45:59.640Z,ns_1@127.0.0.1:<0.506.0>:ns_audit:put:248]Audit setup_node_services: [{services,[index,kv,n1ql]},
                            {node,'ns_1@127.0.0.1'},
                            {real_userid,{[{source,anonymous},{user,<<>>}]}},
                            {remote,{[{ip,<<"127.0.0.1">>},{port,35768}]}},
                            {timestamp,<<"2021-04-19T19:45:59.639Z">>}]
[ns_server:debug,2021-04-19T19:45:59.640Z,ns_1@127.0.0.1:ns_config_rep<0.260.0>:ns_config_rep:do_push_keys:321]Replicating some config keys ([{local_changes_count,
                                   <<"dbb8bee8b38705437e7f5ebc78107bfa">>},
                               {node,'ns_1@127.0.0.1',services}]..)
[ns_server:debug,2021-04-19T19:45:59.689Z,ns_1@127.0.0.1:ns_config_rep<0.260.0>:ns_config_rep:do_push_keys:321]Replicating some config keys ([rest,
                               {local_changes_count,
                                   <<"dbb8bee8b38705437e7f5ebc78107bfa">>}]..)
[ns_server:debug,2021-04-19T19:45:59.690Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{local_changes_count,<<"dbb8bee8b38705437e7f5ebc78107bfa">>} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{7,63786080759}}]}]
[ns_server:debug,2021-04-19T19:45:59.690Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
rest ->
[{port,8091}]
[ns_server:debug,2021-04-19T19:45:59.690Z,ns_1@127.0.0.1:menelaus_ui_auth<0.299.0>:menelaus_ui_auth:handle_cast:194]Revoke tokens [] for role admin
[ns_server:debug,2021-04-19T19:45:59.690Z,ns_1@127.0.0.1:<0.513.0>:ns_audit:put:248]Audit password_change: [{identity,{[{source,admin},
                                    {user,<<"Administrator">>}]}},
                        {real_userid,{[{source,anonymous},{user,<<>>}]}},
                        {remote,{[{ip,<<"127.0.0.1">>},{port,35770}]}},
                        {timestamp,<<"2021-04-19T19:45:59.690Z">>}]
[ns_server:debug,2021-04-19T19:45:59.690Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{local_changes_count,<<"dbb8bee8b38705437e7f5ebc78107bfa">>} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{8,63786080759}}]}]
[ns_server:debug,2021-04-19T19:45:59.690Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
rest_creds ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{2,63786080759}}]}|
 {"Administrator",{password,"*****"}}]
[ns_server:debug,2021-04-19T19:45:59.690Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{local_changes_count,<<"dbb8bee8b38705437e7f5ebc78107bfa">>} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{9,63786080759}}]}]
[ns_server:debug,2021-04-19T19:45:59.690Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
uuid ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080759}}]}|
 <<"aaf7f03de532d2dc46a1e96329b1eb02">>]
[ns_server:debug,2021-04-19T19:45:59.693Z,ns_1@127.0.0.1:ns_config_rep<0.260.0>:ns_config_rep:do_push_keys:321]Replicating some config keys ([rest_creds,uuid,
                               {local_changes_count,
                                   <<"dbb8bee8b38705437e7f5ebc78107bfa">>}]..)
[ns_server:debug,2021-04-19T19:45:59.693Z,ns_1@127.0.0.1:json_rpc_connection-goxdcr-cbauth<0.439.0>:json_rpc_connection:handle_call:157]sending jsonrpc call:{[{jsonrpc,<<"2.0">>},
                       {id,1},
                       {method,<<"AuthCacheSvc.UpdateDB">>},
                       {params,
                        [{[{specialUser,<<"@goxdcr-cbauth">>},
                           {nodes,
                            [{[{host,<<"127.0.0.1">>},
                               {user,<<"_admin">>},
                               {password,"*****"},
                               {ports,
                                [8091,18091,18092,8092,11207,9999,11210,
                                 11211]},
                               {local,true}]}]},
                           {buckets,[]},
                           {authCheckURL,<<"http://127.0.0.1:8091/_cbauth">>},
                           {permissionCheckURL,
                            <<"http://127.0.0.1:8091/_cbauth/checkPermission">>},
                           {ldapEnabled,true},
                           {permissionsVersion,125619376},
                           {admin,
                            {[{user,<<"Administrator">>},
                              {salt,<<"6fV7COE6Hrv1Slx3m7c7aw==">>},
                              {mac,
                               <<"88VQXOIVfyUC4fCDlttiZJtlD/s=">>}]}}]}]}]}
[ns_server:debug,2021-04-19T19:45:59.694Z,ns_1@127.0.0.1:json_rpc_connection-goxdcr-cbauth<0.439.0>:json_rpc_connection:handle_info:93]got response: [{<<"id">>,1},{<<"result">>,true},{<<"error">>,null}]
[error_logger:info,2021-04-19T19:45:59.716Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_stats_children_sup}
             started: [{pid,<0.522.0>},
                       {name,{indexer_gsi,index_stats_collector}},
                       {mfargs,
                           {index_stats_collector,start_link,[indexer_gsi]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:59.716Z,ns_1@127.0.0.1:ns_ports_setup<0.335.0>:ns_ports_manager:set_dynamic_children:54]Setting children [memcached,saslauthd_port,goxdcr,xdcr_proxy]
[error_logger:info,2021-04-19T19:45:59.720Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_stats_children_sup}
             started: [{pid,<0.525.0>},
                       {name,{indexer_gsi,stats_archiver,"@index"}},
                       {mfargs,{stats_archiver,start_link,["@index"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:59.720Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_stats_children_sup}
             started: [{pid,<0.527.0>},
                       {name,{indexer_gsi,stats_reader,"@index"}},
                       {mfargs,{stats_reader,start_link,["@index"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:59.727Z,ns_1@127.0.0.1:ns_config_rep<0.260.0>:ns_config_rep:do_push_keys:321]Replicating some config keys ([{local_changes_count,
                                   <<"dbb8bee8b38705437e7f5ebc78107bfa">>},
                               {metakv,<<"/indexing/settings/config">>}]..)
[ns_server:debug,2021-04-19T19:45:59.727Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{metakv,<<"/indexing/settings/config">>} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{4,63786080759}}]}|
 <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.log_level\":\"info\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\""...>>]
[ns_server:debug,2021-04-19T19:45:59.728Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{local_changes_count,<<"dbb8bee8b38705437e7f5ebc78107bfa">>} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{10,63786080759}}]}]
[ns_server:debug,2021-04-19T19:45:59.728Z,ns_1@127.0.0.1:<0.528.0>:ns_audit:put:248]Audit modify_index_storage_mode: [{storageMode,<<"memory_optimized">>},
                                  {real_userid,
                                      {[{source,ns_server},
                                        {user,<<"Administrator">>}]}},
                                  {remote,
                                      {[{ip,<<"127.0.0.1">>},{port,35772}]}},
                                  {timestamp,<<"2021-04-19T19:45:59.727Z">>}]
[stats:error,2021-04-19T19:46:00.229Z,ns_1@127.0.0.1:query_stats_collector<0.381.0>:base_stats_collector:handle_info:109](Collector: query_stats_collector) Exception in stats collector: {error,
                                                                  {badmatch,
                                                                   {error,
                                                                    {econnrefused,
                                                                     [{lhttpc_client,
                                                                       send_request,
                                                                       1,
                                                                       [{file,
                                                                         "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                        {line,
                                                                         220}]},
                                                                      {lhttpc_client,
                                                                       execute,
                                                                       9,
                                                                       [{file,
                                                                         "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                        {line,
                                                                         169}]},
                                                                      {lhttpc_client,
                                                                       request,
                                                                       9,
                                                                       [{file,
                                                                         "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                        {line,
                                                                         92}]}]}}},
                                                                  [{query_rest,
                                                                    send,3,
                                                                    [{file,
                                                                      "src/query_rest.erl"},
                                                                     {line,
                                                                      64}]},
                                                                   {query_rest,
                                                                    do_get_stats,
                                                                    0,
                                                                    [{file,
                                                                      "src/query_rest.erl"},
                                                                     {line,
                                                                      43}]},
                                                                   {base_stats_collector,
                                                                    handle_info,
                                                                    2,
                                                                    [{file,
                                                                      "src/base_stats_collector.erl"},
                                                                     {line,
                                                                      89}]},
                                                                   {gen_server,
                                                                    handle_msg,
                                                                    5,
                                                                    [{file,
                                                                      "gen_server.erl"},
                                                                     {line,
                                                                      604}]},
                                                                   {proc_lib,
                                                                    init_p_do_apply,
                                                                    3,
                                                                    [{file,
                                                                      "proc_lib.erl"},
                                                                     {line,
                                                                      239}]}]}

[ns_server:error,2021-04-19T19:46:00.234Z,ns_1@127.0.0.1:index_stats_collector-index<0.522.0>:index_rest:get_json:42]Request to (indexer) http://127.0.0.1:9102/stats?async=true failed: {error,
                                                                     {econnrefused,
                                                                      [{lhttpc_client,
                                                                        send_request,
                                                                        1,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          220}]},
                                                                       {lhttpc_client,
                                                                        execute,
                                                                        9,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          169}]},
                                                                       {lhttpc_client,
                                                                        request,
                                                                        9,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          92}]}]}}
[ns_server:error,2021-04-19T19:46:01.228Z,ns_1@127.0.0.1:index_stats_collector-index<0.522.0>:index_rest:get_json:42]Request to (indexer) http://127.0.0.1:9102/stats?async=true failed: {error,
                                                                     {econnrefused,
                                                                      [{lhttpc_client,
                                                                        send_request,
                                                                        1,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          220}]},
                                                                       {lhttpc_client,
                                                                        execute,
                                                                        9,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          169}]},
                                                                       {lhttpc_client,
                                                                        request,
                                                                        9,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          92}]}]}}
[stats:error,2021-04-19T19:46:01.228Z,ns_1@127.0.0.1:query_stats_collector<0.381.0>:base_stats_collector:handle_info:109](Collector: query_stats_collector) Exception in stats collector: {error,
                                                                  {badmatch,
                                                                   {error,
                                                                    {econnrefused,
                                                                     [{lhttpc_client,
                                                                       send_request,
                                                                       1,
                                                                       [{file,
                                                                         "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                        {line,
                                                                         220}]},
                                                                      {lhttpc_client,
                                                                       execute,
                                                                       9,
                                                                       [{file,
                                                                         "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                        {line,
                                                                         169}]},
                                                                      {lhttpc_client,
                                                                       request,
                                                                       9,
                                                                       [{file,
                                                                         "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                        {line,
                                                                         92}]}]}}},
                                                                  [{query_rest,
                                                                    send,3,
                                                                    [{file,
                                                                      "src/query_rest.erl"},
                                                                     {line,
                                                                      64}]},
                                                                   {query_rest,
                                                                    do_get_stats,
                                                                    0,
                                                                    [{file,
                                                                      "src/query_rest.erl"},
                                                                     {line,
                                                                      43}]},
                                                                   {base_stats_collector,
                                                                    handle_info,
                                                                    2,
                                                                    [{file,
                                                                      "src/base_stats_collector.erl"},
                                                                     {line,
                                                                      89}]},
                                                                   {gen_server,
                                                                    handle_msg,
                                                                    5,
                                                                    [{file,
                                                                      "gen_server.erl"},
                                                                     {line,
                                                                      604}]},
                                                                   {proc_lib,
                                                                    init_p_do_apply,
                                                                    3,
                                                                    [{file,
                                                                      "proc_lib.erl"},
                                                                     {line,
                                                                      239}]}]}

[ns_server:error,2021-04-19T19:46:02.229Z,ns_1@127.0.0.1:index_stats_collector-index<0.522.0>:index_rest:get_json:42]Request to (indexer) http://127.0.0.1:9102/stats?async=true failed: {error,
                                                                     {econnrefused,
                                                                      [{lhttpc_client,
                                                                        send_request,
                                                                        1,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          220}]},
                                                                       {lhttpc_client,
                                                                        execute,
                                                                        9,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          169}]},
                                                                       {lhttpc_client,
                                                                        request,
                                                                        9,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          92}]}]}}
[stats:error,2021-04-19T19:46:02.230Z,ns_1@127.0.0.1:query_stats_collector<0.381.0>:base_stats_collector:handle_info:109](Collector: query_stats_collector) Exception in stats collector: {error,
                                                                  {badmatch,
                                                                   {error,
                                                                    {econnrefused,
                                                                     [{lhttpc_client,
                                                                       send_request,
                                                                       1,
                                                                       [{file,
                                                                         "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                        {line,
                                                                         220}]},
                                                                      {lhttpc_client,
                                                                       execute,
                                                                       9,
                                                                       [{file,
                                                                         "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                        {line,
                                                                         169}]},
                                                                      {lhttpc_client,
                                                                       request,
                                                                       9,
                                                                       [{file,
                                                                         "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                        {line,
                                                                         92}]}]}}},
                                                                  [{query_rest,
                                                                    send,3,
                                                                    [{file,
                                                                      "src/query_rest.erl"},
                                                                     {line,
                                                                      64}]},
                                                                   {query_rest,
                                                                    do_get_stats,
                                                                    0,
                                                                    [{file,
                                                                      "src/query_rest.erl"},
                                                                     {line,
                                                                      43}]},
                                                                   {base_stats_collector,
                                                                    handle_info,
                                                                    2,
                                                                    [{file,
                                                                      "src/base_stats_collector.erl"},
                                                                     {line,
                                                                      89}]},
                                                                   {gen_server,
                                                                    handle_msg,
                                                                    5,
                                                                    [{file,
                                                                      "gen_server.erl"},
                                                                     {line,
                                                                      604}]},
                                                                   {proc_lib,
                                                                    init_p_do_apply,
                                                                    3,
                                                                    [{file,
                                                                      "proc_lib.erl"},
                                                                     {line,
                                                                      239}]}]}

[user:debug,2021-04-19T19:46:02.484Z,ns_1@127.0.0.1:<0.248.0>:ns_log:crash_consumption_loop:70]Service 'xdcr_proxy' exited with status 0. Restarting. Messages: 271: Booted. Waiting for shutdown request
271: got shutdown request. Exiting
[ns_server:debug,2021-04-19T19:46:02.550Z,ns_1@127.0.0.1:ns_ports_setup<0.335.0>:ns_ports_manager:set_dynamic_children:54]Setting children [memcached,moxi,projector,indexer,query,saslauthd_port,
                  goxdcr,xdcr_proxy]
[stats:error,2021-04-19T19:46:03.230Z,ns_1@127.0.0.1:query_stats_collector<0.381.0>:base_stats_collector:handle_info:109](Collector: query_stats_collector) Exception in stats collector: {error,
                                                                  {badmatch,
                                                                   {error,
                                                                    {econnrefused,
                                                                     [{lhttpc_client,
                                                                       send_request,
                                                                       1,
                                                                       [{file,
                                                                         "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                        {line,
                                                                         220}]},
                                                                      {lhttpc_client,
                                                                       execute,
                                                                       9,
                                                                       [{file,
                                                                         "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                        {line,
                                                                         169}]},
                                                                      {lhttpc_client,
                                                                       request,
                                                                       9,
                                                                       [{file,
                                                                         "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                        {line,
                                                                         92}]}]}}},
                                                                  [{query_rest,
                                                                    send,3,
                                                                    [{file,
                                                                      "src/query_rest.erl"},
                                                                     {line,
                                                                      64}]},
                                                                   {query_rest,
                                                                    do_get_stats,
                                                                    0,
                                                                    [{file,
                                                                      "src/query_rest.erl"},
                                                                     {line,
                                                                      43}]},
                                                                   {base_stats_collector,
                                                                    handle_info,
                                                                    2,
                                                                    [{file,
                                                                      "src/base_stats_collector.erl"},
                                                                     {line,
                                                                      89}]},
                                                                   {gen_server,
                                                                    handle_msg,
                                                                    5,
                                                                    [{file,
                                                                      "gen_server.erl"},
                                                                     {line,
                                                                      604}]},
                                                                   {proc_lib,
                                                                    init_p_do_apply,
                                                                    3,
                                                                    [{file,
                                                                      "proc_lib.erl"},
                                                                     {line,
                                                                      239}]}]}

[ns_server:error,2021-04-19T19:46:03.231Z,ns_1@127.0.0.1:index_stats_collector-index<0.522.0>:index_rest:get_json:42]Request to (indexer) http://127.0.0.1:9102/stats?async=true failed: {error,
                                                                     {econnrefused,
                                                                      [{lhttpc_client,
                                                                        send_request,
                                                                        1,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          220}]},
                                                                       {lhttpc_client,
                                                                        execute,
                                                                        9,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          169}]},
                                                                       {lhttpc_client,
                                                                        request,
                                                                        9,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          92}]}]}}
[ns_server:debug,2021-04-19T19:46:03.796Z,ns_1@127.0.0.1:json_rpc_connection-projector-cbauth<0.558.0>:json_rpc_connection:init:74]Observed revrpc connection: label "projector-cbauth", handling process <0.558.0>
[ns_server:debug,2021-04-19T19:46:03.797Z,ns_1@127.0.0.1:menelaus_cbauth<0.331.0>:menelaus_cbauth:handle_cast:87]Observed json rpc process {"projector-cbauth",<0.558.0>} started
[error_logger:error,2021-04-19T19:46:03.797Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.558.0>,{ok,<0.558.0>}}

[ns_server:debug,2021-04-19T19:46:03.797Z,ns_1@127.0.0.1:json_rpc_connection-projector-cbauth<0.558.0>:json_rpc_connection:handle_call:157]sending jsonrpc call:{[{jsonrpc,<<"2.0">>},
                       {id,0},
                       {method,<<"AuthCacheSvc.UpdateDB">>},
                       {params,
                        [{[{specialUser,<<"@projector-cbauth">>},
                           {nodes,
                            [{[{host,<<"127.0.0.1">>},
                               {user,<<"_admin">>},
                               {password,"*****"},
                               {ports,
                                [8091,18091,18092,8092,11207,9999,11210,
                                 11211]},
                               {local,true}]}]},
                           {buckets,[]},
                           {authCheckURL,<<"http://127.0.0.1:8091/_cbauth">>},
                           {permissionCheckURL,
                            <<"http://127.0.0.1:8091/_cbauth/checkPermission">>},
                           {ldapEnabled,true},
                           {permissionsVersion,125619376},
                           {admin,
                            {[{user,<<"Administrator">>},
                              {salt,<<"6fV7COE6Hrv1Slx3m7c7aw==">>},
                              {mac,
                               <<"88VQXOIVfyUC4fCDlttiZJtlD/s=">>}]}}]}]}]}
[ns_server:debug,2021-04-19T19:46:03.800Z,ns_1@127.0.0.1:json_rpc_connection-projector-cbauth<0.558.0>:json_rpc_connection:handle_info:93]got response: [{<<"id">>,0},{<<"result">>,true},{<<"error">>,null}]
[ns_server:debug,2021-04-19T19:46:03.947Z,ns_1@127.0.0.1:json_rpc_connection-index-cbauth<0.569.0>:json_rpc_connection:init:74]Observed revrpc connection: label "index-cbauth", handling process <0.569.0>
[ns_server:debug,2021-04-19T19:46:03.947Z,ns_1@127.0.0.1:menelaus_cbauth<0.331.0>:menelaus_cbauth:handle_cast:87]Observed json rpc process {"index-cbauth",<0.569.0>} started
[error_logger:error,2021-04-19T19:46:03.947Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.569.0>,{ok,<0.569.0>}}

[ns_server:debug,2021-04-19T19:46:03.947Z,ns_1@127.0.0.1:json_rpc_connection-index-cbauth<0.569.0>:json_rpc_connection:handle_call:157]sending jsonrpc call:{[{jsonrpc,<<"2.0">>},
                       {id,0},
                       {method,<<"AuthCacheSvc.UpdateDB">>},
                       {params,
                        [{[{specialUser,<<"@index-cbauth">>},
                           {nodes,
                            [{[{host,<<"127.0.0.1">>},
                               {user,<<"_admin">>},
                               {password,"*****"},
                               {ports,
                                [8091,18091,18092,8092,11207,9999,11210,
                                 11211]},
                               {local,true}]}]},
                           {buckets,[]},
                           {authCheckURL,<<"http://127.0.0.1:8091/_cbauth">>},
                           {permissionCheckURL,
                            <<"http://127.0.0.1:8091/_cbauth/checkPermission">>},
                           {ldapEnabled,true},
                           {permissionsVersion,125619376},
                           {admin,
                            {[{user,<<"Administrator">>},
                              {salt,<<"6fV7COE6Hrv1Slx3m7c7aw==">>},
                              {mac,
                               <<"88VQXOIVfyUC4fCDlttiZJtlD/s=">>}]}}]}]}]}
[ns_server:debug,2021-04-19T19:46:03.949Z,ns_1@127.0.0.1:json_rpc_connection-index-cbauth<0.569.0>:json_rpc_connection:handle_info:93]got response: [{<<"id">>,0},{<<"result">>,true},{<<"error">>,null}]
[ns_server:debug,2021-04-19T19:46:04.120Z,ns_1@127.0.0.1:json_rpc_connection-cbq-engine-cbauth<0.579.0>:json_rpc_connection:init:74]Observed revrpc connection: label "cbq-engine-cbauth", handling process <0.579.0>
[ns_server:debug,2021-04-19T19:46:04.120Z,ns_1@127.0.0.1:menelaus_cbauth<0.331.0>:menelaus_cbauth:handle_cast:87]Observed json rpc process {"cbq-engine-cbauth",<0.579.0>} started
[error_logger:error,2021-04-19T19:46:04.120Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.579.0>,{ok,<0.579.0>}}

[ns_server:debug,2021-04-19T19:46:04.120Z,ns_1@127.0.0.1:json_rpc_connection-cbq-engine-cbauth<0.579.0>:json_rpc_connection:handle_call:157]sending jsonrpc call:{[{jsonrpc,<<"2.0">>},
                       {id,0},
                       {method,<<"AuthCacheSvc.UpdateDB">>},
                       {params,
                        [{[{specialUser,<<"@cbq-engine-cbauth">>},
                           {nodes,
                            [{[{host,<<"127.0.0.1">>},
                               {user,<<"_admin">>},
                               {password,"*****"},
                               {ports,
                                [8091,18091,18092,8092,11207,9999,11210,
                                 11211]},
                               {local,true}]}]},
                           {buckets,[]},
                           {authCheckURL,<<"http://127.0.0.1:8091/_cbauth">>},
                           {permissionCheckURL,
                            <<"http://127.0.0.1:8091/_cbauth/checkPermission">>},
                           {ldapEnabled,true},
                           {permissionsVersion,125619376},
                           {admin,
                            {[{user,<<"Administrator">>},
                              {salt,<<"6fV7COE6Hrv1Slx3m7c7aw==">>},
                              {mac,
                               <<"88VQXOIVfyUC4fCDlttiZJtlD/s=">>}]}}]}]}]}
[ns_server:debug,2021-04-19T19:46:04.121Z,ns_1@127.0.0.1:json_rpc_connection-cbq-engine-cbauth<0.579.0>:json_rpc_connection:handle_info:93]got response: [{<<"id">>,0},{<<"result">>,true},{<<"error">>,null}]
[ns_server:debug,2021-04-19T19:46:04.238Z,ns_1@127.0.0.1:<0.592.0>:service_janitor:maybe_init_simple_service:68]Created initial service map for service `index'
[ns_server:debug,2021-04-19T19:46:04.239Z,ns_1@127.0.0.1:<0.592.0>:service_janitor:maybe_init_simple_service:68]Created initial service map for service `n1ql'
[ns_server:debug,2021-04-19T19:46:04.239Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{local_changes_count,<<"dbb8bee8b38705437e7f5ebc78107bfa">>} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{11,63786080764}}]}]
[ns_server:debug,2021-04-19T19:46:04.239Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{service_map,index} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{2,63786080764}}]},
 'ns_1@127.0.0.1']
[ns_server:debug,2021-04-19T19:46:04.240Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{local_changes_count,<<"dbb8bee8b38705437e7f5ebc78107bfa">>} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{12,63786080764}}]}]
[ns_server:debug,2021-04-19T19:46:04.240Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{service_map,n1ql} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{2,63786080764}}]},
 'ns_1@127.0.0.1']
[ns_server:debug,2021-04-19T19:46:04.240Z,ns_1@127.0.0.1:json_rpc_connection-cbq-engine-cbauth<0.579.0>:json_rpc_connection:handle_call:157]sending jsonrpc call:{[{jsonrpc,<<"2.0">>},
                       {id,1},
                       {method,<<"AuthCacheSvc.UpdateDB">>},
                       {params,
                        [{[{specialUser,<<"@cbq-engine-cbauth">>},
                           {nodes,
                            [{[{host,<<"127.0.0.1">>},
                               {user,<<"_admin">>},
                               {password,"*****"},
                               {ports,
                                [8091,18091,9100,9101,9102,9103,9104,9105,
                                 18092,8092,11207,9999,11210,11211,8093,
                                 18093]},
                               {local,true}]}]},
                           {buckets,[]},
                           {authCheckURL,<<"http://127.0.0.1:8091/_cbauth">>},
                           {permissionCheckURL,
                            <<"http://127.0.0.1:8091/_cbauth/checkPermission">>},
                           {ldapEnabled,true},
                           {permissionsVersion,125619376},
                           {admin,
                            {[{user,<<"Administrator">>},
                              {salt,<<"6fV7COE6Hrv1Slx3m7c7aw==">>},
                              {mac,
                               <<"88VQXOIVfyUC4fCDlttiZJtlD/s=">>}]}}]}]}]}
[ns_server:debug,2021-04-19T19:46:04.241Z,ns_1@127.0.0.1:json_rpc_connection-cbq-engine-cbauth<0.579.0>:json_rpc_connection:handle_info:93]got response: [{<<"id">>,1},{<<"result">>,true},{<<"error">>,null}]
[ns_server:debug,2021-04-19T19:46:04.241Z,ns_1@127.0.0.1:json_rpc_connection-index-cbauth<0.569.0>:json_rpc_connection:handle_call:157]sending jsonrpc call:{[{jsonrpc,<<"2.0">>},
                       {id,1},
                       {method,<<"AuthCacheSvc.UpdateDB">>},
                       {params,
                        [{[{specialUser,<<"@index-cbauth">>},
                           {nodes,
                            [{[{host,<<"127.0.0.1">>},
                               {user,<<"_admin">>},
                               {password,"*****"},
                               {ports,
                                [8091,18091,9100,9101,9102,9103,9104,9105,
                                 18092,8092,11207,9999,11210,11211,8093,
                                 18093]},
                               {local,true}]}]},
                           {buckets,[]},
                           {authCheckURL,<<"http://127.0.0.1:8091/_cbauth">>},
                           {permissionCheckURL,
                            <<"http://127.0.0.1:8091/_cbauth/checkPermission">>},
                           {ldapEnabled,true},
                           {permissionsVersion,125619376},
                           {admin,
                            {[{user,<<"Administrator">>},
                              {salt,<<"6fV7COE6Hrv1Slx3m7c7aw==">>},
                              {mac,
                               <<"88VQXOIVfyUC4fCDlttiZJtlD/s=">>}]}}]}]}]}
[ns_server:debug,2021-04-19T19:46:04.240Z,ns_1@127.0.0.1:ns_config_rep<0.260.0>:ns_config_rep:do_push_keys:321]Replicating some config keys ([{local_changes_count,
                                   <<"dbb8bee8b38705437e7f5ebc78107bfa">>},
                               {service_map,index},
                               {service_map,n1ql}]..)
[ns_server:debug,2021-04-19T19:46:04.259Z,ns_1@127.0.0.1:json_rpc_connection-index-cbauth<0.569.0>:json_rpc_connection:handle_info:93]got response: [{<<"id">>,1},{<<"result">>,true},{<<"error">>,null}]
[ns_server:debug,2021-04-19T19:46:04.260Z,ns_1@127.0.0.1:json_rpc_connection-projector-cbauth<0.558.0>:json_rpc_connection:handle_call:157]sending jsonrpc call:{[{jsonrpc,<<"2.0">>},
                       {id,1},
                       {method,<<"AuthCacheSvc.UpdateDB">>},
                       {params,
                        [{[{specialUser,<<"@projector-cbauth">>},
                           {nodes,
                            [{[{host,<<"127.0.0.1">>},
                               {user,<<"_admin">>},
                               {password,"*****"},
                               {ports,
                                [8091,18091,9100,9101,9102,9103,9104,9105,
                                 18092,8092,11207,9999,11210,11211,8093,
                                 18093]},
                               {local,true}]}]},
                           {buckets,[]},
                           {authCheckURL,<<"http://127.0.0.1:8091/_cbauth">>},
                           {permissionCheckURL,
                            <<"http://127.0.0.1:8091/_cbauth/checkPermission">>},
                           {ldapEnabled,true},
                           {permissionsVersion,125619376},
                           {admin,
                            {[{user,<<"Administrator">>},
                              {salt,<<"6fV7COE6Hrv1Slx3m7c7aw==">>},
                              {mac,
                               <<"88VQXOIVfyUC4fCDlttiZJtlD/s=">>}]}}]}]}]}
[ns_server:debug,2021-04-19T19:46:04.261Z,ns_1@127.0.0.1:json_rpc_connection-projector-cbauth<0.558.0>:json_rpc_connection:handle_info:93]got response: [{<<"id">>,1},{<<"result">>,true},{<<"error">>,null}]
[ns_server:debug,2021-04-19T19:46:04.261Z,ns_1@127.0.0.1:json_rpc_connection-goxdcr-cbauth<0.439.0>:json_rpc_connection:handle_call:157]sending jsonrpc call:{[{jsonrpc,<<"2.0">>},
                       {id,2},
                       {method,<<"AuthCacheSvc.UpdateDB">>},
                       {params,
                        [{[{specialUser,<<"@goxdcr-cbauth">>},
                           {nodes,
                            [{[{host,<<"127.0.0.1">>},
                               {user,<<"_admin">>},
                               {password,"*****"},
                               {ports,
                                [8091,18091,9100,9101,9102,9103,9104,9105,
                                 18092,8092,11207,9999,11210,11211,8093,
                                 18093]},
                               {local,true}]}]},
                           {buckets,[]},
                           {authCheckURL,<<"http://127.0.0.1:8091/_cbauth">>},
                           {permissionCheckURL,
                            <<"http://127.0.0.1:8091/_cbauth/checkPermission">>},
                           {ldapEnabled,true},
                           {permissionsVersion,125619376},
                           {admin,
                            {[{user,<<"Administrator">>},
                              {salt,<<"6fV7COE6Hrv1Slx3m7c7aw==">>},
                              {mac,
                               <<"88VQXOIVfyUC4fCDlttiZJtlD/s=">>}]}}]}]}]}
[ns_server:debug,2021-04-19T19:46:04.263Z,ns_1@127.0.0.1:json_rpc_connection-goxdcr-cbauth<0.439.0>:json_rpc_connection:handle_info:93]got response: [{<<"id">>,2},{<<"result">>,true},{<<"error">>,null}]
[ns_server:debug,2021-04-19T19:46:24.200Z,ns_1@127.0.0.1:compaction_new_daemon<0.402.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:46:24.200Z,ns_1@127.0.0.1:compaction_new_daemon<0.402.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:46:24.200Z,ns_1@127.0.0.1:compaction_new_daemon<0.402.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:46:24.201Z,ns_1@127.0.0.1:compaction_new_daemon<0.402.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[error_logger:info,2021-04-19T19:46:53.922Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.978.0>},
                       {name,disk_log_sup},
                       {mfargs,{disk_log_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:46:53.923Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.979.0>},
                       {name,disk_log_server},
                       {mfargs,{disk_log_server,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:46:54.201Z,ns_1@127.0.0.1:compaction_new_daemon<0.402.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:46:54.202Z,ns_1@127.0.0.1:compaction_new_daemon<0.402.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:46:54.202Z,ns_1@127.0.0.1:compaction_new_daemon<0.402.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:46:54.202Z,ns_1@127.0.0.1:compaction_new_daemon<0.402.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:47:24.203Z,ns_1@127.0.0.1:compaction_new_daemon<0.402.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:47:24.203Z,ns_1@127.0.0.1:compaction_new_daemon<0.402.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:47:24.203Z,ns_1@127.0.0.1:compaction_new_daemon<0.402.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:47:24.203Z,ns_1@127.0.0.1:compaction_new_daemon<0.402.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:47:54.205Z,ns_1@127.0.0.1:compaction_new_daemon<0.402.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:47:54.205Z,ns_1@127.0.0.1:compaction_new_daemon<0.402.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:47:54.205Z,ns_1@127.0.0.1:compaction_new_daemon<0.402.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:47:54.205Z,ns_1@127.0.0.1:compaction_new_daemon<0.402.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:48:24.206Z,ns_1@127.0.0.1:compaction_new_daemon<0.402.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:48:24.206Z,ns_1@127.0.0.1:compaction_new_daemon<0.402.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:48:24.207Z,ns_1@127.0.0.1:compaction_new_daemon<0.402.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:48:24.207Z,ns_1@127.0.0.1:compaction_new_daemon<0.402.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:info,2021-04-19T19:52:19.012Z,nonode@nohost:<0.88.0>:ns_server:init_logging:151]Started & configured logging
[ns_server:info,2021-04-19T19:52:19.027Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]Static config terms:
[{error_logger_mf_dir,"/opt/couchbase/var/lib/couchbase/logs"},
 {path_config_bindir,"/opt/couchbase/bin"},
 {path_config_etcdir,"/opt/couchbase/etc/couchbase"},
 {path_config_libdir,"/opt/couchbase/lib"},
 {path_config_datadir,"/opt/couchbase/var/lib/couchbase"},
 {path_config_tmpdir,"/opt/couchbase/var/lib/couchbase/tmp"},
 {path_config_secdir,"/opt/couchbase/etc/security"},
 {nodefile,"/opt/couchbase/var/lib/couchbase/couchbase-server.node"},
 {loglevel_default,debug},
 {loglevel_couchdb,info},
 {loglevel_ns_server,debug},
 {loglevel_error_logger,debug},
 {loglevel_user,debug},
 {loglevel_menelaus,debug},
 {loglevel_ns_doctor,debug},
 {loglevel_stats,debug},
 {loglevel_rebalance,debug},
 {loglevel_cluster,debug},
 {loglevel_views,debug},
 {loglevel_mapreduce_errors,debug},
 {loglevel_xdcr,debug},
 {loglevel_xdcr_trace,error},
 {loglevel_access,info},
 {disk_sink_opts,
     [{rotation,
          [{compress,true},
           {size,41943040},
           {num_files,10},
           {buffer_size_max,52428800}]}]},
 {disk_sink_opts_xdcr_trace,
     [{rotation,[{compress,false},{size,83886080},{num_files,5}]}]},
 {net_kernel_verbosity,10}]
[ns_server:warn,2021-04-19T19:52:19.027Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter error_logger_mf_dir, which is given from command line
[ns_server:warn,2021-04-19T19:52:19.027Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter path_config_bindir, which is given from command line
[ns_server:warn,2021-04-19T19:52:19.027Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter path_config_etcdir, which is given from command line
[ns_server:warn,2021-04-19T19:52:19.027Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter path_config_libdir, which is given from command line
[ns_server:warn,2021-04-19T19:52:19.027Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter path_config_datadir, which is given from command line
[ns_server:warn,2021-04-19T19:52:19.027Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter path_config_tmpdir, which is given from command line
[ns_server:warn,2021-04-19T19:52:19.027Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter path_config_secdir, which is given from command line
[ns_server:warn,2021-04-19T19:52:19.027Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter nodefile, which is given from command line
[ns_server:warn,2021-04-19T19:52:19.027Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_default, which is given from command line
[ns_server:warn,2021-04-19T19:52:19.027Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_couchdb, which is given from command line
[ns_server:warn,2021-04-19T19:52:19.027Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_ns_server, which is given from command line
[ns_server:warn,2021-04-19T19:52:19.027Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_error_logger, which is given from command line
[ns_server:warn,2021-04-19T19:52:19.027Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_user, which is given from command line
[ns_server:warn,2021-04-19T19:52:19.027Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_menelaus, which is given from command line
[ns_server:warn,2021-04-19T19:52:19.028Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_ns_doctor, which is given from command line
[ns_server:warn,2021-04-19T19:52:19.028Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_stats, which is given from command line
[ns_server:warn,2021-04-19T19:52:19.028Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_rebalance, which is given from command line
[ns_server:warn,2021-04-19T19:52:19.028Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_cluster, which is given from command line
[ns_server:warn,2021-04-19T19:52:19.028Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_views, which is given from command line
[ns_server:warn,2021-04-19T19:52:19.028Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_mapreduce_errors, which is given from command line
[ns_server:warn,2021-04-19T19:52:19.028Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_xdcr, which is given from command line
[ns_server:warn,2021-04-19T19:52:19.028Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_xdcr_trace, which is given from command line
[ns_server:warn,2021-04-19T19:52:19.028Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_access, which is given from command line
[ns_server:warn,2021-04-19T19:52:19.028Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter disk_sink_opts, which is given from command line
[ns_server:warn,2021-04-19T19:52:19.028Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter disk_sink_opts_xdcr_trace, which is given from command line
[ns_server:warn,2021-04-19T19:52:19.028Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter net_kernel_verbosity, which is given from command line
[error_logger:info,2021-04-19T19:52:19.034Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.128.0>},
                       {name,local_tasks},
                       {mfargs,{local_tasks,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:52:19.040Z,nonode@nohost:ns_server_cluster_sup<0.127.0>:log_os_info:start_link:25]OS type: {unix,linux} Version: {4,19,128}
Runtime info: [{otp_release,"R16B03-1"},
               {erl_version,"5.10.4.0.0.1"},
               {erl_version_long,
                   "Erlang R16B03-1 (erts-5.10.4.0.0.1) [source-00852da] [64-bit] [smp:8:8] [async-threads:16] [kernel-poll:true]\n"},
               {system_arch_raw,"x86_64-unknown-linux-gnu"},
               {system_arch,"x86_64-unknown-linux-gnu"},
               {localtime,{{2021,4,19},{19,52,19}}},
               {memory,
                   [{total,111063792},
                    {processes,9530968},
                    {processes_used,9530064},
                    {system,101532824},
                    {atom,331249},
                    {atom_used,310220},
                    {binary,56536},
                    {code,7694133},
                    {ets,2240656}]},
               {loaded,
                   [ns_info,log_os_info,local_tasks,restartable,
                    ns_server_cluster_sup,calendar,ale_default_formatter,
                    'ale_logger-metakv','ale_logger-rebalance',
                    'ale_logger-xdcr_trace','ale_logger-menelaus',
                    'ale_logger-stats','ale_logger-access',
                    'ale_logger-ns_server','ale_logger-user',
                    'ale_logger-ns_doctor',io_lib_fread,'ale_logger-cluster',
                    'ale_logger-xdcr',otp_internal,ns_log_sink,ale_disk_sink,
                    misc,couch_util,ns_server,filelib,cpu_sup,memsup,disksup,
                    os_mon,io,release_handler,overload,alarm_handler,sasl,
                    timer,tftp_sup,httpd_sup,httpc_handler_sup,httpc_cookie,
                    inets_trace,httpc_manager,httpc,httpc_profile_sup,
                    httpc_sup,ftp_sup,inets_sup,inets_app,ssl,lhttpc_manager,
                    lhttpc_sup,lhttpc,tls_connection_sup,ssl_session_cache,
                    ssl_pkix_db,ssl_manager,ssl_sup,ssl_app,crypto_server,
                    crypto_sup,crypto_app,ale_error_logger_handler,
                    'ale_logger-ale_logger','ale_logger-error_logger',
                    beam_opcodes,beam_dict,beam_asm,beam_validator,beam_z,
                    beam_flatten,beam_trim,beam_receive,beam_bsm,beam_peep,
                    beam_dead,beam_split,beam_type,beam_bool,beam_except,
                    beam_clean,beam_utils,beam_block,beam_jump,beam_a,
                    v3_codegen,v3_life,v3_kernel,sys_core_dsetel,erl_bifs,
                    sys_core_fold,cerl_trees,sys_core_inline,core_lib,cerl,
                    v3_core,erl_bits,erl_expand_records,sys_pre_expand,sofs,
                    erl_internal,sets,ordsets,erl_lint,compile,
                    dynamic_compile,ale_utils,io_lib_pretty,io_lib_format,
                    io_lib,ale_codegen,dict,ale,ale_dynamic_sup,ale_sup,
                    ale_app,epp,ns_bootstrap,child_erlang,file_io_server,
                    orddict,erl_eval,file,c,kernel_config,user_sup,
                    supervisor_bridge,standard_error,code_server,unicode,
                    hipe_unified_loader,gb_sets,ets,binary,code,file_server,
                    net_kernel,global_group,erl_distribution,filename,
                    inet_gethost_native,os,inet_parse,inet,inet_udp,
                    inet_config,inet_db,global,gb_trees,rpc,supervisor,kernel,
                    application_master,sys,application,gen_server,erl_parse,
                    proplists,erl_scan,lists,application_controller,proc_lib,
                    gen,gen_event,error_logger,heart,error_handler,
                    erts_internal,erlang,erl_prim_loader,prim_zip,zlib,
                    prim_file,prim_inet,prim_eval,init,otp_ring0]},
               {applications,
                   [{lhttpc,"Lightweight HTTP Client","1.3.0"},
                    {os_mon,"CPO  CXC 138 46","2.2.14"},
                    {public_key,"Public key infrastructure","0.21"},
                    {asn1,"The Erlang ASN1 compiler version 2.0.4","2.0.4"},
                    {kernel,"ERTS  CXC 138 10","2.16.4"},
                    {ale,"Another Logger for Erlang","4.6.0-3573-enterprise"},
                    {inets,"INETS  CXC 138 49","5.9.8"},
                    {ns_server,"Couchbase server","4.6.0-3573-enterprise"},
                    {crypto,"CRYPTO version 2","3.2"},
                    {ssl,"Erlang/OTP SSL application","5.3.3"},
                    {sasl,"SASL  CXC 138 11","2.3.4"},
                    {stdlib,"ERTS  CXC 138 10","1.19.4"}]},
               {pre_loaded,
                   [erts_internal,erlang,erl_prim_loader,prim_zip,zlib,
                    prim_file,prim_inet,prim_eval,init,otp_ring0]},
               {process_count,94},
               {node,nonode@nohost},
               {nodes,[]},
               {registered,
                   [ftp_sup,'sink-disk_xdcr',code_server,sasl_sup,
                    'sink-disk_debug',application_controller,
                    'sink-disk_error',local_tasks,'sink-disk_default',
                    ale_stats_events,kernel_safe_sup,inets_sup,ale,
                    standard_error,error_logger,lhttpc_sup,ale_sup,
                    lhttpc_manager,timer_server,standard_error_sup,
                    release_handler,httpd_sup,ale_dynamic_sup,overload,
                    alarm_handler,init,inet_db,rex,kernel_sup,'sink-ns_log',
                    global_name_server,sasl_safe_sup,crypto_server,crypto_sup,
                    file_server_2,tftp_sup,global_group,os_mon_sup,
                    'sink-disk_metakv',cpu_sup,tls_connection_sup,memsup,
                    ssl_sup,'sink-disk_access_int',disksup,'sink-disk_access',
                    ns_server_cluster_sup,httpc_sup,ssl_manager,
                    'sink-xdcr_trace',erl_prim_loader,'sink-disk_reports',
                    httpc_profile_sup,'sink-disk_stats',httpc_manager,
                    httpc_handler_sup,'sink-disk_xdcr_errors']},
               {cookie,nocookie},
               {wordsize,8},
               {wall_clock,3}]
[ns_server:info,2021-04-19T19:52:19.052Z,nonode@nohost:ns_server_cluster_sup<0.127.0>:log_os_info:start_link:27]Manifest:
["<?xml version=\"1.0\" encoding=\"UTF-8\"?>","<manifest>",
 "  <remote fetch=\"git://github.com/blevesearch/\" name=\"blevesearch\"/>",
 "  <remote fetch=\"git://github.com/couchbase/\" name=\"couchbase\" review=\"review.couchbase.org\"/>",
 "  <remote fetch=\"ssh://git@github.com/couchbase/\" name=\"couchbase-priv\" review=\"review.couchbase.org\"/>",
 "  <remote fetch=\"git://github.com/couchbasedeps/\" name=\"couchbasedeps\" review=\"review.couchbase.org\"/>",
 "  <remote fetch=\"git://github.com/couchbaselabs/\" name=\"couchbaselabs\" review=\"review.couchbase.org\"/>",
 "  ","  <default remote=\"couchbase\" revision=\"master\"/>","  ",
 "  <project groups=\"notdefault,enterprise\" name=\"backup\" path=\"goproj/src/github.com/couchbase/backup\" remote=\"couchbase-priv\" revision=\"469a5e8cc8661f35ab4af74fe45e92a3d89febed\"/>",
 "  <project name=\"bitset\" path=\"godeps/src/github.com/willf/bitset\" remote=\"couchbasedeps\" revision=\"28a4168144bb8ac95454e1f51c84da1933681ad4\"/>",
 "  <project name=\"blance\" path=\"godeps/src/github.com/couchbase/blance\" revision=\"5ce14d13954e04262b7eabfc6978776a4018402b\"/>",
 "  <project name=\"bleve\" path=\"godeps/src/github.com/blevesearch/bleve\" remote=\"blevesearch\" revision=\"f531835d5c212ee5f95c49d2debc28e65e6d1693\"/>",
 "  <project name=\"bleve-mapping-ui\" path=\"godeps/src/github.com/blevesearch/bleve-mapping-ui\" remote=\"blevesearch\" revision=\"b0453426dc1d59918cc763a970f1ad147b22ad6a\"/>",
 "  <project name=\"blevex\" path=\"godeps/src/github.com/blevesearch/blevex\" remote=\"blevesearch\" revision=\"918d980b0d244c8230c7d8c8ee40919f8d55ef88\"/>",
 "  <project name=\"bolt\" path=\"godeps/src/github.com/boltdb/bolt\" remote=\"couchbasedeps\" revision=\"51f99c862475898df9773747d3accd05a7ca33c1\"/>",
 "  <project name=\"buffer\" path=\"godeps/src/github.com/tdewolff/buffer\" remote=\"couchbasedeps\" revision=\"43cef5ba7b6ce99cc410632dad46cf1c6c97026e\"/>",
 "  <project groups=\"notdefault,build\" name=\"build\" path=\"cbbuild\" revision=\"ccd3ae52bbf0ade5fd59adcedba2b8cbbd16cd9b\">",
 "    <annotation name=\"VERSION\" value=\"4.6.0\"/>",
 "    <annotation name=\"BLD_NUM\" value=\"3573\"/>",
 "    <annotation name=\"RELEASE\" value=\"@RELEASE@\"/>",
 "    <annotation name=\"EDITION\" value=\"@EDITION@\"/>","  </project>",
 "  <project name=\"cbauth\" path=\"godeps/src/github.com/couchbase/cbauth\" revision=\"4a6d537777f57b291a8126f94dfbe3201c1d4efc\"/>",
 "  <project name=\"cbflag\" path=\"godeps/src/github.com/couchbase/cbflag\" revision=\"ce5c10adbb78c1212aefda73a85f8cfd1c3ae7e9\"/>",
 "  <project name=\"cbft\" path=\"goproj/src/github.com/couchbase/cbft\" revision=\"99f44266178dbe423890d8dd5bb9439ef2a71318\"/>",
 "  <project name=\"cbgt\" path=\"goproj/src/github.com/couchbase/cbgt\" revision=\"10790963d9cbada17ebfff728ea9298c1c97b7c5\"/>",
 "  <project groups=\"notdefault,enterprise\" name=\"cbq-gui\" path=\"goproj/src/github.com/couchbase/cbq-gui\" remote=\"couchbase-priv\" revision=\"1e19e5e34b64ca6b43a37de6166dac6e76803848\"/>",
 "  <project name=\"clog\" path=\"godeps/src/github.com/couchbase/clog\" revision=\"eebc98233c3e032eb6b9036575d51324ab5932e6\"/>",
 "  <project name=\"context\" path=\"godeps/src/github.com/gorilla/context\" remote=\"couchbasedeps\" revision=\"215affda49addc4c8ef7e2534915df2c8c35c6cd\"/>",
 "  <project name=\"couchbase-cli\" revision=\"951668b6b2fcaa5386b31d59df5004ff667e91e8\"/>",
 "  <project name=\"couchbase-examples\" revision=\"39ee1c2451ac2f2e86a6ff308e21e1201c49cafe\"/>",
 "  <project name=\"couchdb\" revision=\"7b950cfaa3ad30c75a7fcc7f4eb30b2df1a8bd5b\"/>",
 "  <project groups=\"notdefault,packaging\" name=\"couchdbx-app\" revision=\"be5f6ebaa12ac7c0b5382deb9b1b0efa7bf80497\"/>",
 "  <project groups=\"kv\" name=\"couchstore\" revision=\"9cf71ba60cf95f8b835b1040c68c85a4ddc653ee\"/>",
 "  <project name=\"crypto\" path=\"godeps/src/golang.org/x/crypto\" remote=\"couchbasedeps\" revision=\"f23ba3a5ee43012fcb4b92e1a2a405a92554f4f2\"/>",
 "  <project name=\"cznic-b\" path=\"godeps/src/github.com/cznic/b\" remote=\"couchbasedeps\" revision=\"b96e30f1b7bd34b0b9d8760798d67eca83d7f09e\"/>",
 "  <project name=\"dparval\" path=\"godeps/src/github.com/couchbase/dparval\" revision=\"9def03782da875a2477c05bf64985db3f19f59ae\"/>",
 "  <project groups=\"kv\" name=\"ep-engine\" revision=\"e4c8bcbbf20b52b11e93665901597875e10b2070\"/>",
 "  <project groups=\"kv\" name=\"forestdb\" revision=\"1d169510a5102e81547b1d3dc423eb37db908076\"/>",
 "  <project name=\"geocouch\" revision=\"74b4bab07713b233ca2780f9a9a3f7daa1a1dff4\"/>",
 "  <project name=\"go-bindata-assetfs\" path=\"godeps/src/github.com/elazarl/go-bindata-assetfs\" remote=\"couchbasedeps\" revision=\"57eb5e1fc594ad4b0b1dbea7b286d299e0cb43c2\"/>",
 "  <project name=\"go-couchbase\" path=\"godeps/src/github.com/couchbase/go-couchbase\" revision=\"e06e5adaf45e189d4cf3e471341af0bf80bcc312\"/>",
 "  <project name=\"go-jsonpointer\" path=\"godeps/src/github.com/dustin/go-jsonpointer\" remote=\"couchbasedeps\" revision=\"75939f54b39e7dafae879e61f65438dadc5f288c\"/>",
 "  <project name=\"go-metrics\" path=\"godeps/src/github.com/rcrowley/go-metrics\" remote=\"couchbasedeps\" revision=\"dee209f2455f101a5e4e593dea94872d2c62d85d\"/>",
 "  <project name=\"go-porterstemmer\" path=\"godeps/src/github.com/blevesearch/go-porterstemmer\" remote=\"blevesearch\" revision=\"23a2c8e5cf1f380f27722c6d2ae8896431dc7d0e\"/>",
 "  <project name=\"go-slab\" path=\"godeps/src/github.com/couchbase/go-slab\" revision=\"1f5f7f282713ccfab3f46b1610cb8da34bcf676f\"/>",
 "  <project name=\"go-zookeeper\" path=\"godeps/src/github.com/samuel/go-zookeeper\" remote=\"couchbasedeps\" revision=\"fa6674abf3f4580b946a01bf7a1ce4ba8766205b\"/>",
 "  <project name=\"go_json\" path=\"godeps/src/github.com/couchbase/go_json\" revision=\"f5a178ab380eb9a1911cf9c45b4159115b564169\"/>",
 "  <project name=\"go_n1ql\" path=\"godeps/src/github.com/couchbase/go_n1ql\" revision=\"6cf4e348b127e21f56e53eb8c3faaea56afdc588\"/>",
 "  <project name=\"gocb\" path=\"godeps/src/github.com/couchbase/gocb\" revision=\"d5b1a13c1e81f1255ca8155007b470db37ddeb25\"/>",
 "  <project name=\"godbc\" path=\"godeps/src/github.com/couchbase/godbc\" revision=\"adc62033c392ca9df8b5b42c0dda237576b39f9f\"/>",
 "  <project name=\"goforestdb\" path=\"godeps/src/github.com/couchbase/goforestdb\" revision=\"0b501227de0e8c55d99ed14e900eea1a1dbaf899\"/>",
 "  <project name=\"gojson\" path=\"godeps/src/github.com/dustin/gojson\" remote=\"couchbasedeps\" revision=\"af16e0e771e2ed110f2785564ae33931de8829e4\"/>",
 "  <project name=\"golang-snappy\" path=\"godeps/src/github.com/golang/snappy\" remote=\"couchbasedeps\" revision=\"723cc1e459b8eea2dea4583200fd60757d40097a\"/>",
 "  <project name=\"goleveldb\" path=\"godeps/src/github.com/syndtr/goleveldb\" remote=\"couchbasedeps\" revision=\"fa5b5c78794bc5c18f330361059f871ae8c2b9d6\"/>",
 "  <project name=\"gomemcached\" path=\"godeps/src/github.com/couchbase/gomemcached\" revision=\"4604300463c4a379d36d1427b17d3284a93f7621\"/>",
 "  <project name=\"gometa\" path=\"goproj/src/github.com/couchbase/gometa\" revision=\"7da5634cce1de744293acf27bb2aecc13ee50cc5\"/>",
 "  <project groups=\"kv\" name=\"googletest\" remote=\"couchbasedeps\" revision=\"f397fa5ec6365329b2e82eb2d8c03a7897bbefb5\"/>",
 "  <project name=\"goskiplist\" path=\"godeps/src/github.com/ryszard/goskiplist\" remote=\"couchbasedeps\" revision=\"2dfbae5fcf46374f166f8969cb07e167f1be6273\"/>",
 "  <project name=\"gosnappy\" path=\"godeps/src/github.com/syndtr/gosnappy\" remote=\"couchbasedeps\" revision=\"156a073208e131d7d2e212cb749feae7c339e846\"/>",
 "  <project name=\"goutils\" path=\"godeps/src/github.com/couchbase/goutils\" revision=\"5823a0cbaaa9008406021dc5daf80125ea30bba6\"/>",
 "  <project name=\"goxdcr\" path=\"goproj/src/github.com/couchbase/goxdcr\" revision=\"0f66d74c38453d0c1a620588edb4ee6a8fc22577\"/>",
 "  <project name=\"gtreap\" path=\"godeps/src/github.com/steveyen/gtreap\" remote=\"couchbasedeps\" revision=\"0abe01ef9be25c4aedc174758ec2d917314d6d70\"/>",
 "  <project name=\"indexing\" path=\"goproj/src/github.com/couchbase/indexing\" revision=\"1811cdbff66216861320b7657590e961b10b2c0a\"/>",
 "  <project name=\"levigo\" path=\"godeps/src/github.com/jmhodges/levigo\" remote=\"couchbasedeps\" revision=\"1ddad808d437abb2b8a55a950ec2616caa88969b\"/>",
 "  <project name=\"liner\" path=\"godeps/src/github.com/peterh/liner\" remote=\"couchbasedeps\" revision=\"ad1edfd30321d8f006ccf05f1e0524adeb943060\"/>",
 "  <project name=\"liner\" path=\"godeps/src/github.com/sbinet/liner\" remote=\"couchbasedeps\" revision=\"d9335eee40a45a4f5d74524c90040d6fe6013d50\"/>",
 "  <project groups=\"kv\" name=\"memcached\" revision=\"45a464250e1358593fa9f11ec010ddd992f0a717\"/>",
 "  <project name=\"minify\" path=\"godeps/src/github.com/tdewolff/minify\" remote=\"couchbasedeps\" revision=\"ede45cc53f43891267b1fe7c689db9c76d4ce0fb\"/>",
 "  <project name=\"mmap-go\" path=\"godeps/src/github.com/edsrzf/mmap-go\" remote=\"couchbasedeps\" revision=\"935e0e8a636ca4ba70b713f3e38a19e1b77739e8\"/>",
 "  <project name=\"moss\" path=\"godeps/src/github.com/couchbase/moss\" revision=\"c7cc82a67cf3fe50faf9a0697516b885e4fa34b9\"/>",
 "  <project groups=\"kv\" name=\"moxi\" revision=\"363c250e6087a61bf2d4bc8d6eff3325956be731\"/>",
 "  <project name=\"mux\" path=\"godeps/src/github.com/gorilla/mux\" remote=\"couchbasedeps\" revision=\"8a875a034c69b940914d83ea03d3f1299b4d094b\"/>",
 "  <project name=\"net\" path=\"godeps/src/golang.org/x/net\" remote=\"couchbasedeps\" revision=\"8968c61983e8f51a91b8c0ef25bf739278c89634\"/>",
 "  <project name=\"npipe\" path=\"godeps/src/github.com/natefinch/npipe\" remote=\"couchbasedeps\" revision=\"272c8150302e83f23d32a355364578c9c13ab20f\"/>",
 "  <project name=\"ns_server\" revision=\"b6c99dc71308f44261bbcc80688de02942d69f19\"/>",
 "  <project name=\"parse\" path=\"godeps/src/github.com/tdewolff/parse\" remote=\"couchbasedeps\" revision=\"0334a869253aca4b3a10c56c3f3139b394aec3a9\"/>",
 "  <project groups=\"kv\" name=\"platform\" revision=\"a80097d53c779b548d8c78b0a1886b8d44591b23\"/>",
 "  <project name=\"protobuf\" path=\"godeps/src/github.com/golang/protobuf\" remote=\"couchbasedeps\" revision=\"655cdfa588ea190e901bc5590e65d5621688847c\"/>",
 "  <project name=\"query\" path=\"goproj/src/github.com/couchbase/query\" revision=\"2012f9b883199299df53dec638a2b91c21907a53\"/>",
 "  <project name=\"query-ui\" revision=\"ff1f502b2f0c544ca68d2bda60d80fc3a01d573a\"/>",
 "  <project name=\"retriever\" path=\"godeps/src/github.com/couchbase/retriever\" revision=\"e3419088e4d3b4fe3aad3b364fdbe9a154f85f17\"/>",
 "  <project name=\"segment\" path=\"godeps/src/github.com/blevesearch/segment\" remote=\"blevesearch\" revision=\"db70c57796cc8c310613541dfade3dce627d09c7\"/>",
 "  <project groups=\"kv\" name=\"sigar\" revision=\"83bd88595f558987731a1baa3330f641bc36554c\"/>",
 "  <project name=\"strconv\" path=\"godeps/src/github.com/tdewolff/strconv\" remote=\"couchbasedeps\" revision=\"9b189f5be77f33c46776f24dbddb2a7ab32af214\"/>",
 "  <project groups=\"kv\" name=\"subjson\" revision=\"65d3f053e2d968aea00b60234a42e1d1c5b9f6d2\"/>",
 "  <project groups=\"solaris,notdefault\" name=\"sys\" path=\"godeps/src/golang.org/x/sys\" remote=\"couchbasedeps\" revision=\"9d4e42a20653790449273b3c85e67d6d8bae6e2e\"/>",
 "  <project name=\"testrunner\" revision=\"d63ed33d4130ecac236711b4156d41328728e42e\"/>",
 "  <project name=\"text\" path=\"godeps/src/golang.org/x/text\" remote=\"couchbasedeps\" revision=\"601048ad6acbab6cedd582db09b8c4839ff25b15\"/>",
 "  <project groups=\"kv\" name=\"tlm\" revision=\"29fafd6b365e58e9fc43fad749ce20c900890a6b\">",
 "    <copyfile dest=\"GNUmakefile\" src=\"GNUmakefile\"/>",
 "    <copyfile dest=\"Makefile\" src=\"Makefile\"/>",
 "    <copyfile dest=\"CMakeLists.txt\" src=\"CMakeLists.txt\"/>",
 "  </project>",
 "  <project name=\"ts\" path=\"godeps/src/github.com/olekukonko/ts\" remote=\"couchbasedeps\" revision=\"ecf753e7c962639ab5a1fb46f7da627d4c0a04b8\"/>",
 "  <project groups=\"notdefault,packaging\" name=\"voltron\" remote=\"couchbase-priv\" revision=\"876e25cffb99e0ae89078a0443b179bcb5d639c2\"/>",
 "</manifest>"]

[error_logger:info,2021-04-19T19:52:19.057Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.129.0>},
                       {name,timeout_diag_logger},
                       {mfargs,{timeout_diag_logger,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:52:19.060Z,nonode@nohost:dist_manager<0.130.0>:dist_manager:read_address_config_from_path:86]Reading ip config from "/opt/couchbase/var/lib/couchbase/ip_start"
[ns_server:info,2021-04-19T19:52:19.061Z,nonode@nohost:dist_manager<0.130.0>:dist_manager:read_address_config_from_path:86]Reading ip config from "/opt/couchbase/var/lib/couchbase/ip"
[ns_server:info,2021-04-19T19:52:19.062Z,nonode@nohost:dist_manager<0.130.0>:dist_manager:init:163]ip config not found. Looks like we're brand new node
[error_logger:info,2021-04-19T19:52:19.062Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,inet_gethost_native_sup}
             started: [{pid,<0.132.0>},{mfa,{inet_gethost_native,init,[[]]}}]

[error_logger:info,2021-04-19T19:52:19.063Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.131.0>},
                       {name,inet_gethost_native_sup},
                       {mfargs,{inet_gethost_native,start_link,[]}},
                       {restart_type,temporary},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:52:19.752Z,nonode@nohost:dist_manager<0.130.0>:dist_manager:bringup:214]Attempting to bring up net_kernel with name 'ns_1@127.0.0.1'
[error_logger:info,2021-04-19T19:52:19.762Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.134.0>},
                       {name,erl_epmd},
                       {mfargs,{erl_epmd,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:19.762Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.135.0>},
                       {name,auth},
                       {mfargs,{auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:19.763Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.136.0>},
                       {name,net_kernel},
                       {mfargs,
                           {net_kernel,start_link,
                               [['ns_1@127.0.0.1',longnames]]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:19.763Z,ns_1@127.0.0.1:dist_manager<0.130.0>:dist_manager:configure_net_kernel:255]Set net_kernel vebosity to 10 -> 0
[error_logger:info,2021-04-19T19:52:19.763Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_sup}
             started: [{pid,<0.133.0>},
                       {name,net_sup_dynamic},
                       {mfargs,
                           {erl_distribution,start_link,
                               [['ns_1@127.0.0.1',longnames]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,supervisor}]

[ns_server:info,2021-04-19T19:52:19.766Z,ns_1@127.0.0.1:dist_manager<0.130.0>:dist_manager:save_node:147]saving node to "/opt/couchbase/var/lib/couchbase/couchbase-server.node"
[ns_server:debug,2021-04-19T19:52:19.783Z,ns_1@127.0.0.1:dist_manager<0.130.0>:dist_manager:bringup:228]Attempted to save node name to disk: ok
[ns_server:debug,2021-04-19T19:52:19.784Z,ns_1@127.0.0.1:dist_manager<0.130.0>:dist_manager:wait_for_node:235]Waiting for connection to node 'babysitter_of_ns_1@127.0.0.1' to be established
[error_logger:info,2021-04-19T19:52:19.784Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'babysitter_of_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:52:19.793Z,ns_1@127.0.0.1:dist_manager<0.130.0>:dist_manager:wait_for_node:244]Observed node 'babysitter_of_ns_1@127.0.0.1' to come up
[error_logger:info,2021-04-19T19:52:19.799Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.130.0>},
                       {name,dist_manager},
                       {mfargs,{dist_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:19.801Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.141.0>},
                       {name,ns_cookie_manager},
                       {mfargs,{ns_cookie_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:19.802Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.142.0>},
                       {name,ns_cluster},
                       {mfargs,{ns_cluster,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:52:19.804Z,ns_1@127.0.0.1:ns_config_sup<0.143.0>:ns_config_sup:init:32]loading static ns_config from "/opt/couchbase/etc/couchbase/config"
[error_logger:info,2021-04-19T19:52:19.804Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.144.0>},
                       {name,ns_config_events},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_config_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:19.805Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.145.0>},
                       {name,ns_config_events_local},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,ns_config_events_local}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:52:19.854Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_config:load_config:1083]Loading static config from "/opt/couchbase/etc/couchbase/config"
[ns_server:info,2021-04-19T19:52:19.862Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_config:load_config:1097]Loading dynamic config from "/opt/couchbase/var/lib/couchbase/config/config.dat"
[ns_server:debug,2021-04-19T19:52:19.878Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_config:load_config:1105]Here's full dynamic config we loaded:
[[{{service_map,n1ql},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{2,63786080764}}]},
    'ns_1@127.0.0.1']},
  {{service_map,index},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{2,63786080764}}]},
    'ns_1@127.0.0.1']},
  {{metakv,<<"/indexing/settings/config">>},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{4,63786080759}}]}|
    <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.log_level\":\"info\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\":200,\"indexer.settings.max_cpu_percent\":0,\"indexer.settings.storage_mode\":\"memory_optimized\",\"indexer.settings.recovery.max_rollbacks\":5,\"indexer.settings.memory_quota\":314572800,\"indexer.settings.compaction.abort_exceed_interval\":false}">>]},
  {uuid,
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080759}}]}|
    <<"aaf7f03de532d2dc46a1e96329b1eb02">>]},
  {rest_creds,
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{2,63786080759}}]}|
    {"Administrator",{password,"*****"}}]},
  {rest,[{port,8091}]},
  {{node,'ns_1@127.0.0.1',services},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080759}}]},
    index,kv,n1ql]},
  {memory_quota,
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080759}}]}|
    300]},
  {{node,'ns_1@127.0.0.1',stop_xdcr},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{2,63786080754}}]}|
    '_deleted']},
  {{service_map,fts},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080754}}]}]},
  {goxdcr_upgrade,
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080754}}]}|
    '_deleted']},
  {read_only_user_creds,
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080754}}]}|
    null]},
  {cluster_compat_version,
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{6,63786080754}}]},
    4,6]},
  {otp,
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080753}}]},
    {cookie,{sanitized,<<"Gldz+3QHYFD9UMWZ6D/7VCdFO4es4rvk9HPUTz5soFw=">>}}]},
  {cert_and_pkey,
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080746}}]}|
    {<<"-----BEGIN CERTIFICATE-----\nMIIDAjCCAeqgAwIBAgIIFndZ/+GzDYAwDQYJKoZIhvcNAQELBQAwJDEiMCAGA1UE\nAxMZQ291Y2hiYXNlIFNlcnZlciA4ODFmOWE4YzAeFw0xMzAxMDEwMDAwMDBaFw00\nOTEyMzEyMzU5NTlaMCQxIjAgBgNVBAMTGUNvdWNoYmFzZSBTZXJ2ZXIgODgxZjlh\nOGMwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCz0vvVTMTWH8JLsYfx\nMZ+egYFMFORYbynBjyuWB7+ltQbKZKtnruph7r3agBX8qzQLo1fbuaNJIkb2/TYZ\n7q61KM7aIxCPKBtKs0ms85z8gseSLb3P9dGXLcXHk3KrjUDOO4hh9KPVjY6773bq\nwCjUoqXNBTGySfNZ8Vj6WaDZ1fhxAo6perMdIBIS7TlqPICd7TGWW+Y1BoqljPEy\nYuaym5srhXBN6TvIiUzRGuEjmOnf7mYTj+zEstHhc3TRLgk7NF3vlpVjvVu7UAph\nMWvt5uXp+7tDC40YEzJM7tLU9sWHM46hkUHS95PR+moz9+7V0Su/Ifhb2z+O5eS4\n7HTVAgMBAAGjODA2MA4GA1UdDwEB/wQEAwICpDATBgNVHSUEDDAKBggrBgEFBQcD\nATAPBgNVHRMBAf8EBTADAQH/MA0GCSqGSIb3DQEBCwUAA4IBAQCBpPSeTxLjwYFj\nFuVzvFtSDibDDAXlI9/vqBmcMOJHTFU8M7eGdnL3Wt6GTRQ2m5fbxfz1ez8BvgR1\nUf5i36T9fkDVV5PvS5tjo5u0HGfjmZYpYgagh+Jf6dSzkMcxt/b0W0qeGgUuHxWR\na50a75WQZa0sxyLGKc1ogxykvpBjVETfZaT3JipmtqtyE2ddjddGX4q2mkdVKatI\nQQ8y9zftTlhxwICviP588S7FJ9u1njXVmxwaUSiB1iElOy57WBz+9exdWOhAn3TO\ncDtPcuVHD8GRd0IZ96Yk1mPMDWe99syzNNcpXPDtbgnjqobifQwBXIdA7OS+fDnc\nULaceJqi\n-----END CERTIFICATE-----\n">>,
     <<"*****">>}]},
  {alert_limits,
   [{max_overhead_perc,50},{max_disk_used,90},{max_indexer_ram,75}]},
  {audit,
   [{auditd_enabled,false},
    {rotate_interval,86400},
    {rotate_size,20971520},
    {disabled,[]},
    {sync,[]},
    {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]},
  {auto_failover_cfg,[{enabled,false},{timeout,120},{max_nodes,1},{count,0}]},
  {autocompaction,
   [{database_fragmentation_threshold,{30,undefined}},
    {view_fragmentation_threshold,{30,undefined}}]},
  {buckets,[{configs,[]}]},
  {drop_request_memory_threshold_mib,undefined},
  {email_alerts,
   [{recipients,["root@localhost"]},
    {sender,"couchbase@localhost"},
    {enabled,false},
    {email_server,
     [{user,[]},{pass,"*****"},{host,"localhost"},{port,25},{encrypt,false}]},
    {alerts,
     [auto_failover_node,auto_failover_maximum_reached,
      auto_failover_other_nodes_down,auto_failover_cluster_too_small,
      auto_failover_disabled,ip,disk,overhead,ep_oom_errors,
      ep_item_commit_failed,audit_dropped_events,indexer_ram_max_usage,
      ep_clock_cas_drift_threshold_exceeded]}]},
  {fts_memory_quota,512},
  {index_aware_rebalance_disabled,false},
  {max_bucket_count,10},
  {memcached,[]},
  {nodes_wanted,['ns_1@127.0.0.1']},
  {remote_clusters,[]},
  {replication,[{enabled,true}]},
  {roles_definitions,
   [{admin,[],
     [{name,<<"Admin">>},
      {desc,<<"Can manage ALL cluster features including security.">>}],
     [{[],all}]},
    {ro_admin,[],
     [{name,<<"Read Only Admin">>},
      {desc,<<"Can view ALL cluster features.">>}],
     [{[{bucket,any},password],none},
      {[{bucket,any},data],none},
      {[admin,security],[read]},
      {[admin],none},
      {[],[read]}]},
    {cluster_admin,[],
     [{name,<<"Cluster Admin">>},
      {desc,<<"Can manage all cluster features EXCEPT security.">>}],
     [{[admin],none},{[],all}]},
    {bucket_admin,
     [bucket_name],
     [{name,<<"Bucket Admin">>},
      {desc,
       <<"Can manage ALL bucket features for specified buckets (incl. start/stop XDCR)">>}],
     [{[{bucket,bucket_name},xdcr],[read,execute]},
      {[{bucket,bucket_name}],all},
      {[{bucket,any},settings],[read]},
      {[{bucket,any}],none},
      {[xdcr],none},
      {[admin],none},
      {[],[read]}]},
    {bucket_sasl,
     [bucket_name],
     [],
     [{[{bucket,bucket_name},data],all},
      {[{bucket,bucket_name},views],all},
      {[{bucket,bucket_name}],[read,flush]},
      {[pools],[read]}]},
    {views_admin,
     [bucket_name],
     [{name,<<"Views Admin">>},
      {desc,<<"Can manage views for specified buckets">>}],
     [{[{bucket,bucket_name},views],all},
      {[{bucket,bucket_name},data],[read]},
      {[{bucket,any},settings],[read]},
      {[{bucket,any}],none},
      {[xdcr],none},
      {[admin],none},
      {[],[read]}]},
    {replication_admin,[],
     [{name,<<"Replication Admin">>},
      {desc,<<"Can manage ONLY XDCR features (cluster AND bucket level)">>}],
     [{[{bucket,any},xdcr],all},
      {[{bucket,any},data],[read]},
      {[{bucket,any},settings],[read]},
      {[{bucket,any}],none},
      {[xdcr],all},
      {[admin],none},
      {[],[read]}]}]},
  {server_groups,
   [[{uuid,<<"0">>},{name,<<"Group 1">>},{nodes,['ns_1@127.0.0.1']}]]},
  {set_view_update_daemon,
   [{update_interval,5000},
    {update_min_changes,5000},
    {replica_update_min_changes,5000}]},
  {{couchdb,max_parallel_indexers},4},
  {{couchdb,max_parallel_replica_indexers},2},
  {{request_limit,capi},undefined},
  {{request_limit,rest},undefined},
  {{node,'ns_1@127.0.0.1',audit},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}]},
  {{node,'ns_1@127.0.0.1',capi_port},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    8092]},
  {{node,'ns_1@127.0.0.1',compaction_daemon},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
    {check_interval,30},
    {min_db_file_size,131072},
    {min_view_file_size,20971520}]},
  {{node,'ns_1@127.0.0.1',config_version},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    {4,5}]},
  {{node,'ns_1@127.0.0.1',fts_http_port},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    8094]},
  {{node,'ns_1@127.0.0.1',indexer_admin_port},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    9100]},
  {{node,'ns_1@127.0.0.1',indexer_http_port},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    9102]},
  {{node,'ns_1@127.0.0.1',indexer_scan_port},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    9101]},
  {{node,'ns_1@127.0.0.1',indexer_stcatchup_port},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    9104]},
  {{node,'ns_1@127.0.0.1',indexer_stinit_port},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    9103]},
  {{node,'ns_1@127.0.0.1',indexer_stmaint_port},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    9105]},
  {{node,'ns_1@127.0.0.1',is_enterprise},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    true]},
  {{node,'ns_1@127.0.0.1',isasl},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
    {path,"/opt/couchbase/var/lib/couchbase/isasl.pw"}]},
  {{node,'ns_1@127.0.0.1',ldap_enabled},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    true]},
  {{node,'ns_1@127.0.0.1',membership},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    active]},
  {{node,'ns_1@127.0.0.1',memcached},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
    {port,11210},
    {dedicated_port,11209},
    {ssl_port,11207},
    {admin_user,"_admin"},
    {admin_pass,"*****"},
    {engines,
     [{membase,
       [{engine,"/opt/couchbase/lib/memcached/ep.so"},
        {static_config_string,"failpartialwarmup=false"}]},
      {memcached,
       [{engine,"/opt/couchbase/lib/memcached/default_engine.so"},
        {static_config_string,"vb0=true"}]}]},
    {config_path,"/opt/couchbase/var/lib/couchbase/config/memcached.json"},
    {audit_file,"/opt/couchbase/var/lib/couchbase/config/audit.json"},
    {log_path,"/opt/couchbase/var/lib/couchbase/logs"},
    {log_prefix,"memcached.log"},
    {log_generations,20},
    {log_cyclesize,10485760},
    {log_sleeptime,19},
    {log_rotation_period,39003}]},
  {{node,'ns_1@127.0.0.1',memcached_config},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    {[{interfaces,
       {memcached_config_mgr,omit_missing_mcd_ports,
        [{[{host,<<"*">>},{port,port},{maxconn,maxconn}]},
         {[{host,<<"*">>},
           {port,dedicated_port},
           {maxconn,dedicated_port_maxconn}]},
         {[{host,<<"*">>},
           {port,ssl_port},
           {maxconn,maxconn},
           {ssl,
            {[{key,
               <<"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem">>},
              {cert,
               <<"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem">>}]}}]}]}},
      {ssl_cipher_list,{"~s",[ssl_cipher_list]}},
      {ssl_minimum_protocol,{memcached_config_mgr,ssl_minimum_protocol,[]}},
      {connection_idle_time,connection_idle_time},
      {breakpad,
       {[{enabled,breakpad_enabled},
         {minidump_dir,{memcached_config_mgr,get_minidump_dir,[]}}]}},
      {extensions,
       [{[{module,<<"/opt/couchbase/lib/memcached/stdin_term_handler.so">>},
          {config,<<>>}]},
        {[{module,<<"/opt/couchbase/lib/memcached/file_logger.so">>},
          {config,
           {"cyclesize=~B;sleeptime=~B;filename=~s/~s",
            [log_cyclesize,log_sleeptime,log_path,log_prefix]}}]}]},
      {admin,{"~s",[admin_user]}},
      {verbosity,verbosity},
      {audit_file,{"~s",[audit_file]}},
      {dedupe_nmvb_maps,dedupe_nmvb_maps}]}]},
  {{node,'ns_1@127.0.0.1',memcached_defaults},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
    {maxconn,30000},
    {dedicated_port_maxconn,5000},
    {ssl_cipher_list,"HIGH"},
    {connection_idle_time,0},
    {verbosity,0},
    {breakpad_enabled,true},
    {breakpad_minidump_dir_path,"/opt/couchbase/var/lib/couchbase/crash"},
    {dedupe_nmvb_maps,false}]},
  {{node,'ns_1@127.0.0.1',moxi},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
    {port,11211},
    {verbosity,[]}]},
  {{node,'ns_1@127.0.0.1',ns_log},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
    {filename,"/opt/couchbase/var/lib/couchbase/ns_log"}]},
  {{node,'ns_1@127.0.0.1',port_servers},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}]},
  {{node,'ns_1@127.0.0.1',projector_port},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    9999]},
  {{node,'ns_1@127.0.0.1',query_port},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    8093]},
  {{node,'ns_1@127.0.0.1',rest},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
    {port,8091},
    {port_meta,global}]},
  {{node,'ns_1@127.0.0.1',ssl_capi_port},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    18092]},
  {{node,'ns_1@127.0.0.1',ssl_proxy_downstream_port},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    11214]},
  {{node,'ns_1@127.0.0.1',ssl_proxy_upstream_port},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    11215]},
  {{node,'ns_1@127.0.0.1',ssl_query_port},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    18093]},
  {{node,'ns_1@127.0.0.1',ssl_rest_port},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    18091]},
  {{node,'ns_1@127.0.0.1',uuid},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    <<"dbb8bee8b38705437e7f5ebc78107bfa">>]},
  {{node,'ns_1@127.0.0.1',xdcr_rest_port},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    9998]},
  {{local_changes_count,<<"dbb8bee8b38705437e7f5ebc78107bfa">>},
   [{'_vclock',
     [{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{12,63786080764}}]}]}]]
[ns_server:info,2021-04-19T19:52:19.885Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_config:load_config:1126]Here's full dynamic config we loaded + static & default config:
[{{local_changes_count,<<"dbb8bee8b38705437e7f5ebc78107bfa">>},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{12,63786080764}}]}]},
 {{node,'ns_1@127.0.0.1',xdcr_rest_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   9998]},
 {{node,'ns_1@127.0.0.1',uuid},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   <<"dbb8bee8b38705437e7f5ebc78107bfa">>]},
 {{node,'ns_1@127.0.0.1',ssl_rest_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   18091]},
 {{node,'ns_1@127.0.0.1',ssl_query_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   18093]},
 {{node,'ns_1@127.0.0.1',ssl_proxy_upstream_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   11215]},
 {{node,'ns_1@127.0.0.1',ssl_proxy_downstream_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   11214]},
 {{node,'ns_1@127.0.0.1',ssl_capi_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   18092]},
 {{node,'ns_1@127.0.0.1',rest},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
   {port,8091},
   {port_meta,global}]},
 {{node,'ns_1@127.0.0.1',query_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   8093]},
 {{node,'ns_1@127.0.0.1',projector_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   9999]},
 {{node,'ns_1@127.0.0.1',port_servers},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}]},
 {{node,'ns_1@127.0.0.1',ns_log},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
   {filename,"/opt/couchbase/var/lib/couchbase/ns_log"}]},
 {{node,'ns_1@127.0.0.1',moxi},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
   {port,11211},
   {verbosity,[]}]},
 {{node,'ns_1@127.0.0.1',memcached_defaults},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
   {maxconn,30000},
   {dedicated_port_maxconn,5000},
   {ssl_cipher_list,"HIGH"},
   {connection_idle_time,0},
   {verbosity,0},
   {breakpad_enabled,true},
   {breakpad_minidump_dir_path,"/opt/couchbase/var/lib/couchbase/crash"},
   {dedupe_nmvb_maps,false}]},
 {{node,'ns_1@127.0.0.1',memcached_config},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   {[{interfaces,
      {memcached_config_mgr,omit_missing_mcd_ports,
       [{[{host,<<"*">>},{port,port},{maxconn,maxconn}]},
        {[{host,<<"*">>},
          {port,dedicated_port},
          {maxconn,dedicated_port_maxconn}]},
        {[{host,<<"*">>},
          {port,ssl_port},
          {maxconn,maxconn},
          {ssl,
           {[{key,
              <<"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem">>},
             {cert,
              <<"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem">>}]}}]}]}},
     {ssl_cipher_list,{"~s",[ssl_cipher_list]}},
     {ssl_minimum_protocol,{memcached_config_mgr,ssl_minimum_protocol,[]}},
     {connection_idle_time,connection_idle_time},
     {breakpad,
      {[{enabled,breakpad_enabled},
        {minidump_dir,{memcached_config_mgr,get_minidump_dir,[]}}]}},
     {extensions,
      [{[{module,<<"/opt/couchbase/lib/memcached/stdin_term_handler.so">>},
         {config,<<>>}]},
       {[{module,<<"/opt/couchbase/lib/memcached/file_logger.so">>},
         {config,
          {"cyclesize=~B;sleeptime=~B;filename=~s/~s",
           [log_cyclesize,log_sleeptime,log_path,log_prefix]}}]}]},
     {admin,{"~s",[admin_user]}},
     {verbosity,verbosity},
     {audit_file,{"~s",[audit_file]}},
     {dedupe_nmvb_maps,dedupe_nmvb_maps}]}]},
 {{node,'ns_1@127.0.0.1',memcached},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
   {port,11210},
   {dedicated_port,11209},
   {ssl_port,11207},
   {admin_user,"_admin"},
   {admin_pass,"*****"},
   {engines,
    [{membase,
      [{engine,"/opt/couchbase/lib/memcached/ep.so"},
       {static_config_string,"failpartialwarmup=false"}]},
     {memcached,
      [{engine,"/opt/couchbase/lib/memcached/default_engine.so"},
       {static_config_string,"vb0=true"}]}]},
   {config_path,"/opt/couchbase/var/lib/couchbase/config/memcached.json"},
   {audit_file,"/opt/couchbase/var/lib/couchbase/config/audit.json"},
   {log_path,"/opt/couchbase/var/lib/couchbase/logs"},
   {log_prefix,"memcached.log"},
   {log_generations,20},
   {log_cyclesize,10485760},
   {log_sleeptime,19},
   {log_rotation_period,39003}]},
 {{node,'ns_1@127.0.0.1',membership},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   active]},
 {{node,'ns_1@127.0.0.1',ldap_enabled},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   true]},
 {{node,'ns_1@127.0.0.1',isasl},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
   {path,"/opt/couchbase/var/lib/couchbase/isasl.pw"}]},
 {{node,'ns_1@127.0.0.1',is_enterprise},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   true]},
 {{node,'ns_1@127.0.0.1',indexer_stmaint_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   9105]},
 {{node,'ns_1@127.0.0.1',indexer_stinit_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   9103]},
 {{node,'ns_1@127.0.0.1',indexer_stcatchup_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   9104]},
 {{node,'ns_1@127.0.0.1',indexer_scan_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   9101]},
 {{node,'ns_1@127.0.0.1',indexer_http_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   9102]},
 {{node,'ns_1@127.0.0.1',indexer_admin_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   9100]},
 {{node,'ns_1@127.0.0.1',fts_http_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   8094]},
 {{node,'ns_1@127.0.0.1',config_version},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   {4,5}]},
 {{node,'ns_1@127.0.0.1',compaction_daemon},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
   {check_interval,30},
   {min_db_file_size,131072},
   {min_view_file_size,20971520}]},
 {{node,'ns_1@127.0.0.1',capi_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   8092]},
 {{node,'ns_1@127.0.0.1',audit},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}]},
 {{request_limit,rest},undefined},
 {{request_limit,capi},undefined},
 {{couchdb,max_parallel_replica_indexers},2},
 {{couchdb,max_parallel_indexers},4},
 {set_view_update_daemon,
  [{update_interval,5000},
   {update_min_changes,5000},
   {replica_update_min_changes,5000}]},
 {server_groups,
  [[{uuid,<<"0">>},{name,<<"Group 1">>},{nodes,['ns_1@127.0.0.1']}]]},
 {roles_definitions,
  [{admin,[],
    [{name,<<"Admin">>},
     {desc,<<"Can manage ALL cluster features including security.">>}],
    [{[],all}]},
   {ro_admin,[],
    [{name,<<"Read Only Admin">>},{desc,<<"Can view ALL cluster features.">>}],
    [{[{bucket,any},password],none},
     {[{bucket,any},data],none},
     {[admin,security],[read]},
     {[admin],none},
     {[],[read]}]},
   {cluster_admin,[],
    [{name,<<"Cluster Admin">>},
     {desc,<<"Can manage all cluster features EXCEPT security.">>}],
    [{[admin],none},{[],all}]},
   {bucket_admin,
    [bucket_name],
    [{name,<<"Bucket Admin">>},
     {desc,
      <<"Can manage ALL bucket features for specified buckets (incl. start/stop XDCR)">>}],
    [{[{bucket,bucket_name},xdcr],[read,execute]},
     {[{bucket,bucket_name}],all},
     {[{bucket,any},settings],[read]},
     {[{bucket,any}],none},
     {[xdcr],none},
     {[admin],none},
     {[],[read]}]},
   {bucket_sasl,
    [bucket_name],
    [],
    [{[{bucket,bucket_name},data],all},
     {[{bucket,bucket_name},views],all},
     {[{bucket,bucket_name}],[read,flush]},
     {[pools],[read]}]},
   {views_admin,
    [bucket_name],
    [{name,<<"Views Admin">>},
     {desc,<<"Can manage views for specified buckets">>}],
    [{[{bucket,bucket_name},views],all},
     {[{bucket,bucket_name},data],[read]},
     {[{bucket,any},settings],[read]},
     {[{bucket,any}],none},
     {[xdcr],none},
     {[admin],none},
     {[],[read]}]},
   {replication_admin,[],
    [{name,<<"Replication Admin">>},
     {desc,<<"Can manage ONLY XDCR features (cluster AND bucket level)">>}],
    [{[{bucket,any},xdcr],all},
     {[{bucket,any},data],[read]},
     {[{bucket,any},settings],[read]},
     {[{bucket,any}],none},
     {[xdcr],all},
     {[admin],none},
     {[],[read]}]}]},
 {replication,[{enabled,true}]},
 {remote_clusters,[]},
 {nodes_wanted,['ns_1@127.0.0.1']},
 {memcached,[]},
 {max_bucket_count,10},
 {index_aware_rebalance_disabled,false},
 {fts_memory_quota,512},
 {email_alerts,
  [{recipients,["root@localhost"]},
   {sender,"couchbase@localhost"},
   {enabled,false},
   {email_server,
    [{user,[]},{pass,"*****"},{host,"localhost"},{port,25},{encrypt,false}]},
   {alerts,
    [auto_failover_node,auto_failover_maximum_reached,
     auto_failover_other_nodes_down,auto_failover_cluster_too_small,
     auto_failover_disabled,ip,disk,overhead,ep_oom_errors,
     ep_item_commit_failed,audit_dropped_events,indexer_ram_max_usage,
     ep_clock_cas_drift_threshold_exceeded]}]},
 {drop_request_memory_threshold_mib,undefined},
 {buckets,[{configs,[]}]},
 {autocompaction,
  [{database_fragmentation_threshold,{30,undefined}},
   {view_fragmentation_threshold,{30,undefined}}]},
 {auto_failover_cfg,[{enabled,false},{timeout,120},{max_nodes,1},{count,0}]},
 {audit,
  [{auditd_enabled,false},
   {rotate_interval,86400},
   {rotate_size,20971520},
   {disabled,[]},
   {sync,[]},
   {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]},
 {alert_limits,
  [{max_overhead_perc,50},{max_disk_used,90},{max_indexer_ram,75}]},
 {cert_and_pkey,
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080746}}]}|
   {<<"-----BEGIN CERTIFICATE-----\nMIIDAjCCAeqgAwIBAgIIFndZ/+GzDYAwDQYJKoZIhvcNAQELBQAwJDEiMCAGA1UE\nAxMZQ291Y2hiYXNlIFNlcnZlciA4ODFmOWE4YzAeFw0xMzAxMDEwMDAwMDBaFw00\nOTEyMzEyMzU5NTlaMCQxIjAgBgNVBAMTGUNvdWNoYmFzZSBTZXJ2ZXIgODgxZjlh\nOGMwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCz0vvVTMTWH8JLsYfx\nMZ+egYFMFORYbynBjyuWB7+ltQbKZKtnruph7r3agBX8qzQLo1fbuaNJIkb2/TYZ\n7q61KM7aIxCPKBtKs0ms85z8gseSLb3P9dGXLcXHk3KrjUDOO4hh9KPVjY6773bq\nwCjUoqXNBTGySfNZ8Vj6WaDZ1fhxAo6perMdIBIS7TlqPICd7TGWW+Y1BoqljPEy\nYuaym5srhXBN6TvIiUzRGuEjmOnf7mYTj+zEstHhc3TRLgk7NF3vlpVjvVu7UAph\nMWvt5uXp+7tDC40YEzJM7tLU9sWHM46hkUHS95PR+moz9+7V0Su/Ifhb2z+O5eS4\n7HTVAgMBAAGjODA2MA4GA1UdDwEB/wQEAwICpDATBgNVHSUEDDAKBggrBgEFBQcD\nATAPBgNVHRMBAf8EBTADAQH/MA0GCSqGSIb3DQEBCwUAA4IBAQCBpPSeTxLjwYFj\nFuVzvFtSDibDDAXlI9/vqBmcMOJHTFU8M7eGdnL3Wt6GTRQ2m5fbxfz1ez8BvgR1\nUf5i36T9fkDVV5PvS5tjo5u0HGfjmZYpYgagh+Jf6dSzkMcxt/b0W0qeGgUuHxWR\na50a75WQZa0sxyLGKc1ogxykvpBjVETfZaT3JipmtqtyE2ddjddGX4q2mkdVKatI\nQQ8y9zftTlhxwICviP588S7FJ9u1njXVmxwaUSiB1iElOy57WBz+9exdWOhAn3TO\ncDtPcuVHD8GRd0IZ96Yk1mPMDWe99syzNNcpXPDtbgnjqobifQwBXIdA7OS+fDnc\nULaceJqi\n-----END CERTIFICATE-----\n">>,
    <<"*****">>}]},
 {otp,
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080753}}]},
   {cookie,{sanitized,<<"Gldz+3QHYFD9UMWZ6D/7VCdFO4es4rvk9HPUTz5soFw=">>}}]},
 {cluster_compat_version,
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{6,63786080754}}]},
   4,6]},
 {read_only_user_creds,
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080754}}]}|
   null]},
 {goxdcr_upgrade,
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080754}}]}|
   '_deleted']},
 {{service_map,fts},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080754}}]}]},
 {{node,'ns_1@127.0.0.1',stop_xdcr},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{2,63786080754}}]}|
   '_deleted']},
 {memory_quota,
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080759}}]}|
   300]},
 {{node,'ns_1@127.0.0.1',services},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080759}}]},
   index,kv,n1ql]},
 {rest,[{port,8091}]},
 {rest_creds,
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{2,63786080759}}]}|
   {"Administrator",{password,"*****"}}]},
 {uuid,
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080759}}]}|
   <<"aaf7f03de532d2dc46a1e96329b1eb02">>]},
 {{metakv,<<"/indexing/settings/config">>},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{4,63786080759}}]}|
   <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.log_level\":\"info\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\":200,\"indexer.settings.max_cpu_percent\":0,\"indexer.settings.storage_mode\":\"memory_optimized\",\"indexer.settings.recovery.max_rollbacks\":5,\"indexer.settings.memory_quota\":314572800,\"indexer.settings.compaction.abort_exceed_interval\":false}">>]},
 {{service_map,index},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{2,63786080764}}]},
   'ns_1@127.0.0.1']},
 {{service_map,n1ql},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{2,63786080764}}]},
   'ns_1@127.0.0.1']}]
[error_logger:info,2021-04-19T19:52:19.888Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.146.0>},
                       {name,ns_config},
                       {mfargs,
                           {ns_config,start_link,
                               ["/opt/couchbase/etc/couchbase/config",
                                ns_config_default]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:19.889Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.149.0>},
                       {name,ns_config_remote},
                       {mfargs,
                           {ns_config_replica,start_link,
                               [{local,ns_config_remote}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:19.892Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.150.0>},
                       {name,ns_config_log},
                       {mfargs,{ns_config_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:19.892Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.143.0>},
                       {name,ns_config_sup},
                       {mfargs,{ns_config_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:52:19.894Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.152.0>},
                       {name,vbucket_filter_changes_registry},
                       {mfargs,
                           {ns_process_registry,start_link,
                               [vbucket_filter_changes_registry,
                                [{terminate_command,shutdown}]]}},
                       {restart_type,permanent},
                       {shutdown,100},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:19.896Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.153.0>},
                       {name,json_rpc_connection_sup},
                       {mfargs,{json_rpc_connection_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:52:19.908Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.156.0>},
                       {name,remote_monitors},
                       {mfargs,{remote_monitors,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:19.911Z,ns_1@127.0.0.1:menelaus_barrier<0.157.0>:one_shot_barrier:barrier_body:58]Barrier menelaus_barrier has started
[error_logger:info,2021-04-19T19:52:19.911Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.157.0>},
                       {name,menelaus_barrier},
                       {mfargs,{menelaus_sup,barrier_start_link,[]}},
                       {restart_type,temporary},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:19.911Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.158.0>},
                       {name,rest_lhttpc_pool},
                       {mfargs,
                           {lhttpc_manager,start_link,
                               [[{name,rest_lhttpc_pool},
                                 {connection_timeout,120000},
                                 {pool_size,20}]]}},
                       {restart_type,{permanent,1}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:52:19.942Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.160.0>:ns_ssl_services_setup:init:370]Used ssl options:
[{keyfile,"/opt/couchbase/var/lib/couchbase/config/ssl-cert-key.pem"},
 {certfile,"/opt/couchbase/var/lib/couchbase/config/ssl-cert-key.pem"},
 {versions,[tlsv1,'tlsv1.1','tlsv1.2']},
 {cacertfile,"/opt/couchbase/var/lib/couchbase/config/ssl-cert-key.pem-ca"},
 {dh,<<48,130,1,8,2,130,1,1,0,152,202,99,248,92,201,35,238,246,5,77,93,120,10,
       118,129,36,52,111,193,167,220,49,229,106,105,152,133,121,157,73,158,
       232,153,197,197,21,171,140,30,207,52,165,45,8,221,162,21,199,183,66,
       211,247,51,224,102,214,190,130,96,253,218,193,35,43,139,145,89,200,250,
       145,92,50,80,134,135,188,205,254,148,122,136,237,220,186,147,187,104,
       159,36,147,217,117,74,35,163,145,249,175,242,18,221,124,54,140,16,246,
       169,84,252,45,47,99,136,30,60,189,203,61,86,225,117,255,4,91,46,110,
       167,173,106,51,65,10,248,94,225,223,73,40,232,140,26,11,67,170,118,190,
       67,31,127,233,39,68,88,132,171,224,62,187,207,160,189,209,101,74,8,205,
       174,146,173,80,105,144,246,25,153,86,36,24,178,163,64,202,221,95,184,
       110,244,32,226,217,34,55,188,230,55,16,216,247,173,246,139,76,187,66,
       211,159,17,46,20,18,48,80,27,250,96,189,29,214,234,241,34,69,254,147,
       103,220,133,40,164,84,8,44,241,61,164,151,9,135,41,60,75,4,202,133,173,
       72,6,69,167,89,112,174,40,229,171,2,1,2>>},
 {ciphers,[{dhe_rsa,aes_256_cbc,sha256},
           {dhe_dss,aes_256_cbc,sha256},
           {rsa,aes_256_cbc,sha256},
           {dhe_rsa,aes_128_cbc,sha256},
           {dhe_dss,aes_128_cbc,sha256},
           {rsa,aes_128_cbc,sha256},
           {dhe_rsa,aes_256_cbc,sha},
           {dhe_dss,aes_256_cbc,sha},
           {rsa,aes_256_cbc,sha},
           {dhe_rsa,'3des_ede_cbc',sha},
           {dhe_dss,'3des_ede_cbc',sha},
           {rsa,'3des_ede_cbc',sha},
           {dhe_rsa,aes_128_cbc,sha},
           {dhe_dss,aes_128_cbc,sha},
           {rsa,aes_128_cbc,sha}]}]
[error_logger:info,2021-04-19T19:52:20.061Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_ssl_services_sup}
             started: [{pid,<0.160.0>},
                       {name,ns_ssl_services_setup},
                       {mfargs,{ns_ssl_services_setup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:52:20.097Z,ns_1@127.0.0.1:<0.162.0>:menelaus_pluggable_ui:validate_plugin_spec:117]Loaded pluggable UI specification for fts

[ns_server:info,2021-04-19T19:52:20.097Z,ns_1@127.0.0.1:<0.162.0>:menelaus_pluggable_ui:validate_plugin_spec:117]Loaded pluggable UI specification for n1ql

[ns_server:debug,2021-04-19T19:52:20.119Z,ns_1@127.0.0.1:<0.162.0>:restartable:start_child:98]Started child process <0.164.0>
  MFA: {ns_ssl_services_setup,start_link_rest_service,[]}
[error_logger:info,2021-04-19T19:52:20.119Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_ssl_services_sup}
             started: [{pid,<0.162.0>},
                       {name,ns_rest_ssl_service},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_ssl_services_setup,
                                    start_link_rest_service,[]},
                                1000]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:20.119Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.159.0>},
                       {name,ns_ssl_services_sup},
                       {mfargs,{ns_ssl_services_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2021-04-19T19:52:20.134Z,ns_1@127.0.0.1:wait_link_to_couchdb_node<0.182.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:126]Waiting for ns_couchdb node to start
[error_logger:info,2021-04-19T19:52:20.134Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.181.0>},
                       {name,start_couchdb_node},
                       {mfargs,{ns_server_nodes_sup,start_couchdb_node,[]}},
                       {restart_type,{permanent,5}},
                       {shutdown,86400000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:20.134Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:52:20.135Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:52:20.135Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.185.0>,shutdown}}
[error_logger:info,2021-04-19T19:52:20.135Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:52:20.336Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:52:20.336Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:52:20.336Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.188.0>,shutdown}}
[error_logger:info,2021-04-19T19:52:20.337Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:52:20.537Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:52:20.537Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:52:20.537Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.191.0>,shutdown}}
[error_logger:info,2021-04-19T19:52:20.538Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:52:20.739Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:52:20.739Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:52:20.739Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.194.0>,shutdown}}
[error_logger:info,2021-04-19T19:52:20.740Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:52:20.940Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:52:20.941Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.197.0>,shutdown}}
[ns_server:debug,2021-04-19T19:52:20.941Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:52:20.941Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:52:21.143Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:52:21.145Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.200.0>,shutdown}}
[error_logger:info,2021-04-19T19:52:21.145Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:52:21.145Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:52:21.347Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:52:21.348Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.203.0>,shutdown}}
[ns_server:debug,2021-04-19T19:52:21.348Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:52:21.348Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:52:21.549Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:52:21.553Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:52:21.553Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.206.0>,shutdown}}
[error_logger:info,2021-04-19T19:52:21.553Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:52:21.757Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:52:21.763Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:52:21.763Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.209.0>,shutdown}}
[error_logger:info,2021-04-19T19:52:21.763Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:52:21.964Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:52:21.965Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:52:21.965Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.212.0>,shutdown}}
[error_logger:info,2021-04-19T19:52:21.965Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:52:22.166Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:52:22.166Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:52:22.166Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.215.0>,shutdown}}
[error_logger:info,2021-04-19T19:52:22.167Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:52:22.367Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:52:22.368Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.218.0>,shutdown}}
[ns_server:debug,2021-04-19T19:52:22.368Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:52:22.368Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:52:22.569Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:52:22.570Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.221.0>,shutdown}}
[ns_server:debug,2021-04-19T19:52:22.570Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:52:22.570Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:52:22.771Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:52:22.807Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:52:23.008Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:52:23.209Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:52:23.410Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:52:23.611Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:52:23.813Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:52:24.014Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:52:24.216Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:52:24.417Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[error_logger:info,2021-04-19T19:52:24.858Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.235.0>},
                       {name,timer2_server},
                       {mfargs,{timer2,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:52:25.059Z,ns_1@127.0.0.1:ns_couchdb_port<0.181.0>:ns_port_server:log:210]ns_couchdb<0.181.0>: Apache CouchDB  (LogLevel=info) is starting.

[error_logger:info,2021-04-19T19:52:25.456Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.182.0>},
                       {name,wait_for_couchdb_node},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<ns_server_nodes_sup.0.8580514>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:52:25.475Z,ns_1@127.0.0.1:ns_couchdb_port<0.181.0>:ns_port_server:log:210]ns_couchdb<0.181.0>: Apache CouchDB has started. Time to relax.
ns_couchdb<0.181.0>: 137: Booted. Waiting for shutdown request

[ns_server:debug,2021-04-19T19:52:25.483Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.155.0>:ns_storage_conf:setup_db_and_ix_paths:53]Initialize db_and_ix_paths variable with [{db_path,
                                           "/opt/couchbase/var/lib/couchbase/data"},
                                          {index_path,
                                           "/opt/couchbase/var/lib/couchbase/data"}]
[error_logger:info,2021-04-19T19:52:25.527Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.238.0>},
                       {name,ns_disksup},
                       {mfargs,{ns_disksup,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:25.531Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.239.0>},
                       {name,diag_handler_worker},
                       {mfargs,{work_queue,start_link,[diag_handler_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:52:25.534Z,ns_1@127.0.0.1:ns_server_sup<0.237.0>:dir_size:start_link:39]Starting quick version of dir_size with program name: godu
[error_logger:info,2021-04-19T19:52:25.547Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.240.0>},
                       {name,dir_size},
                       {mfargs,{dir_size,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:25.551Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.241.0>},
                       {name,request_throttler},
                       {mfargs,{request_throttler,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:25.565Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.242.0>},
                       {name,ns_log},
                       {mfargs,{ns_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:25.566Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.243.0>},
                       {name,ns_crash_log_consumer},
                       {mfargs,{ns_log,start_link_crash_consumer,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:25.575Z,ns_1@127.0.0.1:ns_config_isasl_sync<0.244.0>:ns_config_isasl_sync:init:65]isasl_sync init: ["/opt/couchbase/var/lib/couchbase/isasl.pw","_admin"]
[ns_server:debug,2021-04-19T19:52:25.575Z,ns_1@127.0.0.1:ns_config_isasl_sync<0.244.0>:ns_config_isasl_sync:init:73]isasl_sync init buckets: []
[ns_server:debug,2021-04-19T19:52:25.576Z,ns_1@127.0.0.1:ns_config_isasl_sync<0.244.0>:ns_config_isasl_sync:writeSASLConf:145]Writing isasl passwd file: "/opt/couchbase/var/lib/couchbase/isasl.pw"
[ns_server:warn,2021-04-19T19:52:25.604Z,ns_1@127.0.0.1:ns_config_isasl_sync<0.244.0>:ns_memcached:connect:1307]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[error_logger:info,2021-04-19T19:52:26.606Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.244.0>},
                       {name,ns_config_isasl_sync},
                       {mfargs,{ns_config_isasl_sync,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:26.606Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.246.0>},
                       {name,ns_log_events},
                       {mfargs,{gen_event,start_link,[{local,ns_log_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:26.609Z,ns_1@127.0.0.1:ns_node_disco<0.249.0>:ns_node_disco:init:138]Initting ns_node_disco with []
[ns_server:debug,2021-04-19T19:52:26.609Z,ns_1@127.0.0.1:ns_cookie_manager<0.141.0>:ns_cookie_manager:do_cookie_sync:115]ns_cookie_manager do_cookie_sync
[error_logger:info,2021-04-19T19:52:26.609Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.248.0>},
                       {name,ns_node_disco_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,ns_node_disco_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[user:info,2021-04-19T19:52:26.609Z,ns_1@127.0.0.1:ns_cookie_manager<0.141.0>:ns_cookie_manager:do_cookie_sync:134]Node 'ns_1@127.0.0.1' synchronized otp cookie {sanitized,
                                               <<"Gldz+3QHYFD9UMWZ6D/7VCdFO4es4rvk9HPUTz5soFw=">>} from cluster
[ns_server:debug,2021-04-19T19:52:26.609Z,ns_1@127.0.0.1:<0.250.0>:ns_node_disco:do_nodes_wanted_updated_fun:224]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"Gldz+3QHYFD9UMWZ6D/7VCdFO4es4rvk9HPUTz5soFw=">>}
[ns_server:debug,2021-04-19T19:52:26.612Z,ns_1@127.0.0.1:<0.250.0>:ns_node_disco:do_nodes_wanted_updated_fun:230]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"Gldz+3QHYFD9UMWZ6D/7VCdFO4es4rvk9HPUTz5soFw=">>}
[error_logger:info,2021-04-19T19:52:26.612Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.249.0>},
                       {name,ns_node_disco},
                       {mfargs,{ns_node_disco,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:26.614Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.251.0>},
                       {name,ns_node_disco_log},
                       {mfargs,{ns_node_disco_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:26.617Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.252.0>},
                       {name,ns_node_disco_conf_events},
                       {mfargs,{ns_node_disco_conf_events,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:26.620Z,ns_1@127.0.0.1:ns_config_rep<0.254.0>:ns_config_rep:init:68]init pulling
[error_logger:info,2021-04-19T19:52:26.620Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.253.0>},
                       {name,ns_config_rep_merger},
                       {mfargs,{ns_config_rep,start_link_merger,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:26.620Z,ns_1@127.0.0.1:ns_config_rep<0.254.0>:ns_config_rep:init:70]init pushing
[ns_server:debug,2021-04-19T19:52:26.621Z,ns_1@127.0.0.1:ns_config_rep<0.254.0>:ns_config_rep:init:74]init reannouncing
[ns_server:debug,2021-04-19T19:52:26.621Z,ns_1@127.0.0.1:ns_config_events<0.144.0>:ns_node_disco_conf_events:handle_event:44]ns_node_disco_conf_events config on nodes_wanted
[ns_server:debug,2021-04-19T19:52:26.621Z,ns_1@127.0.0.1:ns_config_events<0.144.0>:ns_node_disco_conf_events:handle_event:50]ns_node_disco_conf_events config on otp
[ns_server:debug,2021-04-19T19:52:26.622Z,ns_1@127.0.0.1:ns_cookie_manager<0.141.0>:ns_cookie_manager:do_cookie_sync:115]ns_cookie_manager do_cookie_sync
[ns_server:debug,2021-04-19T19:52:26.622Z,ns_1@127.0.0.1:ns_cookie_manager<0.141.0>:ns_cookie_manager:do_cookie_sync:115]ns_cookie_manager do_cookie_sync
[ns_server:debug,2021-04-19T19:52:26.622Z,ns_1@127.0.0.1:<0.258.0>:ns_node_disco:do_nodes_wanted_updated_fun:224]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"Gldz+3QHYFD9UMWZ6D/7VCdFO4es4rvk9HPUTz5soFw=">>}
[ns_server:debug,2021-04-19T19:52:26.622Z,ns_1@127.0.0.1:<0.259.0>:ns_node_disco:do_nodes_wanted_updated_fun:224]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"Gldz+3QHYFD9UMWZ6D/7VCdFO4es4rvk9HPUTz5soFw=">>}
[ns_server:debug,2021-04-19T19:52:26.622Z,ns_1@127.0.0.1:<0.259.0>:ns_node_disco:do_nodes_wanted_updated_fun:230]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"Gldz+3QHYFD9UMWZ6D/7VCdFO4es4rvk9HPUTz5soFw=">>}
[ns_server:debug,2021-04-19T19:52:26.622Z,ns_1@127.0.0.1:<0.258.0>:ns_node_disco:do_nodes_wanted_updated_fun:230]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"Gldz+3QHYFD9UMWZ6D/7VCdFO4es4rvk9HPUTz5soFw=">>}
[ns_server:debug,2021-04-19T19:52:26.622Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
alert_limits ->
[{max_overhead_perc,50},{max_disk_used,90},{max_indexer_ram,75}]
[ns_server:debug,2021-04-19T19:52:26.622Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
audit ->
[{auditd_enabled,false},
 {rotate_interval,86400},
 {rotate_size,20971520},
 {disabled,[]},
 {sync,[]},
 {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]
[ns_server:debug,2021-04-19T19:52:26.623Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
auto_failover_cfg ->
[{enabled,false},{timeout,120},{max_nodes,1},{count,0}]
[ns_server:debug,2021-04-19T19:52:26.623Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
autocompaction ->
[{database_fragmentation_threshold,{30,undefined}},
 {view_fragmentation_threshold,{30,undefined}}]
[ns_server:debug,2021-04-19T19:52:26.623Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
buckets ->
[[],{configs,[]}]
[ns_server:debug,2021-04-19T19:52:26.623Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
cert_and_pkey ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080746}}]}|
 {<<"-----BEGIN CERTIFICATE-----\nMIIDAjCCAeqgAwIBAgIIFndZ/+GzDYAwDQYJKoZIhvcNAQELBQAwJDEiMCAGA1UE\nAxMZQ291Y2hiYXNlIFNlcnZlciA4ODFmOWE4YzAeFw0xMzAxMDEwMDAwMDBaFw00\nOTEyMzEyMzU5NTlaMCQxIjAgBgNVBAMTGUNvdWNoYmFzZSBTZXJ2ZXIgODgxZjlh\nOGMwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCz0vvVTMTWH8JLsYfx\nMZ+egYFMFORYbynBjyuWB7+ltQbKZKtnruph7r3agBX8qzQLo1fbuaNJIkb2/TYZ\n7q61KM7aIxCPKBtKs0ms85z8gseSLb3"...>>,
  <<"*****">>}]
[ns_server:debug,2021-04-19T19:52:26.623Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
cluster_compat_version ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{6,63786080754}}]},4,6]
[ns_server:debug,2021-04-19T19:52:26.623Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
drop_request_memory_threshold_mib ->
undefined
[ns_server:debug,2021-04-19T19:52:26.624Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
email_alerts ->
[{recipients,["root@localhost"]},
 {sender,"couchbase@localhost"},
 {enabled,false},
 {email_server,[{user,[]},
                {pass,"*****"},
                {host,"localhost"},
                {port,25},
                {encrypt,false}]},
 {alerts,[auto_failover_node,auto_failover_maximum_reached,
          auto_failover_other_nodes_down,auto_failover_cluster_too_small,
          auto_failover_disabled,ip,disk,overhead,ep_oom_errors,
          ep_item_commit_failed,audit_dropped_events,indexer_ram_max_usage,
          ep_clock_cas_drift_threshold_exceeded]}]
[ns_server:debug,2021-04-19T19:52:26.624Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
fts_memory_quota ->
512
[ns_server:debug,2021-04-19T19:52:26.624Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
goxdcr_upgrade ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080754}}]}|
 '_deleted']
[error_logger:info,2021-04-19T19:52:26.624Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.254.0>},
                       {name,ns_config_rep},
                       {mfargs,{ns_config_rep,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:26.624Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
index_aware_rebalance_disabled ->
false
[error_logger:info,2021-04-19T19:52:26.624Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.247.0>},
                       {name,ns_node_disco_sup},
                       {mfargs,{ns_node_disco_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2021-04-19T19:52:26.624Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
max_bucket_count ->
10
[ns_server:debug,2021-04-19T19:52:26.624Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
memcached ->
[]
[ns_server:debug,2021-04-19T19:52:26.624Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
memory_quota ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080759}}]}|300]
[ns_server:debug,2021-04-19T19:52:26.624Z,ns_1@127.0.0.1:ns_config_rep<0.254.0>:ns_config_rep:do_push_keys:321]Replicating some config keys ([alert_limits,audit,auto_failover_cfg,
                               autocompaction,buckets,cert_and_pkey,
                               cluster_compat_version,
                               drop_request_memory_threshold_mib,email_alerts,
                               fts_memory_quota,goxdcr_upgrade,
                               index_aware_rebalance_disabled,
                               max_bucket_count,memcached,memory_quota,
                               nodes_wanted,otp,read_only_user_creds,
                               remote_clusters,replication,rest,rest_creds,
                               roles_definitions,server_groups,
                               set_view_update_daemon,uuid,
                               {couchdb,max_parallel_indexers},
                               {couchdb,max_parallel_replica_indexers},
                               {local_changes_count,
                                   <<"dbb8bee8b38705437e7f5ebc78107bfa">>},
                               {metakv,<<"/indexing/settings/config">>},
                               {request_limit,capi},
                               {request_limit,rest},
                               {service_map,fts},
                               {service_map,index},
                               {service_map,n1ql},
                               {node,'ns_1@127.0.0.1',audit},
                               {node,'ns_1@127.0.0.1',capi_port},
                               {node,'ns_1@127.0.0.1',compaction_daemon},
                               {node,'ns_1@127.0.0.1',config_version},
                               {node,'ns_1@127.0.0.1',fts_http_port},
                               {node,'ns_1@127.0.0.1',indexer_admin_port},
                               {node,'ns_1@127.0.0.1',indexer_http_port},
                               {node,'ns_1@127.0.0.1',indexer_scan_port},
                               {node,'ns_1@127.0.0.1',indexer_stcatchup_port},
                               {node,'ns_1@127.0.0.1',indexer_stinit_port},
                               {node,'ns_1@127.0.0.1',indexer_stmaint_port},
                               {node,'ns_1@127.0.0.1',is_enterprise},
                               {node,'ns_1@127.0.0.1',isasl},
                               {node,'ns_1@127.0.0.1',ldap_enabled},
                               {node,'ns_1@127.0.0.1',membership},
                               {node,'ns_1@127.0.0.1',memcached},
                               {node,'ns_1@127.0.0.1',memcached_config},
                               {node,'ns_1@127.0.0.1',memcached_defaults},
                               {node,'ns_1@127.0.0.1',moxi},
                               {node,'ns_1@127.0.0.1',ns_log},
                               {node,'ns_1@127.0.0.1',port_servers},
                               {node,'ns_1@127.0.0.1',projector_port},
                               {node,'ns_1@127.0.0.1',query_port},
                               {node,'ns_1@127.0.0.1',rest},
                               {node,'ns_1@127.0.0.1',services},
                               {node,'ns_1@127.0.0.1',ssl_capi_port},
                               {node,'ns_1@127.0.0.1',
                                   ssl_proxy_downstream_port},
                               {node,'ns_1@127.0.0.1',ssl_proxy_upstream_port},
                               {node,'ns_1@127.0.0.1',ssl_query_port}]..)
[ns_server:debug,2021-04-19T19:52:26.624Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
nodes_wanted ->
['ns_1@127.0.0.1']
[ns_server:debug,2021-04-19T19:52:26.625Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
otp ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080753}}]},
 {cookie,{sanitized,<<"Gldz+3QHYFD9UMWZ6D/7VCdFO4es4rvk9HPUTz5soFw=">>}}]
[ns_server:debug,2021-04-19T19:52:26.625Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
read_only_user_creds ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080754}}]}|null]
[ns_server:debug,2021-04-19T19:52:26.625Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
remote_clusters ->
[]
[ns_server:debug,2021-04-19T19:52:26.625Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
replication ->
[{enabled,true}]
[ns_server:debug,2021-04-19T19:52:26.625Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
rest ->
[{port,8091}]
[ns_server:debug,2021-04-19T19:52:26.625Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
rest_creds ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{2,63786080759}}]}|
 {"Administrator",{password,"*****"}}]
[ns_server:debug,2021-04-19T19:52:26.626Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
roles_definitions ->
[{admin,[],
        [{name,<<"Admin">>},
         {desc,<<"Can manage ALL cluster features including security.">>}],
        [{[],all}]},
 {ro_admin,[],
           [{name,<<"Read Only Admin">>},
            {desc,<<"Can view ALL cluster features.">>}],
           [{[{bucket,any},password],none},
            {[{bucket,any},data],none},
            {[admin,security],[read]},
            {[admin],none},
            {[],[read]}]},
 {cluster_admin,[],
                [{name,<<"Cluster Admin">>},
                 {desc,<<"Can manage all cluster features EXCEPT security.">>}],
                [{[admin],none},{[],all}]},
 {bucket_admin,[bucket_name],
               [{name,<<"Bucket Admin">>},
                {desc,<<"Can manage ALL bucket features for specified buckets (incl. start/stop XDCR)">>}],
               [{[{bucket,bucket_name},xdcr],[read,execute]},
                {[{bucket,bucket_name}],all},
                {[{bucket,any},settings],[read]},
                {[{bucket,any}],none},
                {[xdcr],none},
                {[admin],none},
                {[],[read]}]},
 {bucket_sasl,[bucket_name],
              [],
              [{[{bucket,bucket_name},data],all},
               {[{bucket,bucket_name},views],all},
               {[{bucket,bucket_name}],[read,flush]},
               {[pools],[read]}]},
 {views_admin,[bucket_name],
              [{name,<<"Views Admin">>},
               {desc,<<"Can manage views for specified buckets">>}],
              [{[{bucket,bucket_name},views],all},
               {[{bucket,bucket_name},data],[read]},
               {[{bucket,any},settings],[read]},
               {[{bucket,any}],none},
               {[xdcr],none},
               {[admin],none},
               {[],[read]}]},
 {replication_admin,[],
                    [{name,<<"Replication Admin">>},
                     {desc,<<"Can manage ONLY XDCR features (cluster AND bucket level)">>}],
                    [{[{bucket,any},xdcr],all},
                     {[{bucket,any},data],[read]},
                     {[{bucket,any},settings],[read]},
                     {[{bucket,any}],none},
                     {[xdcr],all},
                     {[admin],none},
                     {[],[read]}]}]
[ns_server:debug,2021-04-19T19:52:26.626Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
server_groups ->
[[{uuid,<<"0">>},{name,<<"Group 1">>},{nodes,['ns_1@127.0.0.1']}]]
[ns_server:debug,2021-04-19T19:52:26.627Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
set_view_update_daemon ->
[{update_interval,5000},
 {update_min_changes,5000},
 {replica_update_min_changes,5000}]
[ns_server:debug,2021-04-19T19:52:26.627Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
uuid ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080759}}]}|
 <<"aaf7f03de532d2dc46a1e96329b1eb02">>]
[ns_server:debug,2021-04-19T19:52:26.627Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{couchdb,max_parallel_indexers} ->
4
[ns_server:debug,2021-04-19T19:52:26.627Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{couchdb,max_parallel_replica_indexers} ->
2
[error_logger:info,2021-04-19T19:52:26.627Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.262.0>},
                       {name,vbucket_map_mirror},
                       {mfargs,{vbucket_map_mirror,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:26.628Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{local_changes_count,<<"dbb8bee8b38705437e7f5ebc78107bfa">>} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{12,63786080764}}]}]
[ns_server:debug,2021-04-19T19:52:26.628Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{metakv,<<"/indexing/settings/config">>} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{4,63786080759}}]}|
 <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.log_level\":\"info\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\""...>>]
[ns_server:debug,2021-04-19T19:52:26.628Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{request_limit,capi} ->
undefined
[ns_server:debug,2021-04-19T19:52:26.628Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{request_limit,rest} ->
undefined
[ns_server:debug,2021-04-19T19:52:26.628Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{service_map,fts} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080754}}]}]
[ns_server:debug,2021-04-19T19:52:26.629Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{service_map,index} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{2,63786080764}}]},
 'ns_1@127.0.0.1']
[ns_server:debug,2021-04-19T19:52:26.629Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{service_map,n1ql} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{2,63786080764}}]},
 'ns_1@127.0.0.1']
[ns_server:debug,2021-04-19T19:52:26.629Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',audit} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}]
[ns_server:debug,2021-04-19T19:52:26.629Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',capi_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|8092]
[ns_server:debug,2021-04-19T19:52:26.629Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',compaction_daemon} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
 {check_interval,30},
 {min_db_file_size,131072},
 {min_view_file_size,20971520}]
[ns_server:debug,2021-04-19T19:52:26.629Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',config_version} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|{4,5}]
[ns_server:debug,2021-04-19T19:52:26.629Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',fts_http_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|8094]
[ns_server:debug,2021-04-19T19:52:26.630Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',indexer_admin_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|9100]
[ns_server:debug,2021-04-19T19:52:26.630Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',indexer_http_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|9102]
[ns_server:debug,2021-04-19T19:52:26.630Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',indexer_scan_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|9101]
[ns_server:debug,2021-04-19T19:52:26.630Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',indexer_stcatchup_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|9104]
[ns_server:debug,2021-04-19T19:52:26.630Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',indexer_stinit_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|9103]
[ns_server:debug,2021-04-19T19:52:26.630Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',indexer_stmaint_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|9105]
[ns_server:debug,2021-04-19T19:52:26.630Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',is_enterprise} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|true]
[ns_server:debug,2021-04-19T19:52:26.630Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',isasl} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
 {path,"/opt/couchbase/var/lib/couchbase/isasl.pw"}]
[ns_server:debug,2021-04-19T19:52:26.630Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ldap_enabled} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|true]
[ns_server:debug,2021-04-19T19:52:26.631Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',membership} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
 active]
[ns_server:debug,2021-04-19T19:52:26.631Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',memcached} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
 {port,11210},
 {dedicated_port,11209},
 {ssl_port,11207},
 {admin_user,"_admin"},
 {admin_pass,"*****"},
 {engines,[{membase,[{engine,"/opt/couchbase/lib/memcached/ep.so"},
                     {static_config_string,"failpartialwarmup=false"}]},
           {memcached,[{engine,"/opt/couchbase/lib/memcached/default_engine.so"},
                       {static_config_string,"vb0=true"}]}]},
 {config_path,"/opt/couchbase/var/lib/couchbase/config/memcached.json"},
 {audit_file,"/opt/couchbase/var/lib/couchbase/config/audit.json"},
 {log_path,"/opt/couchbase/var/lib/couchbase/logs"},
 {log_prefix,"memcached.log"},
 {log_generations,20},
 {log_cyclesize,10485760},
 {log_sleeptime,19},
 {log_rotation_period,39003}]
[ns_server:debug,2021-04-19T19:52:26.631Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',memcached_config} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
 {[{interfaces,
    {memcached_config_mgr,omit_missing_mcd_ports,
     [{[{host,<<"*">>},{port,port},{maxconn,maxconn}]},
      {[{host,<<"*">>},
        {port,dedicated_port},
        {maxconn,dedicated_port_maxconn}]},
      {[{host,<<"*">>},
        {port,ssl_port},
        {maxconn,maxconn},
        {ssl,
         {[{key,
            <<"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem">>},
           {cert,
            <<"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem">>}]}}]}]}},
   {ssl_cipher_list,{"~s",[ssl_cipher_list]}},
   {ssl_minimum_protocol,{memcached_config_mgr,ssl_minimum_protocol,[]}},
   {connection_idle_time,connection_idle_time},
   {breakpad,
    {[{enabled,breakpad_enabled},
      {minidump_dir,{memcached_config_mgr,get_minidump_dir,[]}}]}},
   {extensions,
    [{[{module,<<"/opt/couchbase/lib/memcached/stdin_term_handler.so">>},
       {config,<<>>}]},
     {[{module,<<"/opt/couchbase/lib/memcached/file_logger.so">>},
       {config,
        {"cyclesize=~B;sleeptime=~B;filename=~s/~s",
         [log_cyclesize,log_sleeptime,log_path,log_prefix]}}]}]},
   {admin,{"~s",[admin_user]}},
   {verbosity,verbosity},
   {audit_file,{"~s",[audit_file]}},
   {dedupe_nmvb_maps,dedupe_nmvb_maps}]}]
[ns_server:debug,2021-04-19T19:52:26.632Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',memcached_defaults} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
 {maxconn,30000},
 {dedicated_port_maxconn,5000},
 {ssl_cipher_list,"HIGH"},
 {connection_idle_time,0},
 {verbosity,0},
 {breakpad_enabled,true},
 {breakpad_minidump_dir_path,"/opt/couchbase/var/lib/couchbase/crash"},
 {dedupe_nmvb_maps,false}]
[ns_server:debug,2021-04-19T19:52:26.632Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',moxi} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
 {port,11211},
 {verbosity,[]}]
[ns_server:debug,2021-04-19T19:52:26.632Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ns_log} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
 {filename,"/opt/couchbase/var/lib/couchbase/ns_log"}]
[ns_server:debug,2021-04-19T19:52:26.632Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',port_servers} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}]
[ns_server:debug,2021-04-19T19:52:26.632Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',projector_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|9999]
[error_logger:info,2021-04-19T19:52:26.632Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.264.0>},
                       {name,bucket_info_cache},
                       {mfargs,{bucket_info_cache,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:26.633Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',query_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|8093]
[ns_server:debug,2021-04-19T19:52:26.633Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',rest} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
 {port,8091},
 {port_meta,global}]
[error_logger:info,2021-04-19T19:52:26.633Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.267.0>},
                       {name,ns_tick_event},
                       {mfargs,{gen_event,start_link,[{local,ns_tick_event}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:26.633Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',services} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080759}}]},
 index,kv,n1ql]
[ns_server:debug,2021-04-19T19:52:26.633Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ssl_capi_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|18092]
[error_logger:info,2021-04-19T19:52:26.633Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.268.0>},
                       {name,buckets_events},
                       {mfargs,
                           {gen_event,start_link,[{local,buckets_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:26.633Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ssl_proxy_downstream_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|11214]
[ns_server:debug,2021-04-19T19:52:26.633Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ssl_proxy_upstream_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|11215]
[ns_server:debug,2021-04-19T19:52:26.633Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ssl_query_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|18093]
[ns_server:debug,2021-04-19T19:52:26.633Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ssl_rest_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|18091]
[ns_server:debug,2021-04-19T19:52:26.634Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',stop_xdcr} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{2,63786080754}}]}|
 '_deleted']
[ns_server:debug,2021-04-19T19:52:26.634Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',uuid} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
 <<"dbb8bee8b38705437e7f5ebc78107bfa">>]
[ns_server:debug,2021-04-19T19:52:26.634Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',xdcr_rest_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|9998]
[ns_server:debug,2021-04-19T19:52:26.639Z,ns_1@127.0.0.1:ns_log_events<0.246.0>:ns_mail_log:init:44]ns_mail_log started up
[error_logger:info,2021-04-19T19:52:26.638Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_mail_sup}
             started: [{pid,<0.270.0>},
                       {name,ns_mail_log},
                       {mfargs,{ns_mail_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:26.639Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.269.0>},
                       {name,ns_mail_sup},
                       {mfargs,{ns_mail_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:52:26.639Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.271.0>},
                       {name,ns_stats_event},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_stats_event}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:26.641Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.272.0>},
                       {name,samples_loader_tasks},
                       {mfargs,{samples_loader_tasks,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:26.648Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_heart_sup}
             started: [{pid,<0.274.0>},
                       {name,ns_heart},
                       {mfargs,{ns_heart,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:26.648Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_heart_sup}
             started: [{pid,<0.277.0>},
                       {name,ns_heart_slow_updater},
                       {mfargs,{ns_heart,start_link_slow_updater,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:26.649Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.273.0>},
                       {name,ns_heart_sup},
                       {mfargs,{ns_heart_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2021-04-19T19:52:26.651Z,ns_1@127.0.0.1:ns_heart<0.274.0>:ns_heart:grab_latest_stats:259]Ignoring failure to grab "@system" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,117}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,255}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,249}]},
                 {ns_heart,update_current_status,1,
                           [{file,"src/ns_heart.erl"},{line,186}]},
                 {ns_heart,handle_info,2,
                           [{file,"src/ns_heart.erl"},{line,118}]}]}}

[ns_server:debug,2021-04-19T19:52:26.652Z,ns_1@127.0.0.1:ns_heart<0.274.0>:ns_heart:grab_latest_stats:259]Ignoring failure to grab "@system-processes" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-processes-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,117}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,255}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,249}]},
                 {ns_heart,update_current_status,1,
                           [{file,"src/ns_heart.erl"},{line,186}]}]}}

[error_logger:info,2021-04-19T19:52:26.654Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_doctor_sup}
             started: [{pid,<0.280.0>},
                       {name,ns_doctor_events},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_doctor_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:26.664Z,ns_1@127.0.0.1:<0.278.0>:restartable:start_child:98]Started child process <0.279.0>
  MFA: {ns_doctor_sup,start_link,[]}
[error_logger:info,2021-04-19T19:52:26.664Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_doctor_sup}
             started: [{pid,<0.281.0>},
                       {name,ns_doctor},
                       {mfargs,{ns_doctor,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:26.664Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.278.0>},
                       {name,ns_doctor_sup},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_doctor_sup,start_link,[]},infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2021-04-19T19:52:26.681Z,ns_1@127.0.0.1:ns_heart<0.274.0>:ns_heart:grab_index_status:373]ignoring failure to get index status: {exit,
                                       {noproc,
                                        {gen_server,call,
                                         ['index_status_keeper-index',
                                          get_status,2000]}}}
[{gen_server,call,3,[{file,"gen_server.erl"},{line,188}]},
 {ns_heart,grab_index_status,0,[{file,"src/ns_heart.erl"},{line,370}]},
 {ns_heart,current_status_slow_inner,0,[{file,"src/ns_heart.erl"},{line,280}]},
 {ns_heart,current_status_slow,1,[{file,"src/ns_heart.erl"},{line,249}]},
 {ns_heart,update_current_status,1,[{file,"src/ns_heart.erl"},{line,186}]},
 {ns_heart,handle_info,2,[{file,"src/ns_heart.erl"},{line,118}]},
 {gen_server,handle_msg,5,[{file,"gen_server.erl"},{line,604}]},
 {proc_lib,init_p_do_apply,3,[{file,"proc_lib.erl"},{line,239}]}]
[ns_server:info,2021-04-19T19:52:26.691Z,ns_1@127.0.0.1:ns_couchdb_port<0.181.0>:ns_port_server:log:210]ns_couchdb<0.181.0>: working as port

[error_logger:info,2021-04-19T19:52:26.703Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.286.0>},
                       {name,disk_log_sup},
                       {mfargs,{disk_log_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:52:26.703Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.287.0>},
                       {name,disk_log_server},
                       {mfargs,{disk_log_server,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:26.719Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.284.0>},
                       {name,remote_clusters_info},
                       {mfargs,{remote_clusters_info,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:26.719Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.290.0>},
                       {name,master_activity_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,master_activity_events}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:26.725Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.291.0>},
                       {name,xdcr_ckpt_store},
                       {mfargs,{simple_store,start_link,[xdcr_ckpt_data]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:26.725Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.292.0>},
                       {name,metakv_worker},
                       {mfargs,{work_queue,start_link,[metakv_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:26.726Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.293.0>},
                       {name,index_events},
                       {mfargs,{gen_event,start_link,[{local,index_events}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:26.734Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.295.0>},
                       {name,index_settings_manager},
                       {mfargs,{index_settings_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:26.743Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.298.0>},
                       {name,menelaus_ui_auth},
                       {mfargs,{menelaus_ui_auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:26.749Z,ns_1@127.0.0.1:ns_heart<0.274.0>:goxdcr_rest:get_from_goxdcr:163]Goxdcr is temporary not available. Return empty list.
[error_logger:info,2021-04-19T19:52:26.751Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.300.0>},
                       {name,menelaus_local_auth},
                       {mfargs,{menelaus_local_auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:26.757Z,ns_1@127.0.0.1:ns_heart<0.274.0>:cluster_logs_collection_task:maybe_build_cluster_logs_task:43]Ignoring exception trying to read cluster_logs_collection_task_status table: error:badarg
[error_logger:info,2021-04-19T19:52:26.761Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.302.0>},
                       {name,menelaus_web_cache},
                       {mfargs,{menelaus_web_cache,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:26.765Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.303.0>},
                       {name,menelaus_stats_gatherer},
                       {mfargs,{menelaus_stats_gatherer,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:26.765Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.304.0>},
                       {name,json_rpc_events},
                       {mfargs,
                           {gen_event,start_link,[{local,json_rpc_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:52:26.773Z,ns_1@127.0.0.1:menelaus_sup<0.297.0>:menelaus_pluggable_ui:validate_plugin_spec:117]Loaded pluggable UI specification for fts

[ns_server:info,2021-04-19T19:52:26.773Z,ns_1@127.0.0.1:menelaus_sup<0.297.0>:menelaus_pluggable_ui:validate_plugin_spec:117]Loaded pluggable UI specification for n1ql

[error_logger:info,2021-04-19T19:52:26.774Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.305.0>},
                       {name,menelaus_web},
                       {mfargs,{menelaus_web,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:26.779Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.322.0>},
                       {name,menelaus_event},
                       {mfargs,{menelaus_event,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:26.780Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.277.0>:ns_heart:grab_latest_stats:259]Ignoring failure to grab "@system" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,117}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,255}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,249}]},
                 {ns_heart,slow_updater_loop,0,
                           [{file,"src/ns_heart.erl"},{line,243}]},
                 {proc_lib,init_p_do_apply,3,
                           [{file,"proc_lib.erl"},{line,239}]}]}}

[ns_server:debug,2021-04-19T19:52:26.781Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.277.0>:ns_heart:grab_latest_stats:259]Ignoring failure to grab "@system-processes" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-processes-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,117}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,255}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,249}]},
                 {ns_heart,slow_updater_loop,0,
                           [{file,"src/ns_heart.erl"},{line,243}]}]}}

[ns_server:debug,2021-04-19T19:52:26.781Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.277.0>:ns_heart:grab_index_status:373]ignoring failure to get index status: {exit,
                                       {noproc,
                                        {gen_server,call,
                                         ['index_status_keeper-index',
                                          get_status,2000]}}}
[{gen_server,call,3,[{file,"gen_server.erl"},{line,188}]},
 {ns_heart,grab_index_status,0,[{file,"src/ns_heart.erl"},{line,370}]},
 {ns_heart,current_status_slow_inner,0,[{file,"src/ns_heart.erl"},{line,280}]},
 {ns_heart,current_status_slow,1,[{file,"src/ns_heart.erl"},{line,249}]},
 {ns_heart,slow_updater_loop,0,[{file,"src/ns_heart.erl"},{line,243}]},
 {proc_lib,init_p_do_apply,3,[{file,"proc_lib.erl"},{line,239}]}]
[ns_server:debug,2021-04-19T19:52:26.783Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.277.0>:goxdcr_rest:get_from_goxdcr:163]Goxdcr is temporary not available. Return empty list.
[ns_server:debug,2021-04-19T19:52:26.783Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.277.0>:cluster_logs_collection_task:maybe_build_cluster_logs_task:43]Ignoring exception trying to read cluster_logs_collection_task_status table: error:badarg
[error_logger:info,2021-04-19T19:52:26.784Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.329.0>},
                       {name,hot_keys_keeper},
                       {mfargs,{hot_keys_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:26.789Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.330.0>},
                       {name,menelaus_web_alerts_srv},
                       {mfargs,{menelaus_web_alerts_srv,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:26.800Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.331.0>},
                       {name,menelaus_cbauth},
                       {mfargs,{menelaus_cbauth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[user:info,2021-04-19T19:52:26.800Z,ns_1@127.0.0.1:ns_server_sup<0.237.0>:menelaus_sup:start_link:46]Couchbase Server has started on web port 8091 on node 'ns_1@127.0.0.1'. Version: "4.6.0-3573-enterprise".
[error_logger:info,2021-04-19T19:52:26.800Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.297.0>},
                       {name,menelaus},
                       {mfargs,{menelaus_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:52:26.801Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.335.0>},
                       {name,ns_ports_setup},
                       {mfargs,{ns_ports_setup,start,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:26.805Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_agent_sup}
             started: [{pid,<0.338.0>},
                       {name,service_agent_children_sup},
                       {mfargs,
                           {supervisor,start_link,
                               [{local,service_agent_children_sup},
                                service_agent_sup,child]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:52:26.805Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_agent_sup}
             started: [{pid,<0.339.0>},
                       {name,service_agent_worker},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<service_agent_sup.0.29791682>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:26.805Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.337.0>},
                       {name,service_agent_sup},
                       {mfargs,{service_agent_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:52:26.829Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.341.0>},
                       {name,ns_memcached_sockets_pool},
                       {mfargs,{ns_memcached_sockets_pool,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:26.829Z,ns_1@127.0.0.1:ns_audit_cfg<0.342.0>:ns_audit_cfg:write_audit_json:158]Writing new content to "/opt/couchbase/var/lib/couchbase/config/audit.json" : [{auditd_enabled,
                                                                                false},
                                                                               {disabled,
                                                                                []},
                                                                               {log_path,
                                                                                "/opt/couchbase/var/lib/couchbase/logs"},
                                                                               {rotate_interval,
                                                                                86400},
                                                                               {rotate_size,
                                                                                20971520},
                                                                               {sync,
                                                                                []},
                                                                               {version,
                                                                                1},
                                                                               {descriptors_path,
                                                                                "/opt/couchbase/etc/security"}]
[ns_server:debug,2021-04-19T19:52:26.844Z,ns_1@127.0.0.1:ns_ports_setup<0.335.0>:ns_ports_manager:set_dynamic_children:54]Setting children [memcached,moxi,projector,indexer,query,saslauthd_port,
                  goxdcr,xdcr_proxy]
[ns_server:debug,2021-04-19T19:52:26.848Z,ns_1@127.0.0.1:ns_audit_cfg<0.342.0>:ns_audit_cfg:handle_info:107]Instruct memcached to reload audit config
[error_logger:info,2021-04-19T19:52:26.848Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.342.0>},
                       {name,ns_audit_cfg},
                       {mfargs,{ns_audit_cfg,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:warn,2021-04-19T19:52:26.849Z,ns_1@127.0.0.1:<0.344.0>:ns_memcached:connect:1307]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[ns_server:debug,2021-04-19T19:52:26.853Z,ns_1@127.0.0.1:memcached_config_mgr<0.346.0>:memcached_config_mgr:init:44]waiting for completion of initial ns_ports_setup round
[error_logger:info,2021-04-19T19:52:26.853Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.346.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:52:26.857Z,ns_1@127.0.0.1:<0.347.0>:ns_memcached_log_rotator:init:28]Starting log rotator on "/opt/couchbase/var/lib/couchbase/logs"/"memcached.log"* with an initial period of 39003ms
[error_logger:info,2021-04-19T19:52:26.858Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.347.0>},
                       {name,ns_memcached_log_rotator},
                       {mfargs,{ns_memcached_log_rotator,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:26.865Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.348.0>},
                       {name,memcached_clients_pool},
                       {mfargs,{memcached_clients_pool,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:26.870Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.349.0>},
                       {name,proxied_memcached_clients_pool},
                       {mfargs,{proxied_memcached_clients_pool,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:26.870Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.350.0>},
                       {name,xdc_lhttpc_pool},
                       {mfargs,
                           {lhttpc_manager,start_link,
                               [[{name,xdc_lhttpc_pool},
                                 {connection_timeout,120000},
                                 {pool_size,200}]]}},
                       {restart_type,{permanent,1}},
                       {shutdown,10000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:26.874Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.351.0>},
                       {name,ns_null_connection_pool},
                       {mfargs,
                           {ns_null_connection_pool,start_link,
                               [ns_null_connection_pool]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:26.883Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {<0.352.0>,xdcr_sup}
             started: [{pid,<0.353.0>},
                       {name,xdc_stats_holder},
                       {mfargs,
                           {proc_lib,start_link,
                               [xdcr_sup,link_stats_holder_body,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:26.887Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {<0.352.0>,xdcr_sup}
             started: [{pid,<0.354.0>},
                       {name,xdc_replication_sup},
                       {mfargs,{xdc_replication_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:52:26.893Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {<0.352.0>,xdcr_sup}
             started: [{pid,<0.355.0>},
                       {name,xdc_rep_manager},
                       {mfargs,{xdc_rep_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,30000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:26.894Z,ns_1@127.0.0.1:xdc_rep_manager<0.355.0>:ns_couchdb_api:wait_for_doc_manager:298]Start waiting for doc manager
[ns_server:debug,2021-04-19T19:52:26.904Z,ns_1@127.0.0.1:xdcr_doc_replicator<0.357.0>:ns_couchdb_api:wait_for_doc_manager:298]Start waiting for doc manager
[ns_server:debug,2021-04-19T19:52:26.904Z,ns_1@127.0.0.1:xdc_rdoc_replication_srv<0.358.0>:ns_couchdb_api:wait_for_doc_manager:298]Start waiting for doc manager
[error_logger:info,2021-04-19T19:52:26.904Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {<0.352.0>,xdcr_sup}
             started: [{pid,<0.357.0>},
                       {name,xdc_rdoc_replicator},
                       {mfargs,{doc_replicator,start_link_xdcr,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:26.905Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {<0.352.0>,xdcr_sup}
             started: [{pid,<0.358.0>},
                       {name,xdc_rdoc_replication_srv},
                       {mfargs,{doc_replication_srv,start_link_xdcr,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:26.910Z,ns_1@127.0.0.1:<0.352.0>:xdc_rdoc_manager:start_link_remote:42]Starting xdc_rdoc_manager on 'couchdb_ns_1@127.0.0.1' with following links: [<0.357.0>,
                                                                             <0.358.0>,
                                                                             <0.355.0>]
[ns_server:debug,2021-04-19T19:52:26.921Z,ns_1@127.0.0.1:xdcr_doc_replicator<0.357.0>:ns_couchdb_api:wait_for_doc_manager:301]Received doc manager registration from <11633.250.0>
[ns_server:debug,2021-04-19T19:52:26.921Z,ns_1@127.0.0.1:xdc_rdoc_replication_srv<0.358.0>:ns_couchdb_api:wait_for_doc_manager:301]Received doc manager registration from <11633.250.0>
[ns_server:debug,2021-04-19T19:52:26.922Z,ns_1@127.0.0.1:xdc_rep_manager<0.355.0>:ns_couchdb_api:wait_for_doc_manager:301]Received doc manager registration from <11633.250.0>
[error_logger:info,2021-04-19T19:52:26.922Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {<0.352.0>,xdcr_sup}
             started: [{pid,<11633.250.0>},
                       {name,xdc_rdoc_manager},
                       {mfargs,
                           {xdc_rdoc_manager,start_link_remote,
                               ['couchdb_ns_1@127.0.0.1']}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:26.922Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.352.0>},
                       {name,xdcr_sup},
                       {mfargs,{xdcr_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:52:26.926Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.360.0>},
                       {name,xdcr_dcp_sockets_pool},
                       {mfargs,{xdcr_dcp_sockets_pool,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:26.930Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_worker_sup}
             started: [{pid,<0.362.0>},
                       {name,ns_bucket_worker},
                       {mfargs,{work_queue,start_link,[ns_bucket_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:26.934Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_sup}
             started: [{pid,<0.364.0>},
                       {name,buckets_observing_subscription},
                       {mfargs,{ns_bucket_sup,subscribe_on_config_events,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:26.935Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_worker_sup}
             started: [{pid,<0.363.0>},
                       {name,ns_bucket_sup},
                       {mfargs,{ns_bucket_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:52:26.935Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.361.0>},
                       {name,ns_bucket_worker_sup},
                       {mfargs,{ns_bucket_worker_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2021-04-19T19:52:26.939Z,ns_1@127.0.0.1:xdcr_doc_replicator<0.357.0>:doc_replicator:loop:64]doing replicate_newnodes_docs
[error_logger:info,2021-04-19T19:52:26.940Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.365.0>},
                       {name,system_stats_collector},
                       {mfargs,{system_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:26.942Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.369.0>},
                       {name,{stats_archiver,"@system"}},
                       {mfargs,{stats_archiver,start_link,["@system"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:26.951Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.371.0>},
                       {name,{stats_reader,"@system"}},
                       {mfargs,{stats_reader,start_link,["@system"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:26.961Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.372.0>},
                       {name,{stats_archiver,"@system-processes"}},
                       {mfargs,
                           {stats_archiver,start_link,["@system-processes"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:26.962Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.374.0>},
                       {name,{stats_reader,"@system-processes"}},
                       {mfargs,
                           {stats_reader,start_link,["@system-processes"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:26.983Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.375.0>},
                       {name,{stats_archiver,"@query"}},
                       {mfargs,{stats_archiver,start_link,["@query"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:26.983Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.377.0>},
                       {name,{stats_reader,"@query"}},
                       {mfargs,{stats_reader,start_link,["@query"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:26.988Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.378.0>},
                       {name,query_stats_collector},
                       {mfargs,{query_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:27.029Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.380.0>},
                       {name,{stats_archiver,"@global"}},
                       {mfargs,{stats_archiver,start_link,["@global"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:27.029Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.382.0>},
                       {name,{stats_reader,"@global"}},
                       {mfargs,{stats_reader,start_link,["@global"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:27.035Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.383.0>},
                       {name,global_stats_collector},
                       {mfargs,{global_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:27.041Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.385.0>},
                       {name,goxdcr_status_keeper},
                       {mfargs,{goxdcr_status_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:27.043Z,ns_1@127.0.0.1:goxdcr_status_keeper<0.385.0>:goxdcr_rest:get_from_goxdcr:163]Goxdcr is temporary not available. Return empty list.
[ns_server:debug,2021-04-19T19:52:27.045Z,ns_1@127.0.0.1:goxdcr_status_keeper<0.385.0>:goxdcr_rest:get_from_goxdcr:163]Goxdcr is temporary not available. Return empty list.
[error_logger:info,2021-04-19T19:52:27.053Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_stats_sup}
             started: [{pid,<0.389.0>},
                       {name,index_stats_children_sup},
                       {mfargs,
                           {supervisor,start_link,
                               [{local,index_stats_children_sup},
                                index_stats_sup,child]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:52:27.060Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_status_keeper_sup}
             started: [{pid,<0.391.0>},
                       {name,index_status_keeper_worker},
                       {mfargs,
                           {work_queue,start_link,
                               [index_status_keeper_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:27.062Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_status_keeper_sup}
             started: [{pid,<0.392.0>},
                       {name,index_status_keeper},
                       {mfargs,{indexer_gsi,start_keeper,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:27.072Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_status_keeper_sup}
             started: [{pid,<0.395.0>},
                       {name,index_status_keeper_fts},
                       {mfargs,{indexer_fts,start_keeper,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:27.073Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_stats_sup}
             started: [{pid,<0.390.0>},
                       {name,index_status_keeper_sup},
                       {mfargs,{index_status_keeper_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:52:27.075Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_stats_sup}
             started: [{pid,<0.398.0>},
                       {name,index_stats_worker},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<index_stats_sup.0.21142793>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:27.075Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.388.0>},
                       {name,index_stats_sup},
                       {mfargs,{index_stats_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:error,2021-04-19T19:52:27.096Z,ns_1@127.0.0.1:index_status_keeper_worker<0.391.0>:index_rest:get_json:42]Request to (indexer) http://127.0.0.1:9102/getIndexStatus failed: {error,
                                                                   {econnrefused,
                                                                    [{lhttpc_client,
                                                                      send_request,
                                                                      1,
                                                                      [{file,
                                                                        "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                       {line,
                                                                        220}]},
                                                                     {lhttpc_client,
                                                                      execute,
                                                                      9,
                                                                      [{file,
                                                                        "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                       {line,
                                                                        169}]},
                                                                     {lhttpc_client,
                                                                      request,
                                                                      9,
                                                                      [{file,
                                                                        "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                       {line,
                                                                        92}]}]}}
[error_logger:info,2021-04-19T19:52:27.125Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_stats_children_sup}
             started: [{pid,<0.401.0>},
                       {name,{indexer_gsi,index_stats_collector}},
                       {mfargs,
                           {index_stats_collector,start_link,[indexer_gsi]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:27.133Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.405.0>},
                       {name,compaction_daemon},
                       {mfargs,{compaction_daemon,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:27.146Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_stats_children_sup}
             started: [{pid,<0.404.0>},
                       {name,{indexer_gsi,stats_archiver,"@index"}},
                       {mfargs,{stats_archiver,start_link,["@index"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:27.146Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_stats_children_sup}
             started: [{pid,<0.407.0>},
                       {name,{indexer_gsi,stats_reader,"@index"}},
                       {mfargs,{stats_reader,start_link,["@index"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:27.167Z,ns_1@127.0.0.1:<0.410.0>:new_concurrency_throttle:init:113]init concurrent throttle process, pid: <0.410.0>, type: kv_throttle# of available token: 1
[ns_server:debug,2021-04-19T19:52:27.174Z,ns_1@127.0.0.1:compaction_new_daemon<0.408.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:52:27.174Z,ns_1@127.0.0.1:compaction_new_daemon<0.408.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:52:27.174Z,ns_1@127.0.0.1:compaction_new_daemon<0.408.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:52:27.174Z,ns_1@127.0.0.1:compaction_new_daemon<0.408.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:52:27.175Z,ns_1@127.0.0.1:compaction_new_daemon<0.408.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_master. Rescheduling compaction.
[error_logger:info,2021-04-19T19:52:27.174Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.408.0>},
                       {name,compaction_new_daemon},
                       {mfargs,{compaction_new_daemon,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,86400000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:27.175Z,ns_1@127.0.0.1:compaction_new_daemon<0.408.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_master too soon. Next run will be in 3600s
[error_logger:info,2021-04-19T19:52:27.186Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,cluster_logs_sup}
             started: [{pid,<0.412.0>},
                       {name,ets_holder},
                       {mfargs,
                           {cluster_logs_collection_task,
                               start_link_ets_holder,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:27.186Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.411.0>},
                       {name,cluster_logs_sup},
                       {mfargs,{cluster_logs_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:52:27.194Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.413.0>},
                       {name,remote_api},
                       {mfargs,{remote_api,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:27.208Z,ns_1@127.0.0.1:<0.414.0>:mb_master:check_master_takeover_needed:141]Sending master node question to the following nodes: []
[ns_server:debug,2021-04-19T19:52:27.208Z,ns_1@127.0.0.1:<0.414.0>:mb_master:check_master_takeover_needed:143]Got replies: []
[ns_server:debug,2021-04-19T19:52:27.208Z,ns_1@127.0.0.1:<0.414.0>:mb_master:check_master_takeover_needed:149]Was unable to discover master, not going to force mastership takeover
[user:info,2021-04-19T19:52:27.208Z,ns_1@127.0.0.1:mb_master<0.416.0>:mb_master:init:86]I'm the only node, so I'm the master.
[ns_server:debug,2021-04-19T19:52:27.235Z,ns_1@127.0.0.1:mb_master_sup<0.418.0>:misc:start_singleton:1097]start_singleton(gen_server, ns_tick, [], []): started as <0.419.0> on 'ns_1@127.0.0.1'

[error_logger:info,2021-04-19T19:52:27.235Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.419.0>},
                       {name,ns_tick},
                       {mfargs,{ns_tick,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,10},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:27.250Z,ns_1@127.0.0.1:ns_orchestrator_sup<0.420.0>:misc:start_singleton:1097]start_singleton(gen_fsm, ns_orchestrator, [], []): started as <0.421.0> on 'ns_1@127.0.0.1'

[error_logger:info,2021-04-19T19:52:27.251Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_sup}
             started: [{pid,<0.421.0>},
                       {name,ns_orchestrator},
                       {mfargs,{ns_orchestrator,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:27.260Z,ns_1@127.0.0.1:<0.423.0>:auto_failover:init:147]init auto_failover.
[ns_server:debug,2021-04-19T19:52:27.260Z,ns_1@127.0.0.1:ns_orchestrator_sup<0.420.0>:misc:start_singleton:1097]start_singleton(gen_server, auto_failover, [], []): started as <0.423.0> on 'ns_1@127.0.0.1'

[ns_server:debug,2021-04-19T19:52:27.261Z,ns_1@127.0.0.1:<0.414.0>:restartable:start_child:98]Started child process <0.416.0>
  MFA: {mb_master,start_link,[]}
[error_logger:info,2021-04-19T19:52:27.261Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_sup}
             started: [{pid,<0.423.0>},
                       {name,auto_failover},
                       {mfargs,{auto_failover,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:27.261Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.420.0>},
                       {name,ns_orchestrator_sup},
                       {mfargs,{ns_orchestrator_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:52:27.262Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.414.0>},
                       {name,mb_master},
                       {mfargs,
                           {restartable,start_link,
                               [{mb_master,start_link,[]},infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:52:27.262Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.424.0>},
                       {name,master_activity_events_ingress},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,master_activity_events_ingress}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:27.262Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.425.0>},
                       {name,master_activity_events_timestamper},
                       {mfargs,
                           {master_activity_events,start_link_timestamper,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:27.283Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.426.0>},
                       {name,master_activity_events_pids_watcher},
                       {mfargs,
                           {master_activity_events_pids_watcher,start_link,
                               []}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:27.316Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.155.0>:one_shot_barrier:notify:27]Notifying on barrier menelaus_barrier
[error_logger:info,2021-04-19T19:52:27.316Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.427.0>},
                       {name,master_activity_events_keeper},
                       {mfargs,{master_activity_events_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:27.316Z,ns_1@127.0.0.1:menelaus_barrier<0.157.0>:one_shot_barrier:barrier_body:62]Barrier menelaus_barrier got notification from <0.155.0>
[ns_server:debug,2021-04-19T19:52:27.316Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.155.0>:one_shot_barrier:notify:32]Successfuly notified on barrier menelaus_barrier
[error_logger:info,2021-04-19T19:52:27.316Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.237.0>},
                       {name,ns_server_sup},
                       {mfargs,{ns_server_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2021-04-19T19:52:27.317Z,ns_1@127.0.0.1:<0.154.0>:restartable:start_child:98]Started child process <0.155.0>
  MFA: {ns_server_nodes_sup,start_link,[]}
[ns_server:debug,2021-04-19T19:52:27.317Z,ns_1@127.0.0.1:<0.2.0>:child_erlang:child_loop:116]97: Entered child_loop
[error_logger:info,2021-04-19T19:52:27.317Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.154.0>},
                       {name,ns_server_nodes_sup},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_server_nodes_sup,start_link,[]},
                                infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:52:27.318Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
         application: ns_server
          started_at: 'ns_1@127.0.0.1'

[ns_server:debug,2021-04-19T19:52:27.825Z,ns_1@127.0.0.1:ns_ports_setup<0.335.0>:ns_ports_setup:set_children:72]Monitor ns_child_ports_sup <11632.72.0>
[ns_server:debug,2021-04-19T19:52:27.825Z,ns_1@127.0.0.1:memcached_config_mgr<0.346.0>:memcached_config_mgr:init:46]ns_ports_setup seems to be ready
[ns_server:debug,2021-04-19T19:52:27.832Z,ns_1@127.0.0.1:memcached_config_mgr<0.346.0>:memcached_config_mgr:find_port_pid_loop:119]Found memcached port <11632.79.0>
[ns_server:warn,2021-04-19T19:52:27.853Z,ns_1@127.0.0.1:<0.344.0>:ns_memcached:connect:1307]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[ns_server:debug,2021-04-19T19:52:27.861Z,ns_1@127.0.0.1:memcached_config_mgr<0.346.0>:memcached_config_mgr:init:77]wrote memcached config to /opt/couchbase/var/lib/couchbase/config/memcached.json. Will activate memcached port server
[ns_server:debug,2021-04-19T19:52:27.877Z,ns_1@127.0.0.1:memcached_config_mgr<0.346.0>:memcached_config_mgr:init:80]activated memcached port server
[stats:error,2021-04-19T19:52:28.240Z,ns_1@127.0.0.1:query_stats_collector<0.378.0>:base_stats_collector:handle_info:109](Collector: query_stats_collector) Exception in stats collector: {error,
                                                                  {badmatch,
                                                                   {error,
                                                                    {econnrefused,
                                                                     [{lhttpc_client,
                                                                       send_request,
                                                                       1,
                                                                       [{file,
                                                                         "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                        {line,
                                                                         220}]},
                                                                      {lhttpc_client,
                                                                       execute,
                                                                       9,
                                                                       [{file,
                                                                         "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                        {line,
                                                                         169}]},
                                                                      {lhttpc_client,
                                                                       request,
                                                                       9,
                                                                       [{file,
                                                                         "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                        {line,
                                                                         92}]}]}}},
                                                                  [{query_rest,
                                                                    send,3,
                                                                    [{file,
                                                                      "src/query_rest.erl"},
                                                                     {line,
                                                                      64}]},
                                                                   {query_rest,
                                                                    do_get_stats,
                                                                    0,
                                                                    [{file,
                                                                      "src/query_rest.erl"},
                                                                     {line,
                                                                      43}]},
                                                                   {base_stats_collector,
                                                                    handle_info,
                                                                    2,
                                                                    [{file,
                                                                      "src/base_stats_collector.erl"},
                                                                     {line,
                                                                      89}]},
                                                                   {gen_server,
                                                                    handle_msg,
                                                                    5,
                                                                    [{file,
                                                                      "gen_server.erl"},
                                                                     {line,
                                                                      604}]},
                                                                   {proc_lib,
                                                                    init_p_do_apply,
                                                                    3,
                                                                    [{file,
                                                                      "proc_lib.erl"},
                                                                     {line,
                                                                      239}]}]}

[ns_server:error,2021-04-19T19:52:28.241Z,ns_1@127.0.0.1:index_stats_collector-index<0.401.0>:index_rest:get_json:42]Request to (indexer) http://127.0.0.1:9102/stats?async=true failed: {error,
                                                                     {econnrefused,
                                                                      [{lhttpc_client,
                                                                        send_request,
                                                                        1,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          220}]},
                                                                       {lhttpc_client,
                                                                        execute,
                                                                        9,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          169}]},
                                                                       {lhttpc_client,
                                                                        request,
                                                                        9,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          92}]}]}}
[ns_server:warn,2021-04-19T19:52:28.278Z,ns_1@127.0.0.1:<0.434.0>:ns_memcached:connect:1307]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[ns_server:debug,2021-04-19T19:52:28.571Z,ns_1@127.0.0.1:json_rpc_connection-projector-cbauth<0.438.0>:json_rpc_connection:init:74]Observed revrpc connection: label "projector-cbauth", handling process <0.438.0>
[error_logger:error,2021-04-19T19:52:28.571Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.438.0>,{ok,<0.438.0>}}

[ns_server:debug,2021-04-19T19:52:28.571Z,ns_1@127.0.0.1:menelaus_cbauth<0.331.0>:menelaus_cbauth:handle_cast:87]Observed json rpc process {"projector-cbauth",<0.438.0>} started
[ns_server:debug,2021-04-19T19:52:28.593Z,ns_1@127.0.0.1:json_rpc_connection-projector-cbauth<0.438.0>:json_rpc_connection:handle_call:157]sending jsonrpc call:{[{jsonrpc,<<"2.0">>},
                       {id,0},
                       {method,<<"AuthCacheSvc.UpdateDB">>},
                       {params,
                        [{[{specialUser,<<"@projector-cbauth">>},
                           {nodes,
                            [{[{host,<<"127.0.0.1">>},
                               {user,<<"_admin">>},
                               {password,"*****"},
                               {ports,
                                [8091,18091,9100,9101,9102,9103,9104,9105,
                                 18092,8092,11207,9999,11210,11211,8093,
                                 18093]},
                               {local,true}]}]},
                           {buckets,[]},
                           {authCheckURL,<<"http://127.0.0.1:8091/_cbauth">>},
                           {permissionCheckURL,
                            <<"http://127.0.0.1:8091/_cbauth/checkPermission">>},
                           {ldapEnabled,true},
                           {permissionsVersion,125619376},
                           {admin,
                            {[{user,<<"Administrator">>},
                              {salt,<<"6fV7COE6Hrv1Slx3m7c7aw==">>},
                              {mac,
                               <<"88VQXOIVfyUC4fCDlttiZJtlD/s=">>}]}}]}]}]}
[ns_server:debug,2021-04-19T19:52:28.595Z,ns_1@127.0.0.1:json_rpc_connection-projector-cbauth<0.438.0>:json_rpc_connection:handle_info:93]got response: [{<<"id">>,0},{<<"result">>,true},{<<"error">>,null}]
[ns_server:warn,2021-04-19T19:52:28.856Z,ns_1@127.0.0.1:<0.344.0>:ns_memcached:connect:1307]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[ns_server:debug,2021-04-19T19:52:28.962Z,ns_1@127.0.0.1:json_rpc_connection-index-cbauth<0.443.0>:json_rpc_connection:init:74]Observed revrpc connection: label "index-cbauth", handling process <0.443.0>
[error_logger:error,2021-04-19T19:52:28.962Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.443.0>,{ok,<0.443.0>}}

[ns_server:debug,2021-04-19T19:52:28.962Z,ns_1@127.0.0.1:menelaus_cbauth<0.331.0>:menelaus_cbauth:handle_cast:87]Observed json rpc process {"index-cbauth",<0.443.0>} started
[ns_server:debug,2021-04-19T19:52:28.963Z,ns_1@127.0.0.1:json_rpc_connection-index-cbauth<0.443.0>:json_rpc_connection:handle_call:157]sending jsonrpc call:{[{jsonrpc,<<"2.0">>},
                       {id,0},
                       {method,<<"AuthCacheSvc.UpdateDB">>},
                       {params,
                        [{[{specialUser,<<"@index-cbauth">>},
                           {nodes,
                            [{[{host,<<"127.0.0.1">>},
                               {user,<<"_admin">>},
                               {password,"*****"},
                               {ports,
                                [8091,18091,9100,9101,9102,9103,9104,9105,
                                 18092,8092,11207,9999,11210,11211,8093,
                                 18093]},
                               {local,true}]}]},
                           {buckets,[]},
                           {authCheckURL,<<"http://127.0.0.1:8091/_cbauth">>},
                           {permissionCheckURL,
                            <<"http://127.0.0.1:8091/_cbauth/checkPermission">>},
                           {ldapEnabled,true},
                           {permissionsVersion,125619376},
                           {admin,
                            {[{user,<<"Administrator">>},
                              {salt,<<"6fV7COE6Hrv1Slx3m7c7aw==">>},
                              {mac,
                               <<"88VQXOIVfyUC4fCDlttiZJtlD/s=">>}]}}]}]}]}
[ns_server:debug,2021-04-19T19:52:28.966Z,ns_1@127.0.0.1:json_rpc_connection-index-cbauth<0.443.0>:json_rpc_connection:handle_info:93]got response: [{<<"id">>,0},{<<"result">>,true},{<<"error">>,null}]
[ns_server:debug,2021-04-19T19:52:29.131Z,ns_1@127.0.0.1:json_rpc_connection-saslauthd-saslauthd-port<0.450.0>:json_rpc_connection:init:74]Observed revrpc connection: label "saslauthd-saslauthd-port", handling process <0.450.0>
[error_logger:error,2021-04-19T19:52:29.131Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.450.0>,{ok,<0.450.0>}}

[ns_server:error,2021-04-19T19:52:29.238Z,ns_1@127.0.0.1:index_stats_collector-index<0.401.0>:index_rest:get_json:42]Request to (indexer) http://127.0.0.1:9102/stats?async=true failed: {error,
                                                                     {econnrefused,
                                                                      [{lhttpc_client,
                                                                        send_request,
                                                                        1,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          220}]},
                                                                       {lhttpc_client,
                                                                        execute,
                                                                        9,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          169}]},
                                                                       {lhttpc_client,
                                                                        request,
                                                                        9,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          92}]}]}}
[stats:error,2021-04-19T19:52:29.238Z,ns_1@127.0.0.1:query_stats_collector<0.378.0>:base_stats_collector:handle_info:109](Collector: query_stats_collector) Exception in stats collector: {error,
                                                                  {badmatch,
                                                                   {error,
                                                                    {econnrefused,
                                                                     [{lhttpc_client,
                                                                       send_request,
                                                                       1,
                                                                       [{file,
                                                                         "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                        {line,
                                                                         220}]},
                                                                      {lhttpc_client,
                                                                       execute,
                                                                       9,
                                                                       [{file,
                                                                         "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                        {line,
                                                                         169}]},
                                                                      {lhttpc_client,
                                                                       request,
                                                                       9,
                                                                       [{file,
                                                                         "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                        {line,
                                                                         92}]}]}}},
                                                                  [{query_rest,
                                                                    send,3,
                                                                    [{file,
                                                                      "src/query_rest.erl"},
                                                                     {line,
                                                                      64}]},
                                                                   {query_rest,
                                                                    do_get_stats,
                                                                    0,
                                                                    [{file,
                                                                      "src/query_rest.erl"},
                                                                     {line,
                                                                      43}]},
                                                                   {base_stats_collector,
                                                                    handle_info,
                                                                    2,
                                                                    [{file,
                                                                      "src/base_stats_collector.erl"},
                                                                     {line,
                                                                      89}]},
                                                                   {gen_server,
                                                                    handle_msg,
                                                                    5,
                                                                    [{file,
                                                                      "gen_server.erl"},
                                                                     {line,
                                                                      604}]},
                                                                   {proc_lib,
                                                                    init_p_do_apply,
                                                                    3,
                                                                    [{file,
                                                                      "proc_lib.erl"},
                                                                     {line,
                                                                      239}]}]}

[ns_server:debug,2021-04-19T19:52:29.249Z,ns_1@127.0.0.1:json_rpc_connection-cbq-engine-cbauth<0.457.0>:json_rpc_connection:init:74]Observed revrpc connection: label "cbq-engine-cbauth", handling process <0.457.0>
[error_logger:error,2021-04-19T19:52:29.250Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.457.0>,{ok,<0.457.0>}}

[ns_server:debug,2021-04-19T19:52:29.249Z,ns_1@127.0.0.1:menelaus_cbauth<0.331.0>:menelaus_cbauth:handle_cast:87]Observed json rpc process {"cbq-engine-cbauth",<0.457.0>} started
[ns_server:debug,2021-04-19T19:52:29.250Z,ns_1@127.0.0.1:json_rpc_connection-cbq-engine-cbauth<0.457.0>:json_rpc_connection:handle_call:157]sending jsonrpc call:{[{jsonrpc,<<"2.0">>},
                       {id,0},
                       {method,<<"AuthCacheSvc.UpdateDB">>},
                       {params,
                        [{[{specialUser,<<"@cbq-engine-cbauth">>},
                           {nodes,
                            [{[{host,<<"127.0.0.1">>},
                               {user,<<"_admin">>},
                               {password,"*****"},
                               {ports,
                                [8091,18091,9100,9101,9102,9103,9104,9105,
                                 18092,8092,11207,9999,11210,11211,8093,
                                 18093]},
                               {local,true}]}]},
                           {buckets,[]},
                           {authCheckURL,<<"http://127.0.0.1:8091/_cbauth">>},
                           {permissionCheckURL,
                            <<"http://127.0.0.1:8091/_cbauth/checkPermission">>},
                           {ldapEnabled,true},
                           {permissionsVersion,125619376},
                           {admin,
                            {[{user,<<"Administrator">>},
                              {salt,<<"6fV7COE6Hrv1Slx3m7c7aw==">>},
                              {mac,
                               <<"88VQXOIVfyUC4fCDlttiZJtlD/s=">>}]}}]}]}]}
[ns_server:debug,2021-04-19T19:52:29.252Z,ns_1@127.0.0.1:json_rpc_connection-cbq-engine-cbauth<0.457.0>:json_rpc_connection:handle_info:93]got response: [{<<"id">>,0},{<<"result">>,true},{<<"error">>,null}]
[ns_server:warn,2021-04-19T19:52:29.280Z,ns_1@127.0.0.1:<0.434.0>:ns_memcached:connect:1307]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[ns_server:debug,2021-04-19T19:52:29.318Z,ns_1@127.0.0.1:json_rpc_connection-goxdcr-cbauth<0.462.0>:json_rpc_connection:init:74]Observed revrpc connection: label "goxdcr-cbauth", handling process <0.462.0>
[error_logger:error,2021-04-19T19:52:29.318Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.462.0>,{ok,<0.462.0>}}

[ns_server:debug,2021-04-19T19:52:29.318Z,ns_1@127.0.0.1:menelaus_cbauth<0.331.0>:menelaus_cbauth:handle_cast:87]Observed json rpc process {"goxdcr-cbauth",<0.462.0>} started
[ns_server:debug,2021-04-19T19:52:29.319Z,ns_1@127.0.0.1:json_rpc_connection-goxdcr-cbauth<0.462.0>:json_rpc_connection:handle_call:157]sending jsonrpc call:{[{jsonrpc,<<"2.0">>},
                       {id,0},
                       {method,<<"AuthCacheSvc.UpdateDB">>},
                       {params,
                        [{[{specialUser,<<"@goxdcr-cbauth">>},
                           {nodes,
                            [{[{host,<<"127.0.0.1">>},
                               {user,<<"_admin">>},
                               {password,"*****"},
                               {ports,
                                [8091,18091,9100,9101,9102,9103,9104,9105,
                                 18092,8092,11207,9999,11210,11211,8093,
                                 18093]},
                               {local,true}]}]},
                           {buckets,[]},
                           {authCheckURL,<<"http://127.0.0.1:8091/_cbauth">>},
                           {permissionCheckURL,
                            <<"http://127.0.0.1:8091/_cbauth/checkPermission">>},
                           {ldapEnabled,true},
                           {permissionsVersion,125619376},
                           {admin,
                            {[{user,<<"Administrator">>},
                              {salt,<<"6fV7COE6Hrv1Slx3m7c7aw==">>},
                              {mac,
                               <<"88VQXOIVfyUC4fCDlttiZJtlD/s=">>}]}}]}]}]}
[ns_server:debug,2021-04-19T19:52:29.321Z,ns_1@127.0.0.1:json_rpc_connection-goxdcr-cbauth<0.462.0>:json_rpc_connection:handle_info:93]got response: [{<<"id">>,0},{<<"result">>,true},{<<"error">>,null}]
[stats:warn,2021-04-19T19:52:30.305Z,ns_1@127.0.0.1:<0.383.0>:base_stats_collector:latest_tick:69](Collector: global_stats_collector) Dropped 2 ticks
[ns_server:debug,2021-04-19T19:52:35.650Z,ns_1@127.0.0.1:<0.525.0>:ns_audit:put:248]Audit modify_index_storage_mode: [{storageMode,<<"memory_optimized">>},
                                  {real_userid,
                                      {[{source,ns_server},
                                        {user,<<"Administrator">>}]}},
                                  {remote,
                                      {[{ip,<<"127.0.0.1">>},{port,36240}]}},
                                  {timestamp,<<"2021-04-19T19:52:35.650Z">>}]
[ns_server:debug,2021-04-19T19:52:35.650Z,ns_1@127.0.0.1:ns_config_rep<0.254.0>:ns_config_rep:do_push_keys:321]Replicating some config keys ([{local_changes_count,
                                   <<"dbb8bee8b38705437e7f5ebc78107bfa">>},
                               {metakv,<<"/indexing/settings/config">>}]..)
[ns_server:debug,2021-04-19T19:52:35.650Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{metakv,<<"/indexing/settings/config">>} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{5,63786081155}}]}|
 <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.log_level\":\"info\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\""...>>]
[ns_server:debug,2021-04-19T19:52:35.650Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{local_changes_count,<<"dbb8bee8b38705437e7f5ebc78107bfa">>} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{13,63786081155}}]}]
[ns_server:debug,2021-04-19T19:52:57.175Z,ns_1@127.0.0.1:compaction_new_daemon<0.408.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:52:57.175Z,ns_1@127.0.0.1:compaction_new_daemon<0.408.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:52:57.175Z,ns_1@127.0.0.1:compaction_new_daemon<0.408.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:52:57.175Z,ns_1@127.0.0.1:compaction_new_daemon<0.408.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:53:27.176Z,ns_1@127.0.0.1:compaction_new_daemon<0.408.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:53:27.176Z,ns_1@127.0.0.1:compaction_new_daemon<0.408.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:53:27.176Z,ns_1@127.0.0.1:compaction_new_daemon<0.408.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:53:27.176Z,ns_1@127.0.0.1:compaction_new_daemon<0.408.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:53:57.177Z,ns_1@127.0.0.1:compaction_new_daemon<0.408.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:53:57.177Z,ns_1@127.0.0.1:compaction_new_daemon<0.408.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:53:57.177Z,ns_1@127.0.0.1:compaction_new_daemon<0.408.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:53:57.177Z,ns_1@127.0.0.1:compaction_new_daemon<0.408.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:info,2021-04-19T19:54:06.249Z,nonode@nohost:<0.88.0>:ns_server:init_logging:151]Started & configured logging
[ns_server:info,2021-04-19T19:54:06.270Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]Static config terms:
[{error_logger_mf_dir,"/opt/couchbase/var/lib/couchbase/logs"},
 {path_config_bindir,"/opt/couchbase/bin"},
 {path_config_etcdir,"/opt/couchbase/etc/couchbase"},
 {path_config_libdir,"/opt/couchbase/lib"},
 {path_config_datadir,"/opt/couchbase/var/lib/couchbase"},
 {path_config_tmpdir,"/opt/couchbase/var/lib/couchbase/tmp"},
 {path_config_secdir,"/opt/couchbase/etc/security"},
 {nodefile,"/opt/couchbase/var/lib/couchbase/couchbase-server.node"},
 {loglevel_default,debug},
 {loglevel_couchdb,info},
 {loglevel_ns_server,debug},
 {loglevel_error_logger,debug},
 {loglevel_user,debug},
 {loglevel_menelaus,debug},
 {loglevel_ns_doctor,debug},
 {loglevel_stats,debug},
 {loglevel_rebalance,debug},
 {loglevel_cluster,debug},
 {loglevel_views,debug},
 {loglevel_mapreduce_errors,debug},
 {loglevel_xdcr,debug},
 {loglevel_xdcr_trace,error},
 {loglevel_access,info},
 {disk_sink_opts,
     [{rotation,
          [{compress,true},
           {size,41943040},
           {num_files,10},
           {buffer_size_max,52428800}]}]},
 {disk_sink_opts_xdcr_trace,
     [{rotation,[{compress,false},{size,83886080},{num_files,5}]}]},
 {net_kernel_verbosity,10}]
[ns_server:warn,2021-04-19T19:54:06.270Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter error_logger_mf_dir, which is given from command line
[ns_server:warn,2021-04-19T19:54:06.270Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter path_config_bindir, which is given from command line
[ns_server:warn,2021-04-19T19:54:06.270Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter path_config_etcdir, which is given from command line
[ns_server:warn,2021-04-19T19:54:06.270Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter path_config_libdir, which is given from command line
[ns_server:warn,2021-04-19T19:54:06.270Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter path_config_datadir, which is given from command line
[ns_server:warn,2021-04-19T19:54:06.270Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter path_config_tmpdir, which is given from command line
[ns_server:warn,2021-04-19T19:54:06.270Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter path_config_secdir, which is given from command line
[ns_server:warn,2021-04-19T19:54:06.271Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter nodefile, which is given from command line
[ns_server:warn,2021-04-19T19:54:06.271Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_default, which is given from command line
[ns_server:warn,2021-04-19T19:54:06.271Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_couchdb, which is given from command line
[ns_server:warn,2021-04-19T19:54:06.271Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_ns_server, which is given from command line
[ns_server:warn,2021-04-19T19:54:06.271Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_error_logger, which is given from command line
[ns_server:warn,2021-04-19T19:54:06.271Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_user, which is given from command line
[ns_server:warn,2021-04-19T19:54:06.271Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_menelaus, which is given from command line
[ns_server:warn,2021-04-19T19:54:06.271Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_ns_doctor, which is given from command line
[ns_server:warn,2021-04-19T19:54:06.271Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_stats, which is given from command line
[ns_server:warn,2021-04-19T19:54:06.271Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_rebalance, which is given from command line
[ns_server:warn,2021-04-19T19:54:06.271Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_cluster, which is given from command line
[ns_server:warn,2021-04-19T19:54:06.271Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_views, which is given from command line
[ns_server:warn,2021-04-19T19:54:06.271Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_mapreduce_errors, which is given from command line
[ns_server:warn,2021-04-19T19:54:06.271Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_xdcr, which is given from command line
[ns_server:warn,2021-04-19T19:54:06.271Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_xdcr_trace, which is given from command line
[ns_server:warn,2021-04-19T19:54:06.271Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_access, which is given from command line
[ns_server:warn,2021-04-19T19:54:06.271Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter disk_sink_opts, which is given from command line
[ns_server:warn,2021-04-19T19:54:06.271Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter disk_sink_opts_xdcr_trace, which is given from command line
[ns_server:warn,2021-04-19T19:54:06.271Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter net_kernel_verbosity, which is given from command line
[error_logger:info,2021-04-19T19:54:06.280Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.128.0>},
                       {name,local_tasks},
                       {mfargs,{local_tasks,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:54:06.288Z,nonode@nohost:ns_server_cluster_sup<0.127.0>:log_os_info:start_link:25]OS type: {unix,linux} Version: {4,19,128}
Runtime info: [{otp_release,"R16B03-1"},
               {erl_version,"5.10.4.0.0.1"},
               {erl_version_long,
                   "Erlang R16B03-1 (erts-5.10.4.0.0.1) [source-00852da] [64-bit] [smp:8:8] [async-threads:16] [kernel-poll:true]\n"},
               {system_arch_raw,"x86_64-unknown-linux-gnu"},
               {system_arch,"x86_64-unknown-linux-gnu"},
               {localtime,{{2021,4,19},{19,54,6}}},
               {memory,
                   [{total,111216088},
                    {processes,9684224},
                    {processes_used,9683568},
                    {system,101531864},
                    {atom,331249},
                    {atom_used,310220},
                    {binary,55608},
                    {code,7694133},
                    {ets,2240584}]},
               {loaded,
                   [ns_info,log_os_info,local_tasks,restartable,
                    ns_server_cluster_sup,calendar,ale_default_formatter,
                    'ale_logger-metakv','ale_logger-rebalance',
                    'ale_logger-xdcr_trace','ale_logger-menelaus',
                    'ale_logger-stats','ale_logger-access',
                    'ale_logger-ns_server','ale_logger-user',
                    'ale_logger-ns_doctor',io_lib_fread,'ale_logger-cluster',
                    'ale_logger-xdcr',otp_internal,ns_log_sink,ale_disk_sink,
                    misc,couch_util,ns_server,filelib,cpu_sup,memsup,disksup,
                    os_mon,io,release_handler,overload,alarm_handler,sasl,
                    timer,tftp_sup,httpd_sup,httpc_handler_sup,httpc_cookie,
                    inets_trace,httpc_manager,httpc,httpc_profile_sup,
                    httpc_sup,ftp_sup,inets_sup,inets_app,ssl,lhttpc_manager,
                    lhttpc_sup,lhttpc,tls_connection_sup,ssl_session_cache,
                    ssl_pkix_db,ssl_manager,ssl_sup,ssl_app,crypto_server,
                    crypto_sup,crypto_app,ale_error_logger_handler,
                    'ale_logger-ale_logger','ale_logger-error_logger',
                    beam_opcodes,beam_dict,beam_asm,beam_validator,beam_z,
                    beam_flatten,beam_trim,beam_receive,beam_bsm,beam_peep,
                    beam_dead,beam_split,beam_type,beam_bool,beam_except,
                    beam_clean,beam_utils,beam_block,beam_jump,beam_a,
                    v3_codegen,v3_life,v3_kernel,sys_core_dsetel,erl_bifs,
                    sys_core_fold,cerl_trees,sys_core_inline,core_lib,cerl,
                    v3_core,erl_bits,erl_expand_records,sys_pre_expand,sofs,
                    erl_internal,sets,ordsets,erl_lint,compile,
                    dynamic_compile,ale_utils,io_lib_pretty,io_lib_format,
                    io_lib,ale_codegen,dict,ale,ale_dynamic_sup,ale_sup,
                    ale_app,epp,ns_bootstrap,child_erlang,file_io_server,
                    orddict,erl_eval,file,c,kernel_config,user_sup,
                    supervisor_bridge,standard_error,code_server,unicode,
                    hipe_unified_loader,gb_sets,ets,binary,code,file_server,
                    net_kernel,global_group,erl_distribution,filename,
                    inet_gethost_native,os,inet_parse,inet,inet_udp,
                    inet_config,inet_db,global,gb_trees,rpc,supervisor,kernel,
                    application_master,sys,application,gen_server,erl_parse,
                    proplists,erl_scan,lists,application_controller,proc_lib,
                    gen,gen_event,error_logger,heart,error_handler,
                    erts_internal,erlang,erl_prim_loader,prim_zip,zlib,
                    prim_file,prim_inet,prim_eval,init,otp_ring0]},
               {applications,
                   [{lhttpc,"Lightweight HTTP Client","1.3.0"},
                    {os_mon,"CPO  CXC 138 46","2.2.14"},
                    {public_key,"Public key infrastructure","0.21"},
                    {asn1,"The Erlang ASN1 compiler version 2.0.4","2.0.4"},
                    {kernel,"ERTS  CXC 138 10","2.16.4"},
                    {ale,"Another Logger for Erlang","4.6.0-3573-enterprise"},
                    {inets,"INETS  CXC 138 49","5.9.8"},
                    {ns_server,"Couchbase server","4.6.0-3573-enterprise"},
                    {crypto,"CRYPTO version 2","3.2"},
                    {ssl,"Erlang/OTP SSL application","5.3.3"},
                    {sasl,"SASL  CXC 138 11","2.3.4"},
                    {stdlib,"ERTS  CXC 138 10","1.19.4"}]},
               {pre_loaded,
                   [erts_internal,erlang,erl_prim_loader,prim_zip,zlib,
                    prim_file,prim_inet,prim_eval,init,otp_ring0]},
               {process_count,94},
               {node,nonode@nohost},
               {nodes,[]},
               {registered,
                   [ftp_sup,'sink-disk_xdcr',code_server,sasl_sup,
                    'sink-disk_debug',application_controller,
                    'sink-disk_error',local_tasks,'sink-disk_default',
                    ale_stats_events,kernel_safe_sup,inets_sup,ale,
                    standard_error,error_logger,lhttpc_sup,ale_sup,
                    lhttpc_manager,timer_server,standard_error_sup,
                    release_handler,httpd_sup,ale_dynamic_sup,overload,
                    alarm_handler,init,inet_db,rex,kernel_sup,'sink-ns_log',
                    global_name_server,sasl_safe_sup,crypto_server,crypto_sup,
                    file_server_2,tftp_sup,global_group,os_mon_sup,
                    'sink-disk_metakv',cpu_sup,tls_connection_sup,memsup,
                    ssl_sup,'sink-disk_access_int',disksup,'sink-disk_access',
                    ns_server_cluster_sup,httpc_sup,ssl_manager,
                    'sink-xdcr_trace',erl_prim_loader,'sink-disk_reports',
                    httpc_profile_sup,'sink-disk_stats',httpc_manager,
                    httpc_handler_sup,'sink-disk_xdcr_errors']},
               {cookie,nocookie},
               {wordsize,8},
               {wall_clock,4}]
[ns_server:info,2021-04-19T19:54:06.301Z,nonode@nohost:ns_server_cluster_sup<0.127.0>:log_os_info:start_link:27]Manifest:
["<?xml version=\"1.0\" encoding=\"UTF-8\"?>","<manifest>",
 "  <remote fetch=\"git://github.com/blevesearch/\" name=\"blevesearch\"/>",
 "  <remote fetch=\"git://github.com/couchbase/\" name=\"couchbase\" review=\"review.couchbase.org\"/>",
 "  <remote fetch=\"ssh://git@github.com/couchbase/\" name=\"couchbase-priv\" review=\"review.couchbase.org\"/>",
 "  <remote fetch=\"git://github.com/couchbasedeps/\" name=\"couchbasedeps\" review=\"review.couchbase.org\"/>",
 "  <remote fetch=\"git://github.com/couchbaselabs/\" name=\"couchbaselabs\" review=\"review.couchbase.org\"/>",
 "  ","  <default remote=\"couchbase\" revision=\"master\"/>","  ",
 "  <project groups=\"notdefault,enterprise\" name=\"backup\" path=\"goproj/src/github.com/couchbase/backup\" remote=\"couchbase-priv\" revision=\"469a5e8cc8661f35ab4af74fe45e92a3d89febed\"/>",
 "  <project name=\"bitset\" path=\"godeps/src/github.com/willf/bitset\" remote=\"couchbasedeps\" revision=\"28a4168144bb8ac95454e1f51c84da1933681ad4\"/>",
 "  <project name=\"blance\" path=\"godeps/src/github.com/couchbase/blance\" revision=\"5ce14d13954e04262b7eabfc6978776a4018402b\"/>",
 "  <project name=\"bleve\" path=\"godeps/src/github.com/blevesearch/bleve\" remote=\"blevesearch\" revision=\"f531835d5c212ee5f95c49d2debc28e65e6d1693\"/>",
 "  <project name=\"bleve-mapping-ui\" path=\"godeps/src/github.com/blevesearch/bleve-mapping-ui\" remote=\"blevesearch\" revision=\"b0453426dc1d59918cc763a970f1ad147b22ad6a\"/>",
 "  <project name=\"blevex\" path=\"godeps/src/github.com/blevesearch/blevex\" remote=\"blevesearch\" revision=\"918d980b0d244c8230c7d8c8ee40919f8d55ef88\"/>",
 "  <project name=\"bolt\" path=\"godeps/src/github.com/boltdb/bolt\" remote=\"couchbasedeps\" revision=\"51f99c862475898df9773747d3accd05a7ca33c1\"/>",
 "  <project name=\"buffer\" path=\"godeps/src/github.com/tdewolff/buffer\" remote=\"couchbasedeps\" revision=\"43cef5ba7b6ce99cc410632dad46cf1c6c97026e\"/>",
 "  <project groups=\"notdefault,build\" name=\"build\" path=\"cbbuild\" revision=\"ccd3ae52bbf0ade5fd59adcedba2b8cbbd16cd9b\">",
 "    <annotation name=\"VERSION\" value=\"4.6.0\"/>",
 "    <annotation name=\"BLD_NUM\" value=\"3573\"/>",
 "    <annotation name=\"RELEASE\" value=\"@RELEASE@\"/>",
 "    <annotation name=\"EDITION\" value=\"@EDITION@\"/>","  </project>",
 "  <project name=\"cbauth\" path=\"godeps/src/github.com/couchbase/cbauth\" revision=\"4a6d537777f57b291a8126f94dfbe3201c1d4efc\"/>",
 "  <project name=\"cbflag\" path=\"godeps/src/github.com/couchbase/cbflag\" revision=\"ce5c10adbb78c1212aefda73a85f8cfd1c3ae7e9\"/>",
 "  <project name=\"cbft\" path=\"goproj/src/github.com/couchbase/cbft\" revision=\"99f44266178dbe423890d8dd5bb9439ef2a71318\"/>",
 "  <project name=\"cbgt\" path=\"goproj/src/github.com/couchbase/cbgt\" revision=\"10790963d9cbada17ebfff728ea9298c1c97b7c5\"/>",
 "  <project groups=\"notdefault,enterprise\" name=\"cbq-gui\" path=\"goproj/src/github.com/couchbase/cbq-gui\" remote=\"couchbase-priv\" revision=\"1e19e5e34b64ca6b43a37de6166dac6e76803848\"/>",
 "  <project name=\"clog\" path=\"godeps/src/github.com/couchbase/clog\" revision=\"eebc98233c3e032eb6b9036575d51324ab5932e6\"/>",
 "  <project name=\"context\" path=\"godeps/src/github.com/gorilla/context\" remote=\"couchbasedeps\" revision=\"215affda49addc4c8ef7e2534915df2c8c35c6cd\"/>",
 "  <project name=\"couchbase-cli\" revision=\"951668b6b2fcaa5386b31d59df5004ff667e91e8\"/>",
 "  <project name=\"couchbase-examples\" revision=\"39ee1c2451ac2f2e86a6ff308e21e1201c49cafe\"/>",
 "  <project name=\"couchdb\" revision=\"7b950cfaa3ad30c75a7fcc7f4eb30b2df1a8bd5b\"/>",
 "  <project groups=\"notdefault,packaging\" name=\"couchdbx-app\" revision=\"be5f6ebaa12ac7c0b5382deb9b1b0efa7bf80497\"/>",
 "  <project groups=\"kv\" name=\"couchstore\" revision=\"9cf71ba60cf95f8b835b1040c68c85a4ddc653ee\"/>",
 "  <project name=\"crypto\" path=\"godeps/src/golang.org/x/crypto\" remote=\"couchbasedeps\" revision=\"f23ba3a5ee43012fcb4b92e1a2a405a92554f4f2\"/>",
 "  <project name=\"cznic-b\" path=\"godeps/src/github.com/cznic/b\" remote=\"couchbasedeps\" revision=\"b96e30f1b7bd34b0b9d8760798d67eca83d7f09e\"/>",
 "  <project name=\"dparval\" path=\"godeps/src/github.com/couchbase/dparval\" revision=\"9def03782da875a2477c05bf64985db3f19f59ae\"/>",
 "  <project groups=\"kv\" name=\"ep-engine\" revision=\"e4c8bcbbf20b52b11e93665901597875e10b2070\"/>",
 "  <project groups=\"kv\" name=\"forestdb\" revision=\"1d169510a5102e81547b1d3dc423eb37db908076\"/>",
 "  <project name=\"geocouch\" revision=\"74b4bab07713b233ca2780f9a9a3f7daa1a1dff4\"/>",
 "  <project name=\"go-bindata-assetfs\" path=\"godeps/src/github.com/elazarl/go-bindata-assetfs\" remote=\"couchbasedeps\" revision=\"57eb5e1fc594ad4b0b1dbea7b286d299e0cb43c2\"/>",
 "  <project name=\"go-couchbase\" path=\"godeps/src/github.com/couchbase/go-couchbase\" revision=\"e06e5adaf45e189d4cf3e471341af0bf80bcc312\"/>",
 "  <project name=\"go-jsonpointer\" path=\"godeps/src/github.com/dustin/go-jsonpointer\" remote=\"couchbasedeps\" revision=\"75939f54b39e7dafae879e61f65438dadc5f288c\"/>",
 "  <project name=\"go-metrics\" path=\"godeps/src/github.com/rcrowley/go-metrics\" remote=\"couchbasedeps\" revision=\"dee209f2455f101a5e4e593dea94872d2c62d85d\"/>",
 "  <project name=\"go-porterstemmer\" path=\"godeps/src/github.com/blevesearch/go-porterstemmer\" remote=\"blevesearch\" revision=\"23a2c8e5cf1f380f27722c6d2ae8896431dc7d0e\"/>",
 "  <project name=\"go-slab\" path=\"godeps/src/github.com/couchbase/go-slab\" revision=\"1f5f7f282713ccfab3f46b1610cb8da34bcf676f\"/>",
 "  <project name=\"go-zookeeper\" path=\"godeps/src/github.com/samuel/go-zookeeper\" remote=\"couchbasedeps\" revision=\"fa6674abf3f4580b946a01bf7a1ce4ba8766205b\"/>",
 "  <project name=\"go_json\" path=\"godeps/src/github.com/couchbase/go_json\" revision=\"f5a178ab380eb9a1911cf9c45b4159115b564169\"/>",
 "  <project name=\"go_n1ql\" path=\"godeps/src/github.com/couchbase/go_n1ql\" revision=\"6cf4e348b127e21f56e53eb8c3faaea56afdc588\"/>",
 "  <project name=\"gocb\" path=\"godeps/src/github.com/couchbase/gocb\" revision=\"d5b1a13c1e81f1255ca8155007b470db37ddeb25\"/>",
 "  <project name=\"godbc\" path=\"godeps/src/github.com/couchbase/godbc\" revision=\"adc62033c392ca9df8b5b42c0dda237576b39f9f\"/>",
 "  <project name=\"goforestdb\" path=\"godeps/src/github.com/couchbase/goforestdb\" revision=\"0b501227de0e8c55d99ed14e900eea1a1dbaf899\"/>",
 "  <project name=\"gojson\" path=\"godeps/src/github.com/dustin/gojson\" remote=\"couchbasedeps\" revision=\"af16e0e771e2ed110f2785564ae33931de8829e4\"/>",
 "  <project name=\"golang-snappy\" path=\"godeps/src/github.com/golang/snappy\" remote=\"couchbasedeps\" revision=\"723cc1e459b8eea2dea4583200fd60757d40097a\"/>",
 "  <project name=\"goleveldb\" path=\"godeps/src/github.com/syndtr/goleveldb\" remote=\"couchbasedeps\" revision=\"fa5b5c78794bc5c18f330361059f871ae8c2b9d6\"/>",
 "  <project name=\"gomemcached\" path=\"godeps/src/github.com/couchbase/gomemcached\" revision=\"4604300463c4a379d36d1427b17d3284a93f7621\"/>",
 "  <project name=\"gometa\" path=\"goproj/src/github.com/couchbase/gometa\" revision=\"7da5634cce1de744293acf27bb2aecc13ee50cc5\"/>",
 "  <project groups=\"kv\" name=\"googletest\" remote=\"couchbasedeps\" revision=\"f397fa5ec6365329b2e82eb2d8c03a7897bbefb5\"/>",
 "  <project name=\"goskiplist\" path=\"godeps/src/github.com/ryszard/goskiplist\" remote=\"couchbasedeps\" revision=\"2dfbae5fcf46374f166f8969cb07e167f1be6273\"/>",
 "  <project name=\"gosnappy\" path=\"godeps/src/github.com/syndtr/gosnappy\" remote=\"couchbasedeps\" revision=\"156a073208e131d7d2e212cb749feae7c339e846\"/>",
 "  <project name=\"goutils\" path=\"godeps/src/github.com/couchbase/goutils\" revision=\"5823a0cbaaa9008406021dc5daf80125ea30bba6\"/>",
 "  <project name=\"goxdcr\" path=\"goproj/src/github.com/couchbase/goxdcr\" revision=\"0f66d74c38453d0c1a620588edb4ee6a8fc22577\"/>",
 "  <project name=\"gtreap\" path=\"godeps/src/github.com/steveyen/gtreap\" remote=\"couchbasedeps\" revision=\"0abe01ef9be25c4aedc174758ec2d917314d6d70\"/>",
 "  <project name=\"indexing\" path=\"goproj/src/github.com/couchbase/indexing\" revision=\"1811cdbff66216861320b7657590e961b10b2c0a\"/>",
 "  <project name=\"levigo\" path=\"godeps/src/github.com/jmhodges/levigo\" remote=\"couchbasedeps\" revision=\"1ddad808d437abb2b8a55a950ec2616caa88969b\"/>",
 "  <project name=\"liner\" path=\"godeps/src/github.com/peterh/liner\" remote=\"couchbasedeps\" revision=\"ad1edfd30321d8f006ccf05f1e0524adeb943060\"/>",
 "  <project name=\"liner\" path=\"godeps/src/github.com/sbinet/liner\" remote=\"couchbasedeps\" revision=\"d9335eee40a45a4f5d74524c90040d6fe6013d50\"/>",
 "  <project groups=\"kv\" name=\"memcached\" revision=\"45a464250e1358593fa9f11ec010ddd992f0a717\"/>",
 "  <project name=\"minify\" path=\"godeps/src/github.com/tdewolff/minify\" remote=\"couchbasedeps\" revision=\"ede45cc53f43891267b1fe7c689db9c76d4ce0fb\"/>",
 "  <project name=\"mmap-go\" path=\"godeps/src/github.com/edsrzf/mmap-go\" remote=\"couchbasedeps\" revision=\"935e0e8a636ca4ba70b713f3e38a19e1b77739e8\"/>",
 "  <project name=\"moss\" path=\"godeps/src/github.com/couchbase/moss\" revision=\"c7cc82a67cf3fe50faf9a0697516b885e4fa34b9\"/>",
 "  <project groups=\"kv\" name=\"moxi\" revision=\"363c250e6087a61bf2d4bc8d6eff3325956be731\"/>",
 "  <project name=\"mux\" path=\"godeps/src/github.com/gorilla/mux\" remote=\"couchbasedeps\" revision=\"8a875a034c69b940914d83ea03d3f1299b4d094b\"/>",
 "  <project name=\"net\" path=\"godeps/src/golang.org/x/net\" remote=\"couchbasedeps\" revision=\"8968c61983e8f51a91b8c0ef25bf739278c89634\"/>",
 "  <project name=\"npipe\" path=\"godeps/src/github.com/natefinch/npipe\" remote=\"couchbasedeps\" revision=\"272c8150302e83f23d32a355364578c9c13ab20f\"/>",
 "  <project name=\"ns_server\" revision=\"b6c99dc71308f44261bbcc80688de02942d69f19\"/>",
 "  <project name=\"parse\" path=\"godeps/src/github.com/tdewolff/parse\" remote=\"couchbasedeps\" revision=\"0334a869253aca4b3a10c56c3f3139b394aec3a9\"/>",
 "  <project groups=\"kv\" name=\"platform\" revision=\"a80097d53c779b548d8c78b0a1886b8d44591b23\"/>",
 "  <project name=\"protobuf\" path=\"godeps/src/github.com/golang/protobuf\" remote=\"couchbasedeps\" revision=\"655cdfa588ea190e901bc5590e65d5621688847c\"/>",
 "  <project name=\"query\" path=\"goproj/src/github.com/couchbase/query\" revision=\"2012f9b883199299df53dec638a2b91c21907a53\"/>",
 "  <project name=\"query-ui\" revision=\"ff1f502b2f0c544ca68d2bda60d80fc3a01d573a\"/>",
 "  <project name=\"retriever\" path=\"godeps/src/github.com/couchbase/retriever\" revision=\"e3419088e4d3b4fe3aad3b364fdbe9a154f85f17\"/>",
 "  <project name=\"segment\" path=\"godeps/src/github.com/blevesearch/segment\" remote=\"blevesearch\" revision=\"db70c57796cc8c310613541dfade3dce627d09c7\"/>",
 "  <project groups=\"kv\" name=\"sigar\" revision=\"83bd88595f558987731a1baa3330f641bc36554c\"/>",
 "  <project name=\"strconv\" path=\"godeps/src/github.com/tdewolff/strconv\" remote=\"couchbasedeps\" revision=\"9b189f5be77f33c46776f24dbddb2a7ab32af214\"/>",
 "  <project groups=\"kv\" name=\"subjson\" revision=\"65d3f053e2d968aea00b60234a42e1d1c5b9f6d2\"/>",
 "  <project groups=\"solaris,notdefault\" name=\"sys\" path=\"godeps/src/golang.org/x/sys\" remote=\"couchbasedeps\" revision=\"9d4e42a20653790449273b3c85e67d6d8bae6e2e\"/>",
 "  <project name=\"testrunner\" revision=\"d63ed33d4130ecac236711b4156d41328728e42e\"/>",
 "  <project name=\"text\" path=\"godeps/src/golang.org/x/text\" remote=\"couchbasedeps\" revision=\"601048ad6acbab6cedd582db09b8c4839ff25b15\"/>",
 "  <project groups=\"kv\" name=\"tlm\" revision=\"29fafd6b365e58e9fc43fad749ce20c900890a6b\">",
 "    <copyfile dest=\"GNUmakefile\" src=\"GNUmakefile\"/>",
 "    <copyfile dest=\"Makefile\" src=\"Makefile\"/>",
 "    <copyfile dest=\"CMakeLists.txt\" src=\"CMakeLists.txt\"/>",
 "  </project>",
 "  <project name=\"ts\" path=\"godeps/src/github.com/olekukonko/ts\" remote=\"couchbasedeps\" revision=\"ecf753e7c962639ab5a1fb46f7da627d4c0a04b8\"/>",
 "  <project groups=\"notdefault,packaging\" name=\"voltron\" remote=\"couchbase-priv\" revision=\"876e25cffb99e0ae89078a0443b179bcb5d639c2\"/>",
 "</manifest>"]

[error_logger:info,2021-04-19T19:54:06.306Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.129.0>},
                       {name,timeout_diag_logger},
                       {mfargs,{timeout_diag_logger,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:54:06.310Z,nonode@nohost:dist_manager<0.130.0>:dist_manager:read_address_config_from_path:86]Reading ip config from "/opt/couchbase/var/lib/couchbase/ip_start"
[ns_server:info,2021-04-19T19:54:06.311Z,nonode@nohost:dist_manager<0.130.0>:dist_manager:read_address_config_from_path:86]Reading ip config from "/opt/couchbase/var/lib/couchbase/ip"
[ns_server:info,2021-04-19T19:54:06.312Z,nonode@nohost:dist_manager<0.130.0>:dist_manager:init:163]ip config not found. Looks like we're brand new node
[error_logger:info,2021-04-19T19:54:06.313Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,inet_gethost_native_sup}
             started: [{pid,<0.132.0>},{mfa,{inet_gethost_native,init,[[]]}}]

[error_logger:info,2021-04-19T19:54:06.313Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.131.0>},
                       {name,inet_gethost_native_sup},
                       {mfargs,{inet_gethost_native,start_link,[]}},
                       {restart_type,temporary},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:54:07.143Z,nonode@nohost:dist_manager<0.130.0>:dist_manager:bringup:214]Attempting to bring up net_kernel with name 'ns_1@127.0.0.1'
[error_logger:info,2021-04-19T19:54:07.154Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.134.0>},
                       {name,erl_epmd},
                       {mfargs,{erl_epmd,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:07.154Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.135.0>},
                       {name,auth},
                       {mfargs,{auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:07.155Z,ns_1@127.0.0.1:dist_manager<0.130.0>:dist_manager:configure_net_kernel:255]Set net_kernel vebosity to 10 -> 0
[error_logger:info,2021-04-19T19:54:07.155Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.136.0>},
                       {name,net_kernel},
                       {mfargs,
                           {net_kernel,start_link,
                               [['ns_1@127.0.0.1',longnames]]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:07.155Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_sup}
             started: [{pid,<0.133.0>},
                       {name,net_sup_dynamic},
                       {mfargs,
                           {erl_distribution,start_link,
                               [['ns_1@127.0.0.1',longnames]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,supervisor}]

[ns_server:info,2021-04-19T19:54:07.158Z,ns_1@127.0.0.1:dist_manager<0.130.0>:dist_manager:save_node:147]saving node to "/opt/couchbase/var/lib/couchbase/couchbase-server.node"
[ns_server:debug,2021-04-19T19:54:07.175Z,ns_1@127.0.0.1:dist_manager<0.130.0>:dist_manager:bringup:228]Attempted to save node name to disk: ok
[ns_server:debug,2021-04-19T19:54:07.175Z,ns_1@127.0.0.1:dist_manager<0.130.0>:dist_manager:wait_for_node:235]Waiting for connection to node 'babysitter_of_ns_1@127.0.0.1' to be established
[error_logger:info,2021-04-19T19:54:07.175Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'babysitter_of_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:54:07.184Z,ns_1@127.0.0.1:dist_manager<0.130.0>:dist_manager:wait_for_node:244]Observed node 'babysitter_of_ns_1@127.0.0.1' to come up
[error_logger:info,2021-04-19T19:54:07.191Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.130.0>},
                       {name,dist_manager},
                       {mfargs,{dist_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:07.193Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.141.0>},
                       {name,ns_cookie_manager},
                       {mfargs,{ns_cookie_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:07.194Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.142.0>},
                       {name,ns_cluster},
                       {mfargs,{ns_cluster,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:54:07.197Z,ns_1@127.0.0.1:ns_config_sup<0.143.0>:ns_config_sup:init:32]loading static ns_config from "/opt/couchbase/etc/couchbase/config"
[error_logger:info,2021-04-19T19:54:07.197Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.144.0>},
                       {name,ns_config_events},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_config_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:07.197Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.145.0>},
                       {name,ns_config_events_local},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,ns_config_events_local}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:54:07.253Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_config:load_config:1083]Loading static config from "/opt/couchbase/etc/couchbase/config"
[ns_server:info,2021-04-19T19:54:07.261Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_config:load_config:1097]Loading dynamic config from "/opt/couchbase/var/lib/couchbase/config/config.dat"
[ns_server:debug,2021-04-19T19:54:07.278Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_config:load_config:1105]Here's full dynamic config we loaded:
[[{{metakv,<<"/indexing/settings/config">>},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{5,63786081155}}]}|
    <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.log_level\":\"info\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\":200,\"indexer.settings.max_cpu_percent\":0,\"indexer.settings.storage_mode\":\"memory_optimized\",\"indexer.settings.recovery.max_rollbacks\":5,\"indexer.settings.memory_quota\":314572800,\"indexer.settings.compaction.abort_exceed_interval\":false}">>]},
  {alert_limits,
   [{max_overhead_perc,50},{max_disk_used,90},{max_indexer_ram,75}]},
  {audit,
   [{auditd_enabled,false},
    {rotate_interval,86400},
    {rotate_size,20971520},
    {disabled,[]},
    {sync,[]},
    {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]},
  {auto_failover_cfg,[{enabled,false},{timeout,120},{max_nodes,1},{count,0}]},
  {autocompaction,
   [{database_fragmentation_threshold,{30,undefined}},
    {view_fragmentation_threshold,{30,undefined}}]},
  {buckets,[{configs,[]}]},
  {cert_and_pkey,
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080746}}]}|
    {<<"-----BEGIN CERTIFICATE-----\nMIIDAjCCAeqgAwIBAgIIFndZ/+GzDYAwDQYJKoZIhvcNAQELBQAwJDEiMCAGA1UE\nAxMZQ291Y2hiYXNlIFNlcnZlciA4ODFmOWE4YzAeFw0xMzAxMDEwMDAwMDBaFw00\nOTEyMzEyMzU5NTlaMCQxIjAgBgNVBAMTGUNvdWNoYmFzZSBTZXJ2ZXIgODgxZjlh\nOGMwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCz0vvVTMTWH8JLsYfx\nMZ+egYFMFORYbynBjyuWB7+ltQbKZKtnruph7r3agBX8qzQLo1fbuaNJIkb2/TYZ\n7q61KM7aIxCPKBtKs0ms85z8gseSLb3P9dGXLcXHk3KrjUDOO4hh9KPVjY6773bq\nwCjUoqXNBTGySfNZ8Vj6WaDZ1fhxAo6perMdIBIS7TlqPICd7TGWW+Y1BoqljPEy\nYuaym5srhXBN6TvIiUzRGuEjmOnf7mYTj+zEstHhc3TRLgk7NF3vlpVjvVu7UAph\nMWvt5uXp+7tDC40YEzJM7tLU9sWHM46hkUHS95PR+moz9+7V0Su/Ifhb2z+O5eS4\n7HTVAgMBAAGjODA2MA4GA1UdDwEB/wQEAwICpDATBgNVHSUEDDAKBggrBgEFBQcD\nATAPBgNVHRMBAf8EBTADAQH/MA0GCSqGSIb3DQEBCwUAA4IBAQCBpPSeTxLjwYFj\nFuVzvFtSDibDDAXlI9/vqBmcMOJHTFU8M7eGdnL3Wt6GTRQ2m5fbxfz1ez8BvgR1\nUf5i36T9fkDVV5PvS5tjo5u0HGfjmZYpYgagh+Jf6dSzkMcxt/b0W0qeGgUuHxWR\na50a75WQZa0sxyLGKc1ogxykvpBjVETfZaT3JipmtqtyE2ddjddGX4q2mkdVKatI\nQQ8y9zftTlhxwICviP588S7FJ9u1njXVmxwaUSiB1iElOy57WBz+9exdWOhAn3TO\ncDtPcuVHD8GRd0IZ96Yk1mPMDWe99syzNNcpXPDtbgnjqobifQwBXIdA7OS+fDnc\nULaceJqi\n-----END CERTIFICATE-----\n">>,
     <<"*****">>}]},
  {cluster_compat_version,
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{6,63786080754}}]},
    4,6]},
  {drop_request_memory_threshold_mib,undefined},
  {email_alerts,
   [{recipients,["root@localhost"]},
    {sender,"couchbase@localhost"},
    {enabled,false},
    {email_server,
     [{user,[]},{pass,"*****"},{host,"localhost"},{port,25},{encrypt,false}]},
    {alerts,
     [auto_failover_node,auto_failover_maximum_reached,
      auto_failover_other_nodes_down,auto_failover_cluster_too_small,
      auto_failover_disabled,ip,disk,overhead,ep_oom_errors,
      ep_item_commit_failed,audit_dropped_events,indexer_ram_max_usage,
      ep_clock_cas_drift_threshold_exceeded]}]},
  {fts_memory_quota,512},
  {goxdcr_upgrade,
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080754}}]}|
    '_deleted']},
  {index_aware_rebalance_disabled,false},
  {max_bucket_count,10},
  {memcached,[]},
  {memory_quota,
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080759}}]}|
    300]},
  {nodes_wanted,['ns_1@127.0.0.1']},
  {otp,
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080753}}]},
    {cookie,{sanitized,<<"Gldz+3QHYFD9UMWZ6D/7VCdFO4es4rvk9HPUTz5soFw=">>}}]},
  {read_only_user_creds,
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080754}}]}|
    null]},
  {remote_clusters,[]},
  {replication,[{enabled,true}]},
  {rest,[{port,8091}]},
  {rest_creds,
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{2,63786080759}}]}|
    {"Administrator",{password,"*****"}}]},
  {roles_definitions,
   [{admin,[],
     [{name,<<"Admin">>},
      {desc,<<"Can manage ALL cluster features including security.">>}],
     [{[],all}]},
    {ro_admin,[],
     [{name,<<"Read Only Admin">>},
      {desc,<<"Can view ALL cluster features.">>}],
     [{[{bucket,any},password],none},
      {[{bucket,any},data],none},
      {[admin,security],[read]},
      {[admin],none},
      {[],[read]}]},
    {cluster_admin,[],
     [{name,<<"Cluster Admin">>},
      {desc,<<"Can manage all cluster features EXCEPT security.">>}],
     [{[admin],none},{[],all}]},
    {bucket_admin,
     [bucket_name],
     [{name,<<"Bucket Admin">>},
      {desc,
       <<"Can manage ALL bucket features for specified buckets (incl. start/stop XDCR)">>}],
     [{[{bucket,bucket_name},xdcr],[read,execute]},
      {[{bucket,bucket_name}],all},
      {[{bucket,any},settings],[read]},
      {[{bucket,any}],none},
      {[xdcr],none},
      {[admin],none},
      {[],[read]}]},
    {bucket_sasl,
     [bucket_name],
     [],
     [{[{bucket,bucket_name},data],all},
      {[{bucket,bucket_name},views],all},
      {[{bucket,bucket_name}],[read,flush]},
      {[pools],[read]}]},
    {views_admin,
     [bucket_name],
     [{name,<<"Views Admin">>},
      {desc,<<"Can manage views for specified buckets">>}],
     [{[{bucket,bucket_name},views],all},
      {[{bucket,bucket_name},data],[read]},
      {[{bucket,any},settings],[read]},
      {[{bucket,any}],none},
      {[xdcr],none},
      {[admin],none},
      {[],[read]}]},
    {replication_admin,[],
     [{name,<<"Replication Admin">>},
      {desc,<<"Can manage ONLY XDCR features (cluster AND bucket level)">>}],
     [{[{bucket,any},xdcr],all},
      {[{bucket,any},data],[read]},
      {[{bucket,any},settings],[read]},
      {[{bucket,any}],none},
      {[xdcr],all},
      {[admin],none},
      {[],[read]}]}]},
  {server_groups,
   [[{uuid,<<"0">>},{name,<<"Group 1">>},{nodes,['ns_1@127.0.0.1']}]]},
  {set_view_update_daemon,
   [{update_interval,5000},
    {update_min_changes,5000},
    {replica_update_min_changes,5000}]},
  {uuid,
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080759}}]}|
    <<"aaf7f03de532d2dc46a1e96329b1eb02">>]},
  {{couchdb,max_parallel_indexers},4},
  {{couchdb,max_parallel_replica_indexers},2},
  {{local_changes_count,<<"dbb8bee8b38705437e7f5ebc78107bfa">>},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{13,63786081155}}]}]},
  {{request_limit,capi},undefined},
  {{request_limit,rest},undefined},
  {{service_map,fts},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080754}}]}]},
  {{service_map,index},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{2,63786080764}}]},
    'ns_1@127.0.0.1']},
  {{service_map,n1ql},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{2,63786080764}}]},
    'ns_1@127.0.0.1']},
  {{node,'ns_1@127.0.0.1',audit},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}]},
  {{node,'ns_1@127.0.0.1',capi_port},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    8092]},
  {{node,'ns_1@127.0.0.1',compaction_daemon},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
    {check_interval,30},
    {min_db_file_size,131072},
    {min_view_file_size,20971520}]},
  {{node,'ns_1@127.0.0.1',config_version},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    {4,5}]},
  {{node,'ns_1@127.0.0.1',fts_http_port},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    8094]},
  {{node,'ns_1@127.0.0.1',indexer_admin_port},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    9100]},
  {{node,'ns_1@127.0.0.1',indexer_http_port},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    9102]},
  {{node,'ns_1@127.0.0.1',indexer_scan_port},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    9101]},
  {{node,'ns_1@127.0.0.1',indexer_stcatchup_port},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    9104]},
  {{node,'ns_1@127.0.0.1',indexer_stinit_port},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    9103]},
  {{node,'ns_1@127.0.0.1',indexer_stmaint_port},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    9105]},
  {{node,'ns_1@127.0.0.1',is_enterprise},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    true]},
  {{node,'ns_1@127.0.0.1',isasl},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
    {path,"/opt/couchbase/var/lib/couchbase/isasl.pw"}]},
  {{node,'ns_1@127.0.0.1',ldap_enabled},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    true]},
  {{node,'ns_1@127.0.0.1',membership},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    active]},
  {{node,'ns_1@127.0.0.1',memcached},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
    {port,11210},
    {dedicated_port,11209},
    {ssl_port,11207},
    {admin_user,"_admin"},
    {admin_pass,"*****"},
    {engines,
     [{membase,
       [{engine,"/opt/couchbase/lib/memcached/ep.so"},
        {static_config_string,"failpartialwarmup=false"}]},
      {memcached,
       [{engine,"/opt/couchbase/lib/memcached/default_engine.so"},
        {static_config_string,"vb0=true"}]}]},
    {config_path,"/opt/couchbase/var/lib/couchbase/config/memcached.json"},
    {audit_file,"/opt/couchbase/var/lib/couchbase/config/audit.json"},
    {log_path,"/opt/couchbase/var/lib/couchbase/logs"},
    {log_prefix,"memcached.log"},
    {log_generations,20},
    {log_cyclesize,10485760},
    {log_sleeptime,19},
    {log_rotation_period,39003}]},
  {{node,'ns_1@127.0.0.1',memcached_config},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    {[{interfaces,
       {memcached_config_mgr,omit_missing_mcd_ports,
        [{[{host,<<"*">>},{port,port},{maxconn,maxconn}]},
         {[{host,<<"*">>},
           {port,dedicated_port},
           {maxconn,dedicated_port_maxconn}]},
         {[{host,<<"*">>},
           {port,ssl_port},
           {maxconn,maxconn},
           {ssl,
            {[{key,
               <<"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem">>},
              {cert,
               <<"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem">>}]}}]}]}},
      {ssl_cipher_list,{"~s",[ssl_cipher_list]}},
      {ssl_minimum_protocol,{memcached_config_mgr,ssl_minimum_protocol,[]}},
      {connection_idle_time,connection_idle_time},
      {breakpad,
       {[{enabled,breakpad_enabled},
         {minidump_dir,{memcached_config_mgr,get_minidump_dir,[]}}]}},
      {extensions,
       [{[{module,<<"/opt/couchbase/lib/memcached/stdin_term_handler.so">>},
          {config,<<>>}]},
        {[{module,<<"/opt/couchbase/lib/memcached/file_logger.so">>},
          {config,
           {"cyclesize=~B;sleeptime=~B;filename=~s/~s",
            [log_cyclesize,log_sleeptime,log_path,log_prefix]}}]}]},
      {admin,{"~s",[admin_user]}},
      {verbosity,verbosity},
      {audit_file,{"~s",[audit_file]}},
      {dedupe_nmvb_maps,dedupe_nmvb_maps}]}]},
  {{node,'ns_1@127.0.0.1',memcached_defaults},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
    {maxconn,30000},
    {dedicated_port_maxconn,5000},
    {ssl_cipher_list,"HIGH"},
    {connection_idle_time,0},
    {verbosity,0},
    {breakpad_enabled,true},
    {breakpad_minidump_dir_path,"/opt/couchbase/var/lib/couchbase/crash"},
    {dedupe_nmvb_maps,false}]},
  {{node,'ns_1@127.0.0.1',moxi},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
    {port,11211},
    {verbosity,[]}]},
  {{node,'ns_1@127.0.0.1',ns_log},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
    {filename,"/opt/couchbase/var/lib/couchbase/ns_log"}]},
  {{node,'ns_1@127.0.0.1',port_servers},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}]},
  {{node,'ns_1@127.0.0.1',projector_port},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    9999]},
  {{node,'ns_1@127.0.0.1',query_port},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    8093]},
  {{node,'ns_1@127.0.0.1',rest},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
    {port,8091},
    {port_meta,global}]},
  {{node,'ns_1@127.0.0.1',services},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080759}}]},
    index,kv,n1ql]},
  {{node,'ns_1@127.0.0.1',ssl_capi_port},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    18092]},
  {{node,'ns_1@127.0.0.1',ssl_proxy_downstream_port},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    11214]},
  {{node,'ns_1@127.0.0.1',ssl_proxy_upstream_port},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    11215]},
  {{node,'ns_1@127.0.0.1',ssl_query_port},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    18093]},
  {{node,'ns_1@127.0.0.1',ssl_rest_port},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    18091]},
  {{node,'ns_1@127.0.0.1',stop_xdcr},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{2,63786080754}}]}|
    '_deleted']},
  {{node,'ns_1@127.0.0.1',uuid},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    <<"dbb8bee8b38705437e7f5ebc78107bfa">>]},
  {{node,'ns_1@127.0.0.1',xdcr_rest_port},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    9998]}]]
[ns_server:info,2021-04-19T19:54:07.286Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_config:load_config:1126]Here's full dynamic config we loaded + static & default config:
[{{node,'ns_1@127.0.0.1',xdcr_rest_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   9998]},
 {{node,'ns_1@127.0.0.1',uuid},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   <<"dbb8bee8b38705437e7f5ebc78107bfa">>]},
 {{node,'ns_1@127.0.0.1',stop_xdcr},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{2,63786080754}}]}|
   '_deleted']},
 {{node,'ns_1@127.0.0.1',ssl_rest_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   18091]},
 {{node,'ns_1@127.0.0.1',ssl_query_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   18093]},
 {{node,'ns_1@127.0.0.1',ssl_proxy_upstream_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   11215]},
 {{node,'ns_1@127.0.0.1',ssl_proxy_downstream_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   11214]},
 {{node,'ns_1@127.0.0.1',ssl_capi_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   18092]},
 {{node,'ns_1@127.0.0.1',services},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080759}}]},
   index,kv,n1ql]},
 {{node,'ns_1@127.0.0.1',rest},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
   {port,8091},
   {port_meta,global}]},
 {{node,'ns_1@127.0.0.1',query_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   8093]},
 {{node,'ns_1@127.0.0.1',projector_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   9999]},
 {{node,'ns_1@127.0.0.1',port_servers},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}]},
 {{node,'ns_1@127.0.0.1',ns_log},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
   {filename,"/opt/couchbase/var/lib/couchbase/ns_log"}]},
 {{node,'ns_1@127.0.0.1',moxi},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
   {port,11211},
   {verbosity,[]}]},
 {{node,'ns_1@127.0.0.1',memcached_defaults},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
   {maxconn,30000},
   {dedicated_port_maxconn,5000},
   {ssl_cipher_list,"HIGH"},
   {connection_idle_time,0},
   {verbosity,0},
   {breakpad_enabled,true},
   {breakpad_minidump_dir_path,"/opt/couchbase/var/lib/couchbase/crash"},
   {dedupe_nmvb_maps,false}]},
 {{node,'ns_1@127.0.0.1',memcached_config},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   {[{interfaces,
      {memcached_config_mgr,omit_missing_mcd_ports,
       [{[{host,<<"*">>},{port,port},{maxconn,maxconn}]},
        {[{host,<<"*">>},
          {port,dedicated_port},
          {maxconn,dedicated_port_maxconn}]},
        {[{host,<<"*">>},
          {port,ssl_port},
          {maxconn,maxconn},
          {ssl,
           {[{key,
              <<"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem">>},
             {cert,
              <<"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem">>}]}}]}]}},
     {ssl_cipher_list,{"~s",[ssl_cipher_list]}},
     {ssl_minimum_protocol,{memcached_config_mgr,ssl_minimum_protocol,[]}},
     {connection_idle_time,connection_idle_time},
     {breakpad,
      {[{enabled,breakpad_enabled},
        {minidump_dir,{memcached_config_mgr,get_minidump_dir,[]}}]}},
     {extensions,
      [{[{module,<<"/opt/couchbase/lib/memcached/stdin_term_handler.so">>},
         {config,<<>>}]},
       {[{module,<<"/opt/couchbase/lib/memcached/file_logger.so">>},
         {config,
          {"cyclesize=~B;sleeptime=~B;filename=~s/~s",
           [log_cyclesize,log_sleeptime,log_path,log_prefix]}}]}]},
     {admin,{"~s",[admin_user]}},
     {verbosity,verbosity},
     {audit_file,{"~s",[audit_file]}},
     {dedupe_nmvb_maps,dedupe_nmvb_maps}]}]},
 {{node,'ns_1@127.0.0.1',memcached},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
   {port,11210},
   {dedicated_port,11209},
   {ssl_port,11207},
   {admin_user,"_admin"},
   {admin_pass,"*****"},
   {engines,
    [{membase,
      [{engine,"/opt/couchbase/lib/memcached/ep.so"},
       {static_config_string,"failpartialwarmup=false"}]},
     {memcached,
      [{engine,"/opt/couchbase/lib/memcached/default_engine.so"},
       {static_config_string,"vb0=true"}]}]},
   {config_path,"/opt/couchbase/var/lib/couchbase/config/memcached.json"},
   {audit_file,"/opt/couchbase/var/lib/couchbase/config/audit.json"},
   {log_path,"/opt/couchbase/var/lib/couchbase/logs"},
   {log_prefix,"memcached.log"},
   {log_generations,20},
   {log_cyclesize,10485760},
   {log_sleeptime,19},
   {log_rotation_period,39003}]},
 {{node,'ns_1@127.0.0.1',membership},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   active]},
 {{node,'ns_1@127.0.0.1',ldap_enabled},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   true]},
 {{node,'ns_1@127.0.0.1',isasl},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
   {path,"/opt/couchbase/var/lib/couchbase/isasl.pw"}]},
 {{node,'ns_1@127.0.0.1',is_enterprise},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   true]},
 {{node,'ns_1@127.0.0.1',indexer_stmaint_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   9105]},
 {{node,'ns_1@127.0.0.1',indexer_stinit_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   9103]},
 {{node,'ns_1@127.0.0.1',indexer_stcatchup_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   9104]},
 {{node,'ns_1@127.0.0.1',indexer_scan_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   9101]},
 {{node,'ns_1@127.0.0.1',indexer_http_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   9102]},
 {{node,'ns_1@127.0.0.1',indexer_admin_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   9100]},
 {{node,'ns_1@127.0.0.1',fts_http_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   8094]},
 {{node,'ns_1@127.0.0.1',config_version},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   {4,5}]},
 {{node,'ns_1@127.0.0.1',compaction_daemon},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
   {check_interval,30},
   {min_db_file_size,131072},
   {min_view_file_size,20971520}]},
 {{node,'ns_1@127.0.0.1',capi_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   8092]},
 {{node,'ns_1@127.0.0.1',audit},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}]},
 {{service_map,n1ql},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{2,63786080764}}]},
   'ns_1@127.0.0.1']},
 {{service_map,index},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{2,63786080764}}]},
   'ns_1@127.0.0.1']},
 {{service_map,fts},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080754}}]}]},
 {{request_limit,rest},undefined},
 {{request_limit,capi},undefined},
 {{local_changes_count,<<"dbb8bee8b38705437e7f5ebc78107bfa">>},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{13,63786081155}}]}]},
 {{couchdb,max_parallel_replica_indexers},2},
 {{couchdb,max_parallel_indexers},4},
 {uuid,
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080759}}]}|
   <<"aaf7f03de532d2dc46a1e96329b1eb02">>]},
 {set_view_update_daemon,
  [{update_interval,5000},
   {update_min_changes,5000},
   {replica_update_min_changes,5000}]},
 {server_groups,
  [[{uuid,<<"0">>},{name,<<"Group 1">>},{nodes,['ns_1@127.0.0.1']}]]},
 {roles_definitions,
  [{admin,[],
    [{name,<<"Admin">>},
     {desc,<<"Can manage ALL cluster features including security.">>}],
    [{[],all}]},
   {ro_admin,[],
    [{name,<<"Read Only Admin">>},{desc,<<"Can view ALL cluster features.">>}],
    [{[{bucket,any},password],none},
     {[{bucket,any},data],none},
     {[admin,security],[read]},
     {[admin],none},
     {[],[read]}]},
   {cluster_admin,[],
    [{name,<<"Cluster Admin">>},
     {desc,<<"Can manage all cluster features EXCEPT security.">>}],
    [{[admin],none},{[],all}]},
   {bucket_admin,
    [bucket_name],
    [{name,<<"Bucket Admin">>},
     {desc,
      <<"Can manage ALL bucket features for specified buckets (incl. start/stop XDCR)">>}],
    [{[{bucket,bucket_name},xdcr],[read,execute]},
     {[{bucket,bucket_name}],all},
     {[{bucket,any},settings],[read]},
     {[{bucket,any}],none},
     {[xdcr],none},
     {[admin],none},
     {[],[read]}]},
   {bucket_sasl,
    [bucket_name],
    [],
    [{[{bucket,bucket_name},data],all},
     {[{bucket,bucket_name},views],all},
     {[{bucket,bucket_name}],[read,flush]},
     {[pools],[read]}]},
   {views_admin,
    [bucket_name],
    [{name,<<"Views Admin">>},
     {desc,<<"Can manage views for specified buckets">>}],
    [{[{bucket,bucket_name},views],all},
     {[{bucket,bucket_name},data],[read]},
     {[{bucket,any},settings],[read]},
     {[{bucket,any}],none},
     {[xdcr],none},
     {[admin],none},
     {[],[read]}]},
   {replication_admin,[],
    [{name,<<"Replication Admin">>},
     {desc,<<"Can manage ONLY XDCR features (cluster AND bucket level)">>}],
    [{[{bucket,any},xdcr],all},
     {[{bucket,any},data],[read]},
     {[{bucket,any},settings],[read]},
     {[{bucket,any}],none},
     {[xdcr],all},
     {[admin],none},
     {[],[read]}]}]},
 {rest_creds,
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{2,63786080759}}]}|
   {"Administrator",{password,"*****"}}]},
 {rest,[{port,8091}]},
 {replication,[{enabled,true}]},
 {remote_clusters,[]},
 {read_only_user_creds,
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080754}}]}|
   null]},
 {otp,
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080753}}]},
   {cookie,{sanitized,<<"Gldz+3QHYFD9UMWZ6D/7VCdFO4es4rvk9HPUTz5soFw=">>}}]},
 {nodes_wanted,['ns_1@127.0.0.1']},
 {memory_quota,
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080759}}]}|
   300]},
 {memcached,[]},
 {max_bucket_count,10},
 {index_aware_rebalance_disabled,false},
 {goxdcr_upgrade,
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080754}}]}|
   '_deleted']},
 {fts_memory_quota,512},
 {email_alerts,
  [{recipients,["root@localhost"]},
   {sender,"couchbase@localhost"},
   {enabled,false},
   {email_server,
    [{user,[]},{pass,"*****"},{host,"localhost"},{port,25},{encrypt,false}]},
   {alerts,
    [auto_failover_node,auto_failover_maximum_reached,
     auto_failover_other_nodes_down,auto_failover_cluster_too_small,
     auto_failover_disabled,ip,disk,overhead,ep_oom_errors,
     ep_item_commit_failed,audit_dropped_events,indexer_ram_max_usage,
     ep_clock_cas_drift_threshold_exceeded]}]},
 {drop_request_memory_threshold_mib,undefined},
 {cluster_compat_version,
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{6,63786080754}}]},
   4,6]},
 {cert_and_pkey,
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080746}}]}|
   {<<"-----BEGIN CERTIFICATE-----\nMIIDAjCCAeqgAwIBAgIIFndZ/+GzDYAwDQYJKoZIhvcNAQELBQAwJDEiMCAGA1UE\nAxMZQ291Y2hiYXNlIFNlcnZlciA4ODFmOWE4YzAeFw0xMzAxMDEwMDAwMDBaFw00\nOTEyMzEyMzU5NTlaMCQxIjAgBgNVBAMTGUNvdWNoYmFzZSBTZXJ2ZXIgODgxZjlh\nOGMwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCz0vvVTMTWH8JLsYfx\nMZ+egYFMFORYbynBjyuWB7+ltQbKZKtnruph7r3agBX8qzQLo1fbuaNJIkb2/TYZ\n7q61KM7aIxCPKBtKs0ms85z8gseSLb3P9dGXLcXHk3KrjUDOO4hh9KPVjY6773bq\nwCjUoqXNBTGySfNZ8Vj6WaDZ1fhxAo6perMdIBIS7TlqPICd7TGWW+Y1BoqljPEy\nYuaym5srhXBN6TvIiUzRGuEjmOnf7mYTj+zEstHhc3TRLgk7NF3vlpVjvVu7UAph\nMWvt5uXp+7tDC40YEzJM7tLU9sWHM46hkUHS95PR+moz9+7V0Su/Ifhb2z+O5eS4\n7HTVAgMBAAGjODA2MA4GA1UdDwEB/wQEAwICpDATBgNVHSUEDDAKBggrBgEFBQcD\nATAPBgNVHRMBAf8EBTADAQH/MA0GCSqGSIb3DQEBCwUAA4IBAQCBpPSeTxLjwYFj\nFuVzvFtSDibDDAXlI9/vqBmcMOJHTFU8M7eGdnL3Wt6GTRQ2m5fbxfz1ez8BvgR1\nUf5i36T9fkDVV5PvS5tjo5u0HGfjmZYpYgagh+Jf6dSzkMcxt/b0W0qeGgUuHxWR\na50a75WQZa0sxyLGKc1ogxykvpBjVETfZaT3JipmtqtyE2ddjddGX4q2mkdVKatI\nQQ8y9zftTlhxwICviP588S7FJ9u1njXVmxwaUSiB1iElOy57WBz+9exdWOhAn3TO\ncDtPcuVHD8GRd0IZ96Yk1mPMDWe99syzNNcpXPDtbgnjqobifQwBXIdA7OS+fDnc\nULaceJqi\n-----END CERTIFICATE-----\n">>,
    <<"*****">>}]},
 {buckets,[{configs,[]}]},
 {autocompaction,
  [{database_fragmentation_threshold,{30,undefined}},
   {view_fragmentation_threshold,{30,undefined}}]},
 {auto_failover_cfg,[{enabled,false},{timeout,120},{max_nodes,1},{count,0}]},
 {audit,
  [{auditd_enabled,false},
   {rotate_interval,86400},
   {rotate_size,20971520},
   {disabled,[]},
   {sync,[]},
   {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]},
 {alert_limits,
  [{max_overhead_perc,50},{max_disk_used,90},{max_indexer_ram,75}]},
 {{metakv,<<"/indexing/settings/config">>},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{5,63786081155}}]}|
   <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.log_level\":\"info\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\":200,\"indexer.settings.max_cpu_percent\":0,\"indexer.settings.storage_mode\":\"memory_optimized\",\"indexer.settings.recovery.max_rollbacks\":5,\"indexer.settings.memory_quota\":314572800,\"indexer.settings.compaction.abort_exceed_interval\":false}">>]}]
[error_logger:info,2021-04-19T19:54:07.290Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.146.0>},
                       {name,ns_config},
                       {mfargs,
                           {ns_config,start_link,
                               ["/opt/couchbase/etc/couchbase/config",
                                ns_config_default]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:07.293Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.149.0>},
                       {name,ns_config_remote},
                       {mfargs,
                           {ns_config_replica,start_link,
                               [{local,ns_config_remote}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:07.296Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.150.0>},
                       {name,ns_config_log},
                       {mfargs,{ns_config_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:07.296Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.143.0>},
                       {name,ns_config_sup},
                       {mfargs,{ns_config_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:54:07.299Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.152.0>},
                       {name,vbucket_filter_changes_registry},
                       {mfargs,
                           {ns_process_registry,start_link,
                               [vbucket_filter_changes_registry,
                                [{terminate_command,shutdown}]]}},
                       {restart_type,permanent},
                       {shutdown,100},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:07.302Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.153.0>},
                       {name,json_rpc_connection_sup},
                       {mfargs,{json_rpc_connection_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:54:07.317Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.156.0>},
                       {name,remote_monitors},
                       {mfargs,{remote_monitors,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:07.319Z,ns_1@127.0.0.1:menelaus_barrier<0.157.0>:one_shot_barrier:barrier_body:58]Barrier menelaus_barrier has started
[error_logger:info,2021-04-19T19:54:07.319Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.157.0>},
                       {name,menelaus_barrier},
                       {mfargs,{menelaus_sup,barrier_start_link,[]}},
                       {restart_type,temporary},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:07.319Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.158.0>},
                       {name,rest_lhttpc_pool},
                       {mfargs,
                           {lhttpc_manager,start_link,
                               [[{name,rest_lhttpc_pool},
                                 {connection_timeout,120000},
                                 {pool_size,20}]]}},
                       {restart_type,{permanent,1}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:54:07.355Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.160.0>:ns_ssl_services_setup:init:370]Used ssl options:
[{keyfile,"/opt/couchbase/var/lib/couchbase/config/ssl-cert-key.pem"},
 {certfile,"/opt/couchbase/var/lib/couchbase/config/ssl-cert-key.pem"},
 {versions,[tlsv1,'tlsv1.1','tlsv1.2']},
 {cacertfile,"/opt/couchbase/var/lib/couchbase/config/ssl-cert-key.pem-ca"},
 {dh,<<48,130,1,8,2,130,1,1,0,152,202,99,248,92,201,35,238,246,5,77,93,120,10,
       118,129,36,52,111,193,167,220,49,229,106,105,152,133,121,157,73,158,
       232,153,197,197,21,171,140,30,207,52,165,45,8,221,162,21,199,183,66,
       211,247,51,224,102,214,190,130,96,253,218,193,35,43,139,145,89,200,250,
       145,92,50,80,134,135,188,205,254,148,122,136,237,220,186,147,187,104,
       159,36,147,217,117,74,35,163,145,249,175,242,18,221,124,54,140,16,246,
       169,84,252,45,47,99,136,30,60,189,203,61,86,225,117,255,4,91,46,110,
       167,173,106,51,65,10,248,94,225,223,73,40,232,140,26,11,67,170,118,190,
       67,31,127,233,39,68,88,132,171,224,62,187,207,160,189,209,101,74,8,205,
       174,146,173,80,105,144,246,25,153,86,36,24,178,163,64,202,221,95,184,
       110,244,32,226,217,34,55,188,230,55,16,216,247,173,246,139,76,187,66,
       211,159,17,46,20,18,48,80,27,250,96,189,29,214,234,241,34,69,254,147,
       103,220,133,40,164,84,8,44,241,61,164,151,9,135,41,60,75,4,202,133,173,
       72,6,69,167,89,112,174,40,229,171,2,1,2>>},
 {ciphers,[{dhe_rsa,aes_256_cbc,sha256},
           {dhe_dss,aes_256_cbc,sha256},
           {rsa,aes_256_cbc,sha256},
           {dhe_rsa,aes_128_cbc,sha256},
           {dhe_dss,aes_128_cbc,sha256},
           {rsa,aes_128_cbc,sha256},
           {dhe_rsa,aes_256_cbc,sha},
           {dhe_dss,aes_256_cbc,sha},
           {rsa,aes_256_cbc,sha},
           {dhe_rsa,'3des_ede_cbc',sha},
           {dhe_dss,'3des_ede_cbc',sha},
           {rsa,'3des_ede_cbc',sha},
           {dhe_rsa,aes_128_cbc,sha},
           {dhe_dss,aes_128_cbc,sha},
           {rsa,aes_128_cbc,sha}]}]
[error_logger:info,2021-04-19T19:54:07.450Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_ssl_services_sup}
             started: [{pid,<0.160.0>},
                       {name,ns_ssl_services_setup},
                       {mfargs,{ns_ssl_services_setup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:54:07.492Z,ns_1@127.0.0.1:<0.162.0>:menelaus_pluggable_ui:validate_plugin_spec:117]Loaded pluggable UI specification for fts

[ns_server:info,2021-04-19T19:54:07.492Z,ns_1@127.0.0.1:<0.162.0>:menelaus_pluggable_ui:validate_plugin_spec:117]Loaded pluggable UI specification for n1ql

[ns_server:debug,2021-04-19T19:54:07.521Z,ns_1@127.0.0.1:<0.162.0>:restartable:start_child:98]Started child process <0.164.0>
  MFA: {ns_ssl_services_setup,start_link_rest_service,[]}
[error_logger:info,2021-04-19T19:54:07.521Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_ssl_services_sup}
             started: [{pid,<0.162.0>},
                       {name,ns_rest_ssl_service},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_ssl_services_setup,
                                    start_link_rest_service,[]},
                                1000]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:07.521Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.159.0>},
                       {name,ns_ssl_services_sup},
                       {mfargs,{ns_ssl_services_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:54:07.536Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.181.0>},
                       {name,start_couchdb_node},
                       {mfargs,{ns_server_nodes_sup,start_couchdb_node,[]}},
                       {restart_type,{permanent,5}},
                       {shutdown,86400000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:07.537Z,ns_1@127.0.0.1:wait_link_to_couchdb_node<0.182.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:126]Waiting for ns_couchdb node to start
[error_logger:info,2021-04-19T19:54:07.537Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:54:07.538Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.185.0>,shutdown}}
[ns_server:debug,2021-04-19T19:54:07.538Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:54:07.538Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:54:07.739Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:54:07.740Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.188.0>,shutdown}}
[error_logger:info,2021-04-19T19:54:07.740Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:54:07.740Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:54:07.941Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:54:07.941Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:54:07.941Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.191.0>,shutdown}}
[error_logger:info,2021-04-19T19:54:07.942Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:54:08.143Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:54:08.143Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:54:08.143Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.194.0>,shutdown}}
[error_logger:info,2021-04-19T19:54:08.144Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:54:08.345Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:54:08.345Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:54:08.345Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.197.0>,shutdown}}
[error_logger:info,2021-04-19T19:54:08.346Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:54:08.547Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:54:08.548Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.200.0>,shutdown}}
[ns_server:debug,2021-04-19T19:54:08.548Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:54:08.548Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:54:08.749Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:54:08.750Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:54:08.750Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.203.0>,shutdown}}
[error_logger:info,2021-04-19T19:54:08.750Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:54:08.951Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:54:08.952Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:54:08.952Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.206.0>,shutdown}}
[error_logger:info,2021-04-19T19:54:08.952Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:54:09.153Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:54:09.154Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.209.0>,shutdown}}
[ns_server:debug,2021-04-19T19:54:09.155Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:54:09.155Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:54:09.356Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:54:09.357Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:54:09.357Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.212.0>,shutdown}}
[error_logger:info,2021-04-19T19:54:09.357Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:54:09.558Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:54:09.559Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.215.0>,shutdown}}
[ns_server:debug,2021-04-19T19:54:09.559Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:54:09.559Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:54:09.760Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:54:09.761Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:54:09.761Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.218.0>,shutdown}}
[error_logger:info,2021-04-19T19:54:09.761Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:54:09.962Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:54:09.963Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:54:09.963Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.221.0>,shutdown}}
[error_logger:info,2021-04-19T19:54:09.963Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:54:10.164Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:54:10.164Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:54:10.164Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.224.0>,shutdown}}
[error_logger:info,2021-04-19T19:54:10.165Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:54:10.365Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:54:10.474Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:54:10.685Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:54:10.886Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:54:11.087Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:54:11.288Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:54:11.489Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:54:11.690Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:54:11.893Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:54:12.094Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:54:12.295Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[error_logger:info,2021-04-19T19:54:12.897Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.239.0>},
                       {name,timer2_server},
                       {mfargs,{timer2,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:54:13.098Z,ns_1@127.0.0.1:ns_couchdb_port<0.181.0>:ns_port_server:log:210]ns_couchdb<0.181.0>: Apache CouchDB  (LogLevel=info) is starting.

[ns_server:info,2021-04-19T19:54:13.559Z,ns_1@127.0.0.1:ns_couchdb_port<0.181.0>:ns_port_server:log:210]ns_couchdb<0.181.0>: Apache CouchDB has started. Time to relax.

[error_logger:info,2021-04-19T19:54:13.578Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.182.0>},
                       {name,wait_for_couchdb_node},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<ns_server_nodes_sup.0.8580514>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:13.590Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.155.0>:ns_storage_conf:setup_db_and_ix_paths:53]Initialize db_and_ix_paths variable with [{db_path,
                                           "/opt/couchbase/var/lib/couchbase/data"},
                                          {index_path,
                                           "/opt/couchbase/var/lib/couchbase/data"}]
[error_logger:info,2021-04-19T19:54:13.632Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.242.0>},
                       {name,ns_disksup},
                       {mfargs,{ns_disksup,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:13.638Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.243.0>},
                       {name,diag_handler_worker},
                       {mfargs,{work_queue,start_link,[diag_handler_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:54:13.642Z,ns_1@127.0.0.1:ns_server_sup<0.241.0>:dir_size:start_link:39]Starting quick version of dir_size with program name: godu
[error_logger:info,2021-04-19T19:54:13.647Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.244.0>},
                       {name,dir_size},
                       {mfargs,{dir_size,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:13.653Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.245.0>},
                       {name,request_throttler},
                       {mfargs,{request_throttler,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:13.665Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.246.0>},
                       {name,ns_log},
                       {mfargs,{ns_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:13.666Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.247.0>},
                       {name,ns_crash_log_consumer},
                       {mfargs,{ns_log,start_link_crash_consumer,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:13.675Z,ns_1@127.0.0.1:ns_config_isasl_sync<0.248.0>:ns_config_isasl_sync:init:65]isasl_sync init: ["/opt/couchbase/var/lib/couchbase/isasl.pw","_admin"]
[ns_server:debug,2021-04-19T19:54:13.676Z,ns_1@127.0.0.1:ns_config_isasl_sync<0.248.0>:ns_config_isasl_sync:init:73]isasl_sync init buckets: []
[ns_server:debug,2021-04-19T19:54:13.677Z,ns_1@127.0.0.1:ns_config_isasl_sync<0.248.0>:ns_config_isasl_sync:writeSASLConf:145]Writing isasl passwd file: "/opt/couchbase/var/lib/couchbase/isasl.pw"
[ns_server:warn,2021-04-19T19:54:13.714Z,ns_1@127.0.0.1:ns_config_isasl_sync<0.248.0>:ns_memcached:connect:1307]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[ns_server:info,2021-04-19T19:54:13.779Z,ns_1@127.0.0.1:ns_couchdb_port<0.181.0>:ns_port_server:log:210]ns_couchdb<0.181.0>: 137: Booted. Waiting for shutdown request

[error_logger:info,2021-04-19T19:54:14.716Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.248.0>},
                       {name,ns_config_isasl_sync},
                       {mfargs,{ns_config_isasl_sync,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:14.716Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.250.0>},
                       {name,ns_log_events},
                       {mfargs,{gen_event,start_link,[{local,ns_log_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:14.721Z,ns_1@127.0.0.1:ns_node_disco<0.253.0>:ns_node_disco:init:138]Initting ns_node_disco with []
[error_logger:info,2021-04-19T19:54:14.721Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.252.0>},
                       {name,ns_node_disco_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,ns_node_disco_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:14.721Z,ns_1@127.0.0.1:ns_cookie_manager<0.141.0>:ns_cookie_manager:do_cookie_sync:115]ns_cookie_manager do_cookie_sync
[user:info,2021-04-19T19:54:14.721Z,ns_1@127.0.0.1:ns_cookie_manager<0.141.0>:ns_cookie_manager:do_cookie_sync:134]Node 'ns_1@127.0.0.1' synchronized otp cookie {sanitized,
                                               <<"Gldz+3QHYFD9UMWZ6D/7VCdFO4es4rvk9HPUTz5soFw=">>} from cluster
[ns_server:debug,2021-04-19T19:54:14.721Z,ns_1@127.0.0.1:<0.254.0>:ns_node_disco:do_nodes_wanted_updated_fun:224]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"Gldz+3QHYFD9UMWZ6D/7VCdFO4es4rvk9HPUTz5soFw=">>}
[ns_server:debug,2021-04-19T19:54:14.725Z,ns_1@127.0.0.1:<0.254.0>:ns_node_disco:do_nodes_wanted_updated_fun:230]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"Gldz+3QHYFD9UMWZ6D/7VCdFO4es4rvk9HPUTz5soFw=">>}
[error_logger:info,2021-04-19T19:54:14.725Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.253.0>},
                       {name,ns_node_disco},
                       {mfargs,{ns_node_disco,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:14.729Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.255.0>},
                       {name,ns_node_disco_log},
                       {mfargs,{ns_node_disco_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:14.733Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.256.0>},
                       {name,ns_node_disco_conf_events},
                       {mfargs,{ns_node_disco_conf_events,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:14.737Z,ns_1@127.0.0.1:ns_config_rep<0.258.0>:ns_config_rep:init:68]init pulling
[ns_server:debug,2021-04-19T19:54:14.737Z,ns_1@127.0.0.1:ns_config_rep<0.258.0>:ns_config_rep:init:70]init pushing
[error_logger:info,2021-04-19T19:54:14.737Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.257.0>},
                       {name,ns_config_rep_merger},
                       {mfargs,{ns_config_rep,start_link_merger,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:14.740Z,ns_1@127.0.0.1:ns_config_rep<0.258.0>:ns_config_rep:init:74]init reannouncing
[ns_server:debug,2021-04-19T19:54:14.740Z,ns_1@127.0.0.1:ns_config_events<0.144.0>:ns_node_disco_conf_events:handle_event:44]ns_node_disco_conf_events config on nodes_wanted
[ns_server:debug,2021-04-19T19:54:14.740Z,ns_1@127.0.0.1:ns_config_events<0.144.0>:ns_node_disco_conf_events:handle_event:50]ns_node_disco_conf_events config on otp
[ns_server:debug,2021-04-19T19:54:14.740Z,ns_1@127.0.0.1:ns_cookie_manager<0.141.0>:ns_cookie_manager:do_cookie_sync:115]ns_cookie_manager do_cookie_sync
[ns_server:debug,2021-04-19T19:54:14.740Z,ns_1@127.0.0.1:ns_cookie_manager<0.141.0>:ns_cookie_manager:do_cookie_sync:115]ns_cookie_manager do_cookie_sync
[ns_server:debug,2021-04-19T19:54:14.740Z,ns_1@127.0.0.1:<0.262.0>:ns_node_disco:do_nodes_wanted_updated_fun:224]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"Gldz+3QHYFD9UMWZ6D/7VCdFO4es4rvk9HPUTz5soFw=">>}
[ns_server:debug,2021-04-19T19:54:14.740Z,ns_1@127.0.0.1:<0.263.0>:ns_node_disco:do_nodes_wanted_updated_fun:224]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"Gldz+3QHYFD9UMWZ6D/7VCdFO4es4rvk9HPUTz5soFw=">>}
[ns_server:debug,2021-04-19T19:54:14.740Z,ns_1@127.0.0.1:<0.262.0>:ns_node_disco:do_nodes_wanted_updated_fun:230]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"Gldz+3QHYFD9UMWZ6D/7VCdFO4es4rvk9HPUTz5soFw=">>}
[ns_server:debug,2021-04-19T19:54:14.741Z,ns_1@127.0.0.1:<0.263.0>:ns_node_disco:do_nodes_wanted_updated_fun:230]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"Gldz+3QHYFD9UMWZ6D/7VCdFO4es4rvk9HPUTz5soFw=">>}
[ns_server:debug,2021-04-19T19:54:14.741Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
alert_limits ->
[{max_overhead_perc,50},{max_disk_used,90},{max_indexer_ram,75}]
[ns_server:debug,2021-04-19T19:54:14.741Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
audit ->
[{auditd_enabled,false},
 {rotate_interval,86400},
 {rotate_size,20971520},
 {disabled,[]},
 {sync,[]},
 {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]
[ns_server:debug,2021-04-19T19:54:14.742Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
auto_failover_cfg ->
[{enabled,false},{timeout,120},{max_nodes,1},{count,0}]
[ns_server:debug,2021-04-19T19:54:14.742Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
autocompaction ->
[{database_fragmentation_threshold,{30,undefined}},
 {view_fragmentation_threshold,{30,undefined}}]
[ns_server:debug,2021-04-19T19:54:14.742Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
buckets ->
[[],{configs,[]}]
[ns_server:debug,2021-04-19T19:54:14.742Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
cert_and_pkey ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080746}}]}|
 {<<"-----BEGIN CERTIFICATE-----\nMIIDAjCCAeqgAwIBAgIIFndZ/+GzDYAwDQYJKoZIhvcNAQELBQAwJDEiMCAGA1UE\nAxMZQ291Y2hiYXNlIFNlcnZlciA4ODFmOWE4YzAeFw0xMzAxMDEwMDAwMDBaFw00\nOTEyMzEyMzU5NTlaMCQxIjAgBgNVBAMTGUNvdWNoYmFzZSBTZXJ2ZXIgODgxZjlh\nOGMwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCz0vvVTMTWH8JLsYfx\nMZ+egYFMFORYbynBjyuWB7+ltQbKZKtnruph7r3agBX8qzQLo1fbuaNJIkb2/TYZ\n7q61KM7aIxCPKBtKs0ms85z8gseSLb3"...>>,
  <<"*****">>}]
[ns_server:debug,2021-04-19T19:54:14.743Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
cluster_compat_version ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{6,63786080754}}]},4,6]
[ns_server:debug,2021-04-19T19:54:14.743Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
drop_request_memory_threshold_mib ->
undefined
[ns_server:debug,2021-04-19T19:54:14.743Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
email_alerts ->
[{recipients,["root@localhost"]},
 {sender,"couchbase@localhost"},
 {enabled,false},
 {email_server,[{user,[]},
                {pass,"*****"},
                {host,"localhost"},
                {port,25},
                {encrypt,false}]},
 {alerts,[auto_failover_node,auto_failover_maximum_reached,
          auto_failover_other_nodes_down,auto_failover_cluster_too_small,
          auto_failover_disabled,ip,disk,overhead,ep_oom_errors,
          ep_item_commit_failed,audit_dropped_events,indexer_ram_max_usage,
          ep_clock_cas_drift_threshold_exceeded]}]
[ns_server:debug,2021-04-19T19:54:14.743Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
fts_memory_quota ->
512
[ns_server:debug,2021-04-19T19:54:14.743Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
goxdcr_upgrade ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080754}}]}|
 '_deleted']
[ns_server:debug,2021-04-19T19:54:14.743Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
index_aware_rebalance_disabled ->
false
[ns_server:debug,2021-04-19T19:54:14.744Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
max_bucket_count ->
10
[ns_server:debug,2021-04-19T19:54:14.744Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
memcached ->
[]
[error_logger:info,2021-04-19T19:54:14.744Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.258.0>},
                       {name,ns_config_rep},
                       {mfargs,{ns_config_rep,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:14.744Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
memory_quota ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080759}}]}|300]
[ns_server:debug,2021-04-19T19:54:14.744Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
nodes_wanted ->
['ns_1@127.0.0.1']
[error_logger:info,2021-04-19T19:54:14.744Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.251.0>},
                       {name,ns_node_disco_sup},
                       {mfargs,{ns_node_disco_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2021-04-19T19:54:14.744Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
otp ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080753}}]},
 {cookie,{sanitized,<<"Gldz+3QHYFD9UMWZ6D/7VCdFO4es4rvk9HPUTz5soFw=">>}}]
[ns_server:debug,2021-04-19T19:54:14.744Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
read_only_user_creds ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080754}}]}|null]
[ns_server:debug,2021-04-19T19:54:14.744Z,ns_1@127.0.0.1:ns_config_rep<0.258.0>:ns_config_rep:do_push_keys:321]Replicating some config keys ([alert_limits,audit,auto_failover_cfg,
                               autocompaction,buckets,cert_and_pkey,
                               cluster_compat_version,
                               drop_request_memory_threshold_mib,email_alerts,
                               fts_memory_quota,goxdcr_upgrade,
                               index_aware_rebalance_disabled,
                               max_bucket_count,memcached,memory_quota,
                               nodes_wanted,otp,read_only_user_creds,
                               remote_clusters,replication,rest,rest_creds,
                               roles_definitions,server_groups,
                               set_view_update_daemon,uuid,
                               {couchdb,max_parallel_indexers},
                               {couchdb,max_parallel_replica_indexers},
                               {local_changes_count,
                                   <<"dbb8bee8b38705437e7f5ebc78107bfa">>},
                               {metakv,<<"/indexing/settings/config">>},
                               {request_limit,capi},
                               {request_limit,rest},
                               {service_map,fts},
                               {service_map,index},
                               {service_map,n1ql},
                               {node,'ns_1@127.0.0.1',audit},
                               {node,'ns_1@127.0.0.1',capi_port},
                               {node,'ns_1@127.0.0.1',compaction_daemon},
                               {node,'ns_1@127.0.0.1',config_version},
                               {node,'ns_1@127.0.0.1',fts_http_port},
                               {node,'ns_1@127.0.0.1',indexer_admin_port},
                               {node,'ns_1@127.0.0.1',indexer_http_port},
                               {node,'ns_1@127.0.0.1',indexer_scan_port},
                               {node,'ns_1@127.0.0.1',indexer_stcatchup_port},
                               {node,'ns_1@127.0.0.1',indexer_stinit_port},
                               {node,'ns_1@127.0.0.1',indexer_stmaint_port},
                               {node,'ns_1@127.0.0.1',is_enterprise},
                               {node,'ns_1@127.0.0.1',isasl},
                               {node,'ns_1@127.0.0.1',ldap_enabled},
                               {node,'ns_1@127.0.0.1',membership},
                               {node,'ns_1@127.0.0.1',memcached},
                               {node,'ns_1@127.0.0.1',memcached_config},
                               {node,'ns_1@127.0.0.1',memcached_defaults},
                               {node,'ns_1@127.0.0.1',moxi},
                               {node,'ns_1@127.0.0.1',ns_log},
                               {node,'ns_1@127.0.0.1',port_servers},
                               {node,'ns_1@127.0.0.1',projector_port},
                               {node,'ns_1@127.0.0.1',query_port},
                               {node,'ns_1@127.0.0.1',rest},
                               {node,'ns_1@127.0.0.1',services},
                               {node,'ns_1@127.0.0.1',ssl_capi_port},
                               {node,'ns_1@127.0.0.1',
                                   ssl_proxy_downstream_port},
                               {node,'ns_1@127.0.0.1',ssl_proxy_upstream_port},
                               {node,'ns_1@127.0.0.1',ssl_query_port}]..)
[ns_server:debug,2021-04-19T19:54:14.744Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
remote_clusters ->
[]
[ns_server:debug,2021-04-19T19:54:14.745Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
replication ->
[{enabled,true}]
[ns_server:debug,2021-04-19T19:54:14.745Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
rest ->
[{port,8091}]
[ns_server:debug,2021-04-19T19:54:14.745Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
rest_creds ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{2,63786080759}}]}|
 {"Administrator",{password,"*****"}}]
[ns_server:debug,2021-04-19T19:54:14.746Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
roles_definitions ->
[{admin,[],
        [{name,<<"Admin">>},
         {desc,<<"Can manage ALL cluster features including security.">>}],
        [{[],all}]},
 {ro_admin,[],
           [{name,<<"Read Only Admin">>},
            {desc,<<"Can view ALL cluster features.">>}],
           [{[{bucket,any},password],none},
            {[{bucket,any},data],none},
            {[admin,security],[read]},
            {[admin],none},
            {[],[read]}]},
 {cluster_admin,[],
                [{name,<<"Cluster Admin">>},
                 {desc,<<"Can manage all cluster features EXCEPT security.">>}],
                [{[admin],none},{[],all}]},
 {bucket_admin,[bucket_name],
               [{name,<<"Bucket Admin">>},
                {desc,<<"Can manage ALL bucket features for specified buckets (incl. start/stop XDCR)">>}],
               [{[{bucket,bucket_name},xdcr],[read,execute]},
                {[{bucket,bucket_name}],all},
                {[{bucket,any},settings],[read]},
                {[{bucket,any}],none},
                {[xdcr],none},
                {[admin],none},
                {[],[read]}]},
 {bucket_sasl,[bucket_name],
              [],
              [{[{bucket,bucket_name},data],all},
               {[{bucket,bucket_name},views],all},
               {[{bucket,bucket_name}],[read,flush]},
               {[pools],[read]}]},
 {views_admin,[bucket_name],
              [{name,<<"Views Admin">>},
               {desc,<<"Can manage views for specified buckets">>}],
              [{[{bucket,bucket_name},views],all},
               {[{bucket,bucket_name},data],[read]},
               {[{bucket,any},settings],[read]},
               {[{bucket,any}],none},
               {[xdcr],none},
               {[admin],none},
               {[],[read]}]},
 {replication_admin,[],
                    [{name,<<"Replication Admin">>},
                     {desc,<<"Can manage ONLY XDCR features (cluster AND bucket level)">>}],
                    [{[{bucket,any},xdcr],all},
                     {[{bucket,any},data],[read]},
                     {[{bucket,any},settings],[read]},
                     {[{bucket,any}],none},
                     {[xdcr],all},
                     {[admin],none},
                     {[],[read]}]}]
[ns_server:debug,2021-04-19T19:54:14.747Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
server_groups ->
[[{uuid,<<"0">>},{name,<<"Group 1">>},{nodes,['ns_1@127.0.0.1']}]]
[ns_server:debug,2021-04-19T19:54:14.747Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
set_view_update_daemon ->
[{update_interval,5000},
 {update_min_changes,5000},
 {replica_update_min_changes,5000}]
[ns_server:debug,2021-04-19T19:54:14.747Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
uuid ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080759}}]}|
 <<"aaf7f03de532d2dc46a1e96329b1eb02">>]
[ns_server:debug,2021-04-19T19:54:14.747Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{couchdb,max_parallel_indexers} ->
4
[ns_server:debug,2021-04-19T19:54:14.747Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{couchdb,max_parallel_replica_indexers} ->
2
[ns_server:debug,2021-04-19T19:54:14.748Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{local_changes_count,<<"dbb8bee8b38705437e7f5ebc78107bfa">>} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{13,63786081155}}]}]
[ns_server:debug,2021-04-19T19:54:14.748Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{metakv,<<"/indexing/settings/config">>} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{5,63786081155}}]}|
 <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.log_level\":\"info\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\""...>>]
[ns_server:debug,2021-04-19T19:54:14.748Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{request_limit,capi} ->
undefined
[ns_server:debug,2021-04-19T19:54:14.748Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{request_limit,rest} ->
undefined
[ns_server:debug,2021-04-19T19:54:14.748Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{service_map,fts} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080754}}]}]
[ns_server:debug,2021-04-19T19:54:14.748Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{service_map,index} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{2,63786080764}}]},
 'ns_1@127.0.0.1']
[ns_server:debug,2021-04-19T19:54:14.748Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{service_map,n1ql} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{2,63786080764}}]},
 'ns_1@127.0.0.1']
[ns_server:debug,2021-04-19T19:54:14.749Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',audit} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}]
[ns_server:debug,2021-04-19T19:54:14.749Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',capi_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|8092]
[ns_server:debug,2021-04-19T19:54:14.749Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',compaction_daemon} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
 {check_interval,30},
 {min_db_file_size,131072},
 {min_view_file_size,20971520}]
[ns_server:debug,2021-04-19T19:54:14.749Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',config_version} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|{4,5}]
[ns_server:debug,2021-04-19T19:54:14.749Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',fts_http_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|8094]
[ns_server:debug,2021-04-19T19:54:14.749Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',indexer_admin_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|9100]
[ns_server:debug,2021-04-19T19:54:14.749Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',indexer_http_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|9102]
[ns_server:debug,2021-04-19T19:54:14.749Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',indexer_scan_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|9101]
[ns_server:debug,2021-04-19T19:54:14.749Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',indexer_stcatchup_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|9104]
[ns_server:debug,2021-04-19T19:54:14.749Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',indexer_stinit_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|9103]
[ns_server:debug,2021-04-19T19:54:14.749Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',indexer_stmaint_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|9105]
[ns_server:debug,2021-04-19T19:54:14.750Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',is_enterprise} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|true]
[ns_server:debug,2021-04-19T19:54:14.750Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',isasl} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
 {path,"/opt/couchbase/var/lib/couchbase/isasl.pw"}]
[ns_server:debug,2021-04-19T19:54:14.750Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ldap_enabled} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|true]
[ns_server:debug,2021-04-19T19:54:14.750Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',membership} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
 active]
[ns_server:debug,2021-04-19T19:54:14.751Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',memcached} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
 {port,11210},
 {dedicated_port,11209},
 {ssl_port,11207},
 {admin_user,"_admin"},
 {admin_pass,"*****"},
 {engines,[{membase,[{engine,"/opt/couchbase/lib/memcached/ep.so"},
                     {static_config_string,"failpartialwarmup=false"}]},
           {memcached,[{engine,"/opt/couchbase/lib/memcached/default_engine.so"},
                       {static_config_string,"vb0=true"}]}]},
 {config_path,"/opt/couchbase/var/lib/couchbase/config/memcached.json"},
 {audit_file,"/opt/couchbase/var/lib/couchbase/config/audit.json"},
 {log_path,"/opt/couchbase/var/lib/couchbase/logs"},
 {log_prefix,"memcached.log"},
 {log_generations,20},
 {log_cyclesize,10485760},
 {log_sleeptime,19},
 {log_rotation_period,39003}]
[error_logger:info,2021-04-19T19:54:14.751Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.266.0>},
                       {name,vbucket_map_mirror},
                       {mfargs,{vbucket_map_mirror,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:14.752Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',memcached_config} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
 {[{interfaces,
    {memcached_config_mgr,omit_missing_mcd_ports,
     [{[{host,<<"*">>},{port,port},{maxconn,maxconn}]},
      {[{host,<<"*">>},
        {port,dedicated_port},
        {maxconn,dedicated_port_maxconn}]},
      {[{host,<<"*">>},
        {port,ssl_port},
        {maxconn,maxconn},
        {ssl,
         {[{key,
            <<"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem">>},
           {cert,
            <<"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem">>}]}}]}]}},
   {ssl_cipher_list,{"~s",[ssl_cipher_list]}},
   {ssl_minimum_protocol,{memcached_config_mgr,ssl_minimum_protocol,[]}},
   {connection_idle_time,connection_idle_time},
   {breakpad,
    {[{enabled,breakpad_enabled},
      {minidump_dir,{memcached_config_mgr,get_minidump_dir,[]}}]}},
   {extensions,
    [{[{module,<<"/opt/couchbase/lib/memcached/stdin_term_handler.so">>},
       {config,<<>>}]},
     {[{module,<<"/opt/couchbase/lib/memcached/file_logger.so">>},
       {config,
        {"cyclesize=~B;sleeptime=~B;filename=~s/~s",
         [log_cyclesize,log_sleeptime,log_path,log_prefix]}}]}]},
   {admin,{"~s",[admin_user]}},
   {verbosity,verbosity},
   {audit_file,{"~s",[audit_file]}},
   {dedupe_nmvb_maps,dedupe_nmvb_maps}]}]
[ns_server:debug,2021-04-19T19:54:14.752Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',memcached_defaults} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
 {maxconn,30000},
 {dedicated_port_maxconn,5000},
 {ssl_cipher_list,"HIGH"},
 {connection_idle_time,0},
 {verbosity,0},
 {breakpad_enabled,true},
 {breakpad_minidump_dir_path,"/opt/couchbase/var/lib/couchbase/crash"},
 {dedupe_nmvb_maps,false}]
[ns_server:debug,2021-04-19T19:54:14.752Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',moxi} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
 {port,11211},
 {verbosity,[]}]
[ns_server:debug,2021-04-19T19:54:14.753Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ns_log} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
 {filename,"/opt/couchbase/var/lib/couchbase/ns_log"}]
[ns_server:debug,2021-04-19T19:54:14.753Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',port_servers} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}]
[ns_server:debug,2021-04-19T19:54:14.753Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',projector_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|9999]
[ns_server:debug,2021-04-19T19:54:14.753Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',query_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|8093]
[ns_server:debug,2021-04-19T19:54:14.754Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',rest} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
 {port,8091},
 {port_meta,global}]
[ns_server:debug,2021-04-19T19:54:14.754Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',services} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080759}}]},
 index,kv,n1ql]
[ns_server:debug,2021-04-19T19:54:14.754Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ssl_capi_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|18092]
[ns_server:debug,2021-04-19T19:54:14.754Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ssl_proxy_downstream_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|11214]
[ns_server:debug,2021-04-19T19:54:14.754Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ssl_proxy_upstream_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|11215]
[ns_server:debug,2021-04-19T19:54:14.755Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ssl_query_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|18093]
[ns_server:debug,2021-04-19T19:54:14.755Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ssl_rest_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|18091]
[ns_server:debug,2021-04-19T19:54:14.755Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',stop_xdcr} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{2,63786080754}}]}|
 '_deleted']
[ns_server:debug,2021-04-19T19:54:14.755Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',uuid} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
 <<"dbb8bee8b38705437e7f5ebc78107bfa">>]
[ns_server:debug,2021-04-19T19:54:14.755Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',xdcr_rest_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|9998]
[error_logger:info,2021-04-19T19:54:14.756Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.268.0>},
                       {name,bucket_info_cache},
                       {mfargs,{bucket_info_cache,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:14.757Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.271.0>},
                       {name,ns_tick_event},
                       {mfargs,{gen_event,start_link,[{local,ns_tick_event}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:14.757Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.272.0>},
                       {name,buckets_events},
                       {mfargs,
                           {gen_event,start_link,[{local,buckets_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:14.764Z,ns_1@127.0.0.1:ns_log_events<0.250.0>:ns_mail_log:init:44]ns_mail_log started up
[error_logger:info,2021-04-19T19:54:14.764Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_mail_sup}
             started: [{pid,<0.274.0>},
                       {name,ns_mail_log},
                       {mfargs,{ns_mail_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:14.765Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.273.0>},
                       {name,ns_mail_sup},
                       {mfargs,{ns_mail_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:54:14.765Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.275.0>},
                       {name,ns_stats_event},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_stats_event}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:14.769Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.276.0>},
                       {name,samples_loader_tasks},
                       {mfargs,{samples_loader_tasks,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:14.780Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_heart_sup}
             started: [{pid,<0.278.0>},
                       {name,ns_heart},
                       {mfargs,{ns_heart,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:14.781Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_heart_sup}
             started: [{pid,<0.280.0>},
                       {name,ns_heart_slow_updater},
                       {mfargs,{ns_heart,start_link_slow_updater,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:14.781Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.277.0>},
                       {name,ns_heart_sup},
                       {mfargs,{ns_heart_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:54:14.785Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_doctor_sup}
             started: [{pid,<0.284.0>},
                       {name,ns_doctor_events},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_doctor_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:14.790Z,ns_1@127.0.0.1:ns_heart<0.278.0>:ns_heart:grab_latest_stats:259]Ignoring failure to grab "@system" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,117}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,255}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,249}]},
                 {ns_heart,update_current_status,1,
                           [{file,"src/ns_heart.erl"},{line,186}]},
                 {ns_heart,handle_info,2,
                           [{file,"src/ns_heart.erl"},{line,118}]}]}}

[ns_server:debug,2021-04-19T19:54:14.791Z,ns_1@127.0.0.1:ns_heart<0.278.0>:ns_heart:grab_latest_stats:259]Ignoring failure to grab "@system-processes" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-processes-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,117}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,255}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,249}]},
                 {ns_heart,update_current_status,1,
                           [{file,"src/ns_heart.erl"},{line,186}]}]}}

[ns_server:debug,2021-04-19T19:54:14.804Z,ns_1@127.0.0.1:<0.282.0>:restartable:start_child:98]Started child process <0.283.0>
  MFA: {ns_doctor_sup,start_link,[]}
[error_logger:info,2021-04-19T19:54:14.804Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_doctor_sup}
             started: [{pid,<0.285.0>},
                       {name,ns_doctor},
                       {mfargs,{ns_doctor,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:14.804Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.282.0>},
                       {name,ns_doctor_sup},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_doctor_sup,start_link,[]},infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2021-04-19T19:54:14.868Z,ns_1@127.0.0.1:ns_heart<0.278.0>:ns_heart:grab_index_status:373]ignoring failure to get index status: {exit,
                                       {noproc,
                                        {gen_server,call,
                                         ['index_status_keeper-index',
                                          get_status,2000]}}}
[{gen_server,call,3,[{file,"gen_server.erl"},{line,188}]},
 {ns_heart,grab_index_status,0,[{file,"src/ns_heart.erl"},{line,370}]},
 {ns_heart,current_status_slow_inner,0,[{file,"src/ns_heart.erl"},{line,280}]},
 {ns_heart,current_status_slow,1,[{file,"src/ns_heart.erl"},{line,249}]},
 {ns_heart,update_current_status,1,[{file,"src/ns_heart.erl"},{line,186}]},
 {ns_heart,handle_info,2,[{file,"src/ns_heart.erl"},{line,118}]},
 {gen_server,handle_msg,5,[{file,"gen_server.erl"},{line,604}]},
 {proc_lib,init_p_do_apply,3,[{file,"proc_lib.erl"},{line,239}]}]
[error_logger:info,2021-04-19T19:54:14.871Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.290.0>},
                       {name,disk_log_sup},
                       {mfargs,{disk_log_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:54:14.871Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.291.0>},
                       {name,disk_log_server},
                       {mfargs,{disk_log_server,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:14.901Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.288.0>},
                       {name,remote_clusters_info},
                       {mfargs,{remote_clusters_info,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:14.902Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.294.0>},
                       {name,master_activity_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,master_activity_events}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:14.912Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.295.0>},
                       {name,xdcr_ckpt_store},
                       {mfargs,{simple_store,start_link,[xdcr_ckpt_data]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:14.913Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.296.0>},
                       {name,metakv_worker},
                       {mfargs,{work_queue,start_link,[metakv_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:14.913Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.297.0>},
                       {name,index_events},
                       {mfargs,{gen_event,start_link,[{local,index_events}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:14.922Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.298.0>},
                       {name,index_settings_manager},
                       {mfargs,{index_settings_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:14.930Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.302.0>},
                       {name,menelaus_ui_auth},
                       {mfargs,{menelaus_ui_auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:14.944Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.304.0>},
                       {name,menelaus_local_auth},
                       {mfargs,{menelaus_local_auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:14.953Z,ns_1@127.0.0.1:ns_heart<0.278.0>:goxdcr_rest:get_from_goxdcr:163]Goxdcr is temporary not available. Return empty list.
[error_logger:info,2021-04-19T19:54:14.963Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.305.0>},
                       {name,menelaus_web_cache},
                       {mfargs,{menelaus_web_cache,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:14.970Z,ns_1@127.0.0.1:ns_heart<0.278.0>:cluster_logs_collection_task:maybe_build_cluster_logs_task:43]Ignoring exception trying to read cluster_logs_collection_task_status table: error:badarg
[error_logger:info,2021-04-19T19:54:14.974Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.307.0>},
                       {name,menelaus_stats_gatherer},
                       {mfargs,{menelaus_stats_gatherer,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:14.974Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.308.0>},
                       {name,json_rpc_events},
                       {mfargs,
                           {gen_event,start_link,[{local,json_rpc_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:54:14.977Z,ns_1@127.0.0.1:menelaus_sup<0.300.0>:menelaus_pluggable_ui:validate_plugin_spec:117]Loaded pluggable UI specification for fts

[ns_server:info,2021-04-19T19:54:14.978Z,ns_1@127.0.0.1:menelaus_sup<0.300.0>:menelaus_pluggable_ui:validate_plugin_spec:117]Loaded pluggable UI specification for n1ql

[error_logger:info,2021-04-19T19:54:14.978Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.309.0>},
                       {name,menelaus_web},
                       {mfargs,{menelaus_web,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:14.982Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.326.0>},
                       {name,menelaus_event},
                       {mfargs,{menelaus_event,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:14.986Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.327.0>},
                       {name,hot_keys_keeper},
                       {mfargs,{hot_keys_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:14.990Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.280.0>:ns_heart:grab_latest_stats:259]Ignoring failure to grab "@system" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,117}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,255}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,249}]},
                 {ns_heart,slow_updater_loop,0,
                           [{file,"src/ns_heart.erl"},{line,243}]},
                 {proc_lib,init_p_do_apply,3,
                           [{file,"proc_lib.erl"},{line,239}]}]}}

[ns_server:debug,2021-04-19T19:54:14.991Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.280.0>:ns_heart:grab_latest_stats:259]Ignoring failure to grab "@system-processes" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-processes-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,117}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,255}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,249}]},
                 {ns_heart,slow_updater_loop,0,
                           [{file,"src/ns_heart.erl"},{line,243}]}]}}

[ns_server:debug,2021-04-19T19:54:14.991Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.280.0>:ns_heart:grab_index_status:373]ignoring failure to get index status: {exit,
                                       {noproc,
                                        {gen_server,call,
                                         ['index_status_keeper-index',
                                          get_status,2000]}}}
[{gen_server,call,3,[{file,"gen_server.erl"},{line,188}]},
 {ns_heart,grab_index_status,0,[{file,"src/ns_heart.erl"},{line,370}]},
 {ns_heart,current_status_slow_inner,0,[{file,"src/ns_heart.erl"},{line,280}]},
 {ns_heart,current_status_slow,1,[{file,"src/ns_heart.erl"},{line,249}]},
 {ns_heart,slow_updater_loop,0,[{file,"src/ns_heart.erl"},{line,243}]},
 {proc_lib,init_p_do_apply,3,[{file,"proc_lib.erl"},{line,239}]}]
[ns_server:debug,2021-04-19T19:54:14.992Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.280.0>:goxdcr_rest:get_from_goxdcr:163]Goxdcr is temporary not available. Return empty list.
[ns_server:debug,2021-04-19T19:54:14.992Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.280.0>:cluster_logs_collection_task:maybe_build_cluster_logs_task:43]Ignoring exception trying to read cluster_logs_collection_task_status table: error:badarg
[error_logger:info,2021-04-19T19:54:14.995Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.334.0>},
                       {name,menelaus_web_alerts_srv},
                       {mfargs,{menelaus_web_alerts_srv,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:15.001Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.335.0>},
                       {name,menelaus_cbauth},
                       {mfargs,{menelaus_cbauth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[user:info,2021-04-19T19:54:15.001Z,ns_1@127.0.0.1:ns_server_sup<0.241.0>:menelaus_sup:start_link:46]Couchbase Server has started on web port 8091 on node 'ns_1@127.0.0.1'. Version: "4.6.0-3573-enterprise".
[error_logger:info,2021-04-19T19:54:15.002Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.300.0>},
                       {name,menelaus},
                       {mfargs,{menelaus_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:54:15.002Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.339.0>},
                       {name,ns_ports_setup},
                       {mfargs,{ns_ports_setup,start,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:15.007Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_agent_sup}
             started: [{pid,<0.342.0>},
                       {name,service_agent_children_sup},
                       {mfargs,
                           {supervisor,start_link,
                               [{local,service_agent_children_sup},
                                service_agent_sup,child]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:54:15.007Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_agent_sup}
             started: [{pid,<0.343.0>},
                       {name,service_agent_worker},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<service_agent_sup.0.29791682>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:15.008Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.341.0>},
                       {name,service_agent_sup},
                       {mfargs,{service_agent_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:54:15.028Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.345.0>},
                       {name,ns_memcached_sockets_pool},
                       {mfargs,{ns_memcached_sockets_pool,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:15.029Z,ns_1@127.0.0.1:ns_audit_cfg<0.346.0>:ns_audit_cfg:write_audit_json:158]Writing new content to "/opt/couchbase/var/lib/couchbase/config/audit.json" : [{auditd_enabled,
                                                                                false},
                                                                               {disabled,
                                                                                []},
                                                                               {log_path,
                                                                                "/opt/couchbase/var/lib/couchbase/logs"},
                                                                               {rotate_interval,
                                                                                86400},
                                                                               {rotate_size,
                                                                                20971520},
                                                                               {sync,
                                                                                []},
                                                                               {version,
                                                                                1},
                                                                               {descriptors_path,
                                                                                "/opt/couchbase/etc/security"}]
[ns_server:debug,2021-04-19T19:54:15.041Z,ns_1@127.0.0.1:ns_ports_setup<0.339.0>:ns_ports_manager:set_dynamic_children:54]Setting children [memcached,moxi,projector,indexer,query,saslauthd_port,
                  goxdcr,xdcr_proxy]
[ns_server:debug,2021-04-19T19:54:15.051Z,ns_1@127.0.0.1:ns_audit_cfg<0.346.0>:ns_audit_cfg:handle_info:107]Instruct memcached to reload audit config
[error_logger:info,2021-04-19T19:54:15.051Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.346.0>},
                       {name,ns_audit_cfg},
                       {mfargs,{ns_audit_cfg,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:warn,2021-04-19T19:54:15.052Z,ns_1@127.0.0.1:<0.348.0>:ns_memcached:connect:1307]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[ns_server:debug,2021-04-19T19:54:15.055Z,ns_1@127.0.0.1:memcached_config_mgr<0.350.0>:memcached_config_mgr:init:44]waiting for completion of initial ns_ports_setup round
[error_logger:info,2021-04-19T19:54:15.055Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.350.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:54:15.064Z,ns_1@127.0.0.1:<0.351.0>:ns_memcached_log_rotator:init:28]Starting log rotator on "/opt/couchbase/var/lib/couchbase/logs"/"memcached.log"* with an initial period of 39003ms
[error_logger:info,2021-04-19T19:54:15.064Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.351.0>},
                       {name,ns_memcached_log_rotator},
                       {mfargs,{ns_memcached_log_rotator,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:15.070Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.352.0>},
                       {name,memcached_clients_pool},
                       {mfargs,{memcached_clients_pool,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:15.078Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.353.0>},
                       {name,proxied_memcached_clients_pool},
                       {mfargs,{proxied_memcached_clients_pool,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:15.078Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.354.0>},
                       {name,xdc_lhttpc_pool},
                       {mfargs,
                           {lhttpc_manager,start_link,
                               [[{name,xdc_lhttpc_pool},
                                 {connection_timeout,120000},
                                 {pool_size,200}]]}},
                       {restart_type,{permanent,1}},
                       {shutdown,10000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:15.084Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.355.0>},
                       {name,ns_null_connection_pool},
                       {mfargs,
                           {ns_null_connection_pool,start_link,
                               [ns_null_connection_pool]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:54:15.087Z,ns_1@127.0.0.1:ns_couchdb_port<0.181.0>:ns_port_server:log:210]ns_couchdb<0.181.0>: working as port

[error_logger:info,2021-04-19T19:54:15.095Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {<0.356.0>,xdcr_sup}
             started: [{pid,<0.357.0>},
                       {name,xdc_stats_holder},
                       {mfargs,
                           {proc_lib,start_link,
                               [xdcr_sup,link_stats_holder_body,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:15.099Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {<0.356.0>,xdcr_sup}
             started: [{pid,<0.358.0>},
                       {name,xdc_replication_sup},
                       {mfargs,{xdc_replication_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2021-04-19T19:54:15.105Z,ns_1@127.0.0.1:xdc_rep_manager<0.359.0>:ns_couchdb_api:wait_for_doc_manager:298]Start waiting for doc manager
[error_logger:info,2021-04-19T19:54:15.105Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {<0.356.0>,xdcr_sup}
             started: [{pid,<0.359.0>},
                       {name,xdc_rep_manager},
                       {mfargs,{xdc_rep_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,30000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:15.113Z,ns_1@127.0.0.1:xdcr_doc_replicator<0.361.0>:ns_couchdb_api:wait_for_doc_manager:298]Start waiting for doc manager
[ns_server:debug,2021-04-19T19:54:15.113Z,ns_1@127.0.0.1:xdc_rdoc_replication_srv<0.362.0>:ns_couchdb_api:wait_for_doc_manager:298]Start waiting for doc manager
[error_logger:info,2021-04-19T19:54:15.113Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {<0.356.0>,xdcr_sup}
             started: [{pid,<0.361.0>},
                       {name,xdc_rdoc_replicator},
                       {mfargs,{doc_replicator,start_link_xdcr,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:15.114Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {<0.356.0>,xdcr_sup}
             started: [{pid,<0.362.0>},
                       {name,xdc_rdoc_replication_srv},
                       {mfargs,{doc_replication_srv,start_link_xdcr,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:15.118Z,ns_1@127.0.0.1:<0.356.0>:xdc_rdoc_manager:start_link_remote:42]Starting xdc_rdoc_manager on 'couchdb_ns_1@127.0.0.1' with following links: [<0.361.0>,
                                                                             <0.362.0>,
                                                                             <0.359.0>]
[ns_server:debug,2021-04-19T19:54:15.122Z,ns_1@127.0.0.1:xdcr_doc_replicator<0.361.0>:ns_couchdb_api:wait_for_doc_manager:301]Received doc manager registration from <11633.251.0>
[ns_server:debug,2021-04-19T19:54:15.123Z,ns_1@127.0.0.1:xdc_rep_manager<0.359.0>:ns_couchdb_api:wait_for_doc_manager:301]Received doc manager registration from <11633.251.0>
[ns_server:debug,2021-04-19T19:54:15.123Z,ns_1@127.0.0.1:xdc_rdoc_replication_srv<0.362.0>:ns_couchdb_api:wait_for_doc_manager:301]Received doc manager registration from <11633.251.0>
[error_logger:info,2021-04-19T19:54:15.123Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {<0.356.0>,xdcr_sup}
             started: [{pid,<11633.251.0>},
                       {name,xdc_rdoc_manager},
                       {mfargs,
                           {xdc_rdoc_manager,start_link_remote,
                               ['couchdb_ns_1@127.0.0.1']}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:15.124Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.356.0>},
                       {name,xdcr_sup},
                       {mfargs,{xdcr_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:54:15.128Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.364.0>},
                       {name,xdcr_dcp_sockets_pool},
                       {mfargs,{xdcr_dcp_sockets_pool,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:15.132Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_worker_sup}
             started: [{pid,<0.366.0>},
                       {name,ns_bucket_worker},
                       {mfargs,{work_queue,start_link,[ns_bucket_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:15.138Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_sup}
             started: [{pid,<0.368.0>},
                       {name,buckets_observing_subscription},
                       {mfargs,{ns_bucket_sup,subscribe_on_config_events,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:15.138Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_worker_sup}
             started: [{pid,<0.367.0>},
                       {name,ns_bucket_sup},
                       {mfargs,{ns_bucket_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:54:15.139Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.365.0>},
                       {name,ns_bucket_worker_sup},
                       {mfargs,{ns_bucket_worker_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:54:15.144Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.369.0>},
                       {name,system_stats_collector},
                       {mfargs,{system_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:15.146Z,ns_1@127.0.0.1:xdcr_doc_replicator<0.361.0>:doc_replicator:loop:64]doing replicate_newnodes_docs
[error_logger:info,2021-04-19T19:54:15.147Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.373.0>},
                       {name,{stats_archiver,"@system"}},
                       {mfargs,{stats_archiver,start_link,["@system"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:15.156Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.375.0>},
                       {name,{stats_reader,"@system"}},
                       {mfargs,{stats_reader,start_link,["@system"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:15.159Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.376.0>},
                       {name,{stats_archiver,"@system-processes"}},
                       {mfargs,
                           {stats_archiver,start_link,["@system-processes"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:15.159Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.378.0>},
                       {name,{stats_reader,"@system-processes"}},
                       {mfargs,
                           {stats_reader,start_link,["@system-processes"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:15.201Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.379.0>},
                       {name,{stats_archiver,"@query"}},
                       {mfargs,{stats_archiver,start_link,["@query"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:15.201Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.381.0>},
                       {name,{stats_reader,"@query"}},
                       {mfargs,{stats_reader,start_link,["@query"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:15.206Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.382.0>},
                       {name,query_stats_collector},
                       {mfargs,{query_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:15.235Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.384.0>},
                       {name,{stats_archiver,"@global"}},
                       {mfargs,{stats_archiver,start_link,["@global"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:15.236Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.386.0>},
                       {name,{stats_reader,"@global"}},
                       {mfargs,{stats_reader,start_link,["@global"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:15.239Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.387.0>},
                       {name,global_stats_collector},
                       {mfargs,{global_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:15.246Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.389.0>},
                       {name,goxdcr_status_keeper},
                       {mfargs,{goxdcr_status_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:15.247Z,ns_1@127.0.0.1:goxdcr_status_keeper<0.389.0>:goxdcr_rest:get_from_goxdcr:163]Goxdcr is temporary not available. Return empty list.
[ns_server:debug,2021-04-19T19:54:15.249Z,ns_1@127.0.0.1:goxdcr_status_keeper<0.389.0>:goxdcr_rest:get_from_goxdcr:163]Goxdcr is temporary not available. Return empty list.
[error_logger:info,2021-04-19T19:54:15.253Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_stats_sup}
             started: [{pid,<0.393.0>},
                       {name,index_stats_children_sup},
                       {mfargs,
                           {supervisor,start_link,
                               [{local,index_stats_children_sup},
                                index_stats_sup,child]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:54:15.259Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_status_keeper_sup}
             started: [{pid,<0.395.0>},
                       {name,index_status_keeper_worker},
                       {mfargs,
                           {work_queue,start_link,
                               [index_status_keeper_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:15.259Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_status_keeper_sup}
             started: [{pid,<0.396.0>},
                       {name,index_status_keeper},
                       {mfargs,{indexer_gsi,start_keeper,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:15.265Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_status_keeper_sup}
             started: [{pid,<0.399.0>},
                       {name,index_status_keeper_fts},
                       {mfargs,{indexer_fts,start_keeper,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:15.266Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_stats_sup}
             started: [{pid,<0.394.0>},
                       {name,index_status_keeper_sup},
                       {mfargs,{index_status_keeper_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:54:15.266Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_stats_sup}
             started: [{pid,<0.402.0>},
                       {name,index_stats_worker},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<index_stats_sup.0.21142793>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:15.266Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.392.0>},
                       {name,index_stats_sup},
                       {mfargs,{index_stats_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:error,2021-04-19T19:54:15.276Z,ns_1@127.0.0.1:index_status_keeper_worker<0.395.0>:index_rest:get_json:42]Request to (indexer) http://127.0.0.1:9102/getIndexStatus failed: {error,
                                                                   {econnrefused,
                                                                    [{lhttpc_client,
                                                                      send_request,
                                                                      1,
                                                                      [{file,
                                                                        "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                       {line,
                                                                        220}]},
                                                                     {lhttpc_client,
                                                                      execute,
                                                                      9,
                                                                      [{file,
                                                                        "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                       {line,
                                                                        169}]},
                                                                     {lhttpc_client,
                                                                      request,
                                                                      9,
                                                                      [{file,
                                                                        "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                       {line,
                                                                        92}]}]}}
[error_logger:info,2021-04-19T19:54:15.298Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_stats_children_sup}
             started: [{pid,<0.405.0>},
                       {name,{indexer_gsi,index_stats_collector}},
                       {mfargs,
                           {index_stats_collector,start_link,[indexer_gsi]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:15.307Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.409.0>},
                       {name,compaction_daemon},
                       {mfargs,{compaction_daemon,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:15.338Z,ns_1@127.0.0.1:<0.412.0>:new_concurrency_throttle:init:113]init concurrent throttle process, pid: <0.412.0>, type: kv_throttle# of available token: 1
[error_logger:info,2021-04-19T19:54:15.346Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_stats_children_sup}
             started: [{pid,<0.408.0>},
                       {name,{indexer_gsi,stats_archiver,"@index"}},
                       {mfargs,{stats_archiver,start_link,["@index"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:15.347Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_stats_children_sup}
             started: [{pid,<0.414.0>},
                       {name,{indexer_gsi,stats_reader,"@index"}},
                       {mfargs,{stats_reader,start_link,["@index"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:15.349Z,ns_1@127.0.0.1:compaction_new_daemon<0.410.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:54:15.349Z,ns_1@127.0.0.1:compaction_new_daemon<0.410.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[error_logger:info,2021-04-19T19:54:15.349Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.410.0>},
                       {name,compaction_new_daemon},
                       {mfargs,{compaction_new_daemon,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,86400000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:15.350Z,ns_1@127.0.0.1:compaction_new_daemon<0.410.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:54:15.350Z,ns_1@127.0.0.1:compaction_new_daemon<0.410.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:54:15.350Z,ns_1@127.0.0.1:compaction_new_daemon<0.410.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_master. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:54:15.351Z,ns_1@127.0.0.1:compaction_new_daemon<0.410.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_master too soon. Next run will be in 3600s
[error_logger:info,2021-04-19T19:54:15.358Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,cluster_logs_sup}
             started: [{pid,<0.416.0>},
                       {name,ets_holder},
                       {mfargs,
                           {cluster_logs_collection_task,
                               start_link_ets_holder,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:15.359Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.415.0>},
                       {name,cluster_logs_sup},
                       {mfargs,{cluster_logs_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:54:15.369Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.417.0>},
                       {name,remote_api},
                       {mfargs,{remote_api,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:15.379Z,ns_1@127.0.0.1:<0.418.0>:mb_master:check_master_takeover_needed:141]Sending master node question to the following nodes: []
[ns_server:debug,2021-04-19T19:54:15.380Z,ns_1@127.0.0.1:<0.418.0>:mb_master:check_master_takeover_needed:143]Got replies: []
[ns_server:debug,2021-04-19T19:54:15.380Z,ns_1@127.0.0.1:<0.418.0>:mb_master:check_master_takeover_needed:149]Was unable to discover master, not going to force mastership takeover
[user:info,2021-04-19T19:54:15.380Z,ns_1@127.0.0.1:mb_master<0.420.0>:mb_master:init:86]I'm the only node, so I'm the master.
[ns_server:debug,2021-04-19T19:54:15.403Z,ns_1@127.0.0.1:mb_master_sup<0.422.0>:misc:start_singleton:1097]start_singleton(gen_server, ns_tick, [], []): started as <0.423.0> on 'ns_1@127.0.0.1'

[error_logger:info,2021-04-19T19:54:15.403Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.423.0>},
                       {name,ns_tick},
                       {mfargs,{ns_tick,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,10},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:15.409Z,ns_1@127.0.0.1:ns_orchestrator_sup<0.424.0>:misc:start_singleton:1097]start_singleton(gen_fsm, ns_orchestrator, [], []): started as <0.425.0> on 'ns_1@127.0.0.1'

[error_logger:info,2021-04-19T19:54:15.409Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_sup}
             started: [{pid,<0.425.0>},
                       {name,ns_orchestrator},
                       {mfargs,{ns_orchestrator,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:15.422Z,ns_1@127.0.0.1:<0.427.0>:auto_failover:init:147]init auto_failover.
[ns_server:debug,2021-04-19T19:54:15.422Z,ns_1@127.0.0.1:ns_orchestrator_sup<0.424.0>:misc:start_singleton:1097]start_singleton(gen_server, auto_failover, [], []): started as <0.427.0> on 'ns_1@127.0.0.1'

[ns_server:debug,2021-04-19T19:54:15.422Z,ns_1@127.0.0.1:<0.418.0>:restartable:start_child:98]Started child process <0.420.0>
  MFA: {mb_master,start_link,[]}
[error_logger:info,2021-04-19T19:54:15.422Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_sup}
             started: [{pid,<0.427.0>},
                       {name,auto_failover},
                       {mfargs,{auto_failover,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:15.423Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.424.0>},
                       {name,ns_orchestrator_sup},
                       {mfargs,{ns_orchestrator_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:54:15.423Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.418.0>},
                       {name,mb_master},
                       {mfargs,
                           {restartable,start_link,
                               [{mb_master,start_link,[]},infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:54:15.423Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.428.0>},
                       {name,master_activity_events_ingress},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,master_activity_events_ingress}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:15.424Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.429.0>},
                       {name,master_activity_events_timestamper},
                       {mfargs,
                           {master_activity_events,start_link_timestamper,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:15.429Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.430.0>},
                       {name,master_activity_events_pids_watcher},
                       {mfargs,
                           {master_activity_events_pids_watcher,start_link,
                               []}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:15.454Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.155.0>:one_shot_barrier:notify:27]Notifying on barrier menelaus_barrier
[ns_server:debug,2021-04-19T19:54:15.454Z,ns_1@127.0.0.1:menelaus_barrier<0.157.0>:one_shot_barrier:barrier_body:62]Barrier menelaus_barrier got notification from <0.155.0>
[error_logger:info,2021-04-19T19:54:15.454Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.431.0>},
                       {name,master_activity_events_keeper},
                       {mfargs,{master_activity_events_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:15.454Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.155.0>:one_shot_barrier:notify:32]Successfuly notified on barrier menelaus_barrier
[error_logger:info,2021-04-19T19:54:15.454Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.241.0>},
                       {name,ns_server_sup},
                       {mfargs,{ns_server_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2021-04-19T19:54:15.454Z,ns_1@127.0.0.1:<0.154.0>:restartable:start_child:98]Started child process <0.155.0>
  MFA: {ns_server_nodes_sup,start_link,[]}
[ns_server:debug,2021-04-19T19:54:15.455Z,ns_1@127.0.0.1:<0.2.0>:child_erlang:child_loop:116]97: Entered child_loop
[error_logger:info,2021-04-19T19:54:15.455Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.154.0>},
                       {name,ns_server_nodes_sup},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_server_nodes_sup,start_link,[]},
                                infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:54:15.455Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
         application: ns_server
          started_at: 'ns_1@127.0.0.1'

[ns_server:warn,2021-04-19T19:54:16.055Z,ns_1@127.0.0.1:<0.348.0>:ns_memcached:connect:1307]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[ns_server:debug,2021-04-19T19:54:16.099Z,ns_1@127.0.0.1:ns_ports_setup<0.339.0>:ns_ports_setup:set_children:72]Monitor ns_child_ports_sup <11632.72.0>
[ns_server:debug,2021-04-19T19:54:16.100Z,ns_1@127.0.0.1:memcached_config_mgr<0.350.0>:memcached_config_mgr:init:46]ns_ports_setup seems to be ready
[ns_server:debug,2021-04-19T19:54:16.107Z,ns_1@127.0.0.1:memcached_config_mgr<0.350.0>:memcached_config_mgr:find_port_pid_loop:119]Found memcached port <11632.79.0>
[ns_server:debug,2021-04-19T19:54:16.138Z,ns_1@127.0.0.1:memcached_config_mgr<0.350.0>:memcached_config_mgr:init:77]wrote memcached config to /opt/couchbase/var/lib/couchbase/config/memcached.json. Will activate memcached port server
[ns_server:debug,2021-04-19T19:54:16.157Z,ns_1@127.0.0.1:memcached_config_mgr<0.350.0>:memcached_config_mgr:init:80]activated memcached port server
[ns_server:error,2021-04-19T19:54:16.405Z,ns_1@127.0.0.1:index_stats_collector-index<0.405.0>:index_rest:get_json:42]Request to (indexer) http://127.0.0.1:9102/stats?async=true failed: {error,
                                                                     {econnrefused,
                                                                      [{lhttpc_client,
                                                                        send_request,
                                                                        1,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          220}]},
                                                                       {lhttpc_client,
                                                                        execute,
                                                                        9,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          169}]},
                                                                       {lhttpc_client,
                                                                        request,
                                                                        9,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          92}]}]}}
[stats:error,2021-04-19T19:54:16.405Z,ns_1@127.0.0.1:query_stats_collector<0.382.0>:base_stats_collector:handle_info:109](Collector: query_stats_collector) Exception in stats collector: {error,
                                                                  {badmatch,
                                                                   {error,
                                                                    {econnrefused,
                                                                     [{lhttpc_client,
                                                                       send_request,
                                                                       1,
                                                                       [{file,
                                                                         "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                        {line,
                                                                         220}]},
                                                                      {lhttpc_client,
                                                                       execute,
                                                                       9,
                                                                       [{file,
                                                                         "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                        {line,
                                                                         169}]},
                                                                      {lhttpc_client,
                                                                       request,
                                                                       9,
                                                                       [{file,
                                                                         "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                        {line,
                                                                         92}]}]}}},
                                                                  [{query_rest,
                                                                    send,3,
                                                                    [{file,
                                                                      "src/query_rest.erl"},
                                                                     {line,
                                                                      64}]},
                                                                   {query_rest,
                                                                    do_get_stats,
                                                                    0,
                                                                    [{file,
                                                                      "src/query_rest.erl"},
                                                                     {line,
                                                                      43}]},
                                                                   {base_stats_collector,
                                                                    handle_info,
                                                                    2,
                                                                    [{file,
                                                                      "src/base_stats_collector.erl"},
                                                                     {line,
                                                                      89}]},
                                                                   {gen_server,
                                                                    handle_msg,
                                                                    5,
                                                                    [{file,
                                                                      "gen_server.erl"},
                                                                     {line,
                                                                      604}]},
                                                                   {proc_lib,
                                                                    init_p_do_apply,
                                                                    3,
                                                                    [{file,
                                                                      "proc_lib.erl"},
                                                                     {line,
                                                                      239}]}]}

[ns_server:warn,2021-04-19T19:54:16.412Z,ns_1@127.0.0.1:<0.438.0>:ns_memcached:connect:1307]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[ns_server:warn,2021-04-19T19:54:17.063Z,ns_1@127.0.0.1:<0.348.0>:ns_memcached:connect:1307]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[ns_server:debug,2021-04-19T19:54:17.126Z,ns_1@127.0.0.1:json_rpc_connection-projector-cbauth<0.442.0>:json_rpc_connection:init:74]Observed revrpc connection: label "projector-cbauth", handling process <0.442.0>
[ns_server:debug,2021-04-19T19:54:17.126Z,ns_1@127.0.0.1:menelaus_cbauth<0.335.0>:menelaus_cbauth:handle_cast:87]Observed json rpc process {"projector-cbauth",<0.442.0>} started
[error_logger:error,2021-04-19T19:54:17.127Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.442.0>,{ok,<0.442.0>}}

[ns_server:debug,2021-04-19T19:54:17.157Z,ns_1@127.0.0.1:json_rpc_connection-projector-cbauth<0.442.0>:json_rpc_connection:handle_call:157]sending jsonrpc call:{[{jsonrpc,<<"2.0">>},
                       {id,0},
                       {method,<<"AuthCacheSvc.UpdateDB">>},
                       {params,
                        [{[{specialUser,<<"@projector-cbauth">>},
                           {nodes,
                            [{[{host,<<"127.0.0.1">>},
                               {user,<<"_admin">>},
                               {password,"*****"},
                               {ports,
                                [8091,18091,9100,9101,9102,9103,9104,9105,
                                 18092,8092,11207,9999,11210,11211,8093,
                                 18093]},
                               {local,true}]}]},
                           {buckets,[]},
                           {authCheckURL,<<"http://127.0.0.1:8091/_cbauth">>},
                           {permissionCheckURL,
                            <<"http://127.0.0.1:8091/_cbauth/checkPermission">>},
                           {ldapEnabled,true},
                           {permissionsVersion,125619376},
                           {admin,
                            {[{user,<<"Administrator">>},
                              {salt,<<"6fV7COE6Hrv1Slx3m7c7aw==">>},
                              {mac,
                               <<"88VQXOIVfyUC4fCDlttiZJtlD/s=">>}]}}]}]}]}
[ns_server:debug,2021-04-19T19:54:17.161Z,ns_1@127.0.0.1:json_rpc_connection-projector-cbauth<0.442.0>:json_rpc_connection:handle_info:93]got response: [{<<"id">>,0},{<<"result">>,true},{<<"error">>,null}]
[ns_server:error,2021-04-19T19:54:17.406Z,ns_1@127.0.0.1:index_stats_collector-index<0.405.0>:index_rest:get_json:42]Request to (indexer) http://127.0.0.1:9102/stats?async=true failed: {error,
                                                                     {econnrefused,
                                                                      [{lhttpc_client,
                                                                        send_request,
                                                                        1,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          220}]},
                                                                       {lhttpc_client,
                                                                        execute,
                                                                        9,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          169}]},
                                                                       {lhttpc_client,
                                                                        request,
                                                                        9,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          92}]}]}}
[stats:error,2021-04-19T19:54:17.406Z,ns_1@127.0.0.1:query_stats_collector<0.382.0>:base_stats_collector:handle_info:109](Collector: query_stats_collector) Exception in stats collector: {error,
                                                                  {badmatch,
                                                                   {error,
                                                                    {econnrefused,
                                                                     [{lhttpc_client,
                                                                       send_request,
                                                                       1,
                                                                       [{file,
                                                                         "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                        {line,
                                                                         220}]},
                                                                      {lhttpc_client,
                                                                       execute,
                                                                       9,
                                                                       [{file,
                                                                         "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                        {line,
                                                                         169}]},
                                                                      {lhttpc_client,
                                                                       request,
                                                                       9,
                                                                       [{file,
                                                                         "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                        {line,
                                                                         92}]}]}}},
                                                                  [{query_rest,
                                                                    send,3,
                                                                    [{file,
                                                                      "src/query_rest.erl"},
                                                                     {line,
                                                                      64}]},
                                                                   {query_rest,
                                                                    do_get_stats,
                                                                    0,
                                                                    [{file,
                                                                      "src/query_rest.erl"},
                                                                     {line,
                                                                      43}]},
                                                                   {base_stats_collector,
                                                                    handle_info,
                                                                    2,
                                                                    [{file,
                                                                      "src/base_stats_collector.erl"},
                                                                     {line,
                                                                      89}]},
                                                                   {gen_server,
                                                                    handle_msg,
                                                                    5,
                                                                    [{file,
                                                                      "gen_server.erl"},
                                                                     {line,
                                                                      604}]},
                                                                   {proc_lib,
                                                                    init_p_do_apply,
                                                                    3,
                                                                    [{file,
                                                                      "proc_lib.erl"},
                                                                     {line,
                                                                      239}]}]}

[ns_server:warn,2021-04-19T19:54:17.417Z,ns_1@127.0.0.1:<0.438.0>:ns_memcached:connect:1307]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[ns_server:debug,2021-04-19T19:54:17.609Z,ns_1@127.0.0.1:json_rpc_connection-index-cbauth<0.451.0>:json_rpc_connection:init:74]Observed revrpc connection: label "index-cbauth", handling process <0.451.0>
[error_logger:error,2021-04-19T19:54:17.610Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.451.0>,{ok,<0.451.0>}}

[ns_server:debug,2021-04-19T19:54:17.609Z,ns_1@127.0.0.1:menelaus_cbauth<0.335.0>:menelaus_cbauth:handle_cast:87]Observed json rpc process {"index-cbauth",<0.451.0>} started
[ns_server:debug,2021-04-19T19:54:17.619Z,ns_1@127.0.0.1:json_rpc_connection-index-cbauth<0.451.0>:json_rpc_connection:handle_call:157]sending jsonrpc call:{[{jsonrpc,<<"2.0">>},
                       {id,0},
                       {method,<<"AuthCacheSvc.UpdateDB">>},
                       {params,
                        [{[{specialUser,<<"@index-cbauth">>},
                           {nodes,
                            [{[{host,<<"127.0.0.1">>},
                               {user,<<"_admin">>},
                               {password,"*****"},
                               {ports,
                                [8091,18091,9100,9101,9102,9103,9104,9105,
                                 18092,8092,11207,9999,11210,11211,8093,
                                 18093]},
                               {local,true}]}]},
                           {buckets,[]},
                           {authCheckURL,<<"http://127.0.0.1:8091/_cbauth">>},
                           {permissionCheckURL,
                            <<"http://127.0.0.1:8091/_cbauth/checkPermission">>},
                           {ldapEnabled,true},
                           {permissionsVersion,125619376},
                           {admin,
                            {[{user,<<"Administrator">>},
                              {salt,<<"6fV7COE6Hrv1Slx3m7c7aw==">>},
                              {mac,
                               <<"88VQXOIVfyUC4fCDlttiZJtlD/s=">>}]}}]}]}]}
[ns_server:debug,2021-04-19T19:54:17.626Z,ns_1@127.0.0.1:json_rpc_connection-index-cbauth<0.451.0>:json_rpc_connection:handle_info:93]got response: [{<<"id">>,0},{<<"result">>,true},{<<"error">>,null}]
[ns_server:debug,2021-04-19T19:54:17.740Z,ns_1@127.0.0.1:json_rpc_connection-cbq-engine-cbauth<0.458.0>:json_rpc_connection:init:74]Observed revrpc connection: label "cbq-engine-cbauth", handling process <0.458.0>
[ns_server:debug,2021-04-19T19:54:17.741Z,ns_1@127.0.0.1:menelaus_cbauth<0.335.0>:menelaus_cbauth:handle_cast:87]Observed json rpc process {"cbq-engine-cbauth",<0.458.0>} started
[error_logger:error,2021-04-19T19:54:17.741Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.458.0>,{ok,<0.458.0>}}

[ns_server:debug,2021-04-19T19:54:17.741Z,ns_1@127.0.0.1:json_rpc_connection-cbq-engine-cbauth<0.458.0>:json_rpc_connection:handle_call:157]sending jsonrpc call:{[{jsonrpc,<<"2.0">>},
                       {id,0},
                       {method,<<"AuthCacheSvc.UpdateDB">>},
                       {params,
                        [{[{specialUser,<<"@cbq-engine-cbauth">>},
                           {nodes,
                            [{[{host,<<"127.0.0.1">>},
                               {user,<<"_admin">>},
                               {password,"*****"},
                               {ports,
                                [8091,18091,9100,9101,9102,9103,9104,9105,
                                 18092,8092,11207,9999,11210,11211,8093,
                                 18093]},
                               {local,true}]}]},
                           {buckets,[]},
                           {authCheckURL,<<"http://127.0.0.1:8091/_cbauth">>},
                           {permissionCheckURL,
                            <<"http://127.0.0.1:8091/_cbauth/checkPermission">>},
                           {ldapEnabled,true},
                           {permissionsVersion,125619376},
                           {admin,
                            {[{user,<<"Administrator">>},
                              {salt,<<"6fV7COE6Hrv1Slx3m7c7aw==">>},
                              {mac,
                               <<"88VQXOIVfyUC4fCDlttiZJtlD/s=">>}]}}]}]}]}
[ns_server:debug,2021-04-19T19:54:17.745Z,ns_1@127.0.0.1:json_rpc_connection-cbq-engine-cbauth<0.458.0>:json_rpc_connection:handle_info:93]got response: [{<<"id">>,0},{<<"result">>,true},{<<"error">>,null}]
[ns_server:debug,2021-04-19T19:54:17.785Z,ns_1@127.0.0.1:json_rpc_connection-saslauthd-saslauthd-port<0.463.0>:json_rpc_connection:init:74]Observed revrpc connection: label "saslauthd-saslauthd-port", handling process <0.463.0>
[error_logger:error,2021-04-19T19:54:17.785Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.463.0>,{ok,<0.463.0>}}

[ns_server:debug,2021-04-19T19:54:17.888Z,ns_1@127.0.0.1:json_rpc_connection-goxdcr-cbauth<0.466.0>:json_rpc_connection:init:74]Observed revrpc connection: label "goxdcr-cbauth", handling process <0.466.0>
[error_logger:error,2021-04-19T19:54:17.888Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.466.0>,{ok,<0.466.0>}}

[ns_server:debug,2021-04-19T19:54:17.888Z,ns_1@127.0.0.1:menelaus_cbauth<0.335.0>:menelaus_cbauth:handle_cast:87]Observed json rpc process {"goxdcr-cbauth",<0.466.0>} started
[ns_server:debug,2021-04-19T19:54:17.889Z,ns_1@127.0.0.1:json_rpc_connection-goxdcr-cbauth<0.466.0>:json_rpc_connection:handle_call:157]sending jsonrpc call:{[{jsonrpc,<<"2.0">>},
                       {id,0},
                       {method,<<"AuthCacheSvc.UpdateDB">>},
                       {params,
                        [{[{specialUser,<<"@goxdcr-cbauth">>},
                           {nodes,
                            [{[{host,<<"127.0.0.1">>},
                               {user,<<"_admin">>},
                               {password,"*****"},
                               {ports,
                                [8091,18091,9100,9101,9102,9103,9104,9105,
                                 18092,8092,11207,9999,11210,11211,8093,
                                 18093]},
                               {local,true}]}]},
                           {buckets,[]},
                           {authCheckURL,<<"http://127.0.0.1:8091/_cbauth">>},
                           {permissionCheckURL,
                            <<"http://127.0.0.1:8091/_cbauth/checkPermission">>},
                           {ldapEnabled,true},
                           {permissionsVersion,125619376},
                           {admin,
                            {[{user,<<"Administrator">>},
                              {salt,<<"6fV7COE6Hrv1Slx3m7c7aw==">>},
                              {mac,
                               <<"88VQXOIVfyUC4fCDlttiZJtlD/s=">>}]}}]}]}]}
[ns_server:debug,2021-04-19T19:54:17.898Z,ns_1@127.0.0.1:json_rpc_connection-goxdcr-cbauth<0.466.0>:json_rpc_connection:handle_info:93]got response: [{<<"id">>,0},{<<"result">>,true},{<<"error">>,null}]
[ns_server:warn,2021-04-19T19:54:18.065Z,ns_1@127.0.0.1:<0.348.0>:ns_memcached:connect:1307]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[ns_server:error,2021-04-19T19:54:18.405Z,ns_1@127.0.0.1:index_stats_collector-index<0.405.0>:index_rest:get_json:42]Request to (indexer) http://127.0.0.1:9102/stats?async=true failed: {error,
                                                                     {econnrefused,
                                                                      [{lhttpc_client,
                                                                        send_request,
                                                                        1,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          220}]},
                                                                       {lhttpc_client,
                                                                        execute,
                                                                        9,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          169}]},
                                                                       {lhttpc_client,
                                                                        request,
                                                                        9,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          92}]}]}}
[stats:warn,2021-04-19T19:54:18.434Z,ns_1@127.0.0.1:<0.387.0>:base_stats_collector:latest_tick:69](Collector: global_stats_collector) Dropped 2 ticks
[ns_server:debug,2021-04-19T19:54:20.095Z,ns_1@127.0.0.1:<0.504.0>:ns_audit:put:248]Audit modify_index_storage_mode: [{storageMode,<<"memory_optimized">>},
                                  {real_userid,
                                      {[{source,ns_server},
                                        {user,<<"Administrator">>}]}},
                                  {remote,
                                      {[{ip,<<"127.0.0.1">>},{port,36498}]}},
                                  {timestamp,<<"2021-04-19T19:54:20.095Z">>}]
[ns_server:debug,2021-04-19T19:54:20.096Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{metakv,<<"/indexing/settings/config">>} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{6,63786081260}}]}|
 <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.log_level\":\"info\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\""...>>]
[ns_server:debug,2021-04-19T19:54:20.096Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{local_changes_count,<<"dbb8bee8b38705437e7f5ebc78107bfa">>} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{14,63786081260}}]}]
[ns_server:debug,2021-04-19T19:54:20.096Z,ns_1@127.0.0.1:ns_config_rep<0.258.0>:ns_config_rep:do_push_keys:321]Replicating some config keys ([{local_changes_count,
                                   <<"dbb8bee8b38705437e7f5ebc78107bfa">>},
                               {metakv,<<"/indexing/settings/config">>}]..)
[ns_server:debug,2021-04-19T19:54:45.350Z,ns_1@127.0.0.1:compaction_new_daemon<0.410.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:54:45.350Z,ns_1@127.0.0.1:compaction_new_daemon<0.410.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:54:45.350Z,ns_1@127.0.0.1:compaction_new_daemon<0.410.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:54:45.350Z,ns_1@127.0.0.1:compaction_new_daemon<0.410.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:55:15.351Z,ns_1@127.0.0.1:compaction_new_daemon<0.410.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:55:15.351Z,ns_1@127.0.0.1:compaction_new_daemon<0.410.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:55:15.351Z,ns_1@127.0.0.1:compaction_new_daemon<0.410.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:55:15.351Z,ns_1@127.0.0.1:compaction_new_daemon<0.410.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:55:45.352Z,ns_1@127.0.0.1:compaction_new_daemon<0.410.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:55:45.352Z,ns_1@127.0.0.1:compaction_new_daemon<0.410.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:55:45.352Z,ns_1@127.0.0.1:compaction_new_daemon<0.410.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:55:45.352Z,ns_1@127.0.0.1:compaction_new_daemon<0.410.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:56:15.353Z,ns_1@127.0.0.1:compaction_new_daemon<0.410.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:56:15.353Z,ns_1@127.0.0.1:compaction_new_daemon<0.410.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:56:15.353Z,ns_1@127.0.0.1:compaction_new_daemon<0.410.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:56:15.353Z,ns_1@127.0.0.1:compaction_new_daemon<0.410.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:56:45.354Z,ns_1@127.0.0.1:compaction_new_daemon<0.410.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:56:45.354Z,ns_1@127.0.0.1:compaction_new_daemon<0.410.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:56:45.354Z,ns_1@127.0.0.1:compaction_new_daemon<0.410.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:56:45.354Z,ns_1@127.0.0.1:compaction_new_daemon<0.410.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:57:15.355Z,ns_1@127.0.0.1:compaction_new_daemon<0.410.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:57:15.355Z,ns_1@127.0.0.1:compaction_new_daemon<0.410.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:57:15.355Z,ns_1@127.0.0.1:compaction_new_daemon<0.410.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:57:15.355Z,ns_1@127.0.0.1:compaction_new_daemon<0.410.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:57:45.356Z,ns_1@127.0.0.1:compaction_new_daemon<0.410.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:57:45.356Z,ns_1@127.0.0.1:compaction_new_daemon<0.410.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:57:45.356Z,ns_1@127.0.0.1:compaction_new_daemon<0.410.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:57:45.356Z,ns_1@127.0.0.1:compaction_new_daemon<0.410.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:58:15.357Z,ns_1@127.0.0.1:compaction_new_daemon<0.410.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:58:15.357Z,ns_1@127.0.0.1:compaction_new_daemon<0.410.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:58:15.357Z,ns_1@127.0.0.1:compaction_new_daemon<0.410.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:58:15.357Z,ns_1@127.0.0.1:compaction_new_daemon<0.410.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:info,2021-04-19T20:01:45.930Z,nonode@nohost:<0.88.0>:ns_server:init_logging:151]Started & configured logging
[ns_server:info,2021-04-19T20:01:45.949Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]Static config terms:
[{error_logger_mf_dir,"/opt/couchbase/var/lib/couchbase/logs"},
 {path_config_bindir,"/opt/couchbase/bin"},
 {path_config_etcdir,"/opt/couchbase/etc/couchbase"},
 {path_config_libdir,"/opt/couchbase/lib"},
 {path_config_datadir,"/opt/couchbase/var/lib/couchbase"},
 {path_config_tmpdir,"/opt/couchbase/var/lib/couchbase/tmp"},
 {path_config_secdir,"/opt/couchbase/etc/security"},
 {nodefile,"/opt/couchbase/var/lib/couchbase/couchbase-server.node"},
 {loglevel_default,debug},
 {loglevel_couchdb,info},
 {loglevel_ns_server,debug},
 {loglevel_error_logger,debug},
 {loglevel_user,debug},
 {loglevel_menelaus,debug},
 {loglevel_ns_doctor,debug},
 {loglevel_stats,debug},
 {loglevel_rebalance,debug},
 {loglevel_cluster,debug},
 {loglevel_views,debug},
 {loglevel_mapreduce_errors,debug},
 {loglevel_xdcr,debug},
 {loglevel_xdcr_trace,error},
 {loglevel_access,info},
 {disk_sink_opts,
     [{rotation,
          [{compress,true},
           {size,41943040},
           {num_files,10},
           {buffer_size_max,52428800}]}]},
 {disk_sink_opts_xdcr_trace,
     [{rotation,[{compress,false},{size,83886080},{num_files,5}]}]},
 {net_kernel_verbosity,10}]
[ns_server:warn,2021-04-19T20:01:45.949Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter error_logger_mf_dir, which is given from command line
[ns_server:warn,2021-04-19T20:01:45.949Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter path_config_bindir, which is given from command line
[ns_server:warn,2021-04-19T20:01:45.949Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter path_config_etcdir, which is given from command line
[ns_server:warn,2021-04-19T20:01:45.949Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter path_config_libdir, which is given from command line
[ns_server:warn,2021-04-19T20:01:45.949Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter path_config_datadir, which is given from command line
[ns_server:warn,2021-04-19T20:01:45.949Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter path_config_tmpdir, which is given from command line
[ns_server:warn,2021-04-19T20:01:45.949Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter path_config_secdir, which is given from command line
[ns_server:warn,2021-04-19T20:01:45.950Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter nodefile, which is given from command line
[ns_server:warn,2021-04-19T20:01:45.950Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_default, which is given from command line
[ns_server:warn,2021-04-19T20:01:45.950Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_couchdb, which is given from command line
[ns_server:warn,2021-04-19T20:01:45.950Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_ns_server, which is given from command line
[ns_server:warn,2021-04-19T20:01:45.950Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_error_logger, which is given from command line
[ns_server:warn,2021-04-19T20:01:45.950Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_user, which is given from command line
[ns_server:warn,2021-04-19T20:01:45.950Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_menelaus, which is given from command line
[ns_server:warn,2021-04-19T20:01:45.950Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_ns_doctor, which is given from command line
[ns_server:warn,2021-04-19T20:01:45.950Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_stats, which is given from command line
[ns_server:warn,2021-04-19T20:01:45.950Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_rebalance, which is given from command line
[ns_server:warn,2021-04-19T20:01:45.950Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_cluster, which is given from command line
[ns_server:warn,2021-04-19T20:01:45.950Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_views, which is given from command line
[ns_server:warn,2021-04-19T20:01:45.950Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_mapreduce_errors, which is given from command line
[ns_server:warn,2021-04-19T20:01:45.950Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_xdcr, which is given from command line
[ns_server:warn,2021-04-19T20:01:45.950Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_xdcr_trace, which is given from command line
[ns_server:warn,2021-04-19T20:01:45.950Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_access, which is given from command line
[ns_server:warn,2021-04-19T20:01:45.950Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter disk_sink_opts, which is given from command line
[ns_server:warn,2021-04-19T20:01:45.950Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter disk_sink_opts_xdcr_trace, which is given from command line
[ns_server:warn,2021-04-19T20:01:45.951Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter net_kernel_verbosity, which is given from command line
[error_logger:info,2021-04-19T20:01:45.957Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.128.0>},
                       {name,local_tasks},
                       {mfargs,{local_tasks,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:info,2021-04-19T20:01:45.964Z,nonode@nohost:ns_server_cluster_sup<0.127.0>:log_os_info:start_link:25]OS type: {unix,linux} Version: {4,19,128}
Runtime info: [{otp_release,"R16B03-1"},
               {erl_version,"5.10.4.0.0.1"},
               {erl_version_long,
                   "Erlang R16B03-1 (erts-5.10.4.0.0.1) [source-00852da] [64-bit] [smp:8:8] [async-threads:16] [kernel-poll:true]\n"},
               {system_arch_raw,"x86_64-unknown-linux-gnu"},
               {system_arch,"x86_64-unknown-linux-gnu"},
               {localtime,{{2021,4,19},{20,1,45}}},
               {memory,
                   [{total,111108208},
                    {processes,9577632},
                    {processes_used,9576656},
                    {system,101530576},
                    {atom,331249},
                    {atom_used,310220},
                    {binary,54248},
                    {code,7694133},
                    {ets,2240584}]},
               {loaded,
                   [ns_info,log_os_info,local_tasks,restartable,
                    ns_server_cluster_sup,calendar,ale_default_formatter,
                    'ale_logger-metakv','ale_logger-rebalance',
                    'ale_logger-xdcr_trace','ale_logger-menelaus',
                    'ale_logger-stats','ale_logger-access',
                    'ale_logger-ns_server','ale_logger-user',
                    'ale_logger-ns_doctor','ale_logger-cluster',io_lib_fread,
                    'ale_logger-xdcr',otp_internal,ns_log_sink,ale_disk_sink,
                    misc,couch_util,ns_server,filelib,cpu_sup,memsup,disksup,
                    os_mon,io,release_handler,overload,alarm_handler,sasl,
                    timer,tftp_sup,httpd_sup,httpc_handler_sup,httpc_cookie,
                    inets_trace,httpc_manager,httpc,httpc_profile_sup,
                    httpc_sup,ftp_sup,inets_sup,inets_app,ssl,lhttpc_manager,
                    lhttpc_sup,lhttpc,tls_connection_sup,ssl_session_cache,
                    ssl_pkix_db,ssl_manager,ssl_sup,ssl_app,crypto_server,
                    crypto_sup,crypto_app,ale_error_logger_handler,
                    'ale_logger-ale_logger','ale_logger-error_logger',
                    beam_opcodes,beam_dict,beam_asm,beam_validator,beam_z,
                    beam_flatten,beam_trim,beam_receive,beam_bsm,beam_peep,
                    beam_dead,beam_split,beam_type,beam_bool,beam_except,
                    beam_clean,beam_utils,beam_block,beam_jump,beam_a,
                    v3_codegen,v3_life,v3_kernel,sys_core_dsetel,erl_bifs,
                    sys_core_fold,cerl_trees,sys_core_inline,core_lib,cerl,
                    v3_core,erl_bits,erl_expand_records,sys_pre_expand,sofs,
                    erl_internal,sets,ordsets,erl_lint,compile,
                    dynamic_compile,ale_utils,io_lib_pretty,io_lib_format,
                    io_lib,ale_codegen,dict,ale,ale_dynamic_sup,ale_sup,
                    ale_app,epp,ns_bootstrap,child_erlang,file_io_server,
                    orddict,erl_eval,file,c,kernel_config,user_sup,
                    supervisor_bridge,standard_error,code_server,unicode,
                    hipe_unified_loader,gb_sets,ets,binary,code,file_server,
                    net_kernel,global_group,erl_distribution,filename,
                    inet_gethost_native,os,inet_parse,inet,inet_udp,
                    inet_config,inet_db,global,gb_trees,rpc,supervisor,kernel,
                    application_master,sys,application,gen_server,erl_parse,
                    proplists,erl_scan,lists,application_controller,proc_lib,
                    gen,gen_event,error_logger,heart,error_handler,
                    erts_internal,erlang,erl_prim_loader,prim_zip,zlib,
                    prim_file,prim_inet,prim_eval,init,otp_ring0]},
               {applications,
                   [{lhttpc,"Lightweight HTTP Client","1.3.0"},
                    {os_mon,"CPO  CXC 138 46","2.2.14"},
                    {public_key,"Public key infrastructure","0.21"},
                    {asn1,"The Erlang ASN1 compiler version 2.0.4","2.0.4"},
                    {kernel,"ERTS  CXC 138 10","2.16.4"},
                    {ale,"Another Logger for Erlang","4.6.0-3573-enterprise"},
                    {inets,"INETS  CXC 138 49","5.9.8"},
                    {ns_server,"Couchbase server","4.6.0-3573-enterprise"},
                    {crypto,"CRYPTO version 2","3.2"},
                    {ssl,"Erlang/OTP SSL application","5.3.3"},
                    {sasl,"SASL  CXC 138 11","2.3.4"},
                    {stdlib,"ERTS  CXC 138 10","1.19.4"}]},
               {pre_loaded,
                   [erts_internal,erlang,erl_prim_loader,prim_zip,zlib,
                    prim_file,prim_inet,prim_eval,init,otp_ring0]},
               {process_count,94},
               {node,nonode@nohost},
               {nodes,[]},
               {registered,
                   [ftp_sup,'sink-disk_xdcr',code_server,sasl_sup,
                    'sink-disk_debug',application_controller,
                    'sink-disk_error',local_tasks,'sink-disk_default',
                    ale_stats_events,kernel_safe_sup,inets_sup,ale,
                    standard_error,error_logger,lhttpc_sup,ale_sup,
                    lhttpc_manager,timer_server,standard_error_sup,
                    release_handler,httpd_sup,ale_dynamic_sup,overload,
                    alarm_handler,init,inet_db,rex,kernel_sup,'sink-ns_log',
                    global_name_server,sasl_safe_sup,crypto_server,crypto_sup,
                    file_server_2,tftp_sup,global_group,os_mon_sup,
                    'sink-disk_metakv',cpu_sup,tls_connection_sup,memsup,
                    ssl_sup,'sink-disk_access_int',disksup,'sink-disk_access',
                    ns_server_cluster_sup,httpc_sup,ssl_manager,
                    'sink-xdcr_trace',erl_prim_loader,'sink-disk_reports',
                    httpc_profile_sup,'sink-disk_stats',httpc_manager,
                    httpc_handler_sup,'sink-disk_xdcr_errors']},
               {cookie,nocookie},
               {wordsize,8},
               {wall_clock,3}]
[ns_server:info,2021-04-19T20:01:45.975Z,nonode@nohost:ns_server_cluster_sup<0.127.0>:log_os_info:start_link:27]Manifest:
["<?xml version=\"1.0\" encoding=\"UTF-8\"?>","<manifest>",
 "  <remote fetch=\"git://github.com/blevesearch/\" name=\"blevesearch\"/>",
 "  <remote fetch=\"git://github.com/couchbase/\" name=\"couchbase\" review=\"review.couchbase.org\"/>",
 "  <remote fetch=\"ssh://git@github.com/couchbase/\" name=\"couchbase-priv\" review=\"review.couchbase.org\"/>",
 "  <remote fetch=\"git://github.com/couchbasedeps/\" name=\"couchbasedeps\" review=\"review.couchbase.org\"/>",
 "  <remote fetch=\"git://github.com/couchbaselabs/\" name=\"couchbaselabs\" review=\"review.couchbase.org\"/>",
 "  ","  <default remote=\"couchbase\" revision=\"master\"/>","  ",
 "  <project groups=\"notdefault,enterprise\" name=\"backup\" path=\"goproj/src/github.com/couchbase/backup\" remote=\"couchbase-priv\" revision=\"469a5e8cc8661f35ab4af74fe45e92a3d89febed\"/>",
 "  <project name=\"bitset\" path=\"godeps/src/github.com/willf/bitset\" remote=\"couchbasedeps\" revision=\"28a4168144bb8ac95454e1f51c84da1933681ad4\"/>",
 "  <project name=\"blance\" path=\"godeps/src/github.com/couchbase/blance\" revision=\"5ce14d13954e04262b7eabfc6978776a4018402b\"/>",
 "  <project name=\"bleve\" path=\"godeps/src/github.com/blevesearch/bleve\" remote=\"blevesearch\" revision=\"f531835d5c212ee5f95c49d2debc28e65e6d1693\"/>",
 "  <project name=\"bleve-mapping-ui\" path=\"godeps/src/github.com/blevesearch/bleve-mapping-ui\" remote=\"blevesearch\" revision=\"b0453426dc1d59918cc763a970f1ad147b22ad6a\"/>",
 "  <project name=\"blevex\" path=\"godeps/src/github.com/blevesearch/blevex\" remote=\"blevesearch\" revision=\"918d980b0d244c8230c7d8c8ee40919f8d55ef88\"/>",
 "  <project name=\"bolt\" path=\"godeps/src/github.com/boltdb/bolt\" remote=\"couchbasedeps\" revision=\"51f99c862475898df9773747d3accd05a7ca33c1\"/>",
 "  <project name=\"buffer\" path=\"godeps/src/github.com/tdewolff/buffer\" remote=\"couchbasedeps\" revision=\"43cef5ba7b6ce99cc410632dad46cf1c6c97026e\"/>",
 "  <project groups=\"notdefault,build\" name=\"build\" path=\"cbbuild\" revision=\"ccd3ae52bbf0ade5fd59adcedba2b8cbbd16cd9b\">",
 "    <annotation name=\"VERSION\" value=\"4.6.0\"/>",
 "    <annotation name=\"BLD_NUM\" value=\"3573\"/>",
 "    <annotation name=\"RELEASE\" value=\"@RELEASE@\"/>",
 "    <annotation name=\"EDITION\" value=\"@EDITION@\"/>","  </project>",
 "  <project name=\"cbauth\" path=\"godeps/src/github.com/couchbase/cbauth\" revision=\"4a6d537777f57b291a8126f94dfbe3201c1d4efc\"/>",
 "  <project name=\"cbflag\" path=\"godeps/src/github.com/couchbase/cbflag\" revision=\"ce5c10adbb78c1212aefda73a85f8cfd1c3ae7e9\"/>",
 "  <project name=\"cbft\" path=\"goproj/src/github.com/couchbase/cbft\" revision=\"99f44266178dbe423890d8dd5bb9439ef2a71318\"/>",
 "  <project name=\"cbgt\" path=\"goproj/src/github.com/couchbase/cbgt\" revision=\"10790963d9cbada17ebfff728ea9298c1c97b7c5\"/>",
 "  <project groups=\"notdefault,enterprise\" name=\"cbq-gui\" path=\"goproj/src/github.com/couchbase/cbq-gui\" remote=\"couchbase-priv\" revision=\"1e19e5e34b64ca6b43a37de6166dac6e76803848\"/>",
 "  <project name=\"clog\" path=\"godeps/src/github.com/couchbase/clog\" revision=\"eebc98233c3e032eb6b9036575d51324ab5932e6\"/>",
 "  <project name=\"context\" path=\"godeps/src/github.com/gorilla/context\" remote=\"couchbasedeps\" revision=\"215affda49addc4c8ef7e2534915df2c8c35c6cd\"/>",
 "  <project name=\"couchbase-cli\" revision=\"951668b6b2fcaa5386b31d59df5004ff667e91e8\"/>",
 "  <project name=\"couchbase-examples\" revision=\"39ee1c2451ac2f2e86a6ff308e21e1201c49cafe\"/>",
 "  <project name=\"couchdb\" revision=\"7b950cfaa3ad30c75a7fcc7f4eb30b2df1a8bd5b\"/>",
 "  <project groups=\"notdefault,packaging\" name=\"couchdbx-app\" revision=\"be5f6ebaa12ac7c0b5382deb9b1b0efa7bf80497\"/>",
 "  <project groups=\"kv\" name=\"couchstore\" revision=\"9cf71ba60cf95f8b835b1040c68c85a4ddc653ee\"/>",
 "  <project name=\"crypto\" path=\"godeps/src/golang.org/x/crypto\" remote=\"couchbasedeps\" revision=\"f23ba3a5ee43012fcb4b92e1a2a405a92554f4f2\"/>",
 "  <project name=\"cznic-b\" path=\"godeps/src/github.com/cznic/b\" remote=\"couchbasedeps\" revision=\"b96e30f1b7bd34b0b9d8760798d67eca83d7f09e\"/>",
 "  <project name=\"dparval\" path=\"godeps/src/github.com/couchbase/dparval\" revision=\"9def03782da875a2477c05bf64985db3f19f59ae\"/>",
 "  <project groups=\"kv\" name=\"ep-engine\" revision=\"e4c8bcbbf20b52b11e93665901597875e10b2070\"/>",
 "  <project groups=\"kv\" name=\"forestdb\" revision=\"1d169510a5102e81547b1d3dc423eb37db908076\"/>",
 "  <project name=\"geocouch\" revision=\"74b4bab07713b233ca2780f9a9a3f7daa1a1dff4\"/>",
 "  <project name=\"go-bindata-assetfs\" path=\"godeps/src/github.com/elazarl/go-bindata-assetfs\" remote=\"couchbasedeps\" revision=\"57eb5e1fc594ad4b0b1dbea7b286d299e0cb43c2\"/>",
 "  <project name=\"go-couchbase\" path=\"godeps/src/github.com/couchbase/go-couchbase\" revision=\"e06e5adaf45e189d4cf3e471341af0bf80bcc312\"/>",
 "  <project name=\"go-jsonpointer\" path=\"godeps/src/github.com/dustin/go-jsonpointer\" remote=\"couchbasedeps\" revision=\"75939f54b39e7dafae879e61f65438dadc5f288c\"/>",
 "  <project name=\"go-metrics\" path=\"godeps/src/github.com/rcrowley/go-metrics\" remote=\"couchbasedeps\" revision=\"dee209f2455f101a5e4e593dea94872d2c62d85d\"/>",
 "  <project name=\"go-porterstemmer\" path=\"godeps/src/github.com/blevesearch/go-porterstemmer\" remote=\"blevesearch\" revision=\"23a2c8e5cf1f380f27722c6d2ae8896431dc7d0e\"/>",
 "  <project name=\"go-slab\" path=\"godeps/src/github.com/couchbase/go-slab\" revision=\"1f5f7f282713ccfab3f46b1610cb8da34bcf676f\"/>",
 "  <project name=\"go-zookeeper\" path=\"godeps/src/github.com/samuel/go-zookeeper\" remote=\"couchbasedeps\" revision=\"fa6674abf3f4580b946a01bf7a1ce4ba8766205b\"/>",
 "  <project name=\"go_json\" path=\"godeps/src/github.com/couchbase/go_json\" revision=\"f5a178ab380eb9a1911cf9c45b4159115b564169\"/>",
 "  <project name=\"go_n1ql\" path=\"godeps/src/github.com/couchbase/go_n1ql\" revision=\"6cf4e348b127e21f56e53eb8c3faaea56afdc588\"/>",
 "  <project name=\"gocb\" path=\"godeps/src/github.com/couchbase/gocb\" revision=\"d5b1a13c1e81f1255ca8155007b470db37ddeb25\"/>",
 "  <project name=\"godbc\" path=\"godeps/src/github.com/couchbase/godbc\" revision=\"adc62033c392ca9df8b5b42c0dda237576b39f9f\"/>",
 "  <project name=\"goforestdb\" path=\"godeps/src/github.com/couchbase/goforestdb\" revision=\"0b501227de0e8c55d99ed14e900eea1a1dbaf899\"/>",
 "  <project name=\"gojson\" path=\"godeps/src/github.com/dustin/gojson\" remote=\"couchbasedeps\" revision=\"af16e0e771e2ed110f2785564ae33931de8829e4\"/>",
 "  <project name=\"golang-snappy\" path=\"godeps/src/github.com/golang/snappy\" remote=\"couchbasedeps\" revision=\"723cc1e459b8eea2dea4583200fd60757d40097a\"/>",
 "  <project name=\"goleveldb\" path=\"godeps/src/github.com/syndtr/goleveldb\" remote=\"couchbasedeps\" revision=\"fa5b5c78794bc5c18f330361059f871ae8c2b9d6\"/>",
 "  <project name=\"gomemcached\" path=\"godeps/src/github.com/couchbase/gomemcached\" revision=\"4604300463c4a379d36d1427b17d3284a93f7621\"/>",
 "  <project name=\"gometa\" path=\"goproj/src/github.com/couchbase/gometa\" revision=\"7da5634cce1de744293acf27bb2aecc13ee50cc5\"/>",
 "  <project groups=\"kv\" name=\"googletest\" remote=\"couchbasedeps\" revision=\"f397fa5ec6365329b2e82eb2d8c03a7897bbefb5\"/>",
 "  <project name=\"goskiplist\" path=\"godeps/src/github.com/ryszard/goskiplist\" remote=\"couchbasedeps\" revision=\"2dfbae5fcf46374f166f8969cb07e167f1be6273\"/>",
 "  <project name=\"gosnappy\" path=\"godeps/src/github.com/syndtr/gosnappy\" remote=\"couchbasedeps\" revision=\"156a073208e131d7d2e212cb749feae7c339e846\"/>",
 "  <project name=\"goutils\" path=\"godeps/src/github.com/couchbase/goutils\" revision=\"5823a0cbaaa9008406021dc5daf80125ea30bba6\"/>",
 "  <project name=\"goxdcr\" path=\"goproj/src/github.com/couchbase/goxdcr\" revision=\"0f66d74c38453d0c1a620588edb4ee6a8fc22577\"/>",
 "  <project name=\"gtreap\" path=\"godeps/src/github.com/steveyen/gtreap\" remote=\"couchbasedeps\" revision=\"0abe01ef9be25c4aedc174758ec2d917314d6d70\"/>",
 "  <project name=\"indexing\" path=\"goproj/src/github.com/couchbase/indexing\" revision=\"1811cdbff66216861320b7657590e961b10b2c0a\"/>",
 "  <project name=\"levigo\" path=\"godeps/src/github.com/jmhodges/levigo\" remote=\"couchbasedeps\" revision=\"1ddad808d437abb2b8a55a950ec2616caa88969b\"/>",
 "  <project name=\"liner\" path=\"godeps/src/github.com/peterh/liner\" remote=\"couchbasedeps\" revision=\"ad1edfd30321d8f006ccf05f1e0524adeb943060\"/>",
 "  <project name=\"liner\" path=\"godeps/src/github.com/sbinet/liner\" remote=\"couchbasedeps\" revision=\"d9335eee40a45a4f5d74524c90040d6fe6013d50\"/>",
 "  <project groups=\"kv\" name=\"memcached\" revision=\"45a464250e1358593fa9f11ec010ddd992f0a717\"/>",
 "  <project name=\"minify\" path=\"godeps/src/github.com/tdewolff/minify\" remote=\"couchbasedeps\" revision=\"ede45cc53f43891267b1fe7c689db9c76d4ce0fb\"/>",
 "  <project name=\"mmap-go\" path=\"godeps/src/github.com/edsrzf/mmap-go\" remote=\"couchbasedeps\" revision=\"935e0e8a636ca4ba70b713f3e38a19e1b77739e8\"/>",
 "  <project name=\"moss\" path=\"godeps/src/github.com/couchbase/moss\" revision=\"c7cc82a67cf3fe50faf9a0697516b885e4fa34b9\"/>",
 "  <project groups=\"kv\" name=\"moxi\" revision=\"363c250e6087a61bf2d4bc8d6eff3325956be731\"/>",
 "  <project name=\"mux\" path=\"godeps/src/github.com/gorilla/mux\" remote=\"couchbasedeps\" revision=\"8a875a034c69b940914d83ea03d3f1299b4d094b\"/>",
 "  <project name=\"net\" path=\"godeps/src/golang.org/x/net\" remote=\"couchbasedeps\" revision=\"8968c61983e8f51a91b8c0ef25bf739278c89634\"/>",
 "  <project name=\"npipe\" path=\"godeps/src/github.com/natefinch/npipe\" remote=\"couchbasedeps\" revision=\"272c8150302e83f23d32a355364578c9c13ab20f\"/>",
 "  <project name=\"ns_server\" revision=\"b6c99dc71308f44261bbcc80688de02942d69f19\"/>",
 "  <project name=\"parse\" path=\"godeps/src/github.com/tdewolff/parse\" remote=\"couchbasedeps\" revision=\"0334a869253aca4b3a10c56c3f3139b394aec3a9\"/>",
 "  <project groups=\"kv\" name=\"platform\" revision=\"a80097d53c779b548d8c78b0a1886b8d44591b23\"/>",
 "  <project name=\"protobuf\" path=\"godeps/src/github.com/golang/protobuf\" remote=\"couchbasedeps\" revision=\"655cdfa588ea190e901bc5590e65d5621688847c\"/>",
 "  <project name=\"query\" path=\"goproj/src/github.com/couchbase/query\" revision=\"2012f9b883199299df53dec638a2b91c21907a53\"/>",
 "  <project name=\"query-ui\" revision=\"ff1f502b2f0c544ca68d2bda60d80fc3a01d573a\"/>",
 "  <project name=\"retriever\" path=\"godeps/src/github.com/couchbase/retriever\" revision=\"e3419088e4d3b4fe3aad3b364fdbe9a154f85f17\"/>",
 "  <project name=\"segment\" path=\"godeps/src/github.com/blevesearch/segment\" remote=\"blevesearch\" revision=\"db70c57796cc8c310613541dfade3dce627d09c7\"/>",
 "  <project groups=\"kv\" name=\"sigar\" revision=\"83bd88595f558987731a1baa3330f641bc36554c\"/>",
 "  <project name=\"strconv\" path=\"godeps/src/github.com/tdewolff/strconv\" remote=\"couchbasedeps\" revision=\"9b189f5be77f33c46776f24dbddb2a7ab32af214\"/>",
 "  <project groups=\"kv\" name=\"subjson\" revision=\"65d3f053e2d968aea00b60234a42e1d1c5b9f6d2\"/>",
 "  <project groups=\"solaris,notdefault\" name=\"sys\" path=\"godeps/src/golang.org/x/sys\" remote=\"couchbasedeps\" revision=\"9d4e42a20653790449273b3c85e67d6d8bae6e2e\"/>",
 "  <project name=\"testrunner\" revision=\"d63ed33d4130ecac236711b4156d41328728e42e\"/>",
 "  <project name=\"text\" path=\"godeps/src/golang.org/x/text\" remote=\"couchbasedeps\" revision=\"601048ad6acbab6cedd582db09b8c4839ff25b15\"/>",
 "  <project groups=\"kv\" name=\"tlm\" revision=\"29fafd6b365e58e9fc43fad749ce20c900890a6b\">",
 "    <copyfile dest=\"GNUmakefile\" src=\"GNUmakefile\"/>",
 "    <copyfile dest=\"Makefile\" src=\"Makefile\"/>",
 "    <copyfile dest=\"CMakeLists.txt\" src=\"CMakeLists.txt\"/>",
 "  </project>",
 "  <project name=\"ts\" path=\"godeps/src/github.com/olekukonko/ts\" remote=\"couchbasedeps\" revision=\"ecf753e7c962639ab5a1fb46f7da627d4c0a04b8\"/>",
 "  <project groups=\"notdefault,packaging\" name=\"voltron\" remote=\"couchbase-priv\" revision=\"876e25cffb99e0ae89078a0443b179bcb5d639c2\"/>",
 "</manifest>"]

[error_logger:info,2021-04-19T20:01:45.979Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.129.0>},
                       {name,timeout_diag_logger},
                       {mfargs,{timeout_diag_logger,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T20:01:45.981Z,nonode@nohost:dist_manager<0.130.0>:dist_manager:read_address_config_from_path:86]Reading ip config from "/opt/couchbase/var/lib/couchbase/ip_start"
[ns_server:info,2021-04-19T20:01:45.982Z,nonode@nohost:dist_manager<0.130.0>:dist_manager:read_address_config_from_path:86]Reading ip config from "/opt/couchbase/var/lib/couchbase/ip"
[ns_server:info,2021-04-19T20:01:45.983Z,nonode@nohost:dist_manager<0.130.0>:dist_manager:init:163]ip config not found. Looks like we're brand new node
[error_logger:info,2021-04-19T20:01:45.983Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,inet_gethost_native_sup}
             started: [{pid,<0.132.0>},{mfa,{inet_gethost_native,init,[[]]}}]

[error_logger:info,2021-04-19T20:01:45.984Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.131.0>},
                       {name,inet_gethost_native_sup},
                       {mfargs,{inet_gethost_native,start_link,[]}},
                       {restart_type,temporary},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T20:01:46.771Z,nonode@nohost:dist_manager<0.130.0>:dist_manager:bringup:214]Attempting to bring up net_kernel with name 'ns_1@127.0.0.1'
[error_logger:info,2021-04-19T20:01:46.783Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.134.0>},
                       {name,erl_epmd},
                       {mfargs,{erl_epmd,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:46.783Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.135.0>},
                       {name,auth},
                       {mfargs,{auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:46.784Z,ns_1@127.0.0.1:dist_manager<0.130.0>:dist_manager:configure_net_kernel:255]Set net_kernel vebosity to 10 -> 0
[error_logger:info,2021-04-19T20:01:46.784Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.136.0>},
                       {name,net_kernel},
                       {mfargs,
                           {net_kernel,start_link,
                               [['ns_1@127.0.0.1',longnames]]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:46.784Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_sup}
             started: [{pid,<0.133.0>},
                       {name,net_sup_dynamic},
                       {mfargs,
                           {erl_distribution,start_link,
                               [['ns_1@127.0.0.1',longnames]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,supervisor}]

[ns_server:info,2021-04-19T20:01:46.787Z,ns_1@127.0.0.1:dist_manager<0.130.0>:dist_manager:save_node:147]saving node to "/opt/couchbase/var/lib/couchbase/couchbase-server.node"
[ns_server:debug,2021-04-19T20:01:46.815Z,ns_1@127.0.0.1:dist_manager<0.130.0>:dist_manager:bringup:228]Attempted to save node name to disk: ok
[ns_server:debug,2021-04-19T20:01:46.815Z,ns_1@127.0.0.1:dist_manager<0.130.0>:dist_manager:wait_for_node:235]Waiting for connection to node 'babysitter_of_ns_1@127.0.0.1' to be established
[error_logger:info,2021-04-19T20:01:46.815Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'babysitter_of_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T20:01:46.824Z,ns_1@127.0.0.1:dist_manager<0.130.0>:dist_manager:wait_for_node:244]Observed node 'babysitter_of_ns_1@127.0.0.1' to come up
[error_logger:info,2021-04-19T20:01:46.830Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.130.0>},
                       {name,dist_manager},
                       {mfargs,{dist_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:46.832Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.141.0>},
                       {name,ns_cookie_manager},
                       {mfargs,{ns_cookie_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:46.834Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.142.0>},
                       {name,ns_cluster},
                       {mfargs,{ns_cluster,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T20:01:46.836Z,ns_1@127.0.0.1:ns_config_sup<0.143.0>:ns_config_sup:init:32]loading static ns_config from "/opt/couchbase/etc/couchbase/config"
[error_logger:info,2021-04-19T20:01:46.836Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.144.0>},
                       {name,ns_config_events},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_config_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:46.836Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.145.0>},
                       {name,ns_config_events_local},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,ns_config_events_local}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:info,2021-04-19T20:01:46.892Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_config:load_config:1083]Loading static config from "/opt/couchbase/etc/couchbase/config"
[ns_server:info,2021-04-19T20:01:46.900Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_config:load_config:1097]Loading dynamic config from "/opt/couchbase/var/lib/couchbase/config/config.dat"
[ns_server:debug,2021-04-19T20:01:46.915Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_config:load_config:1105]Here's full dynamic config we loaded:
[[{{metakv,<<"/indexing/settings/config">>},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{6,63786081260}}]}|
    <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.log_level\":\"info\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\":200,\"indexer.settings.max_cpu_percent\":0,\"indexer.settings.storage_mode\":\"memory_optimized\",\"indexer.settings.recovery.max_rollbacks\":5,\"indexer.settings.memory_quota\":314572800,\"indexer.settings.compaction.abort_exceed_interval\":false}">>]},
  {alert_limits,
   [{max_overhead_perc,50},{max_disk_used,90},{max_indexer_ram,75}]},
  {audit,
   [{auditd_enabled,false},
    {rotate_interval,86400},
    {rotate_size,20971520},
    {disabled,[]},
    {sync,[]},
    {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]},
  {auto_failover_cfg,[{enabled,false},{timeout,120},{max_nodes,1},{count,0}]},
  {autocompaction,
   [{database_fragmentation_threshold,{30,undefined}},
    {view_fragmentation_threshold,{30,undefined}}]},
  {buckets,[{configs,[]}]},
  {cert_and_pkey,
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080746}}]}|
    {<<"-----BEGIN CERTIFICATE-----\nMIIDAjCCAeqgAwIBAgIIFndZ/+GzDYAwDQYJKoZIhvcNAQELBQAwJDEiMCAGA1UE\nAxMZQ291Y2hiYXNlIFNlcnZlciA4ODFmOWE4YzAeFw0xMzAxMDEwMDAwMDBaFw00\nOTEyMzEyMzU5NTlaMCQxIjAgBgNVBAMTGUNvdWNoYmFzZSBTZXJ2ZXIgODgxZjlh\nOGMwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCz0vvVTMTWH8JLsYfx\nMZ+egYFMFORYbynBjyuWB7+ltQbKZKtnruph7r3agBX8qzQLo1fbuaNJIkb2/TYZ\n7q61KM7aIxCPKBtKs0ms85z8gseSLb3P9dGXLcXHk3KrjUDOO4hh9KPVjY6773bq\nwCjUoqXNBTGySfNZ8Vj6WaDZ1fhxAo6perMdIBIS7TlqPICd7TGWW+Y1BoqljPEy\nYuaym5srhXBN6TvIiUzRGuEjmOnf7mYTj+zEstHhc3TRLgk7NF3vlpVjvVu7UAph\nMWvt5uXp+7tDC40YEzJM7tLU9sWHM46hkUHS95PR+moz9+7V0Su/Ifhb2z+O5eS4\n7HTVAgMBAAGjODA2MA4GA1UdDwEB/wQEAwICpDATBgNVHSUEDDAKBggrBgEFBQcD\nATAPBgNVHRMBAf8EBTADAQH/MA0GCSqGSIb3DQEBCwUAA4IBAQCBpPSeTxLjwYFj\nFuVzvFtSDibDDAXlI9/vqBmcMOJHTFU8M7eGdnL3Wt6GTRQ2m5fbxfz1ez8BvgR1\nUf5i36T9fkDVV5PvS5tjo5u0HGfjmZYpYgagh+Jf6dSzkMcxt/b0W0qeGgUuHxWR\na50a75WQZa0sxyLGKc1ogxykvpBjVETfZaT3JipmtqtyE2ddjddGX4q2mkdVKatI\nQQ8y9zftTlhxwICviP588S7FJ9u1njXVmxwaUSiB1iElOy57WBz+9exdWOhAn3TO\ncDtPcuVHD8GRd0IZ96Yk1mPMDWe99syzNNcpXPDtbgnjqobifQwBXIdA7OS+fDnc\nULaceJqi\n-----END CERTIFICATE-----\n">>,
     <<"*****">>}]},
  {cluster_compat_version,
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{6,63786080754}}]},
    4,6]},
  {drop_request_memory_threshold_mib,undefined},
  {email_alerts,
   [{recipients,["root@localhost"]},
    {sender,"couchbase@localhost"},
    {enabled,false},
    {email_server,
     [{user,[]},{pass,"*****"},{host,"localhost"},{port,25},{encrypt,false}]},
    {alerts,
     [auto_failover_node,auto_failover_maximum_reached,
      auto_failover_other_nodes_down,auto_failover_cluster_too_small,
      auto_failover_disabled,ip,disk,overhead,ep_oom_errors,
      ep_item_commit_failed,audit_dropped_events,indexer_ram_max_usage,
      ep_clock_cas_drift_threshold_exceeded]}]},
  {fts_memory_quota,512},
  {goxdcr_upgrade,
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080754}}]}|
    '_deleted']},
  {index_aware_rebalance_disabled,false},
  {max_bucket_count,10},
  {memcached,[]},
  {memory_quota,
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080759}}]}|
    300]},
  {nodes_wanted,['ns_1@127.0.0.1']},
  {otp,
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080753}}]},
    {cookie,{sanitized,<<"Gldz+3QHYFD9UMWZ6D/7VCdFO4es4rvk9HPUTz5soFw=">>}}]},
  {read_only_user_creds,
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080754}}]}|
    null]},
  {remote_clusters,[]},
  {replication,[{enabled,true}]},
  {rest,[{port,8091}]},
  {rest_creds,
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{2,63786080759}}]}|
    {"Administrator",{password,"*****"}}]},
  {roles_definitions,
   [{admin,[],
     [{name,<<"Admin">>},
      {desc,<<"Can manage ALL cluster features including security.">>}],
     [{[],all}]},
    {ro_admin,[],
     [{name,<<"Read Only Admin">>},
      {desc,<<"Can view ALL cluster features.">>}],
     [{[{bucket,any},password],none},
      {[{bucket,any},data],none},
      {[admin,security],[read]},
      {[admin],none},
      {[],[read]}]},
    {cluster_admin,[],
     [{name,<<"Cluster Admin">>},
      {desc,<<"Can manage all cluster features EXCEPT security.">>}],
     [{[admin],none},{[],all}]},
    {bucket_admin,
     [bucket_name],
     [{name,<<"Bucket Admin">>},
      {desc,
       <<"Can manage ALL bucket features for specified buckets (incl. start/stop XDCR)">>}],
     [{[{bucket,bucket_name},xdcr],[read,execute]},
      {[{bucket,bucket_name}],all},
      {[{bucket,any},settings],[read]},
      {[{bucket,any}],none},
      {[xdcr],none},
      {[admin],none},
      {[],[read]}]},
    {bucket_sasl,
     [bucket_name],
     [],
     [{[{bucket,bucket_name},data],all},
      {[{bucket,bucket_name},views],all},
      {[{bucket,bucket_name}],[read,flush]},
      {[pools],[read]}]},
    {views_admin,
     [bucket_name],
     [{name,<<"Views Admin">>},
      {desc,<<"Can manage views for specified buckets">>}],
     [{[{bucket,bucket_name},views],all},
      {[{bucket,bucket_name},data],[read]},
      {[{bucket,any},settings],[read]},
      {[{bucket,any}],none},
      {[xdcr],none},
      {[admin],none},
      {[],[read]}]},
    {replication_admin,[],
     [{name,<<"Replication Admin">>},
      {desc,<<"Can manage ONLY XDCR features (cluster AND bucket level)">>}],
     [{[{bucket,any},xdcr],all},
      {[{bucket,any},data],[read]},
      {[{bucket,any},settings],[read]},
      {[{bucket,any}],none},
      {[xdcr],all},
      {[admin],none},
      {[],[read]}]}]},
  {server_groups,
   [[{uuid,<<"0">>},{name,<<"Group 1">>},{nodes,['ns_1@127.0.0.1']}]]},
  {set_view_update_daemon,
   [{update_interval,5000},
    {update_min_changes,5000},
    {replica_update_min_changes,5000}]},
  {uuid,
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080759}}]}|
    <<"aaf7f03de532d2dc46a1e96329b1eb02">>]},
  {{couchdb,max_parallel_indexers},4},
  {{couchdb,max_parallel_replica_indexers},2},
  {{local_changes_count,<<"dbb8bee8b38705437e7f5ebc78107bfa">>},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{14,63786081260}}]}]},
  {{request_limit,capi},undefined},
  {{request_limit,rest},undefined},
  {{service_map,fts},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080754}}]}]},
  {{service_map,index},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{2,63786080764}}]},
    'ns_1@127.0.0.1']},
  {{service_map,n1ql},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{2,63786080764}}]},
    'ns_1@127.0.0.1']},
  {{node,'ns_1@127.0.0.1',audit},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}]},
  {{node,'ns_1@127.0.0.1',capi_port},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    8092]},
  {{node,'ns_1@127.0.0.1',compaction_daemon},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
    {check_interval,30},
    {min_db_file_size,131072},
    {min_view_file_size,20971520}]},
  {{node,'ns_1@127.0.0.1',config_version},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    {4,5}]},
  {{node,'ns_1@127.0.0.1',fts_http_port},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    8094]},
  {{node,'ns_1@127.0.0.1',indexer_admin_port},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    9100]},
  {{node,'ns_1@127.0.0.1',indexer_http_port},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    9102]},
  {{node,'ns_1@127.0.0.1',indexer_scan_port},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    9101]},
  {{node,'ns_1@127.0.0.1',indexer_stcatchup_port},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    9104]},
  {{node,'ns_1@127.0.0.1',indexer_stinit_port},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    9103]},
  {{node,'ns_1@127.0.0.1',indexer_stmaint_port},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    9105]},
  {{node,'ns_1@127.0.0.1',is_enterprise},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    true]},
  {{node,'ns_1@127.0.0.1',isasl},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
    {path,"/opt/couchbase/var/lib/couchbase/isasl.pw"}]},
  {{node,'ns_1@127.0.0.1',ldap_enabled},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    true]},
  {{node,'ns_1@127.0.0.1',membership},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    active]},
  {{node,'ns_1@127.0.0.1',memcached},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
    {port,11210},
    {dedicated_port,11209},
    {ssl_port,11207},
    {admin_user,"_admin"},
    {admin_pass,"*****"},
    {engines,
     [{membase,
       [{engine,"/opt/couchbase/lib/memcached/ep.so"},
        {static_config_string,"failpartialwarmup=false"}]},
      {memcached,
       [{engine,"/opt/couchbase/lib/memcached/default_engine.so"},
        {static_config_string,"vb0=true"}]}]},
    {config_path,"/opt/couchbase/var/lib/couchbase/config/memcached.json"},
    {audit_file,"/opt/couchbase/var/lib/couchbase/config/audit.json"},
    {log_path,"/opt/couchbase/var/lib/couchbase/logs"},
    {log_prefix,"memcached.log"},
    {log_generations,20},
    {log_cyclesize,10485760},
    {log_sleeptime,19},
    {log_rotation_period,39003}]},
  {{node,'ns_1@127.0.0.1',memcached_config},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    {[{interfaces,
       {memcached_config_mgr,omit_missing_mcd_ports,
        [{[{host,<<"*">>},{port,port},{maxconn,maxconn}]},
         {[{host,<<"*">>},
           {port,dedicated_port},
           {maxconn,dedicated_port_maxconn}]},
         {[{host,<<"*">>},
           {port,ssl_port},
           {maxconn,maxconn},
           {ssl,
            {[{key,
               <<"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem">>},
              {cert,
               <<"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem">>}]}}]}]}},
      {ssl_cipher_list,{"~s",[ssl_cipher_list]}},
      {ssl_minimum_protocol,{memcached_config_mgr,ssl_minimum_protocol,[]}},
      {connection_idle_time,connection_idle_time},
      {breakpad,
       {[{enabled,breakpad_enabled},
         {minidump_dir,{memcached_config_mgr,get_minidump_dir,[]}}]}},
      {extensions,
       [{[{module,<<"/opt/couchbase/lib/memcached/stdin_term_handler.so">>},
          {config,<<>>}]},
        {[{module,<<"/opt/couchbase/lib/memcached/file_logger.so">>},
          {config,
           {"cyclesize=~B;sleeptime=~B;filename=~s/~s",
            [log_cyclesize,log_sleeptime,log_path,log_prefix]}}]}]},
      {admin,{"~s",[admin_user]}},
      {verbosity,verbosity},
      {audit_file,{"~s",[audit_file]}},
      {dedupe_nmvb_maps,dedupe_nmvb_maps}]}]},
  {{node,'ns_1@127.0.0.1',memcached_defaults},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
    {maxconn,30000},
    {dedicated_port_maxconn,5000},
    {ssl_cipher_list,"HIGH"},
    {connection_idle_time,0},
    {verbosity,0},
    {breakpad_enabled,true},
    {breakpad_minidump_dir_path,"/opt/couchbase/var/lib/couchbase/crash"},
    {dedupe_nmvb_maps,false}]},
  {{node,'ns_1@127.0.0.1',moxi},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
    {port,11211},
    {verbosity,[]}]},
  {{node,'ns_1@127.0.0.1',ns_log},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
    {filename,"/opt/couchbase/var/lib/couchbase/ns_log"}]},
  {{node,'ns_1@127.0.0.1',port_servers},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}]},
  {{node,'ns_1@127.0.0.1',projector_port},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    9999]},
  {{node,'ns_1@127.0.0.1',query_port},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    8093]},
  {{node,'ns_1@127.0.0.1',rest},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
    {port,8091},
    {port_meta,global}]},
  {{node,'ns_1@127.0.0.1',services},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080759}}]},
    index,kv,n1ql]},
  {{node,'ns_1@127.0.0.1',ssl_capi_port},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    18092]},
  {{node,'ns_1@127.0.0.1',ssl_proxy_downstream_port},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    11214]},
  {{node,'ns_1@127.0.0.1',ssl_proxy_upstream_port},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    11215]},
  {{node,'ns_1@127.0.0.1',ssl_query_port},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    18093]},
  {{node,'ns_1@127.0.0.1',ssl_rest_port},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    18091]},
  {{node,'ns_1@127.0.0.1',stop_xdcr},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{2,63786080754}}]}|
    '_deleted']},
  {{node,'ns_1@127.0.0.1',uuid},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    <<"dbb8bee8b38705437e7f5ebc78107bfa">>]},
  {{node,'ns_1@127.0.0.1',xdcr_rest_port},
   [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
    9998]}]]
[ns_server:info,2021-04-19T20:01:46.924Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_config:load_config:1126]Here's full dynamic config we loaded + static & default config:
[{{node,'ns_1@127.0.0.1',xdcr_rest_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   9998]},
 {{node,'ns_1@127.0.0.1',uuid},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   <<"dbb8bee8b38705437e7f5ebc78107bfa">>]},
 {{node,'ns_1@127.0.0.1',stop_xdcr},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{2,63786080754}}]}|
   '_deleted']},
 {{node,'ns_1@127.0.0.1',ssl_rest_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   18091]},
 {{node,'ns_1@127.0.0.1',ssl_query_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   18093]},
 {{node,'ns_1@127.0.0.1',ssl_proxy_upstream_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   11215]},
 {{node,'ns_1@127.0.0.1',ssl_proxy_downstream_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   11214]},
 {{node,'ns_1@127.0.0.1',ssl_capi_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   18092]},
 {{node,'ns_1@127.0.0.1',services},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080759}}]},
   index,kv,n1ql]},
 {{node,'ns_1@127.0.0.1',rest},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
   {port,8091},
   {port_meta,global}]},
 {{node,'ns_1@127.0.0.1',query_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   8093]},
 {{node,'ns_1@127.0.0.1',projector_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   9999]},
 {{node,'ns_1@127.0.0.1',port_servers},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}]},
 {{node,'ns_1@127.0.0.1',ns_log},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
   {filename,"/opt/couchbase/var/lib/couchbase/ns_log"}]},
 {{node,'ns_1@127.0.0.1',moxi},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
   {port,11211},
   {verbosity,[]}]},
 {{node,'ns_1@127.0.0.1',memcached_defaults},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
   {maxconn,30000},
   {dedicated_port_maxconn,5000},
   {ssl_cipher_list,"HIGH"},
   {connection_idle_time,0},
   {verbosity,0},
   {breakpad_enabled,true},
   {breakpad_minidump_dir_path,"/opt/couchbase/var/lib/couchbase/crash"},
   {dedupe_nmvb_maps,false}]},
 {{node,'ns_1@127.0.0.1',memcached_config},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   {[{interfaces,
      {memcached_config_mgr,omit_missing_mcd_ports,
       [{[{host,<<"*">>},{port,port},{maxconn,maxconn}]},
        {[{host,<<"*">>},
          {port,dedicated_port},
          {maxconn,dedicated_port_maxconn}]},
        {[{host,<<"*">>},
          {port,ssl_port},
          {maxconn,maxconn},
          {ssl,
           {[{key,
              <<"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem">>},
             {cert,
              <<"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem">>}]}}]}]}},
     {ssl_cipher_list,{"~s",[ssl_cipher_list]}},
     {ssl_minimum_protocol,{memcached_config_mgr,ssl_minimum_protocol,[]}},
     {connection_idle_time,connection_idle_time},
     {breakpad,
      {[{enabled,breakpad_enabled},
        {minidump_dir,{memcached_config_mgr,get_minidump_dir,[]}}]}},
     {extensions,
      [{[{module,<<"/opt/couchbase/lib/memcached/stdin_term_handler.so">>},
         {config,<<>>}]},
       {[{module,<<"/opt/couchbase/lib/memcached/file_logger.so">>},
         {config,
          {"cyclesize=~B;sleeptime=~B;filename=~s/~s",
           [log_cyclesize,log_sleeptime,log_path,log_prefix]}}]}]},
     {admin,{"~s",[admin_user]}},
     {verbosity,verbosity},
     {audit_file,{"~s",[audit_file]}},
     {dedupe_nmvb_maps,dedupe_nmvb_maps}]}]},
 {{node,'ns_1@127.0.0.1',memcached},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
   {port,11210},
   {dedicated_port,11209},
   {ssl_port,11207},
   {admin_user,"_admin"},
   {admin_pass,"*****"},
   {engines,
    [{membase,
      [{engine,"/opt/couchbase/lib/memcached/ep.so"},
       {static_config_string,"failpartialwarmup=false"}]},
     {memcached,
      [{engine,"/opt/couchbase/lib/memcached/default_engine.so"},
       {static_config_string,"vb0=true"}]}]},
   {config_path,"/opt/couchbase/var/lib/couchbase/config/memcached.json"},
   {audit_file,"/opt/couchbase/var/lib/couchbase/config/audit.json"},
   {log_path,"/opt/couchbase/var/lib/couchbase/logs"},
   {log_prefix,"memcached.log"},
   {log_generations,20},
   {log_cyclesize,10485760},
   {log_sleeptime,19},
   {log_rotation_period,39003}]},
 {{node,'ns_1@127.0.0.1',membership},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   active]},
 {{node,'ns_1@127.0.0.1',ldap_enabled},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   true]},
 {{node,'ns_1@127.0.0.1',isasl},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
   {path,"/opt/couchbase/var/lib/couchbase/isasl.pw"}]},
 {{node,'ns_1@127.0.0.1',is_enterprise},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   true]},
 {{node,'ns_1@127.0.0.1',indexer_stmaint_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   9105]},
 {{node,'ns_1@127.0.0.1',indexer_stinit_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   9103]},
 {{node,'ns_1@127.0.0.1',indexer_stcatchup_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   9104]},
 {{node,'ns_1@127.0.0.1',indexer_scan_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   9101]},
 {{node,'ns_1@127.0.0.1',indexer_http_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   9102]},
 {{node,'ns_1@127.0.0.1',indexer_admin_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   9100]},
 {{node,'ns_1@127.0.0.1',fts_http_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   8094]},
 {{node,'ns_1@127.0.0.1',config_version},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   {4,5}]},
 {{node,'ns_1@127.0.0.1',compaction_daemon},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
   {check_interval,30},
   {min_db_file_size,131072},
   {min_view_file_size,20971520}]},
 {{node,'ns_1@127.0.0.1',capi_port},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
   8092]},
 {{node,'ns_1@127.0.0.1',audit},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}]},
 {{service_map,n1ql},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{2,63786080764}}]},
   'ns_1@127.0.0.1']},
 {{service_map,index},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{2,63786080764}}]},
   'ns_1@127.0.0.1']},
 {{service_map,fts},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080754}}]}]},
 {{request_limit,rest},undefined},
 {{request_limit,capi},undefined},
 {{local_changes_count,<<"dbb8bee8b38705437e7f5ebc78107bfa">>},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{14,63786081260}}]}]},
 {{couchdb,max_parallel_replica_indexers},2},
 {{couchdb,max_parallel_indexers},4},
 {uuid,
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080759}}]}|
   <<"aaf7f03de532d2dc46a1e96329b1eb02">>]},
 {set_view_update_daemon,
  [{update_interval,5000},
   {update_min_changes,5000},
   {replica_update_min_changes,5000}]},
 {server_groups,
  [[{uuid,<<"0">>},{name,<<"Group 1">>},{nodes,['ns_1@127.0.0.1']}]]},
 {roles_definitions,
  [{admin,[],
    [{name,<<"Admin">>},
     {desc,<<"Can manage ALL cluster features including security.">>}],
    [{[],all}]},
   {ro_admin,[],
    [{name,<<"Read Only Admin">>},{desc,<<"Can view ALL cluster features.">>}],
    [{[{bucket,any},password],none},
     {[{bucket,any},data],none},
     {[admin,security],[read]},
     {[admin],none},
     {[],[read]}]},
   {cluster_admin,[],
    [{name,<<"Cluster Admin">>},
     {desc,<<"Can manage all cluster features EXCEPT security.">>}],
    [{[admin],none},{[],all}]},
   {bucket_admin,
    [bucket_name],
    [{name,<<"Bucket Admin">>},
     {desc,
      <<"Can manage ALL bucket features for specified buckets (incl. start/stop XDCR)">>}],
    [{[{bucket,bucket_name},xdcr],[read,execute]},
     {[{bucket,bucket_name}],all},
     {[{bucket,any},settings],[read]},
     {[{bucket,any}],none},
     {[xdcr],none},
     {[admin],none},
     {[],[read]}]},
   {bucket_sasl,
    [bucket_name],
    [],
    [{[{bucket,bucket_name},data],all},
     {[{bucket,bucket_name},views],all},
     {[{bucket,bucket_name}],[read,flush]},
     {[pools],[read]}]},
   {views_admin,
    [bucket_name],
    [{name,<<"Views Admin">>},
     {desc,<<"Can manage views for specified buckets">>}],
    [{[{bucket,bucket_name},views],all},
     {[{bucket,bucket_name},data],[read]},
     {[{bucket,any},settings],[read]},
     {[{bucket,any}],none},
     {[xdcr],none},
     {[admin],none},
     {[],[read]}]},
   {replication_admin,[],
    [{name,<<"Replication Admin">>},
     {desc,<<"Can manage ONLY XDCR features (cluster AND bucket level)">>}],
    [{[{bucket,any},xdcr],all},
     {[{bucket,any},data],[read]},
     {[{bucket,any},settings],[read]},
     {[{bucket,any}],none},
     {[xdcr],all},
     {[admin],none},
     {[],[read]}]}]},
 {rest_creds,
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{2,63786080759}}]}|
   {"Administrator",{password,"*****"}}]},
 {rest,[{port,8091}]},
 {replication,[{enabled,true}]},
 {remote_clusters,[]},
 {read_only_user_creds,
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080754}}]}|
   null]},
 {otp,
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080753}}]},
   {cookie,{sanitized,<<"Gldz+3QHYFD9UMWZ6D/7VCdFO4es4rvk9HPUTz5soFw=">>}}]},
 {nodes_wanted,['ns_1@127.0.0.1']},
 {memory_quota,
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080759}}]}|
   300]},
 {memcached,[]},
 {max_bucket_count,10},
 {index_aware_rebalance_disabled,false},
 {goxdcr_upgrade,
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080754}}]}|
   '_deleted']},
 {fts_memory_quota,512},
 {email_alerts,
  [{recipients,["root@localhost"]},
   {sender,"couchbase@localhost"},
   {enabled,false},
   {email_server,
    [{user,[]},{pass,"*****"},{host,"localhost"},{port,25},{encrypt,false}]},
   {alerts,
    [auto_failover_node,auto_failover_maximum_reached,
     auto_failover_other_nodes_down,auto_failover_cluster_too_small,
     auto_failover_disabled,ip,disk,overhead,ep_oom_errors,
     ep_item_commit_failed,audit_dropped_events,indexer_ram_max_usage,
     ep_clock_cas_drift_threshold_exceeded]}]},
 {drop_request_memory_threshold_mib,undefined},
 {cluster_compat_version,
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{6,63786080754}}]},
   4,6]},
 {cert_and_pkey,
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080746}}]}|
   {<<"-----BEGIN CERTIFICATE-----\nMIIDAjCCAeqgAwIBAgIIFndZ/+GzDYAwDQYJKoZIhvcNAQELBQAwJDEiMCAGA1UE\nAxMZQ291Y2hiYXNlIFNlcnZlciA4ODFmOWE4YzAeFw0xMzAxMDEwMDAwMDBaFw00\nOTEyMzEyMzU5NTlaMCQxIjAgBgNVBAMTGUNvdWNoYmFzZSBTZXJ2ZXIgODgxZjlh\nOGMwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCz0vvVTMTWH8JLsYfx\nMZ+egYFMFORYbynBjyuWB7+ltQbKZKtnruph7r3agBX8qzQLo1fbuaNJIkb2/TYZ\n7q61KM7aIxCPKBtKs0ms85z8gseSLb3P9dGXLcXHk3KrjUDOO4hh9KPVjY6773bq\nwCjUoqXNBTGySfNZ8Vj6WaDZ1fhxAo6perMdIBIS7TlqPICd7TGWW+Y1BoqljPEy\nYuaym5srhXBN6TvIiUzRGuEjmOnf7mYTj+zEstHhc3TRLgk7NF3vlpVjvVu7UAph\nMWvt5uXp+7tDC40YEzJM7tLU9sWHM46hkUHS95PR+moz9+7V0Su/Ifhb2z+O5eS4\n7HTVAgMBAAGjODA2MA4GA1UdDwEB/wQEAwICpDATBgNVHSUEDDAKBggrBgEFBQcD\nATAPBgNVHRMBAf8EBTADAQH/MA0GCSqGSIb3DQEBCwUAA4IBAQCBpPSeTxLjwYFj\nFuVzvFtSDibDDAXlI9/vqBmcMOJHTFU8M7eGdnL3Wt6GTRQ2m5fbxfz1ez8BvgR1\nUf5i36T9fkDVV5PvS5tjo5u0HGfjmZYpYgagh+Jf6dSzkMcxt/b0W0qeGgUuHxWR\na50a75WQZa0sxyLGKc1ogxykvpBjVETfZaT3JipmtqtyE2ddjddGX4q2mkdVKatI\nQQ8y9zftTlhxwICviP588S7FJ9u1njXVmxwaUSiB1iElOy57WBz+9exdWOhAn3TO\ncDtPcuVHD8GRd0IZ96Yk1mPMDWe99syzNNcpXPDtbgnjqobifQwBXIdA7OS+fDnc\nULaceJqi\n-----END CERTIFICATE-----\n">>,
    <<"*****">>}]},
 {buckets,[{configs,[]}]},
 {autocompaction,
  [{database_fragmentation_threshold,{30,undefined}},
   {view_fragmentation_threshold,{30,undefined}}]},
 {auto_failover_cfg,[{enabled,false},{timeout,120},{max_nodes,1},{count,0}]},
 {audit,
  [{auditd_enabled,false},
   {rotate_interval,86400},
   {rotate_size,20971520},
   {disabled,[]},
   {sync,[]},
   {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]},
 {alert_limits,
  [{max_overhead_perc,50},{max_disk_used,90},{max_indexer_ram,75}]},
 {{metakv,<<"/indexing/settings/config">>},
  [{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{6,63786081260}}]}|
   <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.log_level\":\"info\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\":200,\"indexer.settings.max_cpu_percent\":0,\"indexer.settings.storage_mode\":\"memory_optimized\",\"indexer.settings.recovery.max_rollbacks\":5,\"indexer.settings.memory_quota\":314572800,\"indexer.settings.compaction.abort_exceed_interval\":false}">>]}]
[error_logger:info,2021-04-19T20:01:46.927Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.146.0>},
                       {name,ns_config},
                       {mfargs,
                           {ns_config,start_link,
                               ["/opt/couchbase/etc/couchbase/config",
                                ns_config_default]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:46.930Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.149.0>},
                       {name,ns_config_remote},
                       {mfargs,
                           {ns_config_replica,start_link,
                               [{local,ns_config_remote}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:46.934Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.150.0>},
                       {name,ns_config_log},
                       {mfargs,{ns_config_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:46.934Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.143.0>},
                       {name,ns_config_sup},
                       {mfargs,{ns_config_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T20:01:46.936Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.152.0>},
                       {name,vbucket_filter_changes_registry},
                       {mfargs,
                           {ns_process_registry,start_link,
                               [vbucket_filter_changes_registry,
                                [{terminate_command,shutdown}]]}},
                       {restart_type,permanent},
                       {shutdown,100},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:46.939Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.153.0>},
                       {name,json_rpc_connection_sup},
                       {mfargs,{json_rpc_connection_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T20:01:46.953Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.156.0>},
                       {name,remote_monitors},
                       {mfargs,{remote_monitors,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:46.956Z,ns_1@127.0.0.1:menelaus_barrier<0.157.0>:one_shot_barrier:barrier_body:58]Barrier menelaus_barrier has started
[error_logger:info,2021-04-19T20:01:46.956Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.157.0>},
                       {name,menelaus_barrier},
                       {mfargs,{menelaus_sup,barrier_start_link,[]}},
                       {restart_type,temporary},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:46.956Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.158.0>},
                       {name,rest_lhttpc_pool},
                       {mfargs,
                           {lhttpc_manager,start_link,
                               [[{name,rest_lhttpc_pool},
                                 {connection_timeout,120000},
                                 {pool_size,20}]]}},
                       {restart_type,{permanent,1}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T20:01:46.988Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.160.0>:ns_ssl_services_setup:init:370]Used ssl options:
[{keyfile,"/opt/couchbase/var/lib/couchbase/config/ssl-cert-key.pem"},
 {certfile,"/opt/couchbase/var/lib/couchbase/config/ssl-cert-key.pem"},
 {versions,[tlsv1,'tlsv1.1','tlsv1.2']},
 {cacertfile,"/opt/couchbase/var/lib/couchbase/config/ssl-cert-key.pem-ca"},
 {dh,<<48,130,1,8,2,130,1,1,0,152,202,99,248,92,201,35,238,246,5,77,93,120,10,
       118,129,36,52,111,193,167,220,49,229,106,105,152,133,121,157,73,158,
       232,153,197,197,21,171,140,30,207,52,165,45,8,221,162,21,199,183,66,
       211,247,51,224,102,214,190,130,96,253,218,193,35,43,139,145,89,200,250,
       145,92,50,80,134,135,188,205,254,148,122,136,237,220,186,147,187,104,
       159,36,147,217,117,74,35,163,145,249,175,242,18,221,124,54,140,16,246,
       169,84,252,45,47,99,136,30,60,189,203,61,86,225,117,255,4,91,46,110,
       167,173,106,51,65,10,248,94,225,223,73,40,232,140,26,11,67,170,118,190,
       67,31,127,233,39,68,88,132,171,224,62,187,207,160,189,209,101,74,8,205,
       174,146,173,80,105,144,246,25,153,86,36,24,178,163,64,202,221,95,184,
       110,244,32,226,217,34,55,188,230,55,16,216,247,173,246,139,76,187,66,
       211,159,17,46,20,18,48,80,27,250,96,189,29,214,234,241,34,69,254,147,
       103,220,133,40,164,84,8,44,241,61,164,151,9,135,41,60,75,4,202,133,173,
       72,6,69,167,89,112,174,40,229,171,2,1,2>>},
 {ciphers,[{dhe_rsa,aes_256_cbc,sha256},
           {dhe_dss,aes_256_cbc,sha256},
           {rsa,aes_256_cbc,sha256},
           {dhe_rsa,aes_128_cbc,sha256},
           {dhe_dss,aes_128_cbc,sha256},
           {rsa,aes_128_cbc,sha256},
           {dhe_rsa,aes_256_cbc,sha},
           {dhe_dss,aes_256_cbc,sha},
           {rsa,aes_256_cbc,sha},
           {dhe_rsa,'3des_ede_cbc',sha},
           {dhe_dss,'3des_ede_cbc',sha},
           {rsa,'3des_ede_cbc',sha},
           {dhe_rsa,aes_128_cbc,sha},
           {dhe_dss,aes_128_cbc,sha},
           {rsa,aes_128_cbc,sha}]}]
[error_logger:info,2021-04-19T20:01:47.080Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_ssl_services_sup}
             started: [{pid,<0.160.0>},
                       {name,ns_ssl_services_setup},
                       {mfargs,{ns_ssl_services_setup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T20:01:47.120Z,ns_1@127.0.0.1:<0.162.0>:menelaus_pluggable_ui:validate_plugin_spec:117]Loaded pluggable UI specification for fts

[ns_server:info,2021-04-19T20:01:47.121Z,ns_1@127.0.0.1:<0.162.0>:menelaus_pluggable_ui:validate_plugin_spec:117]Loaded pluggable UI specification for n1ql

[ns_server:debug,2021-04-19T20:01:47.147Z,ns_1@127.0.0.1:<0.162.0>:restartable:start_child:98]Started child process <0.164.0>
  MFA: {ns_ssl_services_setup,start_link_rest_service,[]}
[error_logger:info,2021-04-19T20:01:47.148Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_ssl_services_sup}
             started: [{pid,<0.162.0>},
                       {name,ns_rest_ssl_service},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_ssl_services_setup,
                                    start_link_rest_service,[]},
                                1000]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:47.148Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.159.0>},
                       {name,ns_ssl_services_sup},
                       {mfargs,{ns_ssl_services_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T20:01:47.162Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.181.0>},
                       {name,start_couchdb_node},
                       {mfargs,{ns_server_nodes_sup,start_couchdb_node,[]}},
                       {restart_type,{permanent,5}},
                       {shutdown,86400000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:47.162Z,ns_1@127.0.0.1:wait_link_to_couchdb_node<0.182.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:126]Waiting for ns_couchdb node to start
[error_logger:info,2021-04-19T20:01:47.162Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T20:01:47.163Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T20:01:47.163Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.185.0>,shutdown}}
[error_logger:info,2021-04-19T20:01:47.163Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T20:01:47.364Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T20:01:47.365Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T20:01:47.365Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.188.0>,shutdown}}
[error_logger:info,2021-04-19T20:01:47.365Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T20:01:47.566Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T20:01:47.567Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T20:01:47.567Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.191.0>,shutdown}}
[error_logger:info,2021-04-19T20:01:47.567Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T20:01:47.768Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T20:01:47.769Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.194.0>,shutdown}}
[error_logger:info,2021-04-19T20:01:47.769Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T20:01:47.769Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T20:01:47.970Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T20:01:47.971Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T20:01:47.971Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.197.0>,shutdown}}
[error_logger:info,2021-04-19T20:01:47.971Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T20:01:48.172Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T20:01:48.173Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.200.0>,shutdown}}
[ns_server:debug,2021-04-19T20:01:48.173Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T20:01:48.173Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T20:01:48.374Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T20:01:48.375Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T20:01:48.375Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.203.0>,shutdown}}
[error_logger:info,2021-04-19T20:01:48.375Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T20:01:48.576Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T20:01:48.577Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.206.0>,shutdown}}
[ns_server:debug,2021-04-19T20:01:48.577Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T20:01:48.577Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T20:01:48.778Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T20:01:48.779Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.209.0>,shutdown}}
[error_logger:info,2021-04-19T20:01:48.779Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T20:01:48.780Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T20:01:48.981Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T20:01:48.982Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.212.0>,shutdown}}
[ns_server:debug,2021-04-19T20:01:48.982Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T20:01:48.982Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T20:01:49.183Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T20:01:49.184Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T20:01:49.184Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.215.0>,shutdown}}
[error_logger:info,2021-04-19T20:01:49.184Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T20:01:49.385Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T20:01:49.385Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T20:01:49.385Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.218.0>,shutdown}}
[error_logger:info,2021-04-19T20:01:49.386Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T20:01:49.587Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T20:01:49.587Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.221.0>,shutdown}}
[ns_server:debug,2021-04-19T20:01:49.587Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T20:01:49.587Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T20:01:49.788Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T20:01:49.789Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T20:01:49.789Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.224.0>,shutdown}}
[error_logger:info,2021-04-19T20:01:49.789Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T20:01:49.990Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T20:01:50.092Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T20:01:50.293Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T20:01:50.496Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T20:01:50.716Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T20:01:50.917Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T20:01:51.120Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T20:01:51.328Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T20:01:51.529Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T20:01:51.730Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T20:01:51.931Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T20:01:52.138Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T20:01:52.341Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T20:01:52.542Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T20:01:52.743Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T20:01:52.948Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[error_logger:info,2021-04-19T20:01:53.495Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.244.0>},
                       {name,timer2_server},
                       {mfargs,{timer2,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T20:01:53.695Z,ns_1@127.0.0.1:ns_couchdb_port<0.181.0>:ns_port_server:log:210]ns_couchdb<0.181.0>: Apache CouchDB  (LogLevel=info) is starting.

[error_logger:info,2021-04-19T20:01:54.067Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.182.0>},
                       {name,wait_for_couchdb_node},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<ns_server_nodes_sup.0.8580514>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:54.079Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.155.0>:ns_storage_conf:setup_db_and_ix_paths:53]Initialize db_and_ix_paths variable with [{db_path,
                                           "/opt/couchbase/var/lib/couchbase/data"},
                                          {index_path,
                                           "/opt/couchbase/var/lib/couchbase/data"}]
[error_logger:info,2021-04-19T20:01:54.095Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.247.0>},
                       {name,ns_disksup},
                       {mfargs,{ns_disksup,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T20:01:54.099Z,ns_1@127.0.0.1:ns_couchdb_port<0.181.0>:ns_port_server:log:210]ns_couchdb<0.181.0>: Apache CouchDB has started. Time to relax.
ns_couchdb<0.181.0>: 137: Booted. Waiting for shutdown request

[error_logger:info,2021-04-19T20:01:54.101Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.248.0>},
                       {name,diag_handler_worker},
                       {mfargs,{work_queue,start_link,[diag_handler_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T20:01:54.105Z,ns_1@127.0.0.1:ns_server_sup<0.246.0>:dir_size:start_link:39]Starting quick version of dir_size with program name: godu
[error_logger:info,2021-04-19T20:01:54.106Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.249.0>},
                       {name,dir_size},
                       {mfargs,{dir_size,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:54.118Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.250.0>},
                       {name,request_throttler},
                       {mfargs,{request_throttler,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:54.143Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.251.0>},
                       {name,ns_log},
                       {mfargs,{ns_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:54.144Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.252.0>},
                       {name,ns_crash_log_consumer},
                       {mfargs,{ns_log,start_link_crash_consumer,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:54.152Z,ns_1@127.0.0.1:ns_config_isasl_sync<0.253.0>:ns_config_isasl_sync:init:65]isasl_sync init: ["/opt/couchbase/var/lib/couchbase/isasl.pw","_admin"]
[ns_server:debug,2021-04-19T20:01:54.153Z,ns_1@127.0.0.1:ns_config_isasl_sync<0.253.0>:ns_config_isasl_sync:init:73]isasl_sync init buckets: []
[ns_server:debug,2021-04-19T20:01:54.175Z,ns_1@127.0.0.1:ns_config_isasl_sync<0.253.0>:ns_config_isasl_sync:writeSASLConf:145]Writing isasl passwd file: "/opt/couchbase/var/lib/couchbase/isasl.pw"
[ns_server:warn,2021-04-19T20:01:54.203Z,ns_1@127.0.0.1:ns_config_isasl_sync<0.253.0>:ns_memcached:connect:1307]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[error_logger:info,2021-04-19T20:01:55.206Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.253.0>},
                       {name,ns_config_isasl_sync},
                       {mfargs,{ns_config_isasl_sync,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.206Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.255.0>},
                       {name,ns_log_events},
                       {mfargs,{gen_event,start_link,[{local,ns_log_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.210Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.257.0>},
                       {name,ns_node_disco_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,ns_node_disco_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:55.210Z,ns_1@127.0.0.1:ns_node_disco<0.258.0>:ns_node_disco:init:138]Initting ns_node_disco with []
[ns_server:debug,2021-04-19T20:01:55.210Z,ns_1@127.0.0.1:ns_cookie_manager<0.141.0>:ns_cookie_manager:do_cookie_sync:115]ns_cookie_manager do_cookie_sync
[user:info,2021-04-19T20:01:55.210Z,ns_1@127.0.0.1:ns_cookie_manager<0.141.0>:ns_cookie_manager:do_cookie_sync:134]Node 'ns_1@127.0.0.1' synchronized otp cookie {sanitized,
                                               <<"Gldz+3QHYFD9UMWZ6D/7VCdFO4es4rvk9HPUTz5soFw=">>} from cluster
[ns_server:debug,2021-04-19T20:01:55.210Z,ns_1@127.0.0.1:<0.259.0>:ns_node_disco:do_nodes_wanted_updated_fun:224]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"Gldz+3QHYFD9UMWZ6D/7VCdFO4es4rvk9HPUTz5soFw=">>}
[ns_server:debug,2021-04-19T20:01:55.213Z,ns_1@127.0.0.1:<0.259.0>:ns_node_disco:do_nodes_wanted_updated_fun:230]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"Gldz+3QHYFD9UMWZ6D/7VCdFO4es4rvk9HPUTz5soFw=">>}
[error_logger:info,2021-04-19T20:01:55.214Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.258.0>},
                       {name,ns_node_disco},
                       {mfargs,{ns_node_disco,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.217Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.260.0>},
                       {name,ns_node_disco_log},
                       {mfargs,{ns_node_disco_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.221Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.261.0>},
                       {name,ns_node_disco_conf_events},
                       {mfargs,{ns_node_disco_conf_events,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.226Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.262.0>},
                       {name,ns_config_rep_merger},
                       {mfargs,{ns_config_rep,start_link_merger,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:55.226Z,ns_1@127.0.0.1:ns_config_rep<0.263.0>:ns_config_rep:init:68]init pulling
[ns_server:debug,2021-04-19T20:01:55.226Z,ns_1@127.0.0.1:ns_config_rep<0.263.0>:ns_config_rep:init:70]init pushing
[ns_server:debug,2021-04-19T20:01:55.228Z,ns_1@127.0.0.1:ns_config_rep<0.263.0>:ns_config_rep:init:74]init reannouncing
[ns_server:debug,2021-04-19T20:01:55.229Z,ns_1@127.0.0.1:ns_config_events<0.144.0>:ns_node_disco_conf_events:handle_event:44]ns_node_disco_conf_events config on nodes_wanted
[ns_server:debug,2021-04-19T20:01:55.230Z,ns_1@127.0.0.1:ns_config_events<0.144.0>:ns_node_disco_conf_events:handle_event:50]ns_node_disco_conf_events config on otp
[ns_server:debug,2021-04-19T20:01:55.230Z,ns_1@127.0.0.1:ns_cookie_manager<0.141.0>:ns_cookie_manager:do_cookie_sync:115]ns_cookie_manager do_cookie_sync
[ns_server:debug,2021-04-19T20:01:55.230Z,ns_1@127.0.0.1:ns_cookie_manager<0.141.0>:ns_cookie_manager:do_cookie_sync:115]ns_cookie_manager do_cookie_sync
[ns_server:debug,2021-04-19T20:01:55.230Z,ns_1@127.0.0.1:<0.267.0>:ns_node_disco:do_nodes_wanted_updated_fun:224]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"Gldz+3QHYFD9UMWZ6D/7VCdFO4es4rvk9HPUTz5soFw=">>}
[ns_server:debug,2021-04-19T20:01:55.230Z,ns_1@127.0.0.1:<0.268.0>:ns_node_disco:do_nodes_wanted_updated_fun:224]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"Gldz+3QHYFD9UMWZ6D/7VCdFO4es4rvk9HPUTz5soFw=">>}
[ns_server:debug,2021-04-19T20:01:55.230Z,ns_1@127.0.0.1:<0.267.0>:ns_node_disco:do_nodes_wanted_updated_fun:230]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"Gldz+3QHYFD9UMWZ6D/7VCdFO4es4rvk9HPUTz5soFw=">>}
[ns_server:debug,2021-04-19T20:01:55.230Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
alert_limits ->
[{max_overhead_perc,50},{max_disk_used,90},{max_indexer_ram,75}]
[ns_server:debug,2021-04-19T20:01:55.230Z,ns_1@127.0.0.1:<0.268.0>:ns_node_disco:do_nodes_wanted_updated_fun:230]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"Gldz+3QHYFD9UMWZ6D/7VCdFO4es4rvk9HPUTz5soFw=">>}
[ns_server:debug,2021-04-19T20:01:55.230Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
audit ->
[{auditd_enabled,false},
 {rotate_interval,86400},
 {rotate_size,20971520},
 {disabled,[]},
 {sync,[]},
 {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]
[ns_server:debug,2021-04-19T20:01:55.231Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
auto_failover_cfg ->
[{enabled,false},{timeout,120},{max_nodes,1},{count,0}]
[ns_server:debug,2021-04-19T20:01:55.231Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
autocompaction ->
[{database_fragmentation_threshold,{30,undefined}},
 {view_fragmentation_threshold,{30,undefined}}]
[ns_server:debug,2021-04-19T20:01:55.231Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
buckets ->
[[],{configs,[]}]
[ns_server:debug,2021-04-19T20:01:55.231Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
cert_and_pkey ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080746}}]}|
 {<<"-----BEGIN CERTIFICATE-----\nMIIDAjCCAeqgAwIBAgIIFndZ/+GzDYAwDQYJKoZIhvcNAQELBQAwJDEiMCAGA1UE\nAxMZQ291Y2hiYXNlIFNlcnZlciA4ODFmOWE4YzAeFw0xMzAxMDEwMDAwMDBaFw00\nOTEyMzEyMzU5NTlaMCQxIjAgBgNVBAMTGUNvdWNoYmFzZSBTZXJ2ZXIgODgxZjlh\nOGMwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCz0vvVTMTWH8JLsYfx\nMZ+egYFMFORYbynBjyuWB7+ltQbKZKtnruph7r3agBX8qzQLo1fbuaNJIkb2/TYZ\n7q61KM7aIxCPKBtKs0ms85z8gseSLb3"...>>,
  <<"*****">>}]
[ns_server:debug,2021-04-19T20:01:55.231Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
cluster_compat_version ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{6,63786080754}}]},4,6]
[ns_server:debug,2021-04-19T20:01:55.231Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
drop_request_memory_threshold_mib ->
undefined
[ns_server:debug,2021-04-19T20:01:55.232Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
email_alerts ->
[{recipients,["root@localhost"]},
 {sender,"couchbase@localhost"},
 {enabled,false},
 {email_server,[{user,[]},
                {pass,"*****"},
                {host,"localhost"},
                {port,25},
                {encrypt,false}]},
 {alerts,[auto_failover_node,auto_failover_maximum_reached,
          auto_failover_other_nodes_down,auto_failover_cluster_too_small,
          auto_failover_disabled,ip,disk,overhead,ep_oom_errors,
          ep_item_commit_failed,audit_dropped_events,indexer_ram_max_usage,
          ep_clock_cas_drift_threshold_exceeded]}]
[ns_server:debug,2021-04-19T20:01:55.232Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
fts_memory_quota ->
512
[ns_server:debug,2021-04-19T20:01:55.232Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
goxdcr_upgrade ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080754}}]}|
 '_deleted']
[ns_server:debug,2021-04-19T20:01:55.232Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
index_aware_rebalance_disabled ->
false
[ns_server:debug,2021-04-19T20:01:55.232Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
max_bucket_count ->
10
[ns_server:debug,2021-04-19T20:01:55.232Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
memcached ->
[]
[ns_server:debug,2021-04-19T20:01:55.232Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
memory_quota ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080759}}]}|300]
[ns_server:debug,2021-04-19T20:01:55.233Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
nodes_wanted ->
['ns_1@127.0.0.1']
[ns_server:debug,2021-04-19T20:01:55.233Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
otp ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080753}}]},
 {cookie,{sanitized,<<"Gldz+3QHYFD9UMWZ6D/7VCdFO4es4rvk9HPUTz5soFw=">>}}]
[ns_server:debug,2021-04-19T20:01:55.233Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
read_only_user_creds ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080754}}]}|null]
[ns_server:debug,2021-04-19T20:01:55.233Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
remote_clusters ->
[]
[error_logger:info,2021-04-19T20:01:55.233Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.263.0>},
                       {name,ns_config_rep},
                       {mfargs,{ns_config_rep,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:55.233Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
replication ->
[{enabled,true}]
[ns_server:debug,2021-04-19T20:01:55.233Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
rest ->
[{port,8091}]
[error_logger:info,2021-04-19T20:01:55.233Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.256.0>},
                       {name,ns_node_disco_sup},
                       {mfargs,{ns_node_disco_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2021-04-19T20:01:55.234Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
rest_creds ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{2,63786080759}}]}|
 {"Administrator",{password,"*****"}}]
[ns_server:debug,2021-04-19T20:01:55.235Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
roles_definitions ->
[{admin,[],
        [{name,<<"Admin">>},
         {desc,<<"Can manage ALL cluster features including security.">>}],
        [{[],all}]},
 {ro_admin,[],
           [{name,<<"Read Only Admin">>},
            {desc,<<"Can view ALL cluster features.">>}],
           [{[{bucket,any},password],none},
            {[{bucket,any},data],none},
            {[admin,security],[read]},
            {[admin],none},
            {[],[read]}]},
 {cluster_admin,[],
                [{name,<<"Cluster Admin">>},
                 {desc,<<"Can manage all cluster features EXCEPT security.">>}],
                [{[admin],none},{[],all}]},
 {bucket_admin,[bucket_name],
               [{name,<<"Bucket Admin">>},
                {desc,<<"Can manage ALL bucket features for specified buckets (incl. start/stop XDCR)">>}],
               [{[{bucket,bucket_name},xdcr],[read,execute]},
                {[{bucket,bucket_name}],all},
                {[{bucket,any},settings],[read]},
                {[{bucket,any}],none},
                {[xdcr],none},
                {[admin],none},
                {[],[read]}]},
 {bucket_sasl,[bucket_name],
              [],
              [{[{bucket,bucket_name},data],all},
               {[{bucket,bucket_name},views],all},
               {[{bucket,bucket_name}],[read,flush]},
               {[pools],[read]}]},
 {views_admin,[bucket_name],
              [{name,<<"Views Admin">>},
               {desc,<<"Can manage views for specified buckets">>}],
              [{[{bucket,bucket_name},views],all},
               {[{bucket,bucket_name},data],[read]},
               {[{bucket,any},settings],[read]},
               {[{bucket,any}],none},
               {[xdcr],none},
               {[admin],none},
               {[],[read]}]},
 {replication_admin,[],
                    [{name,<<"Replication Admin">>},
                     {desc,<<"Can manage ONLY XDCR features (cluster AND bucket level)">>}],
                    [{[{bucket,any},xdcr],all},
                     {[{bucket,any},data],[read]},
                     {[{bucket,any},settings],[read]},
                     {[{bucket,any}],none},
                     {[xdcr],all},
                     {[admin],none},
                     {[],[read]}]}]
[ns_server:debug,2021-04-19T20:01:55.235Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
server_groups ->
[[{uuid,<<"0">>},{name,<<"Group 1">>},{nodes,['ns_1@127.0.0.1']}]]
[ns_server:debug,2021-04-19T20:01:55.233Z,ns_1@127.0.0.1:ns_config_rep<0.263.0>:ns_config_rep:do_push_keys:321]Replicating some config keys ([alert_limits,audit,auto_failover_cfg,
                               autocompaction,buckets,cert_and_pkey,
                               cluster_compat_version,
                               drop_request_memory_threshold_mib,email_alerts,
                               fts_memory_quota,goxdcr_upgrade,
                               index_aware_rebalance_disabled,
                               max_bucket_count,memcached,memory_quota,
                               nodes_wanted,otp,read_only_user_creds,
                               remote_clusters,replication,rest,rest_creds,
                               roles_definitions,server_groups,
                               set_view_update_daemon,uuid,
                               {couchdb,max_parallel_indexers},
                               {couchdb,max_parallel_replica_indexers},
                               {local_changes_count,
                                   <<"dbb8bee8b38705437e7f5ebc78107bfa">>},
                               {metakv,<<"/indexing/settings/config">>},
                               {request_limit,capi},
                               {request_limit,rest},
                               {service_map,fts},
                               {service_map,index},
                               {service_map,n1ql},
                               {node,'ns_1@127.0.0.1',audit},
                               {node,'ns_1@127.0.0.1',capi_port},
                               {node,'ns_1@127.0.0.1',compaction_daemon},
                               {node,'ns_1@127.0.0.1',config_version},
                               {node,'ns_1@127.0.0.1',fts_http_port},
                               {node,'ns_1@127.0.0.1',indexer_admin_port},
                               {node,'ns_1@127.0.0.1',indexer_http_port},
                               {node,'ns_1@127.0.0.1',indexer_scan_port},
                               {node,'ns_1@127.0.0.1',indexer_stcatchup_port},
                               {node,'ns_1@127.0.0.1',indexer_stinit_port},
                               {node,'ns_1@127.0.0.1',indexer_stmaint_port},
                               {node,'ns_1@127.0.0.1',is_enterprise},
                               {node,'ns_1@127.0.0.1',isasl},
                               {node,'ns_1@127.0.0.1',ldap_enabled},
                               {node,'ns_1@127.0.0.1',membership},
                               {node,'ns_1@127.0.0.1',memcached},
                               {node,'ns_1@127.0.0.1',memcached_config},
                               {node,'ns_1@127.0.0.1',memcached_defaults},
                               {node,'ns_1@127.0.0.1',moxi},
                               {node,'ns_1@127.0.0.1',ns_log},
                               {node,'ns_1@127.0.0.1',port_servers},
                               {node,'ns_1@127.0.0.1',projector_port},
                               {node,'ns_1@127.0.0.1',query_port},
                               {node,'ns_1@127.0.0.1',rest},
                               {node,'ns_1@127.0.0.1',services},
                               {node,'ns_1@127.0.0.1',ssl_capi_port},
                               {node,'ns_1@127.0.0.1',
                                   ssl_proxy_downstream_port},
                               {node,'ns_1@127.0.0.1',ssl_proxy_upstream_port},
                               {node,'ns_1@127.0.0.1',ssl_query_port}]..)
[ns_server:debug,2021-04-19T20:01:55.235Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
set_view_update_daemon ->
[{update_interval,5000},
 {update_min_changes,5000},
 {replica_update_min_changes,5000}]
[ns_server:debug,2021-04-19T20:01:55.235Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
uuid ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080759}}]}|
 <<"aaf7f03de532d2dc46a1e96329b1eb02">>]
[ns_server:debug,2021-04-19T20:01:55.236Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{couchdb,max_parallel_indexers} ->
4
[ns_server:debug,2021-04-19T20:01:55.236Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{couchdb,max_parallel_replica_indexers} ->
2
[ns_server:debug,2021-04-19T20:01:55.236Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{local_changes_count,<<"dbb8bee8b38705437e7f5ebc78107bfa">>} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{14,63786081260}}]}]
[ns_server:debug,2021-04-19T20:01:55.236Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{metakv,<<"/indexing/settings/config">>} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{6,63786081260}}]}|
 <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.log_level\":\"info\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\""...>>]
[ns_server:debug,2021-04-19T20:01:55.236Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{request_limit,capi} ->
undefined
[ns_server:debug,2021-04-19T20:01:55.237Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{request_limit,rest} ->
undefined
[ns_server:debug,2021-04-19T20:01:55.237Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{service_map,fts} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080754}}]}]
[ns_server:debug,2021-04-19T20:01:55.237Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{service_map,index} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{2,63786080764}}]},
 'ns_1@127.0.0.1']
[ns_server:debug,2021-04-19T20:01:55.237Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{service_map,n1ql} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{2,63786080764}}]},
 'ns_1@127.0.0.1']
[ns_server:debug,2021-04-19T20:01:55.238Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',audit} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}]
[ns_server:debug,2021-04-19T20:01:55.238Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',capi_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|8092]
[ns_server:debug,2021-04-19T20:01:55.238Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',compaction_daemon} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
 {check_interval,30},
 {min_db_file_size,131072},
 {min_view_file_size,20971520}]
[error_logger:info,2021-04-19T20:01:55.238Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.271.0>},
                       {name,vbucket_map_mirror},
                       {mfargs,{vbucket_map_mirror,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:55.238Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',config_version} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|{4,5}]
[ns_server:debug,2021-04-19T20:01:55.239Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',fts_http_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|8094]
[ns_server:debug,2021-04-19T20:01:55.239Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',indexer_admin_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|9100]
[ns_server:debug,2021-04-19T20:01:55.239Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',indexer_http_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|9102]
[ns_server:debug,2021-04-19T20:01:55.239Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',indexer_scan_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|9101]
[ns_server:debug,2021-04-19T20:01:55.239Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',indexer_stcatchup_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|9104]
[ns_server:debug,2021-04-19T20:01:55.239Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',indexer_stinit_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|9103]
[ns_server:debug,2021-04-19T20:01:55.239Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',indexer_stmaint_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|9105]
[ns_server:debug,2021-04-19T20:01:55.240Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',is_enterprise} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|true]
[ns_server:debug,2021-04-19T20:01:55.240Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',isasl} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
 {path,"/opt/couchbase/var/lib/couchbase/isasl.pw"}]
[ns_server:debug,2021-04-19T20:01:55.240Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ldap_enabled} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|true]
[ns_server:debug,2021-04-19T20:01:55.240Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',membership} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
 active]
[ns_server:debug,2021-04-19T20:01:55.241Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',memcached} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
 {port,11210},
 {dedicated_port,11209},
 {ssl_port,11207},
 {admin_user,"_admin"},
 {admin_pass,"*****"},
 {engines,[{membase,[{engine,"/opt/couchbase/lib/memcached/ep.so"},
                     {static_config_string,"failpartialwarmup=false"}]},
           {memcached,[{engine,"/opt/couchbase/lib/memcached/default_engine.so"},
                       {static_config_string,"vb0=true"}]}]},
 {config_path,"/opt/couchbase/var/lib/couchbase/config/memcached.json"},
 {audit_file,"/opt/couchbase/var/lib/couchbase/config/audit.json"},
 {log_path,"/opt/couchbase/var/lib/couchbase/logs"},
 {log_prefix,"memcached.log"},
 {log_generations,20},
 {log_cyclesize,10485760},
 {log_sleeptime,19},
 {log_rotation_period,39003}]
[ns_server:debug,2021-04-19T20:01:55.241Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',memcached_config} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
 {[{interfaces,
    {memcached_config_mgr,omit_missing_mcd_ports,
     [{[{host,<<"*">>},{port,port},{maxconn,maxconn}]},
      {[{host,<<"*">>},
        {port,dedicated_port},
        {maxconn,dedicated_port_maxconn}]},
      {[{host,<<"*">>},
        {port,ssl_port},
        {maxconn,maxconn},
        {ssl,
         {[{key,
            <<"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem">>},
           {cert,
            <<"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem">>}]}}]}]}},
   {ssl_cipher_list,{"~s",[ssl_cipher_list]}},
   {ssl_minimum_protocol,{memcached_config_mgr,ssl_minimum_protocol,[]}},
   {connection_idle_time,connection_idle_time},
   {breakpad,
    {[{enabled,breakpad_enabled},
      {minidump_dir,{memcached_config_mgr,get_minidump_dir,[]}}]}},
   {extensions,
    [{[{module,<<"/opt/couchbase/lib/memcached/stdin_term_handler.so">>},
       {config,<<>>}]},
     {[{module,<<"/opt/couchbase/lib/memcached/file_logger.so">>},
       {config,
        {"cyclesize=~B;sleeptime=~B;filename=~s/~s",
         [log_cyclesize,log_sleeptime,log_path,log_prefix]}}]}]},
   {admin,{"~s",[admin_user]}},
   {verbosity,verbosity},
   {audit_file,{"~s",[audit_file]}},
   {dedupe_nmvb_maps,dedupe_nmvb_maps}]}]
[ns_server:debug,2021-04-19T20:01:55.241Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',memcached_defaults} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
 {maxconn,30000},
 {dedicated_port_maxconn,5000},
 {ssl_cipher_list,"HIGH"},
 {connection_idle_time,0},
 {verbosity,0},
 {breakpad_enabled,true},
 {breakpad_minidump_dir_path,"/opt/couchbase/var/lib/couchbase/crash"},
 {dedupe_nmvb_maps,false}]
[ns_server:debug,2021-04-19T20:01:55.241Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',moxi} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
 {port,11211},
 {verbosity,[]}]
[ns_server:debug,2021-04-19T20:01:55.242Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ns_log} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
 {filename,"/opt/couchbase/var/lib/couchbase/ns_log"}]
[ns_server:debug,2021-04-19T20:01:55.242Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',port_servers} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}]
[ns_server:debug,2021-04-19T20:01:55.242Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',projector_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|9999]
[ns_server:debug,2021-04-19T20:01:55.242Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',query_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|8093]
[error_logger:info,2021-04-19T20:01:55.242Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.273.0>},
                       {name,bucket_info_cache},
                       {mfargs,{bucket_info_cache,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:55.243Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',rest} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]},
 {port,8091},
 {port_meta,global}]
[ns_server:debug,2021-04-19T20:01:55.243Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',services} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080759}}]},
 index,kv,n1ql]
[error_logger:info,2021-04-19T20:01:55.243Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.276.0>},
                       {name,ns_tick_event},
                       {mfargs,{gen_event,start_link,[{local,ns_tick_event}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:55.243Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ssl_capi_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|18092]
[error_logger:info,2021-04-19T20:01:55.243Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.277.0>},
                       {name,buckets_events},
                       {mfargs,
                           {gen_event,start_link,[{local,buckets_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:55.243Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ssl_proxy_downstream_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|11214]
[ns_server:debug,2021-04-19T20:01:55.243Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ssl_proxy_upstream_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|11215]
[ns_server:debug,2021-04-19T20:01:55.243Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ssl_query_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|18093]
[ns_server:debug,2021-04-19T20:01:55.243Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ssl_rest_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|18091]
[ns_server:debug,2021-04-19T20:01:55.244Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',stop_xdcr} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{2,63786080754}}]}|
 '_deleted']
[ns_server:debug,2021-04-19T20:01:55.244Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',uuid} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|
 <<"dbb8bee8b38705437e7f5ebc78107bfa">>]
[ns_server:debug,2021-04-19T20:01:55.244Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',xdcr_rest_port} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{1,63786080744}}]}|9998]
[ns_server:debug,2021-04-19T20:01:55.249Z,ns_1@127.0.0.1:ns_log_events<0.255.0>:ns_mail_log:init:44]ns_mail_log started up
[error_logger:info,2021-04-19T20:01:55.249Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_mail_sup}
             started: [{pid,<0.279.0>},
                       {name,ns_mail_log},
                       {mfargs,{ns_mail_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.250Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.278.0>},
                       {name,ns_mail_sup},
                       {mfargs,{ns_mail_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T20:01:55.250Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.280.0>},
                       {name,ns_stats_event},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_stats_event}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.253Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.281.0>},
                       {name,samples_loader_tasks},
                       {mfargs,{samples_loader_tasks,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.260Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_heart_sup}
             started: [{pid,<0.283.0>},
                       {name,ns_heart},
                       {mfargs,{ns_heart,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.260Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_heart_sup}
             started: [{pid,<0.286.0>},
                       {name,ns_heart_slow_updater},
                       {mfargs,{ns_heart,start_link_slow_updater,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.260Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.282.0>},
                       {name,ns_heart_sup},
                       {mfargs,{ns_heart_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2021-04-19T20:01:55.264Z,ns_1@127.0.0.1:ns_heart<0.283.0>:ns_heart:grab_latest_stats:259]Ignoring failure to grab "@system" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,117}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,255}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,249}]},
                 {ns_heart,update_current_status,1,
                           [{file,"src/ns_heart.erl"},{line,186}]},
                 {ns_heart,handle_info,2,
                           [{file,"src/ns_heart.erl"},{line,118}]}]}}

[ns_server:debug,2021-04-19T20:01:55.264Z,ns_1@127.0.0.1:ns_heart<0.283.0>:ns_heart:grab_latest_stats:259]Ignoring failure to grab "@system-processes" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-processes-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,117}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,255}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,249}]},
                 {ns_heart,update_current_status,1,
                           [{file,"src/ns_heart.erl"},{line,186}]}]}}

[error_logger:info,2021-04-19T20:01:55.266Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_doctor_sup}
             started: [{pid,<0.289.0>},
                       {name,ns_doctor_events},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_doctor_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:55.293Z,ns_1@127.0.0.1:<0.287.0>:restartable:start_child:98]Started child process <0.288.0>
  MFA: {ns_doctor_sup,start_link,[]}
[error_logger:info,2021-04-19T20:01:55.293Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_doctor_sup}
             started: [{pid,<0.290.0>},
                       {name,ns_doctor},
                       {mfargs,{ns_doctor,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.294Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.287.0>},
                       {name,ns_doctor_sup},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_doctor_sup,start_link,[]},infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2021-04-19T20:01:55.322Z,ns_1@127.0.0.1:ns_heart<0.283.0>:ns_heart:grab_index_status:373]ignoring failure to get index status: {exit,
                                       {noproc,
                                        {gen_server,call,
                                         ['index_status_keeper-index',
                                          get_status,2000]}}}
[{gen_server,call,3,[{file,"gen_server.erl"},{line,188}]},
 {ns_heart,grab_index_status,0,[{file,"src/ns_heart.erl"},{line,370}]},
 {ns_heart,current_status_slow_inner,0,[{file,"src/ns_heart.erl"},{line,280}]},
 {ns_heart,current_status_slow,1,[{file,"src/ns_heart.erl"},{line,249}]},
 {ns_heart,update_current_status,1,[{file,"src/ns_heart.erl"},{line,186}]},
 {ns_heart,handle_info,2,[{file,"src/ns_heart.erl"},{line,118}]},
 {gen_server,handle_msg,5,[{file,"gen_server.erl"},{line,604}]},
 {proc_lib,init_p_do_apply,3,[{file,"proc_lib.erl"},{line,239}]}]
[error_logger:info,2021-04-19T20:01:55.329Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.295.0>},
                       {name,disk_log_sup},
                       {mfargs,{disk_log_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T20:01:55.330Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.296.0>},
                       {name,disk_log_server},
                       {mfargs,{disk_log_server,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.342Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.293.0>},
                       {name,remote_clusters_info},
                       {mfargs,{remote_clusters_info,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.343Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.299.0>},
                       {name,master_activity_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,master_activity_events}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.347Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.300.0>},
                       {name,xdcr_ckpt_store},
                       {mfargs,{simple_store,start_link,[xdcr_ckpt_data]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.348Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.301.0>},
                       {name,metakv_worker},
                       {mfargs,{work_queue,start_link,[metakv_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.348Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.302.0>},
                       {name,index_events},
                       {mfargs,{gen_event,start_link,[{local,index_events}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.354Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.303.0>},
                       {name,index_settings_manager},
                       {mfargs,{index_settings_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.362Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.307.0>},
                       {name,menelaus_ui_auth},
                       {mfargs,{menelaus_ui_auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.371Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.309.0>},
                       {name,menelaus_local_auth},
                       {mfargs,{menelaus_local_auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:55.377Z,ns_1@127.0.0.1:ns_heart<0.283.0>:goxdcr_rest:get_from_goxdcr:163]Goxdcr is temporary not available. Return empty list.
[error_logger:info,2021-04-19T20:01:55.389Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.310.0>},
                       {name,menelaus_web_cache},
                       {mfargs,{menelaus_web_cache,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:55.395Z,ns_1@127.0.0.1:ns_heart<0.283.0>:cluster_logs_collection_task:maybe_build_cluster_logs_task:43]Ignoring exception trying to read cluster_logs_collection_task_status table: error:badarg
[error_logger:info,2021-04-19T20:01:55.398Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.312.0>},
                       {name,menelaus_stats_gatherer},
                       {mfargs,{menelaus_stats_gatherer,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.399Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.313.0>},
                       {name,json_rpc_events},
                       {mfargs,
                           {gen_event,start_link,[{local,json_rpc_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T20:01:55.402Z,ns_1@127.0.0.1:menelaus_sup<0.305.0>:menelaus_pluggable_ui:validate_plugin_spec:117]Loaded pluggable UI specification for fts

[ns_server:info,2021-04-19T20:01:55.402Z,ns_1@127.0.0.1:menelaus_sup<0.305.0>:menelaus_pluggable_ui:validate_plugin_spec:117]Loaded pluggable UI specification for n1ql

[error_logger:info,2021-04-19T20:01:55.403Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.314.0>},
                       {name,menelaus_web},
                       {mfargs,{menelaus_web,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.405Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.331.0>},
                       {name,menelaus_event},
                       {mfargs,{menelaus_event,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T20:01:55.409Z,ns_1@127.0.0.1:ns_couchdb_port<0.181.0>:ns_port_server:log:210]ns_couchdb<0.181.0>: working as port

[error_logger:info,2021-04-19T20:01:55.409Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.332.0>},
                       {name,hot_keys_keeper},
                       {mfargs,{hot_keys_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:55.414Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.286.0>:ns_heart:grab_latest_stats:259]Ignoring failure to grab "@system" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,117}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,255}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,249}]},
                 {ns_heart,slow_updater_loop,0,
                           [{file,"src/ns_heart.erl"},{line,243}]},
                 {proc_lib,init_p_do_apply,3,
                           [{file,"proc_lib.erl"},{line,239}]}]}}

[ns_server:debug,2021-04-19T20:01:55.414Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.286.0>:ns_heart:grab_latest_stats:259]Ignoring failure to grab "@system-processes" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-processes-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,117}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,255}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,249}]},
                 {ns_heart,slow_updater_loop,0,
                           [{file,"src/ns_heart.erl"},{line,243}]}]}}

[ns_server:debug,2021-04-19T20:01:55.415Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.286.0>:ns_heart:grab_index_status:373]ignoring failure to get index status: {exit,
                                       {noproc,
                                        {gen_server,call,
                                         ['index_status_keeper-index',
                                          get_status,2000]}}}
[{gen_server,call,3,[{file,"gen_server.erl"},{line,188}]},
 {ns_heart,grab_index_status,0,[{file,"src/ns_heart.erl"},{line,370}]},
 {ns_heart,current_status_slow_inner,0,[{file,"src/ns_heart.erl"},{line,280}]},
 {ns_heart,current_status_slow,1,[{file,"src/ns_heart.erl"},{line,249}]},
 {ns_heart,slow_updater_loop,0,[{file,"src/ns_heart.erl"},{line,243}]},
 {proc_lib,init_p_do_apply,3,[{file,"proc_lib.erl"},{line,239}]}]
[ns_server:debug,2021-04-19T20:01:55.416Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.286.0>:goxdcr_rest:get_from_goxdcr:163]Goxdcr is temporary not available. Return empty list.
[ns_server:debug,2021-04-19T20:01:55.416Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.286.0>:cluster_logs_collection_task:maybe_build_cluster_logs_task:43]Ignoring exception trying to read cluster_logs_collection_task_status table: error:badarg
[error_logger:info,2021-04-19T20:01:55.418Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.339.0>},
                       {name,menelaus_web_alerts_srv},
                       {mfargs,{menelaus_web_alerts_srv,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.422Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.340.0>},
                       {name,menelaus_cbauth},
                       {mfargs,{menelaus_cbauth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[user:info,2021-04-19T20:01:55.423Z,ns_1@127.0.0.1:ns_server_sup<0.246.0>:menelaus_sup:start_link:46]Couchbase Server has started on web port 8091 on node 'ns_1@127.0.0.1'. Version: "4.6.0-3573-enterprise".
[error_logger:info,2021-04-19T20:01:55.423Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.305.0>},
                       {name,menelaus},
                       {mfargs,{menelaus_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T20:01:55.423Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.344.0>},
                       {name,ns_ports_setup},
                       {mfargs,{ns_ports_setup,start,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.428Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_agent_sup}
             started: [{pid,<0.347.0>},
                       {name,service_agent_children_sup},
                       {mfargs,
                           {supervisor,start_link,
                               [{local,service_agent_children_sup},
                                service_agent_sup,child]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T20:01:55.428Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_agent_sup}
             started: [{pid,<0.348.0>},
                       {name,service_agent_worker},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<service_agent_sup.0.29791682>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.429Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.346.0>},
                       {name,service_agent_sup},
                       {mfargs,{service_agent_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T20:01:55.449Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.350.0>},
                       {name,ns_memcached_sockets_pool},
                       {mfargs,{ns_memcached_sockets_pool,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:55.449Z,ns_1@127.0.0.1:ns_audit_cfg<0.351.0>:ns_audit_cfg:write_audit_json:158]Writing new content to "/opt/couchbase/var/lib/couchbase/config/audit.json" : [{auditd_enabled,
                                                                                false},
                                                                               {disabled,
                                                                                []},
                                                                               {log_path,
                                                                                "/opt/couchbase/var/lib/couchbase/logs"},
                                                                               {rotate_interval,
                                                                                86400},
                                                                               {rotate_size,
                                                                                20971520},
                                                                               {sync,
                                                                                []},
                                                                               {version,
                                                                                1},
                                                                               {descriptors_path,
                                                                                "/opt/couchbase/etc/security"}]
[ns_server:debug,2021-04-19T20:01:55.460Z,ns_1@127.0.0.1:ns_ports_setup<0.344.0>:ns_ports_manager:set_dynamic_children:54]Setting children [memcached,moxi,projector,indexer,query,saslauthd_port,
                  goxdcr,xdcr_proxy]
[ns_server:debug,2021-04-19T20:01:55.479Z,ns_1@127.0.0.1:ns_audit_cfg<0.351.0>:ns_audit_cfg:handle_info:107]Instruct memcached to reload audit config
[error_logger:info,2021-04-19T20:01:55.479Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.351.0>},
                       {name,ns_audit_cfg},
                       {mfargs,{ns_audit_cfg,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:warn,2021-04-19T20:01:55.481Z,ns_1@127.0.0.1:<0.353.0>:ns_memcached:connect:1307]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[ns_server:debug,2021-04-19T20:01:55.484Z,ns_1@127.0.0.1:memcached_config_mgr<0.355.0>:memcached_config_mgr:init:44]waiting for completion of initial ns_ports_setup round
[error_logger:info,2021-04-19T20:01:55.484Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.355.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T20:01:55.488Z,ns_1@127.0.0.1:<0.356.0>:ns_memcached_log_rotator:init:28]Starting log rotator on "/opt/couchbase/var/lib/couchbase/logs"/"memcached.log"* with an initial period of 39003ms
[error_logger:info,2021-04-19T20:01:55.489Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.356.0>},
                       {name,ns_memcached_log_rotator},
                       {mfargs,{ns_memcached_log_rotator,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.494Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.357.0>},
                       {name,memcached_clients_pool},
                       {mfargs,{memcached_clients_pool,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.500Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.358.0>},
                       {name,proxied_memcached_clients_pool},
                       {mfargs,{proxied_memcached_clients_pool,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.501Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.359.0>},
                       {name,xdc_lhttpc_pool},
                       {mfargs,
                           {lhttpc_manager,start_link,
                               [[{name,xdc_lhttpc_pool},
                                 {connection_timeout,120000},
                                 {pool_size,200}]]}},
                       {restart_type,{permanent,1}},
                       {shutdown,10000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.504Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.360.0>},
                       {name,ns_null_connection_pool},
                       {mfargs,
                           {ns_null_connection_pool,start_link,
                               [ns_null_connection_pool]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.512Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {<0.361.0>,xdcr_sup}
             started: [{pid,<0.362.0>},
                       {name,xdc_stats_holder},
                       {mfargs,
                           {proc_lib,start_link,
                               [xdcr_sup,link_stats_holder_body,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.516Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {<0.361.0>,xdcr_sup}
             started: [{pid,<0.363.0>},
                       {name,xdc_replication_sup},
                       {mfargs,{xdc_replication_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2021-04-19T20:01:55.520Z,ns_1@127.0.0.1:xdc_rep_manager<0.364.0>:ns_couchdb_api:wait_for_doc_manager:298]Start waiting for doc manager
[error_logger:info,2021-04-19T20:01:55.520Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {<0.361.0>,xdcr_sup}
             started: [{pid,<0.364.0>},
                       {name,xdc_rep_manager},
                       {mfargs,{xdc_rep_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,30000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:55.525Z,ns_1@127.0.0.1:xdcr_doc_replicator<0.366.0>:ns_couchdb_api:wait_for_doc_manager:298]Start waiting for doc manager
[ns_server:debug,2021-04-19T20:01:55.525Z,ns_1@127.0.0.1:xdc_rdoc_replication_srv<0.367.0>:ns_couchdb_api:wait_for_doc_manager:298]Start waiting for doc manager
[error_logger:info,2021-04-19T20:01:55.525Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {<0.361.0>,xdcr_sup}
             started: [{pid,<0.366.0>},
                       {name,xdc_rdoc_replicator},
                       {mfargs,{doc_replicator,start_link_xdcr,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.526Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {<0.361.0>,xdcr_sup}
             started: [{pid,<0.367.0>},
                       {name,xdc_rdoc_replication_srv},
                       {mfargs,{doc_replication_srv,start_link_xdcr,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:55.529Z,ns_1@127.0.0.1:<0.361.0>:xdc_rdoc_manager:start_link_remote:42]Starting xdc_rdoc_manager on 'couchdb_ns_1@127.0.0.1' with following links: [<0.366.0>,
                                                                             <0.367.0>,
                                                                             <0.364.0>]
[ns_server:debug,2021-04-19T20:01:55.541Z,ns_1@127.0.0.1:xdcr_doc_replicator<0.366.0>:ns_couchdb_api:wait_for_doc_manager:301]Received doc manager registration from <11633.256.0>
[ns_server:debug,2021-04-19T20:01:55.541Z,ns_1@127.0.0.1:xdc_rep_manager<0.364.0>:ns_couchdb_api:wait_for_doc_manager:301]Received doc manager registration from <11633.256.0>
[ns_server:debug,2021-04-19T20:01:55.542Z,ns_1@127.0.0.1:xdc_rdoc_replication_srv<0.367.0>:ns_couchdb_api:wait_for_doc_manager:301]Received doc manager registration from <11633.256.0>
[error_logger:info,2021-04-19T20:01:55.542Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {<0.361.0>,xdcr_sup}
             started: [{pid,<11633.256.0>},
                       {name,xdc_rdoc_manager},
                       {mfargs,
                           {xdc_rdoc_manager,start_link_remote,
                               ['couchdb_ns_1@127.0.0.1']}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.542Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.361.0>},
                       {name,xdcr_sup},
                       {mfargs,{xdcr_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T20:01:55.546Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.369.0>},
                       {name,xdcr_dcp_sockets_pool},
                       {mfargs,{xdcr_dcp_sockets_pool,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.554Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_worker_sup}
             started: [{pid,<0.371.0>},
                       {name,ns_bucket_worker},
                       {mfargs,{work_queue,start_link,[ns_bucket_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.559Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_sup}
             started: [{pid,<0.373.0>},
                       {name,buckets_observing_subscription},
                       {mfargs,{ns_bucket_sup,subscribe_on_config_events,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.559Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_worker_sup}
             started: [{pid,<0.372.0>},
                       {name,ns_bucket_sup},
                       {mfargs,{ns_bucket_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T20:01:55.560Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.370.0>},
                       {name,ns_bucket_worker_sup},
                       {mfargs,{ns_bucket_worker_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T20:01:55.565Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.374.0>},
                       {name,system_stats_collector},
                       {mfargs,{system_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.568Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.378.0>},
                       {name,{stats_archiver,"@system"}},
                       {mfargs,{stats_archiver,start_link,["@system"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:55.577Z,ns_1@127.0.0.1:xdcr_doc_replicator<0.366.0>:doc_replicator:loop:64]doing replicate_newnodes_docs
[error_logger:info,2021-04-19T20:01:55.583Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.380.0>},
                       {name,{stats_reader,"@system"}},
                       {mfargs,{stats_reader,start_link,["@system"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.589Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.381.0>},
                       {name,{stats_archiver,"@system-processes"}},
                       {mfargs,
                           {stats_archiver,start_link,["@system-processes"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.589Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.383.0>},
                       {name,{stats_reader,"@system-processes"}},
                       {mfargs,
                           {stats_reader,start_link,["@system-processes"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.602Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.384.0>},
                       {name,{stats_archiver,"@query"}},
                       {mfargs,{stats_archiver,start_link,["@query"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.602Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.386.0>},
                       {name,{stats_reader,"@query"}},
                       {mfargs,{stats_reader,start_link,["@query"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.606Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.387.0>},
                       {name,query_stats_collector},
                       {mfargs,{query_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.639Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.389.0>},
                       {name,{stats_archiver,"@global"}},
                       {mfargs,{stats_archiver,start_link,["@global"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.639Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.391.0>},
                       {name,{stats_reader,"@global"}},
                       {mfargs,{stats_reader,start_link,["@global"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.647Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.392.0>},
                       {name,global_stats_collector},
                       {mfargs,{global_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.652Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.394.0>},
                       {name,goxdcr_status_keeper},
                       {mfargs,{goxdcr_status_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:55.653Z,ns_1@127.0.0.1:goxdcr_status_keeper<0.394.0>:goxdcr_rest:get_from_goxdcr:163]Goxdcr is temporary not available. Return empty list.
[ns_server:debug,2021-04-19T20:01:55.655Z,ns_1@127.0.0.1:goxdcr_status_keeper<0.394.0>:goxdcr_rest:get_from_goxdcr:163]Goxdcr is temporary not available. Return empty list.
[error_logger:info,2021-04-19T20:01:55.661Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_stats_sup}
             started: [{pid,<0.398.0>},
                       {name,index_stats_children_sup},
                       {mfargs,
                           {supervisor,start_link,
                               [{local,index_stats_children_sup},
                                index_stats_sup,child]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T20:01:55.665Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_status_keeper_sup}
             started: [{pid,<0.400.0>},
                       {name,index_status_keeper_worker},
                       {mfargs,
                           {work_queue,start_link,
                               [index_status_keeper_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.667Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_status_keeper_sup}
             started: [{pid,<0.401.0>},
                       {name,index_status_keeper},
                       {mfargs,{indexer_gsi,start_keeper,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.677Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_status_keeper_sup}
             started: [{pid,<0.404.0>},
                       {name,index_status_keeper_fts},
                       {mfargs,{indexer_fts,start_keeper,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.679Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_stats_sup}
             started: [{pid,<0.399.0>},
                       {name,index_status_keeper_sup},
                       {mfargs,{index_status_keeper_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T20:01:55.680Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_stats_sup}
             started: [{pid,<0.407.0>},
                       {name,index_stats_worker},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<index_stats_sup.0.21142793>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.680Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.397.0>},
                       {name,index_stats_sup},
                       {mfargs,{index_stats_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:error,2021-04-19T20:01:55.683Z,ns_1@127.0.0.1:index_status_keeper_worker<0.400.0>:index_rest:get_json:42]Request to (indexer) http://127.0.0.1:9102/getIndexStatus failed: {error,
                                                                   {econnrefused,
                                                                    [{lhttpc_client,
                                                                      send_request,
                                                                      1,
                                                                      [{file,
                                                                        "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                       {line,
                                                                        220}]},
                                                                     {lhttpc_client,
                                                                      execute,
                                                                      9,
                                                                      [{file,
                                                                        "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                       {line,
                                                                        169}]},
                                                                     {lhttpc_client,
                                                                      request,
                                                                      9,
                                                                      [{file,
                                                                        "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                       {line,
                                                                        92}]}]}}
[error_logger:info,2021-04-19T20:01:55.696Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_stats_children_sup}
             started: [{pid,<0.410.0>},
                       {name,{indexer_gsi,index_stats_collector}},
                       {mfargs,
                           {index_stats_collector,start_link,[indexer_gsi]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.704Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.414.0>},
                       {name,compaction_daemon},
                       {mfargs,{compaction_daemon,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:55.734Z,ns_1@127.0.0.1:<0.417.0>:new_concurrency_throttle:init:113]init concurrent throttle process, pid: <0.417.0>, type: kv_throttle# of available token: 1
[error_logger:info,2021-04-19T20:01:55.735Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_stats_children_sup}
             started: [{pid,<0.413.0>},
                       {name,{indexer_gsi,stats_archiver,"@index"}},
                       {mfargs,{stats_archiver,start_link,["@index"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.735Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_stats_children_sup}
             started: [{pid,<0.419.0>},
                       {name,{indexer_gsi,stats_reader,"@index"}},
                       {mfargs,{stats_reader,start_link,["@index"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:55.739Z,ns_1@127.0.0.1:compaction_new_daemon<0.415.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2021-04-19T20:01:55.739Z,ns_1@127.0.0.1:compaction_new_daemon<0.415.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[error_logger:info,2021-04-19T20:01:55.739Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.415.0>},
                       {name,compaction_new_daemon},
                       {mfargs,{compaction_new_daemon,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,86400000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:55.740Z,ns_1@127.0.0.1:compaction_new_daemon<0.415.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2021-04-19T20:01:55.740Z,ns_1@127.0.0.1:compaction_new_daemon<0.415.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T20:01:55.741Z,ns_1@127.0.0.1:compaction_new_daemon<0.415.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_master. Rescheduling compaction.
[ns_server:debug,2021-04-19T20:01:55.742Z,ns_1@127.0.0.1:compaction_new_daemon<0.415.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_master too soon. Next run will be in 3600s
[error_logger:info,2021-04-19T20:01:55.744Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,cluster_logs_sup}
             started: [{pid,<0.421.0>},
                       {name,ets_holder},
                       {mfargs,
                           {cluster_logs_collection_task,
                               start_link_ets_holder,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.745Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.420.0>},
                       {name,cluster_logs_sup},
                       {mfargs,{cluster_logs_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T20:01:55.749Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.422.0>},
                       {name,remote_api},
                       {mfargs,{remote_api,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:55.756Z,ns_1@127.0.0.1:<0.423.0>:mb_master:check_master_takeover_needed:141]Sending master node question to the following nodes: []
[ns_server:debug,2021-04-19T20:01:55.756Z,ns_1@127.0.0.1:<0.423.0>:mb_master:check_master_takeover_needed:143]Got replies: []
[ns_server:debug,2021-04-19T20:01:55.756Z,ns_1@127.0.0.1:<0.423.0>:mb_master:check_master_takeover_needed:149]Was unable to discover master, not going to force mastership takeover
[user:info,2021-04-19T20:01:55.756Z,ns_1@127.0.0.1:mb_master<0.425.0>:mb_master:init:86]I'm the only node, so I'm the master.
[ns_server:debug,2021-04-19T20:01:55.775Z,ns_1@127.0.0.1:mb_master_sup<0.427.0>:misc:start_singleton:1097]start_singleton(gen_server, ns_tick, [], []): started as <0.428.0> on 'ns_1@127.0.0.1'

[error_logger:info,2021-04-19T20:01:55.776Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.428.0>},
                       {name,ns_tick},
                       {mfargs,{ns_tick,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,10},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:55.781Z,ns_1@127.0.0.1:ns_orchestrator_sup<0.429.0>:misc:start_singleton:1097]start_singleton(gen_fsm, ns_orchestrator, [], []): started as <0.430.0> on 'ns_1@127.0.0.1'

[error_logger:info,2021-04-19T20:01:55.781Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_sup}
             started: [{pid,<0.430.0>},
                       {name,ns_orchestrator},
                       {mfargs,{ns_orchestrator,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:55.787Z,ns_1@127.0.0.1:<0.432.0>:auto_failover:init:147]init auto_failover.
[ns_server:debug,2021-04-19T20:01:55.788Z,ns_1@127.0.0.1:ns_orchestrator_sup<0.429.0>:misc:start_singleton:1097]start_singleton(gen_server, auto_failover, [], []): started as <0.432.0> on 'ns_1@127.0.0.1'

[ns_server:debug,2021-04-19T20:01:55.788Z,ns_1@127.0.0.1:<0.423.0>:restartable:start_child:98]Started child process <0.425.0>
  MFA: {mb_master,start_link,[]}
[error_logger:info,2021-04-19T20:01:55.788Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_sup}
             started: [{pid,<0.432.0>},
                       {name,auto_failover},
                       {mfargs,{auto_failover,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.788Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.429.0>},
                       {name,ns_orchestrator_sup},
                       {mfargs,{ns_orchestrator_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T20:01:55.788Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.423.0>},
                       {name,mb_master},
                       {mfargs,
                           {restartable,start_link,
                               [{mb_master,start_link,[]},infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T20:01:55.789Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.433.0>},
                       {name,master_activity_events_ingress},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,master_activity_events_ingress}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.789Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.434.0>},
                       {name,master_activity_events_timestamper},
                       {mfargs,
                           {master_activity_events,start_link_timestamper,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.796Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.435.0>},
                       {name,master_activity_events_pids_watcher},
                       {mfargs,
                           {master_activity_events_pids_watcher,start_link,
                               []}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:55.815Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.155.0>:one_shot_barrier:notify:27]Notifying on barrier menelaus_barrier
[ns_server:debug,2021-04-19T20:01:55.815Z,ns_1@127.0.0.1:menelaus_barrier<0.157.0>:one_shot_barrier:barrier_body:62]Barrier menelaus_barrier got notification from <0.155.0>
[error_logger:info,2021-04-19T20:01:55.815Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.436.0>},
                       {name,master_activity_events_keeper},
                       {mfargs,{master_activity_events_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:55.816Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.246.0>},
                       {name,ns_server_sup},
                       {mfargs,{ns_server_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2021-04-19T20:01:55.816Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.155.0>:one_shot_barrier:notify:32]Successfuly notified on barrier menelaus_barrier
[ns_server:debug,2021-04-19T20:01:55.816Z,ns_1@127.0.0.1:<0.154.0>:restartable:start_child:98]Started child process <0.155.0>
  MFA: {ns_server_nodes_sup,start_link,[]}
[ns_server:debug,2021-04-19T20:01:55.816Z,ns_1@127.0.0.1:<0.2.0>:child_erlang:child_loop:116]97: Entered child_loop
[error_logger:info,2021-04-19T20:01:55.816Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.154.0>},
                       {name,ns_server_nodes_sup},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_server_nodes_sup,start_link,[]},
                                infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T20:01:55.817Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
         application: ns_server
          started_at: 'ns_1@127.0.0.1'

[ns_server:debug,2021-04-19T20:01:56.330Z,ns_1@127.0.0.1:ns_ports_setup<0.344.0>:ns_ports_setup:set_children:72]Monitor ns_child_ports_sup <11632.72.0>
[ns_server:debug,2021-04-19T20:01:56.330Z,ns_1@127.0.0.1:memcached_config_mgr<0.355.0>:memcached_config_mgr:init:46]ns_ports_setup seems to be ready
[ns_server:debug,2021-04-19T20:01:56.347Z,ns_1@127.0.0.1:memcached_config_mgr<0.355.0>:memcached_config_mgr:find_port_pid_loop:119]Found memcached port <11632.79.0>
[ns_server:debug,2021-04-19T20:01:56.380Z,ns_1@127.0.0.1:memcached_config_mgr<0.355.0>:memcached_config_mgr:init:77]wrote memcached config to /opt/couchbase/var/lib/couchbase/config/memcached.json. Will activate memcached port server
[ns_server:debug,2021-04-19T20:01:56.399Z,ns_1@127.0.0.1:memcached_config_mgr<0.355.0>:memcached_config_mgr:init:80]activated memcached port server
[ns_server:warn,2021-04-19T20:01:56.484Z,ns_1@127.0.0.1:<0.353.0>:ns_memcached:connect:1307]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[stats:error,2021-04-19T20:01:56.779Z,ns_1@127.0.0.1:query_stats_collector<0.387.0>:base_stats_collector:handle_info:109](Collector: query_stats_collector) Exception in stats collector: {error,
                                                                  {badmatch,
                                                                   {error,
                                                                    {econnrefused,
                                                                     [{lhttpc_client,
                                                                       send_request,
                                                                       1,
                                                                       [{file,
                                                                         "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                        {line,
                                                                         220}]},
                                                                      {lhttpc_client,
                                                                       execute,
                                                                       9,
                                                                       [{file,
                                                                         "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                        {line,
                                                                         169}]},
                                                                      {lhttpc_client,
                                                                       request,
                                                                       9,
                                                                       [{file,
                                                                         "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                        {line,
                                                                         92}]}]}}},
                                                                  [{query_rest,
                                                                    send,3,
                                                                    [{file,
                                                                      "src/query_rest.erl"},
                                                                     {line,
                                                                      64}]},
                                                                   {query_rest,
                                                                    do_get_stats,
                                                                    0,
                                                                    [{file,
                                                                      "src/query_rest.erl"},
                                                                     {line,
                                                                      43}]},
                                                                   {base_stats_collector,
                                                                    handle_info,
                                                                    2,
                                                                    [{file,
                                                                      "src/base_stats_collector.erl"},
                                                                     {line,
                                                                      89}]},
                                                                   {gen_server,
                                                                    handle_msg,
                                                                    5,
                                                                    [{file,
                                                                      "gen_server.erl"},
                                                                     {line,
                                                                      604}]},
                                                                   {proc_lib,
                                                                    init_p_do_apply,
                                                                    3,
                                                                    [{file,
                                                                      "proc_lib.erl"},
                                                                     {line,
                                                                      239}]}]}

[ns_server:error,2021-04-19T20:01:56.780Z,ns_1@127.0.0.1:index_stats_collector-index<0.410.0>:index_rest:get_json:42]Request to (indexer) http://127.0.0.1:9102/stats?async=true failed: {error,
                                                                     {econnrefused,
                                                                      [{lhttpc_client,
                                                                        send_request,
                                                                        1,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          220}]},
                                                                       {lhttpc_client,
                                                                        execute,
                                                                        9,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          169}]},
                                                                       {lhttpc_client,
                                                                        request,
                                                                        9,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          92}]}]}}
[ns_server:warn,2021-04-19T20:01:56.789Z,ns_1@127.0.0.1:<0.443.0>:ns_memcached:connect:1307]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[ns_server:debug,2021-04-19T20:01:57.109Z,ns_1@127.0.0.1:json_rpc_connection-projector-cbauth<0.447.0>:json_rpc_connection:init:74]Observed revrpc connection: label "projector-cbauth", handling process <0.447.0>
[ns_server:debug,2021-04-19T20:01:57.109Z,ns_1@127.0.0.1:menelaus_cbauth<0.340.0>:menelaus_cbauth:handle_cast:87]Observed json rpc process {"projector-cbauth",<0.447.0>} started
[error_logger:error,2021-04-19T20:01:57.109Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.447.0>,{ok,<0.447.0>}}

[ns_server:debug,2021-04-19T20:01:57.120Z,ns_1@127.0.0.1:json_rpc_connection-projector-cbauth<0.447.0>:json_rpc_connection:handle_call:157]sending jsonrpc call:{[{jsonrpc,<<"2.0">>},
                       {id,0},
                       {method,<<"AuthCacheSvc.UpdateDB">>},
                       {params,
                        [{[{specialUser,<<"@projector-cbauth">>},
                           {nodes,
                            [{[{host,<<"127.0.0.1">>},
                               {user,<<"_admin">>},
                               {password,"*****"},
                               {ports,
                                [8091,18091,9100,9101,9102,9103,9104,9105,
                                 18092,8092,11207,9999,11210,11211,8093,
                                 18093]},
                               {local,true}]}]},
                           {buckets,[]},
                           {authCheckURL,<<"http://127.0.0.1:8091/_cbauth">>},
                           {permissionCheckURL,
                            <<"http://127.0.0.1:8091/_cbauth/checkPermission">>},
                           {ldapEnabled,true},
                           {permissionsVersion,125619376},
                           {admin,
                            {[{user,<<"Administrator">>},
                              {salt,<<"6fV7COE6Hrv1Slx3m7c7aw==">>},
                              {mac,
                               <<"88VQXOIVfyUC4fCDlttiZJtlD/s=">>}]}}]}]}]}
[ns_server:debug,2021-04-19T20:01:57.123Z,ns_1@127.0.0.1:json_rpc_connection-projector-cbauth<0.447.0>:json_rpc_connection:handle_info:93]got response: [{<<"id">>,0},{<<"result">>,true},{<<"error">>,null}]
[ns_server:debug,2021-04-19T20:01:57.261Z,ns_1@127.0.0.1:json_rpc_connection-index-cbauth<0.452.0>:json_rpc_connection:init:74]Observed revrpc connection: label "index-cbauth", handling process <0.452.0>
[ns_server:debug,2021-04-19T20:01:57.261Z,ns_1@127.0.0.1:menelaus_cbauth<0.340.0>:menelaus_cbauth:handle_cast:87]Observed json rpc process {"index-cbauth",<0.452.0>} started
[error_logger:error,2021-04-19T20:01:57.261Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.452.0>,{ok,<0.452.0>}}

[ns_server:debug,2021-04-19T20:01:57.261Z,ns_1@127.0.0.1:json_rpc_connection-index-cbauth<0.452.0>:json_rpc_connection:handle_call:157]sending jsonrpc call:{[{jsonrpc,<<"2.0">>},
                       {id,0},
                       {method,<<"AuthCacheSvc.UpdateDB">>},
                       {params,
                        [{[{specialUser,<<"@index-cbauth">>},
                           {nodes,
                            [{[{host,<<"127.0.0.1">>},
                               {user,<<"_admin">>},
                               {password,"*****"},
                               {ports,
                                [8091,18091,9100,9101,9102,9103,9104,9105,
                                 18092,8092,11207,9999,11210,11211,8093,
                                 18093]},
                               {local,true}]}]},
                           {buckets,[]},
                           {authCheckURL,<<"http://127.0.0.1:8091/_cbauth">>},
                           {permissionCheckURL,
                            <<"http://127.0.0.1:8091/_cbauth/checkPermission">>},
                           {ldapEnabled,true},
                           {permissionsVersion,125619376},
                           {admin,
                            {[{user,<<"Administrator">>},
                              {salt,<<"6fV7COE6Hrv1Slx3m7c7aw==">>},
                              {mac,
                               <<"88VQXOIVfyUC4fCDlttiZJtlD/s=">>}]}}]}]}]}
[ns_server:debug,2021-04-19T20:01:57.266Z,ns_1@127.0.0.1:json_rpc_connection-index-cbauth<0.452.0>:json_rpc_connection:handle_info:93]got response: [{<<"id">>,0},{<<"result">>,true},{<<"error">>,null}]
[ns_server:warn,2021-04-19T20:01:57.486Z,ns_1@127.0.0.1:<0.353.0>:ns_memcached:connect:1307]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[ns_server:debug,2021-04-19T20:01:57.528Z,ns_1@127.0.0.1:json_rpc_connection-cbq-engine-cbauth<0.459.0>:json_rpc_connection:init:74]Observed revrpc connection: label "cbq-engine-cbauth", handling process <0.459.0>
[error_logger:error,2021-04-19T20:01:57.528Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.459.0>,{ok,<0.459.0>}}

[ns_server:debug,2021-04-19T20:01:57.528Z,ns_1@127.0.0.1:menelaus_cbauth<0.340.0>:menelaus_cbauth:handle_cast:87]Observed json rpc process {"cbq-engine-cbauth",<0.459.0>} started
[ns_server:debug,2021-04-19T20:01:57.529Z,ns_1@127.0.0.1:json_rpc_connection-cbq-engine-cbauth<0.459.0>:json_rpc_connection:handle_call:157]sending jsonrpc call:{[{jsonrpc,<<"2.0">>},
                       {id,0},
                       {method,<<"AuthCacheSvc.UpdateDB">>},
                       {params,
                        [{[{specialUser,<<"@cbq-engine-cbauth">>},
                           {nodes,
                            [{[{host,<<"127.0.0.1">>},
                               {user,<<"_admin">>},
                               {password,"*****"},
                               {ports,
                                [8091,18091,9100,9101,9102,9103,9104,9105,
                                 18092,8092,11207,9999,11210,11211,8093,
                                 18093]},
                               {local,true}]}]},
                           {buckets,[]},
                           {authCheckURL,<<"http://127.0.0.1:8091/_cbauth">>},
                           {permissionCheckURL,
                            <<"http://127.0.0.1:8091/_cbauth/checkPermission">>},
                           {ldapEnabled,true},
                           {permissionsVersion,125619376},
                           {admin,
                            {[{user,<<"Administrator">>},
                              {salt,<<"6fV7COE6Hrv1Slx3m7c7aw==">>},
                              {mac,
                               <<"88VQXOIVfyUC4fCDlttiZJtlD/s=">>}]}}]}]}]}
[ns_server:debug,2021-04-19T20:01:57.530Z,ns_1@127.0.0.1:json_rpc_connection-cbq-engine-cbauth<0.459.0>:json_rpc_connection:handle_info:93]got response: [{<<"id">>,0},{<<"result">>,true},{<<"error">>,null}]
[ns_server:debug,2021-04-19T20:01:57.647Z,ns_1@127.0.0.1:json_rpc_connection-saslauthd-saslauthd-port<0.464.0>:json_rpc_connection:init:74]Observed revrpc connection: label "saslauthd-saslauthd-port", handling process <0.464.0>
[error_logger:error,2021-04-19T20:01:57.647Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.464.0>,{ok,<0.464.0>}}

[ns_server:debug,2021-04-19T20:01:57.760Z,ns_1@127.0.0.1:json_rpc_connection-goxdcr-cbauth<0.469.0>:json_rpc_connection:init:74]Observed revrpc connection: label "goxdcr-cbauth", handling process <0.469.0>
[ns_server:debug,2021-04-19T20:01:57.760Z,ns_1@127.0.0.1:menelaus_cbauth<0.340.0>:menelaus_cbauth:handle_cast:87]Observed json rpc process {"goxdcr-cbauth",<0.469.0>} started
[error_logger:error,2021-04-19T20:01:57.760Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.469.0>,{ok,<0.469.0>}}

[ns_server:debug,2021-04-19T20:01:57.760Z,ns_1@127.0.0.1:json_rpc_connection-goxdcr-cbauth<0.469.0>:json_rpc_connection:handle_call:157]sending jsonrpc call:{[{jsonrpc,<<"2.0">>},
                       {id,0},
                       {method,<<"AuthCacheSvc.UpdateDB">>},
                       {params,
                        [{[{specialUser,<<"@goxdcr-cbauth">>},
                           {nodes,
                            [{[{host,<<"127.0.0.1">>},
                               {user,<<"_admin">>},
                               {password,"*****"},
                               {ports,
                                [8091,18091,9100,9101,9102,9103,9104,9105,
                                 18092,8092,11207,9999,11210,11211,8093,
                                 18093]},
                               {local,true}]}]},
                           {buckets,[]},
                           {authCheckURL,<<"http://127.0.0.1:8091/_cbauth">>},
                           {permissionCheckURL,
                            <<"http://127.0.0.1:8091/_cbauth/checkPermission">>},
                           {ldapEnabled,true},
                           {permissionsVersion,125619376},
                           {admin,
                            {[{user,<<"Administrator">>},
                              {salt,<<"6fV7COE6Hrv1Slx3m7c7aw==">>},
                              {mac,
                               <<"88VQXOIVfyUC4fCDlttiZJtlD/s=">>}]}}]}]}]}
[ns_server:debug,2021-04-19T20:01:57.763Z,ns_1@127.0.0.1:json_rpc_connection-goxdcr-cbauth<0.469.0>:json_rpc_connection:handle_info:93]got response: [{<<"id">>,0},{<<"result">>,true},{<<"error">>,null}]
[ns_server:error,2021-04-19T20:01:57.779Z,ns_1@127.0.0.1:index_stats_collector-index<0.410.0>:index_rest:get_json:42]Request to (indexer) http://127.0.0.1:9102/stats?async=true failed: {error,
                                                                     {econnrefused,
                                                                      [{lhttpc_client,
                                                                        send_request,
                                                                        1,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          220}]},
                                                                       {lhttpc_client,
                                                                        execute,
                                                                        9,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          169}]},
                                                                       {lhttpc_client,
                                                                        request,
                                                                        9,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          92}]}]}}
[ns_server:warn,2021-04-19T20:01:57.794Z,ns_1@127.0.0.1:<0.443.0>:ns_memcached:connect:1307]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[stats:warn,2021-04-19T20:01:58.797Z,ns_1@127.0.0.1:<0.392.0>:base_stats_collector:latest_tick:69](Collector: global_stats_collector) Dropped 2 ticks
[ns_server:debug,2021-04-19T20:02:01.179Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{metakv,<<"/indexing/settings/config">>} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{7,63786081721}}]}|
 <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.log_level\":\"info\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\""...>>]
[ns_server:debug,2021-04-19T20:02:01.179Z,ns_1@127.0.0.1:<0.517.0>:ns_audit:put:248]Audit modify_index_storage_mode: [{storageMode,<<"memory_optimized">>},
                                  {real_userid,
                                      {[{source,ns_server},
                                        {user,<<"Administrator">>}]}},
                                  {remote,
                                      {[{ip,<<"127.0.0.1">>},{port,37198}]}},
                                  {timestamp,<<"2021-04-19T20:02:01.179Z">>}]
[ns_server:debug,2021-04-19T20:02:01.179Z,ns_1@127.0.0.1:ns_config_rep<0.263.0>:ns_config_rep:do_push_keys:321]Replicating some config keys ([{local_changes_count,
                                   <<"dbb8bee8b38705437e7f5ebc78107bfa">>},
                               {metakv,<<"/indexing/settings/config">>}]..)
[ns_server:debug,2021-04-19T20:02:01.179Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{local_changes_count,<<"dbb8bee8b38705437e7f5ebc78107bfa">>} ->
[{'_vclock',[{<<"dbb8bee8b38705437e7f5ebc78107bfa">>,{15,63786081721}}]}]
[ns_server:debug,2021-04-19T20:02:25.741Z,ns_1@127.0.0.1:compaction_new_daemon<0.415.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2021-04-19T20:02:25.742Z,ns_1@127.0.0.1:compaction_new_daemon<0.415.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T20:02:25.742Z,ns_1@127.0.0.1:compaction_new_daemon<0.415.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2021-04-19T20:02:25.742Z,ns_1@127.0.0.1:compaction_new_daemon<0.415.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T20:02:55.743Z,ns_1@127.0.0.1:compaction_new_daemon<0.415.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2021-04-19T20:02:55.744Z,ns_1@127.0.0.1:compaction_new_daemon<0.415.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T20:02:55.744Z,ns_1@127.0.0.1:compaction_new_daemon<0.415.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2021-04-19T20:02:55.744Z,ns_1@127.0.0.1:compaction_new_daemon<0.415.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s

[ns_server:info,2021-04-19T19:45:40.650Z,nonode@nohost:<0.88.0>:ns_server:init_logging:151]Started & configured logging
[ns_server:info,2021-04-19T19:45:40.671Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]Static config terms:
[{error_logger_mf_dir,"/opt/couchbase/var/lib/couchbase/logs"},
 {path_config_bindir,"/opt/couchbase/bin"},
 {path_config_etcdir,"/opt/couchbase/etc/couchbase"},
 {path_config_libdir,"/opt/couchbase/lib"},
 {path_config_datadir,"/opt/couchbase/var/lib/couchbase"},
 {path_config_tmpdir,"/opt/couchbase/var/lib/couchbase/tmp"},
 {path_config_secdir,"/opt/couchbase/etc/security"},
 {nodefile,"/opt/couchbase/var/lib/couchbase/couchbase-server.node"},
 {loglevel_default,debug},
 {loglevel_couchdb,info},
 {loglevel_ns_server,debug},
 {loglevel_error_logger,debug},
 {loglevel_user,debug},
 {loglevel_menelaus,debug},
 {loglevel_ns_doctor,debug},
 {loglevel_stats,debug},
 {loglevel_rebalance,debug},
 {loglevel_cluster,debug},
 {loglevel_views,debug},
 {loglevel_mapreduce_errors,debug},
 {loglevel_xdcr,debug},
 {loglevel_xdcr_trace,error},
 {loglevel_access,info},
 {disk_sink_opts,
     [{rotation,
          [{compress,true},
           {size,41943040},
           {num_files,10},
           {buffer_size_max,52428800}]}]},
 {disk_sink_opts_xdcr_trace,
     [{rotation,[{compress,false},{size,83886080},{num_files,5}]}]},
 {net_kernel_verbosity,10}]
[ns_server:warn,2021-04-19T19:45:40.671Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter error_logger_mf_dir, which is given from command line
[ns_server:warn,2021-04-19T19:45:40.671Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter path_config_bindir, which is given from command line
[ns_server:warn,2021-04-19T19:45:40.672Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter path_config_etcdir, which is given from command line
[ns_server:warn,2021-04-19T19:45:40.672Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter path_config_libdir, which is given from command line
[ns_server:warn,2021-04-19T19:45:40.672Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter path_config_datadir, which is given from command line
[ns_server:warn,2021-04-19T19:45:40.672Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter path_config_tmpdir, which is given from command line
[ns_server:warn,2021-04-19T19:45:40.672Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter path_config_secdir, which is given from command line
[ns_server:warn,2021-04-19T19:45:40.672Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter nodefile, which is given from command line
[ns_server:warn,2021-04-19T19:45:40.672Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_default, which is given from command line
[ns_server:warn,2021-04-19T19:45:40.672Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_couchdb, which is given from command line
[ns_server:warn,2021-04-19T19:45:40.672Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_ns_server, which is given from command line
[ns_server:warn,2021-04-19T19:45:40.672Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_error_logger, which is given from command line
[ns_server:warn,2021-04-19T19:45:40.672Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_user, which is given from command line
[ns_server:warn,2021-04-19T19:45:40.672Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_menelaus, which is given from command line
[ns_server:warn,2021-04-19T19:45:40.672Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_ns_doctor, which is given from command line
[ns_server:warn,2021-04-19T19:45:40.672Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_stats, which is given from command line
[ns_server:warn,2021-04-19T19:45:40.672Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_rebalance, which is given from command line
[ns_server:warn,2021-04-19T19:45:40.672Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_cluster, which is given from command line
[ns_server:warn,2021-04-19T19:45:40.672Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_views, which is given from command line
[ns_server:warn,2021-04-19T19:45:40.672Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_mapreduce_errors, which is given from command line
[ns_server:warn,2021-04-19T19:45:40.672Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_xdcr, which is given from command line
[ns_server:warn,2021-04-19T19:45:40.672Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_xdcr_trace, which is given from command line
[ns_server:warn,2021-04-19T19:45:40.672Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_access, which is given from command line
[ns_server:warn,2021-04-19T19:45:40.673Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter disk_sink_opts, which is given from command line
[ns_server:warn,2021-04-19T19:45:40.673Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter disk_sink_opts_xdcr_trace, which is given from command line
[ns_server:warn,2021-04-19T19:45:40.673Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter net_kernel_verbosity, which is given from command line
[error_logger:info,2021-04-19T19:45:40.680Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.128.0>},
                       {name,local_tasks},
                       {mfargs,{local_tasks,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:45:40.689Z,nonode@nohost:ns_server_cluster_sup<0.127.0>:log_os_info:start_link:25]OS type: {unix,linux} Version: {4,19,128}
Runtime info: [{otp_release,"R16B03-1"},
               {erl_version,"5.10.4.0.0.1"},
               {erl_version_long,
                   "Erlang R16B03-1 (erts-5.10.4.0.0.1) [source-00852da] [64-bit] [smp:8:8] [async-threads:16] [kernel-poll:true]\n"},
               {system_arch_raw,"x86_64-unknown-linux-gnu"},
               {system_arch,"x86_64-unknown-linux-gnu"},
               {localtime,{{2021,4,19},{19,45,40}}},
               {memory,
                   [{total,111104928},
                    {processes,9551880},
                    {processes_used,9550760},
                    {system,101553048},
                    {atom,331249},
                    {atom_used,310220},
                    {binary,74104},
                    {code,7694133},
                    {ets,2240600}]},
               {loaded,
                   [ns_info,log_os_info,local_tasks,restartable,
                    ns_server_cluster_sup,calendar,ale_default_formatter,
                    'ale_logger-metakv','ale_logger-rebalance',
                    'ale_logger-xdcr_trace','ale_logger-menelaus',
                    'ale_logger-stats','ale_logger-access',io_lib_fread,
                    'ale_logger-ns_server','ale_logger-user',
                    'ale_logger-ns_doctor','ale_logger-cluster',
                    'ale_logger-xdcr',otp_internal,ns_log_sink,ale_disk_sink,
                    misc,couch_util,ns_server,filelib,cpu_sup,memsup,disksup,
                    os_mon,io,release_handler,overload,alarm_handler,sasl,
                    timer,tftp_sup,httpd_sup,httpc_handler_sup,httpc_cookie,
                    inets_trace,httpc_manager,httpc,httpc_profile_sup,
                    httpc_sup,ftp_sup,inets_sup,inets_app,ssl,lhttpc_manager,
                    lhttpc_sup,lhttpc,tls_connection_sup,ssl_session_cache,
                    ssl_pkix_db,ssl_manager,ssl_sup,ssl_app,crypto_server,
                    crypto_sup,crypto_app,ale_error_logger_handler,
                    'ale_logger-ale_logger','ale_logger-error_logger',
                    beam_opcodes,beam_dict,beam_asm,beam_validator,beam_z,
                    beam_flatten,beam_trim,beam_receive,beam_bsm,beam_peep,
                    beam_dead,beam_split,beam_type,beam_bool,beam_except,
                    beam_clean,beam_utils,beam_block,beam_jump,beam_a,
                    v3_codegen,v3_life,v3_kernel,sys_core_dsetel,erl_bifs,
                    sys_core_fold,cerl_trees,sys_core_inline,core_lib,cerl,
                    v3_core,erl_bits,erl_expand_records,sys_pre_expand,sofs,
                    erl_internal,sets,ordsets,erl_lint,compile,
                    dynamic_compile,ale_utils,io_lib_pretty,io_lib_format,
                    io_lib,ale_codegen,dict,ale,ale_dynamic_sup,ale_sup,
                    ale_app,epp,ns_bootstrap,child_erlang,file_io_server,
                    orddict,erl_eval,file,c,kernel_config,user_sup,
                    supervisor_bridge,standard_error,code_server,unicode,
                    hipe_unified_loader,gb_sets,ets,binary,code,file_server,
                    net_kernel,global_group,erl_distribution,filename,
                    inet_gethost_native,os,inet_parse,inet,inet_udp,
                    inet_config,inet_db,global,gb_trees,rpc,supervisor,kernel,
                    application_master,sys,application,gen_server,erl_parse,
                    proplists,erl_scan,lists,application_controller,proc_lib,
                    gen,gen_event,error_logger,heart,error_handler,
                    erts_internal,erlang,erl_prim_loader,prim_zip,zlib,
                    prim_file,prim_inet,prim_eval,init,otp_ring0]},
               {applications,
                   [{lhttpc,"Lightweight HTTP Client","1.3.0"},
                    {os_mon,"CPO  CXC 138 46","2.2.14"},
                    {public_key,"Public key infrastructure","0.21"},
                    {asn1,"The Erlang ASN1 compiler version 2.0.4","2.0.4"},
                    {kernel,"ERTS  CXC 138 10","2.16.4"},
                    {ale,"Another Logger for Erlang","4.6.0-3573-enterprise"},
                    {inets,"INETS  CXC 138 49","5.9.8"},
                    {ns_server,"Couchbase server","4.6.0-3573-enterprise"},
                    {crypto,"CRYPTO version 2","3.2"},
                    {ssl,"Erlang/OTP SSL application","5.3.3"},
                    {sasl,"SASL  CXC 138 11","2.3.4"},
                    {stdlib,"ERTS  CXC 138 10","1.19.4"}]},
               {pre_loaded,
                   [erts_internal,erlang,erl_prim_loader,prim_zip,zlib,
                    prim_file,prim_inet,prim_eval,init,otp_ring0]},
               {process_count,94},
               {node,nonode@nohost},
               {nodes,[]},
               {registered,
                   [ftp_sup,'sink-disk_xdcr',code_server,sasl_sup,
                    'sink-disk_debug',application_controller,
                    'sink-disk_error',local_tasks,'sink-disk_default',
                    ale_stats_events,kernel_safe_sup,inets_sup,ale,
                    standard_error,error_logger,lhttpc_sup,ale_sup,
                    lhttpc_manager,timer_server,standard_error_sup,
                    release_handler,httpd_sup,ale_dynamic_sup,overload,
                    alarm_handler,init,inet_db,rex,kernel_sup,'sink-ns_log',
                    global_name_server,sasl_safe_sup,crypto_server,crypto_sup,
                    file_server_2,tftp_sup,global_group,os_mon_sup,
                    'sink-disk_metakv',cpu_sup,tls_connection_sup,memsup,
                    ssl_sup,'sink-disk_access_int',disksup,'sink-disk_access',
                    ns_server_cluster_sup,httpc_sup,ssl_manager,
                    'sink-xdcr_trace',erl_prim_loader,'sink-disk_reports',
                    httpc_profile_sup,'sink-disk_stats',httpc_manager,
                    httpc_handler_sup,'sink-disk_xdcr_errors']},
               {cookie,nocookie},
               {wordsize,8},
               {wall_clock,3}]
[ns_server:info,2021-04-19T19:45:40.701Z,nonode@nohost:ns_server_cluster_sup<0.127.0>:log_os_info:start_link:27]Manifest:
["<?xml version=\"1.0\" encoding=\"UTF-8\"?>","<manifest>",
 "  <remote fetch=\"git://github.com/blevesearch/\" name=\"blevesearch\"/>",
 "  <remote fetch=\"git://github.com/couchbase/\" name=\"couchbase\" review=\"review.couchbase.org\"/>",
 "  <remote fetch=\"ssh://git@github.com/couchbase/\" name=\"couchbase-priv\" review=\"review.couchbase.org\"/>",
 "  <remote fetch=\"git://github.com/couchbasedeps/\" name=\"couchbasedeps\" review=\"review.couchbase.org\"/>",
 "  <remote fetch=\"git://github.com/couchbaselabs/\" name=\"couchbaselabs\" review=\"review.couchbase.org\"/>",
 "  ","  <default remote=\"couchbase\" revision=\"master\"/>","  ",
 "  <project groups=\"notdefault,enterprise\" name=\"backup\" path=\"goproj/src/github.com/couchbase/backup\" remote=\"couchbase-priv\" revision=\"469a5e8cc8661f35ab4af74fe45e92a3d89febed\"/>",
 "  <project name=\"bitset\" path=\"godeps/src/github.com/willf/bitset\" remote=\"couchbasedeps\" revision=\"28a4168144bb8ac95454e1f51c84da1933681ad4\"/>",
 "  <project name=\"blance\" path=\"godeps/src/github.com/couchbase/blance\" revision=\"5ce14d13954e04262b7eabfc6978776a4018402b\"/>",
 "  <project name=\"bleve\" path=\"godeps/src/github.com/blevesearch/bleve\" remote=\"blevesearch\" revision=\"f531835d5c212ee5f95c49d2debc28e65e6d1693\"/>",
 "  <project name=\"bleve-mapping-ui\" path=\"godeps/src/github.com/blevesearch/bleve-mapping-ui\" remote=\"blevesearch\" revision=\"b0453426dc1d59918cc763a970f1ad147b22ad6a\"/>",
 "  <project name=\"blevex\" path=\"godeps/src/github.com/blevesearch/blevex\" remote=\"blevesearch\" revision=\"918d980b0d244c8230c7d8c8ee40919f8d55ef88\"/>",
 "  <project name=\"bolt\" path=\"godeps/src/github.com/boltdb/bolt\" remote=\"couchbasedeps\" revision=\"51f99c862475898df9773747d3accd05a7ca33c1\"/>",
 "  <project name=\"buffer\" path=\"godeps/src/github.com/tdewolff/buffer\" remote=\"couchbasedeps\" revision=\"43cef5ba7b6ce99cc410632dad46cf1c6c97026e\"/>",
 "  <project groups=\"notdefault,build\" name=\"build\" path=\"cbbuild\" revision=\"ccd3ae52bbf0ade5fd59adcedba2b8cbbd16cd9b\">",
 "    <annotation name=\"VERSION\" value=\"4.6.0\"/>",
 "    <annotation name=\"BLD_NUM\" value=\"3573\"/>",
 "    <annotation name=\"RELEASE\" value=\"@RELEASE@\"/>",
 "    <annotation name=\"EDITION\" value=\"@EDITION@\"/>","  </project>",
 "  <project name=\"cbauth\" path=\"godeps/src/github.com/couchbase/cbauth\" revision=\"4a6d537777f57b291a8126f94dfbe3201c1d4efc\"/>",
 "  <project name=\"cbflag\" path=\"godeps/src/github.com/couchbase/cbflag\" revision=\"ce5c10adbb78c1212aefda73a85f8cfd1c3ae7e9\"/>",
 "  <project name=\"cbft\" path=\"goproj/src/github.com/couchbase/cbft\" revision=\"99f44266178dbe423890d8dd5bb9439ef2a71318\"/>",
 "  <project name=\"cbgt\" path=\"goproj/src/github.com/couchbase/cbgt\" revision=\"10790963d9cbada17ebfff728ea9298c1c97b7c5\"/>",
 "  <project groups=\"notdefault,enterprise\" name=\"cbq-gui\" path=\"goproj/src/github.com/couchbase/cbq-gui\" remote=\"couchbase-priv\" revision=\"1e19e5e34b64ca6b43a37de6166dac6e76803848\"/>",
 "  <project name=\"clog\" path=\"godeps/src/github.com/couchbase/clog\" revision=\"eebc98233c3e032eb6b9036575d51324ab5932e6\"/>",
 "  <project name=\"context\" path=\"godeps/src/github.com/gorilla/context\" remote=\"couchbasedeps\" revision=\"215affda49addc4c8ef7e2534915df2c8c35c6cd\"/>",
 "  <project name=\"couchbase-cli\" revision=\"951668b6b2fcaa5386b31d59df5004ff667e91e8\"/>",
 "  <project name=\"couchbase-examples\" revision=\"39ee1c2451ac2f2e86a6ff308e21e1201c49cafe\"/>",
 "  <project name=\"couchdb\" revision=\"7b950cfaa3ad30c75a7fcc7f4eb30b2df1a8bd5b\"/>",
 "  <project groups=\"notdefault,packaging\" name=\"couchdbx-app\" revision=\"be5f6ebaa12ac7c0b5382deb9b1b0efa7bf80497\"/>",
 "  <project groups=\"kv\" name=\"couchstore\" revision=\"9cf71ba60cf95f8b835b1040c68c85a4ddc653ee\"/>",
 "  <project name=\"crypto\" path=\"godeps/src/golang.org/x/crypto\" remote=\"couchbasedeps\" revision=\"f23ba3a5ee43012fcb4b92e1a2a405a92554f4f2\"/>",
 "  <project name=\"cznic-b\" path=\"godeps/src/github.com/cznic/b\" remote=\"couchbasedeps\" revision=\"b96e30f1b7bd34b0b9d8760798d67eca83d7f09e\"/>",
 "  <project name=\"dparval\" path=\"godeps/src/github.com/couchbase/dparval\" revision=\"9def03782da875a2477c05bf64985db3f19f59ae\"/>",
 "  <project groups=\"kv\" name=\"ep-engine\" revision=\"e4c8bcbbf20b52b11e93665901597875e10b2070\"/>",
 "  <project groups=\"kv\" name=\"forestdb\" revision=\"1d169510a5102e81547b1d3dc423eb37db908076\"/>",
 "  <project name=\"geocouch\" revision=\"74b4bab07713b233ca2780f9a9a3f7daa1a1dff4\"/>",
 "  <project name=\"go-bindata-assetfs\" path=\"godeps/src/github.com/elazarl/go-bindata-assetfs\" remote=\"couchbasedeps\" revision=\"57eb5e1fc594ad4b0b1dbea7b286d299e0cb43c2\"/>",
 "  <project name=\"go-couchbase\" path=\"godeps/src/github.com/couchbase/go-couchbase\" revision=\"e06e5adaf45e189d4cf3e471341af0bf80bcc312\"/>",
 "  <project name=\"go-jsonpointer\" path=\"godeps/src/github.com/dustin/go-jsonpointer\" remote=\"couchbasedeps\" revision=\"75939f54b39e7dafae879e61f65438dadc5f288c\"/>",
 "  <project name=\"go-metrics\" path=\"godeps/src/github.com/rcrowley/go-metrics\" remote=\"couchbasedeps\" revision=\"dee209f2455f101a5e4e593dea94872d2c62d85d\"/>",
 "  <project name=\"go-porterstemmer\" path=\"godeps/src/github.com/blevesearch/go-porterstemmer\" remote=\"blevesearch\" revision=\"23a2c8e5cf1f380f27722c6d2ae8896431dc7d0e\"/>",
 "  <project name=\"go-slab\" path=\"godeps/src/github.com/couchbase/go-slab\" revision=\"1f5f7f282713ccfab3f46b1610cb8da34bcf676f\"/>",
 "  <project name=\"go-zookeeper\" path=\"godeps/src/github.com/samuel/go-zookeeper\" remote=\"couchbasedeps\" revision=\"fa6674abf3f4580b946a01bf7a1ce4ba8766205b\"/>",
 "  <project name=\"go_json\" path=\"godeps/src/github.com/couchbase/go_json\" revision=\"f5a178ab380eb9a1911cf9c45b4159115b564169\"/>",
 "  <project name=\"go_n1ql\" path=\"godeps/src/github.com/couchbase/go_n1ql\" revision=\"6cf4e348b127e21f56e53eb8c3faaea56afdc588\"/>",
 "  <project name=\"gocb\" path=\"godeps/src/github.com/couchbase/gocb\" revision=\"d5b1a13c1e81f1255ca8155007b470db37ddeb25\"/>",
 "  <project name=\"godbc\" path=\"godeps/src/github.com/couchbase/godbc\" revision=\"adc62033c392ca9df8b5b42c0dda237576b39f9f\"/>",
 "  <project name=\"goforestdb\" path=\"godeps/src/github.com/couchbase/goforestdb\" revision=\"0b501227de0e8c55d99ed14e900eea1a1dbaf899\"/>",
 "  <project name=\"gojson\" path=\"godeps/src/github.com/dustin/gojson\" remote=\"couchbasedeps\" revision=\"af16e0e771e2ed110f2785564ae33931de8829e4\"/>",
 "  <project name=\"golang-snappy\" path=\"godeps/src/github.com/golang/snappy\" remote=\"couchbasedeps\" revision=\"723cc1e459b8eea2dea4583200fd60757d40097a\"/>",
 "  <project name=\"goleveldb\" path=\"godeps/src/github.com/syndtr/goleveldb\" remote=\"couchbasedeps\" revision=\"fa5b5c78794bc5c18f330361059f871ae8c2b9d6\"/>",
 "  <project name=\"gomemcached\" path=\"godeps/src/github.com/couchbase/gomemcached\" revision=\"4604300463c4a379d36d1427b17d3284a93f7621\"/>",
 "  <project name=\"gometa\" path=\"goproj/src/github.com/couchbase/gometa\" revision=\"7da5634cce1de744293acf27bb2aecc13ee50cc5\"/>",
 "  <project groups=\"kv\" name=\"googletest\" remote=\"couchbasedeps\" revision=\"f397fa5ec6365329b2e82eb2d8c03a7897bbefb5\"/>",
 "  <project name=\"goskiplist\" path=\"godeps/src/github.com/ryszard/goskiplist\" remote=\"couchbasedeps\" revision=\"2dfbae5fcf46374f166f8969cb07e167f1be6273\"/>",
 "  <project name=\"gosnappy\" path=\"godeps/src/github.com/syndtr/gosnappy\" remote=\"couchbasedeps\" revision=\"156a073208e131d7d2e212cb749feae7c339e846\"/>",
 "  <project name=\"goutils\" path=\"godeps/src/github.com/couchbase/goutils\" revision=\"5823a0cbaaa9008406021dc5daf80125ea30bba6\"/>",
 "  <project name=\"goxdcr\" path=\"goproj/src/github.com/couchbase/goxdcr\" revision=\"0f66d74c38453d0c1a620588edb4ee6a8fc22577\"/>",
 "  <project name=\"gtreap\" path=\"godeps/src/github.com/steveyen/gtreap\" remote=\"couchbasedeps\" revision=\"0abe01ef9be25c4aedc174758ec2d917314d6d70\"/>",
 "  <project name=\"indexing\" path=\"goproj/src/github.com/couchbase/indexing\" revision=\"1811cdbff66216861320b7657590e961b10b2c0a\"/>",
 "  <project name=\"levigo\" path=\"godeps/src/github.com/jmhodges/levigo\" remote=\"couchbasedeps\" revision=\"1ddad808d437abb2b8a55a950ec2616caa88969b\"/>",
 "  <project name=\"liner\" path=\"godeps/src/github.com/peterh/liner\" remote=\"couchbasedeps\" revision=\"ad1edfd30321d8f006ccf05f1e0524adeb943060\"/>",
 "  <project name=\"liner\" path=\"godeps/src/github.com/sbinet/liner\" remote=\"couchbasedeps\" revision=\"d9335eee40a45a4f5d74524c90040d6fe6013d50\"/>",
 "  <project groups=\"kv\" name=\"memcached\" revision=\"45a464250e1358593fa9f11ec010ddd992f0a717\"/>",
 "  <project name=\"minify\" path=\"godeps/src/github.com/tdewolff/minify\" remote=\"couchbasedeps\" revision=\"ede45cc53f43891267b1fe7c689db9c76d4ce0fb\"/>",
 "  <project name=\"mmap-go\" path=\"godeps/src/github.com/edsrzf/mmap-go\" remote=\"couchbasedeps\" revision=\"935e0e8a636ca4ba70b713f3e38a19e1b77739e8\"/>",
 "  <project name=\"moss\" path=\"godeps/src/github.com/couchbase/moss\" revision=\"c7cc82a67cf3fe50faf9a0697516b885e4fa34b9\"/>",
 "  <project groups=\"kv\" name=\"moxi\" revision=\"363c250e6087a61bf2d4bc8d6eff3325956be731\"/>",
 "  <project name=\"mux\" path=\"godeps/src/github.com/gorilla/mux\" remote=\"couchbasedeps\" revision=\"8a875a034c69b940914d83ea03d3f1299b4d094b\"/>",
 "  <project name=\"net\" path=\"godeps/src/golang.org/x/net\" remote=\"couchbasedeps\" revision=\"8968c61983e8f51a91b8c0ef25bf739278c89634\"/>",
 "  <project name=\"npipe\" path=\"godeps/src/github.com/natefinch/npipe\" remote=\"couchbasedeps\" revision=\"272c8150302e83f23d32a355364578c9c13ab20f\"/>",
 "  <project name=\"ns_server\" revision=\"b6c99dc71308f44261bbcc80688de02942d69f19\"/>",
 "  <project name=\"parse\" path=\"godeps/src/github.com/tdewolff/parse\" remote=\"couchbasedeps\" revision=\"0334a869253aca4b3a10c56c3f3139b394aec3a9\"/>",
 "  <project groups=\"kv\" name=\"platform\" revision=\"a80097d53c779b548d8c78b0a1886b8d44591b23\"/>",
 "  <project name=\"protobuf\" path=\"godeps/src/github.com/golang/protobuf\" remote=\"couchbasedeps\" revision=\"655cdfa588ea190e901bc5590e65d5621688847c\"/>",
 "  <project name=\"query\" path=\"goproj/src/github.com/couchbase/query\" revision=\"2012f9b883199299df53dec638a2b91c21907a53\"/>",
 "  <project name=\"query-ui\" revision=\"ff1f502b2f0c544ca68d2bda60d80fc3a01d573a\"/>",
 "  <project name=\"retriever\" path=\"godeps/src/github.com/couchbase/retriever\" revision=\"e3419088e4d3b4fe3aad3b364fdbe9a154f85f17\"/>",
 "  <project name=\"segment\" path=\"godeps/src/github.com/blevesearch/segment\" remote=\"blevesearch\" revision=\"db70c57796cc8c310613541dfade3dce627d09c7\"/>",
 "  <project groups=\"kv\" name=\"sigar\" revision=\"83bd88595f558987731a1baa3330f641bc36554c\"/>",
 "  <project name=\"strconv\" path=\"godeps/src/github.com/tdewolff/strconv\" remote=\"couchbasedeps\" revision=\"9b189f5be77f33c46776f24dbddb2a7ab32af214\"/>",
 "  <project groups=\"kv\" name=\"subjson\" revision=\"65d3f053e2d968aea00b60234a42e1d1c5b9f6d2\"/>",
 "  <project groups=\"solaris,notdefault\" name=\"sys\" path=\"godeps/src/golang.org/x/sys\" remote=\"couchbasedeps\" revision=\"9d4e42a20653790449273b3c85e67d6d8bae6e2e\"/>",
 "  <project name=\"testrunner\" revision=\"d63ed33d4130ecac236711b4156d41328728e42e\"/>",
 "  <project name=\"text\" path=\"godeps/src/golang.org/x/text\" remote=\"couchbasedeps\" revision=\"601048ad6acbab6cedd582db09b8c4839ff25b15\"/>",
 "  <project groups=\"kv\" name=\"tlm\" revision=\"29fafd6b365e58e9fc43fad749ce20c900890a6b\">",
 "    <copyfile dest=\"GNUmakefile\" src=\"GNUmakefile\"/>",
 "    <copyfile dest=\"Makefile\" src=\"Makefile\"/>",
 "    <copyfile dest=\"CMakeLists.txt\" src=\"CMakeLists.txt\"/>",
 "  </project>",
 "  <project name=\"ts\" path=\"godeps/src/github.com/olekukonko/ts\" remote=\"couchbasedeps\" revision=\"ecf753e7c962639ab5a1fb46f7da627d4c0a04b8\"/>",
 "  <project groups=\"notdefault,packaging\" name=\"voltron\" remote=\"couchbase-priv\" revision=\"876e25cffb99e0ae89078a0443b179bcb5d639c2\"/>",
 "</manifest>"]

[error_logger:info,2021-04-19T19:45:40.705Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.129.0>},
                       {name,timeout_diag_logger},
                       {mfargs,{timeout_diag_logger,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:45:40.708Z,nonode@nohost:dist_manager<0.130.0>:dist_manager:read_address_config_from_path:86]Reading ip config from "/opt/couchbase/var/lib/couchbase/ip_start"
[ns_server:info,2021-04-19T19:45:40.709Z,nonode@nohost:dist_manager<0.130.0>:dist_manager:read_address_config_from_path:86]Reading ip config from "/opt/couchbase/var/lib/couchbase/ip"
[ns_server:info,2021-04-19T19:45:40.710Z,nonode@nohost:dist_manager<0.130.0>:dist_manager:init:163]ip config not found. Looks like we're brand new node
[error_logger:info,2021-04-19T19:45:40.710Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,inet_gethost_native_sup}
             started: [{pid,<0.132.0>},{mfa,{inet_gethost_native,init,[[]]}}]

[error_logger:info,2021-04-19T19:45:40.711Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.131.0>},
                       {name,inet_gethost_native_sup},
                       {mfargs,{inet_gethost_native,start_link,[]}},
                       {restart_type,temporary},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:45:41.462Z,nonode@nohost:dist_manager<0.130.0>:dist_manager:bringup:214]Attempting to bring up net_kernel with name 'ns_1@127.0.0.1'
[error_logger:info,2021-04-19T19:45:41.474Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.134.0>},
                       {name,erl_epmd},
                       {mfargs,{erl_epmd,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:41.474Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.135.0>},
                       {name,auth},
                       {mfargs,{auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:41.475Z,ns_1@127.0.0.1:dist_manager<0.130.0>:dist_manager:configure_net_kernel:255]Set net_kernel vebosity to 10 -> 0
[error_logger:info,2021-04-19T19:45:41.475Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.136.0>},
                       {name,net_kernel},
                       {mfargs,
                           {net_kernel,start_link,
                               [['ns_1@127.0.0.1',longnames]]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:41.475Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_sup}
             started: [{pid,<0.133.0>},
                       {name,net_sup_dynamic},
                       {mfargs,
                           {erl_distribution,start_link,
                               [['ns_1@127.0.0.1',longnames]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,supervisor}]

[ns_server:info,2021-04-19T19:45:41.478Z,ns_1@127.0.0.1:dist_manager<0.130.0>:dist_manager:save_node:147]saving node to "/opt/couchbase/var/lib/couchbase/couchbase-server.node"
[ns_server:debug,2021-04-19T19:45:41.495Z,ns_1@127.0.0.1:dist_manager<0.130.0>:dist_manager:bringup:228]Attempted to save node name to disk: ok
[ns_server:debug,2021-04-19T19:45:41.495Z,ns_1@127.0.0.1:dist_manager<0.130.0>:dist_manager:wait_for_node:235]Waiting for connection to node 'babysitter_of_ns_1@127.0.0.1' to be established
[error_logger:info,2021-04-19T19:45:41.496Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'babysitter_of_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:45:41.506Z,ns_1@127.0.0.1:dist_manager<0.130.0>:dist_manager:wait_for_node:244]Observed node 'babysitter_of_ns_1@127.0.0.1' to come up
[error_logger:info,2021-04-19T19:45:41.513Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.130.0>},
                       {name,dist_manager},
                       {mfargs,{dist_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:41.515Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.141.0>},
                       {name,ns_cookie_manager},
                       {mfargs,{ns_cookie_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:41.516Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.142.0>},
                       {name,ns_cluster},
                       {mfargs,{ns_cluster,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:45:41.518Z,ns_1@127.0.0.1:ns_config_sup<0.143.0>:ns_config_sup:init:32]loading static ns_config from "/opt/couchbase/etc/couchbase/config"
[error_logger:info,2021-04-19T19:45:41.519Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.144.0>},
                       {name,ns_config_events},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_config_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:41.519Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.145.0>},
                       {name,ns_config_events_local},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,ns_config_events_local}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:45:41.572Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_config:load_config:1083]Loading static config from "/opt/couchbase/etc/couchbase/config"
[ns_server:info,2021-04-19T19:45:41.580Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_config:load_config:1097]Loading dynamic config from "/opt/couchbase/var/lib/couchbase/config/config.dat"
[ns_server:info,2021-04-19T19:45:41.582Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_config:load_config:1102]No dynamic config file found. Assuming we're brand new node
[ns_server:debug,2021-04-19T19:45:41.584Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_config:load_config:1105]Here's full dynamic config we loaded:
[[]]
[ns_server:info,2021-04-19T19:45:41.587Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_config:load_config:1126]Here's full dynamic config we loaded + static & default config:
[{roles_definitions,
  [{admin,[],
    [{name,<<"Admin">>},
     {desc,<<"Can manage ALL cluster features including security.">>}],
    [{[],all}]},
   {ro_admin,[],
    [{name,<<"Read Only Admin">>},{desc,<<"Can view ALL cluster features.">>}],
    [{[{bucket,any},password],none},
     {[{bucket,any},data],none},
     {[admin,security],[read]},
     {[admin],none},
     {[],[read]}]},
   {cluster_admin,[],
    [{name,<<"Cluster Admin">>},
     {desc,<<"Can manage all cluster features EXCEPT security.">>}],
    [{[admin],none},{[],all}]},
   {bucket_admin,
    [bucket_name],
    [{name,<<"Bucket Admin">>},
     {desc,
      <<"Can manage ALL bucket features for specified buckets (incl. start/stop XDCR)">>}],
    [{[{bucket,bucket_name},xdcr],[read,execute]},
     {[{bucket,bucket_name}],all},
     {[{bucket,any},settings],[read]},
     {[{bucket,any}],none},
     {[xdcr],none},
     {[admin],none},
     {[],[read]}]},
   {bucket_sasl,
    [bucket_name],
    [],
    [{[{bucket,bucket_name},data],all},
     {[{bucket,bucket_name},views],all},
     {[{bucket,bucket_name}],[read,flush]},
     {[pools],[read]}]},
   {views_admin,
    [bucket_name],
    [{name,<<"Views Admin">>},
     {desc,<<"Can manage views for specified buckets">>}],
    [{[{bucket,bucket_name},views],all},
     {[{bucket,bucket_name},data],[read]},
     {[{bucket,any},settings],[read]},
     {[{bucket,any}],none},
     {[xdcr],none},
     {[admin],none},
     {[],[read]}]},
   {replication_admin,[],
    [{name,<<"Replication Admin">>},
     {desc,<<"Can manage ONLY XDCR features (cluster AND bucket level)">>}],
    [{[{bucket,any},xdcr],all},
     {[{bucket,any},data],[read]},
     {[{bucket,any},settings],[read]},
     {[{bucket,any}],none},
     {[xdcr],all},
     {[admin],none},
     {[],[read]}]}]},
 {drop_request_memory_threshold_mib,undefined},
 {{request_limit,capi},undefined},
 {{request_limit,rest},undefined},
 {auto_failover_cfg,[{enabled,false},{timeout,120},{max_nodes,1},{count,0}]},
 {replication,[{enabled,true}]},
 {alert_limits,
  [{max_overhead_perc,50},{max_disk_used,90},{max_indexer_ram,75}]},
 {email_alerts,
  [{recipients,["root@localhost"]},
   {sender,"couchbase@localhost"},
   {enabled,false},
   {email_server,
    [{user,[]},{pass,"*****"},{host,"localhost"},{port,25},{encrypt,false}]},
   {alerts,
    [auto_failover_node,auto_failover_maximum_reached,
     auto_failover_other_nodes_down,auto_failover_cluster_too_small,
     auto_failover_disabled,ip,disk,overhead,ep_oom_errors,
     ep_item_commit_failed,audit_dropped_events,indexer_ram_max_usage,
     ep_clock_cas_drift_threshold_exceeded]}]},
 {{node,'ns_1@127.0.0.1',ns_log},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
   {filename,"/opt/couchbase/var/lib/couchbase/ns_log"}]},
 {{node,'ns_1@127.0.0.1',port_servers},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}]},
 {{node,'ns_1@127.0.0.1',moxi},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
   {port,11211},
   {verbosity,[]}]},
 {buckets,[{configs,[]}]},
 {fts_memory_quota,512},
 {memory_quota,7582},
 {{node,'ns_1@127.0.0.1',memcached_config},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   {[{interfaces,
      {memcached_config_mgr,omit_missing_mcd_ports,
       [{[{host,<<"*">>},{port,port},{maxconn,maxconn}]},
        {[{host,<<"*">>},
          {port,dedicated_port},
          {maxconn,dedicated_port_maxconn}]},
        {[{host,<<"*">>},
          {port,ssl_port},
          {maxconn,maxconn},
          {ssl,
           {[{key,
              <<"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem">>},
             {cert,
              <<"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem">>}]}}]}]}},
     {ssl_cipher_list,{"~s",[ssl_cipher_list]}},
     {ssl_minimum_protocol,{memcached_config_mgr,ssl_minimum_protocol,[]}},
     {connection_idle_time,connection_idle_time},
     {breakpad,
      {[{enabled,breakpad_enabled},
        {minidump_dir,{memcached_config_mgr,get_minidump_dir,[]}}]}},
     {extensions,
      [{[{module,<<"/opt/couchbase/lib/memcached/stdin_term_handler.so">>},
         {config,<<>>}]},
       {[{module,<<"/opt/couchbase/lib/memcached/file_logger.so">>},
         {config,
          {"cyclesize=~B;sleeptime=~B;filename=~s/~s",
           [log_cyclesize,log_sleeptime,log_path,log_prefix]}}]}]},
     {admin,{"~s",[admin_user]}},
     {verbosity,verbosity},
     {audit_file,{"~s",[audit_file]}},
     {dedupe_nmvb_maps,dedupe_nmvb_maps}]}]},
 {{node,'ns_1@127.0.0.1',memcached},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
   {port,11210},
   {dedicated_port,11209},
   {ssl_port,11207},
   {admin_user,"_admin"},
   {admin_pass,"*****"},
   {engines,
    [{membase,
      [{engine,"/opt/couchbase/lib/memcached/ep.so"},
       {static_config_string,"failpartialwarmup=false"}]},
     {memcached,
      [{engine,"/opt/couchbase/lib/memcached/default_engine.so"},
       {static_config_string,"vb0=true"}]}]},
   {config_path,"/opt/couchbase/var/lib/couchbase/config/memcached.json"},
   {audit_file,"/opt/couchbase/var/lib/couchbase/config/audit.json"},
   {log_path,"/opt/couchbase/var/lib/couchbase/logs"},
   {log_prefix,"memcached.log"},
   {log_generations,20},
   {log_cyclesize,10485760},
   {log_sleeptime,19},
   {log_rotation_period,39003}]},
 {{node,'ns_1@127.0.0.1',memcached_defaults},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
   {maxconn,30000},
   {dedicated_port_maxconn,5000},
   {ssl_cipher_list,"HIGH"},
   {connection_idle_time,0},
   {verbosity,0},
   {breakpad_enabled,true},
   {breakpad_minidump_dir_path,"/opt/couchbase/var/lib/couchbase/crash"},
   {dedupe_nmvb_maps,false}]},
 {memcached,[]},
 {{node,'ns_1@127.0.0.1',audit},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}]},
 {audit,
  [{auditd_enabled,false},
   {rotate_interval,86400},
   {rotate_size,20971520},
   {disabled,[]},
   {sync,[]},
   {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]},
 {{node,'ns_1@127.0.0.1',isasl},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
   {path,"/opt/couchbase/var/lib/couchbase/isasl.pw"}]},
 {remote_clusters,[]},
 {rest_creds,[{creds,[]}]},
 {{node,'ns_1@127.0.0.1',ssl_proxy_upstream_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   11215]},
 {{node,'ns_1@127.0.0.1',ssl_proxy_downstream_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   11214]},
 {{node,'ns_1@127.0.0.1',fts_http_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   8094]},
 {{node,'ns_1@127.0.0.1',indexer_stmaint_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   9105]},
 {{node,'ns_1@127.0.0.1',indexer_stcatchup_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   9104]},
 {{node,'ns_1@127.0.0.1',indexer_stinit_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   9103]},
 {{node,'ns_1@127.0.0.1',indexer_http_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   9102]},
 {{node,'ns_1@127.0.0.1',indexer_scan_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   9101]},
 {{node,'ns_1@127.0.0.1',indexer_admin_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   9100]},
 {{node,'ns_1@127.0.0.1',xdcr_rest_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   9998]},
 {{node,'ns_1@127.0.0.1',projector_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   9999]},
 {{node,'ns_1@127.0.0.1',ssl_query_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   18093]},
 {{node,'ns_1@127.0.0.1',query_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   8093]},
 {{node,'ns_1@127.0.0.1',ssl_capi_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   18092]},
 {{node,'ns_1@127.0.0.1',capi_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   8092]},
 {{node,'ns_1@127.0.0.1',ssl_rest_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   18091]},
 {{node,'ns_1@127.0.0.1',rest},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
   {port,8091},
   {port_meta,global}]},
 {{couchdb,max_parallel_replica_indexers},2},
 {{couchdb,max_parallel_indexers},4},
 {rest,[{port,8091}]},
 {{node,'ns_1@127.0.0.1',membership},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   active]},
 {server_groups,
  [[{uuid,<<"0">>},{name,<<"Group 1">>},{nodes,['ns_1@127.0.0.1']}]]},
 {nodes_wanted,['ns_1@127.0.0.1']},
 {{node,'ns_1@127.0.0.1',compaction_daemon},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
   {check_interval,30},
   {min_db_file_size,131072},
   {min_view_file_size,20971520}]},
 {set_view_update_daemon,
  [{update_interval,5000},
   {update_min_changes,5000},
   {replica_update_min_changes,5000}]},
 {autocompaction,
  [{database_fragmentation_threshold,{30,undefined}},
   {view_fragmentation_threshold,{30,undefined}}]},
 {max_bucket_count,10},
 {index_aware_rebalance_disabled,false},
 {{node,'ns_1@127.0.0.1',ldap_enabled},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   true]},
 {{node,'ns_1@127.0.0.1',is_enterprise},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   true]},
 {{node,'ns_1@127.0.0.1',config_version},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   {4,5}]},
 {{node,'ns_1@127.0.0.1',uuid},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   <<"360fb3d3641e00b1f4f22714c24e2a2a">>]}]
[error_logger:info,2021-04-19T19:45:41.590Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.146.0>},
                       {name,ns_config},
                       {mfargs,
                           {ns_config,start_link,
                               ["/opt/couchbase/etc/couchbase/config",
                                ns_config_default]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:41.592Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.149.0>},
                       {name,ns_config_remote},
                       {mfargs,
                           {ns_config_replica,start_link,
                               [{local,ns_config_remote}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:41.595Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.150.0>},
                       {name,ns_config_log},
                       {mfargs,{ns_config_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:41.596Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.143.0>},
                       {name,ns_config_sup},
                       {mfargs,{ns_config_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:45:41.598Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.152.0>},
                       {name,vbucket_filter_changes_registry},
                       {mfargs,
                           {ns_process_registry,start_link,
                               [vbucket_filter_changes_registry,
                                [{terminate_command,shutdown}]]}},
                       {restart_type,permanent},
                       {shutdown,100},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:41.600Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.153.0>},
                       {name,json_rpc_connection_sup},
                       {mfargs,{json_rpc_connection_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:45:41.613Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.156.0>},
                       {name,remote_monitors},
                       {mfargs,{remote_monitors,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:41.614Z,ns_1@127.0.0.1:menelaus_barrier<0.157.0>:one_shot_barrier:barrier_body:58]Barrier menelaus_barrier has started
[error_logger:info,2021-04-19T19:45:41.615Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.157.0>},
                       {name,menelaus_barrier},
                       {mfargs,{menelaus_sup,barrier_start_link,[]}},
                       {restart_type,temporary},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:41.615Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.158.0>},
                       {name,rest_lhttpc_pool},
                       {mfargs,
                           {lhttpc_manager,start_link,
                               [[{name,rest_lhttpc_pool},
                                 {connection_timeout,120000},
                                 {pool_size,20}]]}},
                       {restart_type,{permanent,1}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:45:41.644Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.160.0>:ns_ssl_services_setup:init:370]Used ssl options:
[{keyfile,"/opt/couchbase/var/lib/couchbase/config/ssl-cert-key.pem"},
 {certfile,"/opt/couchbase/var/lib/couchbase/config/ssl-cert-key.pem"},
 {versions,[tlsv1,'tlsv1.1','tlsv1.2']},
 {cacertfile,undefined},
 {dh,<<48,130,1,8,2,130,1,1,0,152,202,99,248,92,201,35,238,246,5,77,93,120,10,
       118,129,36,52,111,193,167,220,49,229,106,105,152,133,121,157,73,158,
       232,153,197,197,21,171,140,30,207,52,165,45,8,221,162,21,199,183,66,
       211,247,51,224,102,214,190,130,96,253,218,193,35,43,139,145,89,200,250,
       145,92,50,80,134,135,188,205,254,148,122,136,237,220,186,147,187,104,
       159,36,147,217,117,74,35,163,145,249,175,242,18,221,124,54,140,16,246,
       169,84,252,45,47,99,136,30,60,189,203,61,86,225,117,255,4,91,46,110,
       167,173,106,51,65,10,248,94,225,223,73,40,232,140,26,11,67,170,118,190,
       67,31,127,233,39,68,88,132,171,224,62,187,207,160,189,209,101,74,8,205,
       174,146,173,80,105,144,246,25,153,86,36,24,178,163,64,202,221,95,184,
       110,244,32,226,217,34,55,188,230,55,16,216,247,173,246,139,76,187,66,
       211,159,17,46,20,18,48,80,27,250,96,189,29,214,234,241,34,69,254,147,
       103,220,133,40,164,84,8,44,241,61,164,151,9,135,41,60,75,4,202,133,173,
       72,6,69,167,89,112,174,40,229,171,2,1,2>>},
 {ciphers,[{dhe_rsa,aes_256_cbc,sha256},
           {dhe_dss,aes_256_cbc,sha256},
           {rsa,aes_256_cbc,sha256},
           {dhe_rsa,aes_128_cbc,sha256},
           {dhe_dss,aes_128_cbc,sha256},
           {rsa,aes_128_cbc,sha256},
           {dhe_rsa,aes_256_cbc,sha},
           {dhe_dss,aes_256_cbc,sha},
           {rsa,aes_256_cbc,sha},
           {dhe_rsa,'3des_ede_cbc',sha},
           {dhe_dss,'3des_ede_cbc',sha},
           {rsa,'3des_ede_cbc',sha},
           {dhe_rsa,aes_128_cbc,sha},
           {dhe_dss,aes_128_cbc,sha},
           {rsa,aes_128_cbc,sha}]}]
[ns_server:debug,2021-04-19T19:45:42.761Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.160.0>:ns_server_cert:generate_cert_and_pkey:78]Generated certificate and private key in 1113347 us
[ns_server:debug,2021-04-19T19:45:42.762Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
cert_and_pkey ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080742}}]}|
 {<<"-----BEGIN CERTIFICATE-----\nMIIDAjCCAeqgAwIBAgIIFndZ/vr3iFgwDQYJKoZIhvcNAQELBQAwJDEiMCAGA1UE\nAxMZQ291Y2hiYXNlIFNlcnZlciBiODgwZTU4MjAeFw0xMzAxMDEwMDAwMDBaFw00\nOTEyMzEyMzU5NTlaMCQxIjAgBgNVBAMTGUNvdWNoYmFzZSBTZXJ2ZXIgYjg4MGU1\nODIwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDPKYjrGZUDKn7xXZhz\n/CcGig/KlI7xzgbLixQnJ5VLNHQOaIcz01bkH2SuTUnIg3i9awTEc/vdraqbL7dK\neAQZEWpnUrZo8sPI/sI9nYnAJttUCQD"...>>,
  <<"*****">>}]
[ns_server:debug,2021-04-19T19:45:42.762Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{local_changes_count,<<"360fb3d3641e00b1f4f22714c24e2a2a">>} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080742}}]}]
[error_logger:info,2021-04-19T19:45:42.823Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_ssl_services_sup}
             started: [{pid,<0.160.0>},
                       {name,ns_ssl_services_setup},
                       {mfargs,{ns_ssl_services_setup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:45:42.875Z,ns_1@127.0.0.1:<0.165.0>:menelaus_pluggable_ui:validate_plugin_spec:117]Loaded pluggable UI specification for fts

[ns_server:info,2021-04-19T19:45:42.875Z,ns_1@127.0.0.1:<0.165.0>:menelaus_pluggable_ui:validate_plugin_spec:117]Loaded pluggable UI specification for n1ql

[ns_server:debug,2021-04-19T19:45:42.902Z,ns_1@127.0.0.1:<0.165.0>:restartable:start_child:98]Started child process <0.167.0>
  MFA: {ns_ssl_services_setup,start_link_rest_service,[]}
[error_logger:info,2021-04-19T19:45:42.903Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_ssl_services_sup}
             started: [{pid,<0.165.0>},
                       {name,ns_rest_ssl_service},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_ssl_services_setup,
                                    start_link_rest_service,[]},
                                1000]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:42.903Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.159.0>},
                       {name,ns_ssl_services_sup},
                       {mfargs,{ns_ssl_services_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:45:42.921Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.184.0>},
                       {name,start_couchdb_node},
                       {mfargs,{ns_server_nodes_sup,start_couchdb_node,[]}},
                       {restart_type,{permanent,5}},
                       {shutdown,86400000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:42.921Z,ns_1@127.0.0.1:wait_link_to_couchdb_node<0.185.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:126]Waiting for ns_couchdb node to start
[error_logger:info,2021-04-19T19:45:42.921Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:45:42.923Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.188.0>,shutdown}}
[ns_server:debug,2021-04-19T19:45:42.923Z,ns_1@127.0.0.1:<0.186.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:45:42.923Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:45:43.124Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:45:43.125Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.191.0>,shutdown}}
[ns_server:debug,2021-04-19T19:45:43.125Z,ns_1@127.0.0.1:<0.186.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:45:43.125Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:45:43.326Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:45:43.327Z,ns_1@127.0.0.1:<0.186.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:45:43.327Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.194.0>,shutdown}}
[error_logger:info,2021-04-19T19:45:43.327Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:45:43.528Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:45:43.529Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.197.0>,shutdown}}
[ns_server:debug,2021-04-19T19:45:43.529Z,ns_1@127.0.0.1:<0.186.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:45:43.529Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:45:43.730Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:45:43.730Z,ns_1@127.0.0.1:<0.186.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:45:43.730Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.200.0>,shutdown}}
[error_logger:info,2021-04-19T19:45:43.731Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:45:43.932Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:45:43.933Z,ns_1@127.0.0.1:<0.186.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:45:43.933Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.203.0>,shutdown}}
[error_logger:info,2021-04-19T19:45:43.933Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:45:44.134Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:45:44.134Z,ns_1@127.0.0.1:<0.186.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:45:44.134Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.206.0>,shutdown}}
[error_logger:info,2021-04-19T19:45:44.135Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:45:44.335Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:45:44.335Z,ns_1@127.0.0.1:<0.186.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:45:44.335Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.209.0>,shutdown}}
[error_logger:info,2021-04-19T19:45:44.336Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:45:44.536Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:45:44.537Z,ns_1@127.0.0.1:<0.186.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:45:44.537Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.212.0>,shutdown}}
[error_logger:info,2021-04-19T19:45:44.537Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:45:44.738Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:45:44.738Z,ns_1@127.0.0.1:<0.186.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:45:44.739Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.215.0>,shutdown}}
[error_logger:info,2021-04-19T19:45:44.739Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:45:44.940Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:45:44.940Z,ns_1@127.0.0.1:<0.186.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:45:44.940Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.218.0>,shutdown}}
[error_logger:info,2021-04-19T19:45:44.940Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:45:45.141Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:45:45.174Z,ns_1@127.0.0.1:<0.186.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:45:45.375Z,ns_1@127.0.0.1:<0.186.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:45:45.577Z,ns_1@127.0.0.1:<0.186.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:45:45.779Z,ns_1@127.0.0.1:<0.186.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:45:45.980Z,ns_1@127.0.0.1:<0.186.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:45:46.181Z,ns_1@127.0.0.1:<0.186.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:45:46.383Z,ns_1@127.0.0.1:<0.186.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:45:46.584Z,ns_1@127.0.0.1:<0.186.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:45:46.787Z,ns_1@127.0.0.1:<0.186.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[error_logger:info,2021-04-19T19:45:47.239Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.232.0>},
                       {name,timer2_server},
                       {mfargs,{timer2,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:45:47.439Z,ns_1@127.0.0.1:ns_couchdb_port<0.184.0>:ns_port_server:log:210]ns_couchdb<0.184.0>: Apache CouchDB  (LogLevel=info) is starting.

[error_logger:info,2021-04-19T19:45:47.852Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.185.0>},
                       {name,wait_for_couchdb_node},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<ns_server_nodes_sup.0.8580514>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:47.862Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.155.0>:ns_storage_conf:setup_db_and_ix_paths:53]Initialize db_and_ix_paths variable with [{db_path,
                                           "/opt/couchbase/var/lib/couchbase/data"},
                                          {index_path,
                                           "/opt/couchbase/var/lib/couchbase/data"}]
[error_logger:info,2021-04-19T19:45:47.874Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.235.0>},
                       {name,ns_disksup},
                       {mfargs,{ns_disksup,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:47.877Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.236.0>},
                       {name,diag_handler_worker},
                       {mfargs,{work_queue,start_link,[diag_handler_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:45:47.880Z,ns_1@127.0.0.1:ns_server_sup<0.234.0>:dir_size:start_link:39]Starting quick version of dir_size with program name: godu
[error_logger:info,2021-04-19T19:45:47.884Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.237.0>},
                       {name,dir_size},
                       {mfargs,{dir_size,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:45:47.886Z,ns_1@127.0.0.1:ns_couchdb_port<0.184.0>:ns_port_server:log:210]ns_couchdb<0.184.0>: Apache CouchDB has started. Time to relax.
ns_couchdb<0.184.0>: 142: Booted. Waiting for shutdown request

[error_logger:info,2021-04-19T19:45:47.912Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.238.0>},
                       {name,request_throttler},
                       {mfargs,{request_throttler,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:warn,2021-04-19T19:45:47.920Z,ns_1@127.0.0.1:ns_log<0.239.0>:ns_log:read_logs:128]Couldn't load logs from "/opt/couchbase/var/lib/couchbase/ns_log" (perhaps it's first startup): {error,
                                                                                                 enoent}
[error_logger:info,2021-04-19T19:45:47.920Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.239.0>},
                       {name,ns_log},
                       {mfargs,{ns_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:47.920Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.240.0>},
                       {name,ns_crash_log_consumer},
                       {mfargs,{ns_log,start_link_crash_consumer,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:47.927Z,ns_1@127.0.0.1:ns_config_isasl_sync<0.241.0>:ns_config_isasl_sync:init:65]isasl_sync init: ["/opt/couchbase/var/lib/couchbase/isasl.pw","_admin"]
[ns_server:debug,2021-04-19T19:45:47.927Z,ns_1@127.0.0.1:ns_config_isasl_sync<0.241.0>:ns_config_isasl_sync:init:73]isasl_sync init buckets: []
[ns_server:debug,2021-04-19T19:45:47.928Z,ns_1@127.0.0.1:ns_config_isasl_sync<0.241.0>:ns_config_isasl_sync:writeSASLConf:145]Writing isasl passwd file: "/opt/couchbase/var/lib/couchbase/isasl.pw"
[ns_server:warn,2021-04-19T19:45:47.960Z,ns_1@127.0.0.1:ns_config_isasl_sync<0.241.0>:ns_memcached:connect:1307]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[error_logger:info,2021-04-19T19:45:48.961Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.241.0>},
                       {name,ns_config_isasl_sync},
                       {mfargs,{ns_config_isasl_sync,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:48.961Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.243.0>},
                       {name,ns_log_events},
                       {mfargs,{gen_event,start_link,[{local,ns_log_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:48.963Z,ns_1@127.0.0.1:ns_node_disco<0.246.0>:ns_node_disco:init:138]Initting ns_node_disco with []
[ns_server:debug,2021-04-19T19:45:48.963Z,ns_1@127.0.0.1:ns_cookie_manager<0.141.0>:ns_cookie_manager:do_cookie_sync:115]ns_cookie_manager do_cookie_sync
[error_logger:info,2021-04-19T19:45:48.963Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.245.0>},
                       {name,ns_node_disco_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,ns_node_disco_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[user:info,2021-04-19T19:45:48.963Z,ns_1@127.0.0.1:ns_cookie_manager<0.141.0>:ns_cookie_manager:do_cookie_init:93]Initial otp cookie generated: {sanitized,
                                  <<"igGdfqmbza2bbcUGcHlgLfqDrDSw4MuqpdcFvTedqb0=">>}
[ns_server:debug,2021-04-19T19:45:48.964Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{local_changes_count,<<"360fb3d3641e00b1f4f22714c24e2a2a">>} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{2,63786080748}}]}]
[ns_server:debug,2021-04-19T19:45:48.964Z,ns_1@127.0.0.1:<0.247.0>:ns_node_disco:do_nodes_wanted_updated_fun:224]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"igGdfqmbza2bbcUGcHlgLfqDrDSw4MuqpdcFvTedqb0=">>}
[ns_server:debug,2021-04-19T19:45:48.964Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
otp ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080748}}]},
 {cookie,{sanitized,<<"igGdfqmbza2bbcUGcHlgLfqDrDSw4MuqpdcFvTedqb0=">>}}]
[ns_server:debug,2021-04-19T19:45:48.966Z,ns_1@127.0.0.1:<0.247.0>:ns_node_disco:do_nodes_wanted_updated_fun:230]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"igGdfqmbza2bbcUGcHlgLfqDrDSw4MuqpdcFvTedqb0=">>}
[error_logger:info,2021-04-19T19:45:48.967Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.246.0>},
                       {name,ns_node_disco},
                       {mfargs,{ns_node_disco,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:48.969Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.249.0>},
                       {name,ns_node_disco_log},
                       {mfargs,{ns_node_disco_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:48.971Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.250.0>},
                       {name,ns_node_disco_conf_events},
                       {mfargs,{ns_node_disco_conf_events,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:48.981Z,ns_1@127.0.0.1:ns_config_rep<0.252.0>:ns_config_rep:init:68]init pulling
[ns_server:debug,2021-04-19T19:45:48.981Z,ns_1@127.0.0.1:ns_config_rep<0.252.0>:ns_config_rep:init:70]init pushing
[error_logger:info,2021-04-19T19:45:48.981Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.251.0>},
                       {name,ns_config_rep_merger},
                       {mfargs,{ns_config_rep,start_link_merger,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:48.982Z,ns_1@127.0.0.1:ns_config_rep<0.252.0>:ns_config_rep:init:74]init reannouncing
[ns_server:debug,2021-04-19T19:45:48.982Z,ns_1@127.0.0.1:ns_config_events<0.144.0>:ns_node_disco_conf_events:handle_event:50]ns_node_disco_conf_events config on otp
[ns_server:debug,2021-04-19T19:45:48.982Z,ns_1@127.0.0.1:ns_cookie_manager<0.141.0>:ns_cookie_manager:do_cookie_sync:115]ns_cookie_manager do_cookie_sync
[ns_server:debug,2021-04-19T19:45:48.982Z,ns_1@127.0.0.1:ns_config_events<0.144.0>:ns_node_disco_conf_events:handle_event:44]ns_node_disco_conf_events config on nodes_wanted
[ns_server:debug,2021-04-19T19:45:48.982Z,ns_1@127.0.0.1:ns_cookie_manager<0.141.0>:ns_cookie_manager:do_cookie_sync:115]ns_cookie_manager do_cookie_sync
[ns_server:debug,2021-04-19T19:45:48.982Z,ns_1@127.0.0.1:<0.256.0>:ns_node_disco:do_nodes_wanted_updated_fun:224]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"igGdfqmbza2bbcUGcHlgLfqDrDSw4MuqpdcFvTedqb0=">>}
[ns_server:debug,2021-04-19T19:45:48.982Z,ns_1@127.0.0.1:<0.257.0>:ns_node_disco:do_nodes_wanted_updated_fun:224]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"igGdfqmbza2bbcUGcHlgLfqDrDSw4MuqpdcFvTedqb0=">>}
[ns_server:debug,2021-04-19T19:45:48.983Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
otp ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080748}}]},
 {cookie,{sanitized,<<"igGdfqmbza2bbcUGcHlgLfqDrDSw4MuqpdcFvTedqb0=">>}}]
[ns_server:debug,2021-04-19T19:45:48.983Z,ns_1@127.0.0.1:<0.257.0>:ns_node_disco:do_nodes_wanted_updated_fun:230]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"igGdfqmbza2bbcUGcHlgLfqDrDSw4MuqpdcFvTedqb0=">>}
[ns_server:debug,2021-04-19T19:45:48.983Z,ns_1@127.0.0.1:<0.256.0>:ns_node_disco:do_nodes_wanted_updated_fun:230]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"igGdfqmbza2bbcUGcHlgLfqDrDSw4MuqpdcFvTedqb0=">>}
[ns_server:debug,2021-04-19T19:45:48.983Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
cert_and_pkey ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080742}}]}|
 {<<"-----BEGIN CERTIFICATE-----\nMIIDAjCCAeqgAwIBAgIIFndZ/vr3iFgwDQYJKoZIhvcNAQELBQAwJDEiMCAGA1UE\nAxMZQ291Y2hiYXNlIFNlcnZlciBiODgwZTU4MjAeFw0xMzAxMDEwMDAwMDBaFw00\nOTEyMzEyMzU5NTlaMCQxIjAgBgNVBAMTGUNvdWNoYmFzZSBTZXJ2ZXIgYjg4MGU1\nODIwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDPKYjrGZUDKn7xXZhz\n/CcGig/KlI7xzgbLixQnJ5VLNHQOaIcz01bkH2SuTUnIg3i9awTEc/vdraqbL7dK\neAQZEWpnUrZo8sPI/sI9nYnAJttUCQD"...>>,
  <<"*****">>}]
[ns_server:debug,2021-04-19T19:45:48.983Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
alert_limits ->
[{max_overhead_perc,50},{max_disk_used,90},{max_indexer_ram,75}]
[ns_server:debug,2021-04-19T19:45:48.983Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
audit ->
[{auditd_enabled,false},
 {rotate_interval,86400},
 {rotate_size,20971520},
 {disabled,[]},
 {sync,[]},
 {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]
[ns_server:debug,2021-04-19T19:45:48.983Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
auto_failover_cfg ->
[{enabled,false},{timeout,120},{max_nodes,1},{count,0}]
[ns_server:debug,2021-04-19T19:45:48.984Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
autocompaction ->
[{database_fragmentation_threshold,{30,undefined}},
 {view_fragmentation_threshold,{30,undefined}}]
[ns_server:debug,2021-04-19T19:45:48.984Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
buckets ->
[[],{configs,[]}]
[ns_server:debug,2021-04-19T19:45:48.984Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
drop_request_memory_threshold_mib ->
undefined
[ns_server:debug,2021-04-19T19:45:48.984Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
email_alerts ->
[{recipients,["root@localhost"]},
 {sender,"couchbase@localhost"},
 {enabled,false},
 {email_server,[{user,[]},
                {pass,"*****"},
                {host,"localhost"},
                {port,25},
                {encrypt,false}]},
 {alerts,[auto_failover_node,auto_failover_maximum_reached,
          auto_failover_other_nodes_down,auto_failover_cluster_too_small,
          auto_failover_disabled,ip,disk,overhead,ep_oom_errors,
          ep_item_commit_failed,audit_dropped_events,indexer_ram_max_usage,
          ep_clock_cas_drift_threshold_exceeded]}]
[ns_server:debug,2021-04-19T19:45:48.984Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
fts_memory_quota ->
512
[ns_server:debug,2021-04-19T19:45:48.984Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
index_aware_rebalance_disabled ->
false
[ns_server:debug,2021-04-19T19:45:48.984Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
max_bucket_count ->
10
[ns_server:debug,2021-04-19T19:45:48.984Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
memcached ->
[]
[ns_server:debug,2021-04-19T19:45:48.984Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
memory_quota ->
7582
[ns_server:debug,2021-04-19T19:45:48.984Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
nodes_wanted ->
['ns_1@127.0.0.1']
[ns_server:debug,2021-04-19T19:45:48.984Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
remote_clusters ->
[]
[ns_server:debug,2021-04-19T19:45:48.984Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
replication ->
[{enabled,true}]
[ns_server:debug,2021-04-19T19:45:48.985Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
rest ->
[{port,8091}]
[ns_server:debug,2021-04-19T19:45:48.985Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
rest_creds ->
[{creds,[]}]
[ns_server:debug,2021-04-19T19:45:48.985Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
roles_definitions ->
[{admin,[],
        [{name,<<"Admin">>},
         {desc,<<"Can manage ALL cluster features including security.">>}],
        [{[],all}]},
 {ro_admin,[],
           [{name,<<"Read Only Admin">>},
            {desc,<<"Can view ALL cluster features.">>}],
           [{[{bucket,any},password],none},
            {[{bucket,any},data],none},
            {[admin,security],[read]},
            {[admin],none},
            {[],[read]}]},
 {cluster_admin,[],
                [{name,<<"Cluster Admin">>},
                 {desc,<<"Can manage all cluster features EXCEPT security.">>}],
                [{[admin],none},{[],all}]},
 {bucket_admin,[bucket_name],
               [{name,<<"Bucket Admin">>},
                {desc,<<"Can manage ALL bucket features for specified buckets (incl. start/stop XDCR)">>}],
               [{[{bucket,bucket_name},xdcr],[read,execute]},
                {[{bucket,bucket_name}],all},
                {[{bucket,any},settings],[read]},
                {[{bucket,any}],none},
                {[xdcr],none},
                {[admin],none},
                {[],[read]}]},
 {bucket_sasl,[bucket_name],
              [],
              [{[{bucket,bucket_name},data],all},
               {[{bucket,bucket_name},views],all},
               {[{bucket,bucket_name}],[read,flush]},
               {[pools],[read]}]},
 {views_admin,[bucket_name],
              [{name,<<"Views Admin">>},
               {desc,<<"Can manage views for specified buckets">>}],
              [{[{bucket,bucket_name},views],all},
               {[{bucket,bucket_name},data],[read]},
               {[{bucket,any},settings],[read]},
               {[{bucket,any}],none},
               {[xdcr],none},
               {[admin],none},
               {[],[read]}]},
 {replication_admin,[],
                    [{name,<<"Replication Admin">>},
                     {desc,<<"Can manage ONLY XDCR features (cluster AND bucket level)">>}],
                    [{[{bucket,any},xdcr],all},
                     {[{bucket,any},data],[read]},
                     {[{bucket,any},settings],[read]},
                     {[{bucket,any}],none},
                     {[xdcr],all},
                     {[admin],none},
                     {[],[read]}]}]
[ns_server:debug,2021-04-19T19:45:48.986Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
server_groups ->
[[{uuid,<<"0">>},{name,<<"Group 1">>},{nodes,['ns_1@127.0.0.1']}]]
[ns_server:debug,2021-04-19T19:45:48.986Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
set_view_update_daemon ->
[{update_interval,5000},
 {update_min_changes,5000},
 {replica_update_min_changes,5000}]
[ns_server:debug,2021-04-19T19:45:48.986Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{couchdb,max_parallel_indexers} ->
4
[ns_server:debug,2021-04-19T19:45:48.986Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{couchdb,max_parallel_replica_indexers} ->
2
[ns_server:debug,2021-04-19T19:45:48.986Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{request_limit,capi} ->
undefined
[ns_server:debug,2021-04-19T19:45:48.986Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{request_limit,rest} ->
undefined
[ns_server:debug,2021-04-19T19:45:48.986Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',audit} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}]
[ns_server:debug,2021-04-19T19:45:48.986Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',capi_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|8092]
[ns_server:debug,2021-04-19T19:45:48.986Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',compaction_daemon} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
 {check_interval,30},
 {min_db_file_size,131072},
 {min_view_file_size,20971520}]
[ns_server:debug,2021-04-19T19:45:48.986Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',config_version} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|{4,5}]
[error_logger:info,2021-04-19T19:45:48.986Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.252.0>},
                       {name,ns_config_rep},
                       {mfargs,{ns_config_rep,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:48.986Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',fts_http_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|8094]
[error_logger:info,2021-04-19T19:45:48.986Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.244.0>},
                       {name,ns_node_disco_sup},
                       {mfargs,{ns_node_disco_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2021-04-19T19:45:48.986Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',indexer_admin_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|9100]
[ns_server:debug,2021-04-19T19:45:48.986Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',indexer_http_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|9102]
[ns_server:debug,2021-04-19T19:45:48.987Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',indexer_scan_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|9101]
[ns_server:debug,2021-04-19T19:45:48.987Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',indexer_stcatchup_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|9104]
[ns_server:debug,2021-04-19T19:45:48.987Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',indexer_stinit_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|9103]
[ns_server:debug,2021-04-19T19:45:48.987Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',indexer_stmaint_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|9105]
[ns_server:debug,2021-04-19T19:45:48.986Z,ns_1@127.0.0.1:ns_config_rep<0.252.0>:ns_config_rep:do_push_keys:321]Replicating some config keys ([alert_limits,audit,auto_failover_cfg,
                               autocompaction,buckets,cert_and_pkey,
                               drop_request_memory_threshold_mib,email_alerts,
                               fts_memory_quota,
                               index_aware_rebalance_disabled,
                               max_bucket_count,memcached,memory_quota,
                               nodes_wanted,otp,remote_clusters,replication,
                               rest,rest_creds,roles_definitions,
                               server_groups,set_view_update_daemon,
                               {couchdb,max_parallel_indexers},
                               {couchdb,max_parallel_replica_indexers},
                               {local_changes_count,
                                   <<"360fb3d3641e00b1f4f22714c24e2a2a">>},
                               {request_limit,capi},
                               {request_limit,rest},
                               {node,'ns_1@127.0.0.1',audit},
                               {node,'ns_1@127.0.0.1',capi_port},
                               {node,'ns_1@127.0.0.1',compaction_daemon},
                               {node,'ns_1@127.0.0.1',config_version},
                               {node,'ns_1@127.0.0.1',fts_http_port},
                               {node,'ns_1@127.0.0.1',indexer_admin_port},
                               {node,'ns_1@127.0.0.1',indexer_http_port},
                               {node,'ns_1@127.0.0.1',indexer_scan_port},
                               {node,'ns_1@127.0.0.1',indexer_stcatchup_port},
                               {node,'ns_1@127.0.0.1',indexer_stinit_port},
                               {node,'ns_1@127.0.0.1',indexer_stmaint_port},
                               {node,'ns_1@127.0.0.1',is_enterprise},
                               {node,'ns_1@127.0.0.1',isasl},
                               {node,'ns_1@127.0.0.1',ldap_enabled},
                               {node,'ns_1@127.0.0.1',membership},
                               {node,'ns_1@127.0.0.1',memcached},
                               {node,'ns_1@127.0.0.1',memcached_config},
                               {node,'ns_1@127.0.0.1',memcached_defaults},
                               {node,'ns_1@127.0.0.1',moxi},
                               {node,'ns_1@127.0.0.1',ns_log},
                               {node,'ns_1@127.0.0.1',port_servers},
                               {node,'ns_1@127.0.0.1',projector_port},
                               {node,'ns_1@127.0.0.1',query_port},
                               {node,'ns_1@127.0.0.1',rest},
                               {node,'ns_1@127.0.0.1',ssl_capi_port},
                               {node,'ns_1@127.0.0.1',
                                   ssl_proxy_downstream_port},
                               {node,'ns_1@127.0.0.1',ssl_proxy_upstream_port},
                               {node,'ns_1@127.0.0.1',ssl_query_port},
                               {node,'ns_1@127.0.0.1',ssl_rest_port},
                               {node,'ns_1@127.0.0.1',uuid},
                               {node,'ns_1@127.0.0.1',xdcr_rest_port}]..)
[ns_server:debug,2021-04-19T19:45:48.987Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',is_enterprise} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|true]
[ns_server:debug,2021-04-19T19:45:48.987Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',isasl} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
 {path,"/opt/couchbase/var/lib/couchbase/isasl.pw"}]
[ns_server:debug,2021-04-19T19:45:48.987Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ldap_enabled} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|true]
[ns_server:debug,2021-04-19T19:45:48.987Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',membership} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
 active]
[ns_server:debug,2021-04-19T19:45:48.988Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',memcached} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
 {port,11210},
 {dedicated_port,11209},
 {ssl_port,11207},
 {admin_user,"_admin"},
 {admin_pass,"*****"},
 {engines,[{membase,[{engine,"/opt/couchbase/lib/memcached/ep.so"},
                     {static_config_string,"failpartialwarmup=false"}]},
           {memcached,[{engine,"/opt/couchbase/lib/memcached/default_engine.so"},
                       {static_config_string,"vb0=true"}]}]},
 {config_path,"/opt/couchbase/var/lib/couchbase/config/memcached.json"},
 {audit_file,"/opt/couchbase/var/lib/couchbase/config/audit.json"},
 {log_path,"/opt/couchbase/var/lib/couchbase/logs"},
 {log_prefix,"memcached.log"},
 {log_generations,20},
 {log_cyclesize,10485760},
 {log_sleeptime,19},
 {log_rotation_period,39003}]
[ns_server:debug,2021-04-19T19:45:48.988Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',memcached_config} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
 {[{interfaces,
    {memcached_config_mgr,omit_missing_mcd_ports,
     [{[{host,<<"*">>},{port,port},{maxconn,maxconn}]},
      {[{host,<<"*">>},
        {port,dedicated_port},
        {maxconn,dedicated_port_maxconn}]},
      {[{host,<<"*">>},
        {port,ssl_port},
        {maxconn,maxconn},
        {ssl,
         {[{key,
            <<"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem">>},
           {cert,
            <<"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem">>}]}}]}]}},
   {ssl_cipher_list,{"~s",[ssl_cipher_list]}},
   {ssl_minimum_protocol,{memcached_config_mgr,ssl_minimum_protocol,[]}},
   {connection_idle_time,connection_idle_time},
   {breakpad,
    {[{enabled,breakpad_enabled},
      {minidump_dir,{memcached_config_mgr,get_minidump_dir,[]}}]}},
   {extensions,
    [{[{module,<<"/opt/couchbase/lib/memcached/stdin_term_handler.so">>},
       {config,<<>>}]},
     {[{module,<<"/opt/couchbase/lib/memcached/file_logger.so">>},
       {config,
        {"cyclesize=~B;sleeptime=~B;filename=~s/~s",
         [log_cyclesize,log_sleeptime,log_path,log_prefix]}}]}]},
   {admin,{"~s",[admin_user]}},
   {verbosity,verbosity},
   {audit_file,{"~s",[audit_file]}},
   {dedupe_nmvb_maps,dedupe_nmvb_maps}]}]
[ns_server:debug,2021-04-19T19:45:48.988Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',memcached_defaults} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
 {maxconn,30000},
 {dedicated_port_maxconn,5000},
 {ssl_cipher_list,"HIGH"},
 {connection_idle_time,0},
 {verbosity,0},
 {breakpad_enabled,true},
 {breakpad_minidump_dir_path,"/opt/couchbase/var/lib/couchbase/crash"},
 {dedupe_nmvb_maps,false}]
[ns_server:debug,2021-04-19T19:45:48.988Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',moxi} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
 {port,11211},
 {verbosity,[]}]
[ns_server:debug,2021-04-19T19:45:48.989Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ns_log} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
 {filename,"/opt/couchbase/var/lib/couchbase/ns_log"}]
[ns_server:debug,2021-04-19T19:45:48.989Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',port_servers} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}]
[ns_server:debug,2021-04-19T19:45:48.989Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',projector_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|9999]
[ns_server:debug,2021-04-19T19:45:48.989Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',query_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|8093]
[ns_server:debug,2021-04-19T19:45:48.989Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',rest} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
 {port,8091},
 {port_meta,global}]
[ns_server:debug,2021-04-19T19:45:48.989Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ssl_capi_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|18092]
[ns_server:debug,2021-04-19T19:45:48.989Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ssl_proxy_downstream_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|11214]
[ns_server:debug,2021-04-19T19:45:48.989Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ssl_proxy_upstream_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|11215]
[ns_server:debug,2021-04-19T19:45:48.989Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ssl_query_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|18093]
[ns_server:debug,2021-04-19T19:45:48.989Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ssl_rest_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|18091]
[ns_server:debug,2021-04-19T19:45:48.989Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',uuid} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
 <<"360fb3d3641e00b1f4f22714c24e2a2a">>]
[ns_server:debug,2021-04-19T19:45:48.990Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',xdcr_rest_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|9998]
[ns_server:debug,2021-04-19T19:45:48.990Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{local_changes_count,<<"360fb3d3641e00b1f4f22714c24e2a2a">>} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{2,63786080748}}]}]
[error_logger:info,2021-04-19T19:45:48.990Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.260.0>},
                       {name,vbucket_map_mirror},
                       {mfargs,{vbucket_map_mirror,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:48.994Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.262.0>},
                       {name,bucket_info_cache},
                       {mfargs,{bucket_info_cache,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:48.995Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.265.0>},
                       {name,ns_tick_event},
                       {mfargs,{gen_event,start_link,[{local,ns_tick_event}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:48.995Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.266.0>},
                       {name,buckets_events},
                       {mfargs,
                           {gen_event,start_link,[{local,buckets_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:48.999Z,ns_1@127.0.0.1:ns_log_events<0.243.0>:ns_mail_log:init:44]ns_mail_log started up
[error_logger:info,2021-04-19T19:45:48.999Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_mail_sup}
             started: [{pid,<0.268.0>},
                       {name,ns_mail_log},
                       {mfargs,{ns_mail_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:49.000Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.267.0>},
                       {name,ns_mail_sup},
                       {mfargs,{ns_mail_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:45:49.000Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.269.0>},
                       {name,ns_stats_event},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_stats_event}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:49.002Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.270.0>},
                       {name,samples_loader_tasks},
                       {mfargs,{samples_loader_tasks,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:49.008Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_heart_sup}
             started: [{pid,<0.272.0>},
                       {name,ns_heart},
                       {mfargs,{ns_heart,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:49.009Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_heart_sup}
             started: [{pid,<0.275.0>},
                       {name,ns_heart_slow_updater},
                       {mfargs,{ns_heart,start_link_slow_updater,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:49.009Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.271.0>},
                       {name,ns_heart_sup},
                       {mfargs,{ns_heart_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2021-04-19T19:45:49.011Z,ns_1@127.0.0.1:ns_heart<0.272.0>:ns_heart:grab_latest_stats:259]Ignoring failure to grab "@system" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,117}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,255}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,249}]},
                 {ns_heart,update_current_status,1,
                           [{file,"src/ns_heart.erl"},{line,186}]},
                 {ns_heart,handle_info,2,
                           [{file,"src/ns_heart.erl"},{line,118}]}]}}

[ns_server:debug,2021-04-19T19:45:49.012Z,ns_1@127.0.0.1:ns_heart<0.272.0>:ns_heart:grab_latest_stats:259]Ignoring failure to grab "@system-processes" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-processes-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,117}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,255}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,249}]},
                 {ns_heart,update_current_status,1,
                           [{file,"src/ns_heart.erl"},{line,186}]}]}}

[error_logger:info,2021-04-19T19:45:49.014Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_doctor_sup}
             started: [{pid,<0.278.0>},
                       {name,ns_doctor_events},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_doctor_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:49.024Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_doctor_sup}
             started: [{pid,<0.279.0>},
                       {name,ns_doctor},
                       {mfargs,{ns_doctor,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:49.024Z,ns_1@127.0.0.1:<0.276.0>:restartable:start_child:98]Started child process <0.277.0>
  MFA: {ns_doctor_sup,start_link,[]}
[error_logger:info,2021-04-19T19:45:49.024Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.276.0>},
                       {name,ns_doctor_sup},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_doctor_sup,start_link,[]},infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:45:49.035Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.283.0>},
                       {name,remote_clusters_info},
                       {mfargs,{remote_clusters_info,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:49.035Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.284.0>},
                       {name,master_activity_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,master_activity_events}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:49.041Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.285.0>},
                       {name,xdcr_ckpt_store},
                       {mfargs,{simple_store,start_link,[xdcr_ckpt_data]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:49.041Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.286.0>},
                       {name,metakv_worker},
                       {mfargs,{work_queue,start_link,[metakv_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:49.041Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.287.0>},
                       {name,index_events},
                       {mfargs,{gen_event,start_link,[{local,index_events}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:45:49.042Z,ns_1@127.0.0.1:ns_couchdb_port<0.184.0>:ns_port_server:log:210]ns_couchdb<0.184.0>: working as port

[ns_server:debug,2021-04-19T19:45:49.042Z,ns_1@127.0.0.1:ns_heart<0.272.0>:ns_heart:grab_local_xdcr_replications:460]Ignoring exception getting xdcr replication infos
{exit,{noproc,{gen_server,call,[xdc_replication_sup,which_children,infinity]}},
      [{gen_server,call,3,[{file,"gen_server.erl"},{line,188}]},
       {xdc_replication_sup,all_local_replication_infos,0,
                            [{file,"src/xdc_replication_sup.erl"},{line,58}]},
       {ns_heart,grab_local_xdcr_replications,0,
                 [{file,"src/ns_heart.erl"},{line,439}]},
       {ns_heart,current_status_slow_inner,0,
                 [{file,"src/ns_heart.erl"},{line,317}]},
       {ns_heart,current_status_slow,1,[{file,"src/ns_heart.erl"},{line,249}]},
       {ns_heart,update_current_status,1,
                 [{file,"src/ns_heart.erl"},{line,186}]},
       {ns_heart,handle_info,2,[{file,"src/ns_heart.erl"},{line,118}]},
       {gen_server,handle_msg,5,[{file,"gen_server.erl"},{line,604}]}]}
[error_logger:info,2021-04-19T19:45:49.046Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.288.0>},
                       {name,index_settings_manager},
                       {mfargs,{index_settings_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:49.049Z,ns_1@127.0.0.1:ns_heart<0.272.0>:cluster_logs_collection_task:maybe_build_cluster_logs_task:43]Ignoring exception trying to read cluster_logs_collection_task_status table: error:badarg
[error_logger:info,2021-04-19T19:45:49.052Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.292.0>},
                       {name,menelaus_ui_auth},
                       {mfargs,{menelaus_ui_auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:49.055Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.294.0>},
                       {name,menelaus_local_auth},
                       {mfargs,{menelaus_local_auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:49.062Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.295.0>},
                       {name,menelaus_web_cache},
                       {mfargs,{menelaus_web_cache,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:49.064Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.296.0>},
                       {name,menelaus_stats_gatherer},
                       {mfargs,{menelaus_stats_gatherer,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:49.065Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.297.0>},
                       {name,json_rpc_events},
                       {mfargs,
                           {gen_event,start_link,[{local,json_rpc_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:49.071Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.275.0>:ns_heart:grab_latest_stats:259]Ignoring failure to grab "@system" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,117}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,255}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,249}]},
                 {ns_heart,slow_updater_loop,0,
                           [{file,"src/ns_heart.erl"},{line,243}]},
                 {proc_lib,init_p_do_apply,3,
                           [{file,"proc_lib.erl"},{line,239}]}]}}

[ns_server:debug,2021-04-19T19:45:49.072Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.275.0>:ns_heart:grab_latest_stats:259]Ignoring failure to grab "@system-processes" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-processes-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,117}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,255}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,249}]},
                 {ns_heart,slow_updater_loop,0,
                           [{file,"src/ns_heart.erl"},{line,243}]}]}}

[ns_server:debug,2021-04-19T19:45:49.073Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.275.0>:ns_heart:grab_local_xdcr_replications:460]Ignoring exception getting xdcr replication infos
{exit,{noproc,{gen_server,call,[xdc_replication_sup,which_children,infinity]}},
      [{gen_server,call,3,[{file,"gen_server.erl"},{line,188}]},
       {xdc_replication_sup,all_local_replication_infos,0,
                            [{file,"src/xdc_replication_sup.erl"},{line,58}]},
       {ns_heart,grab_local_xdcr_replications,0,
                 [{file,"src/ns_heart.erl"},{line,439}]},
       {ns_heart,current_status_slow_inner,0,
                 [{file,"src/ns_heart.erl"},{line,317}]},
       {ns_heart,current_status_slow,1,[{file,"src/ns_heart.erl"},{line,249}]},
       {ns_heart,slow_updater_loop,0,[{file,"src/ns_heart.erl"},{line,243}]},
       {proc_lib,init_p_do_apply,3,[{file,"proc_lib.erl"},{line,239}]}]}
[ns_server:debug,2021-04-19T19:45:49.073Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.275.0>:cluster_logs_collection_task:maybe_build_cluster_logs_task:43]Ignoring exception trying to read cluster_logs_collection_task_status table: error:badarg
[ns_server:info,2021-04-19T19:45:49.073Z,ns_1@127.0.0.1:menelaus_sup<0.290.0>:menelaus_pluggable_ui:validate_plugin_spec:117]Loaded pluggable UI specification for fts

[ns_server:info,2021-04-19T19:45:49.073Z,ns_1@127.0.0.1:menelaus_sup<0.290.0>:menelaus_pluggable_ui:validate_plugin_spec:117]Loaded pluggable UI specification for n1ql

[error_logger:info,2021-04-19T19:45:49.074Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.303.0>},
                       {name,menelaus_web},
                       {mfargs,{menelaus_web,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:49.077Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.320.0>},
                       {name,menelaus_event},
                       {mfargs,{menelaus_event,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:49.081Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.321.0>},
                       {name,hot_keys_keeper},
                       {mfargs,{hot_keys_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:49.087Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.322.0>},
                       {name,menelaus_web_alerts_srv},
                       {mfargs,{menelaus_web_alerts_srv,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:49.096Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.323.0>},
                       {name,menelaus_cbauth},
                       {mfargs,{menelaus_cbauth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[user:info,2021-04-19T19:45:49.096Z,ns_1@127.0.0.1:ns_server_sup<0.234.0>:menelaus_sup:start_link:46]Couchbase Server has started on web port 8091 on node 'ns_1@127.0.0.1'. Version: "4.6.0-3573-enterprise".
[error_logger:info,2021-04-19T19:45:49.097Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.290.0>},
                       {name,menelaus},
                       {mfargs,{menelaus_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:45:49.097Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.327.0>},
                       {name,ns_ports_setup},
                       {mfargs,{ns_ports_setup,start,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:49.100Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_agent_sup}
             started: [{pid,<0.330.0>},
                       {name,service_agent_children_sup},
                       {mfargs,
                           {supervisor,start_link,
                               [{local,service_agent_children_sup},
                                service_agent_sup,child]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:45:49.100Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_agent_sup}
             started: [{pid,<0.331.0>},
                       {name,service_agent_worker},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<service_agent_sup.0.29791682>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:49.101Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.329.0>},
                       {name,service_agent_sup},
                       {mfargs,{service_agent_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:45:49.112Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.333.0>},
                       {name,ns_memcached_sockets_pool},
                       {mfargs,{ns_memcached_sockets_pool,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:49.112Z,ns_1@127.0.0.1:ns_audit_cfg<0.334.0>:ns_audit_cfg:write_audit_json:158]Writing new content to "/opt/couchbase/var/lib/couchbase/config/audit.json" : [{auditd_enabled,
                                                                                false},
                                                                               {disabled,
                                                                                []},
                                                                               {log_path,
                                                                                "/opt/couchbase/var/lib/couchbase/logs"},
                                                                               {rotate_interval,
                                                                                86400},
                                                                               {rotate_size,
                                                                                20971520},
                                                                               {sync,
                                                                                []},
                                                                               {version,
                                                                                1},
                                                                               {descriptors_path,
                                                                                "/opt/couchbase/etc/security"}]
[ns_server:debug,2021-04-19T19:45:49.115Z,ns_1@127.0.0.1:ns_ports_setup<0.327.0>:ns_ports_manager:set_dynamic_children:54]Setting children [memcached,saslauthd_port,xdcr_proxy]
[ns_server:debug,2021-04-19T19:45:49.122Z,ns_1@127.0.0.1:ns_ports_setup<0.327.0>:ns_ports_setup:set_children:72]Monitor ns_child_ports_sup <11632.72.0>
[ns_server:debug,2021-04-19T19:45:49.131Z,ns_1@127.0.0.1:ns_audit_cfg<0.334.0>:ns_audit_cfg:handle_info:107]Instruct memcached to reload audit config
[error_logger:info,2021-04-19T19:45:49.131Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.334.0>},
                       {name,ns_audit_cfg},
                       {mfargs,{ns_audit_cfg,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:warn,2021-04-19T19:45:49.132Z,ns_1@127.0.0.1:<0.337.0>:ns_memcached:connect:1307]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[ns_server:debug,2021-04-19T19:45:49.135Z,ns_1@127.0.0.1:memcached_config_mgr<0.339.0>:memcached_config_mgr:init:44]waiting for completion of initial ns_ports_setup round
[error_logger:info,2021-04-19T19:45:49.135Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.339.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:49.135Z,ns_1@127.0.0.1:memcached_config_mgr<0.339.0>:memcached_config_mgr:init:46]ns_ports_setup seems to be ready
[ns_server:info,2021-04-19T19:45:49.140Z,ns_1@127.0.0.1:<0.340.0>:ns_memcached_log_rotator:init:28]Starting log rotator on "/opt/couchbase/var/lib/couchbase/logs"/"memcached.log"* with an initial period of 39003ms
[error_logger:info,2021-04-19T19:45:49.140Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.340.0>},
                       {name,ns_memcached_log_rotator},
                       {mfargs,{ns_memcached_log_rotator,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:49.144Z,ns_1@127.0.0.1:memcached_config_mgr<0.339.0>:memcached_config_mgr:find_port_pid_loop:119]Found memcached port <11632.79.0>
[error_logger:info,2021-04-19T19:45:49.147Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.343.0>},
                       {name,memcached_clients_pool},
                       {mfargs,{memcached_clients_pool,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:49.151Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.344.0>},
                       {name,proxied_memcached_clients_pool},
                       {mfargs,{proxied_memcached_clients_pool,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:49.151Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.345.0>},
                       {name,xdc_lhttpc_pool},
                       {mfargs,
                           {lhttpc_manager,start_link,
                               [[{name,xdc_lhttpc_pool},
                                 {connection_timeout,120000},
                                 {pool_size,200}]]}},
                       {restart_type,{permanent,1}},
                       {shutdown,10000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:49.155Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.346.0>},
                       {name,ns_null_connection_pool},
                       {mfargs,
                           {ns_null_connection_pool,start_link,
                               [ns_null_connection_pool]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:49.161Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {<0.347.0>,xdcr_sup}
             started: [{pid,<0.348.0>},
                       {name,xdc_stats_holder},
                       {mfargs,
                           {proc_lib,start_link,
                               [xdcr_sup,link_stats_holder_body,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:49.162Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {<0.347.0>,xdcr_sup}
             started: [{pid,<0.349.0>},
                       {name,xdc_replication_sup},
                       {mfargs,{xdc_replication_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2021-04-19T19:45:49.167Z,ns_1@127.0.0.1:xdc_rep_manager<0.350.0>:ns_couchdb_api:wait_for_doc_manager:298]Start waiting for doc manager
[error_logger:info,2021-04-19T19:45:49.166Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {<0.347.0>,xdcr_sup}
             started: [{pid,<0.350.0>},
                       {name,xdc_rep_manager},
                       {mfargs,{xdc_rep_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,30000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:49.169Z,ns_1@127.0.0.1:memcached_config_mgr<0.339.0>:memcached_config_mgr:init:77]wrote memcached config to /opt/couchbase/var/lib/couchbase/config/memcached.json. Will activate memcached port server
[ns_server:debug,2021-04-19T19:45:49.170Z,ns_1@127.0.0.1:memcached_config_mgr<0.339.0>:memcached_config_mgr:init:80]activated memcached port server
[ns_server:debug,2021-04-19T19:45:49.174Z,ns_1@127.0.0.1:xdcr_doc_replicator<0.352.0>:ns_couchdb_api:wait_for_doc_manager:298]Start waiting for doc manager
[ns_server:debug,2021-04-19T19:45:49.174Z,ns_1@127.0.0.1:xdc_rdoc_replication_srv<0.353.0>:ns_couchdb_api:wait_for_doc_manager:298]Start waiting for doc manager
[error_logger:info,2021-04-19T19:45:49.174Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {<0.347.0>,xdcr_sup}
             started: [{pid,<0.352.0>},
                       {name,xdc_rdoc_replicator},
                       {mfargs,{doc_replicator,start_link_xdcr,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:49.174Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {<0.347.0>,xdcr_sup}
             started: [{pid,<0.353.0>},
                       {name,xdc_rdoc_replication_srv},
                       {mfargs,{doc_replication_srv,start_link_xdcr,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:49.179Z,ns_1@127.0.0.1:<0.347.0>:xdc_rdoc_manager:start_link_remote:42]Starting xdc_rdoc_manager on 'couchdb_ns_1@127.0.0.1' with following links: [<0.352.0>,
                                                                             <0.353.0>,
                                                                             <0.350.0>]
[ns_server:debug,2021-04-19T19:45:49.183Z,ns_1@127.0.0.1:xdcr_doc_replicator<0.352.0>:ns_couchdb_api:wait_for_doc_manager:301]Received doc manager registration from <11633.252.0>
[ns_server:debug,2021-04-19T19:45:49.183Z,ns_1@127.0.0.1:xdc_rdoc_replication_srv<0.353.0>:ns_couchdb_api:wait_for_doc_manager:301]Received doc manager registration from <11633.252.0>
[ns_server:debug,2021-04-19T19:45:49.183Z,ns_1@127.0.0.1:xdc_rep_manager<0.350.0>:ns_couchdb_api:wait_for_doc_manager:301]Received doc manager registration from <11633.252.0>
[error_logger:info,2021-04-19T19:45:49.183Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {<0.347.0>,xdcr_sup}
             started: [{pid,<11633.252.0>},
                       {name,xdc_rdoc_manager},
                       {mfargs,
                           {xdc_rdoc_manager,start_link_remote,
                               ['couchdb_ns_1@127.0.0.1']}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:49.184Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.347.0>},
                       {name,xdcr_sup},
                       {mfargs,{xdcr_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:45:49.197Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.355.0>},
                       {name,xdcr_dcp_sockets_pool},
                       {mfargs,{xdcr_dcp_sockets_pool,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:49.218Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_worker_sup}
             started: [{pid,<0.357.0>},
                       {name,ns_bucket_worker},
                       {mfargs,{work_queue,start_link,[ns_bucket_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:49.220Z,ns_1@127.0.0.1:xdcr_doc_replicator<0.352.0>:doc_replicator:loop:64]doing replicate_newnodes_docs
[error_logger:info,2021-04-19T19:45:49.223Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_sup}
             started: [{pid,<0.359.0>},
                       {name,buckets_observing_subscription},
                       {mfargs,{ns_bucket_sup,subscribe_on_config_events,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:49.224Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_worker_sup}
             started: [{pid,<0.358.0>},
                       {name,ns_bucket_sup},
                       {mfargs,{ns_bucket_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:45:49.225Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.356.0>},
                       {name,ns_bucket_worker_sup},
                       {mfargs,{ns_bucket_worker_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:45:49.238Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.360.0>},
                       {name,system_stats_collector},
                       {mfargs,{system_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:49.240Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.364.0>},
                       {name,{stats_archiver,"@system"}},
                       {mfargs,{stats_archiver,start_link,["@system"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:49.248Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.366.0>},
                       {name,{stats_reader,"@system"}},
                       {mfargs,{stats_reader,start_link,["@system"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:49.255Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.367.0>},
                       {name,{stats_archiver,"@system-processes"}},
                       {mfargs,
                           {stats_archiver,start_link,["@system-processes"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:49.256Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.369.0>},
                       {name,{stats_reader,"@system-processes"}},
                       {mfargs,
                           {stats_reader,start_link,["@system-processes"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:49.266Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.370.0>},
                       {name,{stats_archiver,"@query"}},
                       {mfargs,{stats_archiver,start_link,["@query"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:49.267Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.372.0>},
                       {name,{stats_reader,"@query"}},
                       {mfargs,{stats_reader,start_link,["@query"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:49.271Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.373.0>},
                       {name,query_stats_collector},
                       {mfargs,{query_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:49.282Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.375.0>},
                       {name,{stats_archiver,"@global"}},
                       {mfargs,{stats_archiver,start_link,["@global"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:49.283Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.377.0>},
                       {name,{stats_reader,"@global"}},
                       {mfargs,{stats_reader,start_link,["@global"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:49.288Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.378.0>},
                       {name,global_stats_collector},
                       {mfargs,{global_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:49.292Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.380.0>},
                       {name,goxdcr_status_keeper},
                       {mfargs,{goxdcr_status_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:49.296Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_stats_sup}
             started: [{pid,<0.382.0>},
                       {name,index_stats_children_sup},
                       {mfargs,
                           {supervisor,start_link,
                               [{local,index_stats_children_sup},
                                index_stats_sup,child]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:45:49.300Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_status_keeper_sup}
             started: [{pid,<0.384.0>},
                       {name,index_status_keeper_worker},
                       {mfargs,
                           {work_queue,start_link,
                               [index_status_keeper_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:49.312Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_status_keeper_sup}
             started: [{pid,<0.385.0>},
                       {name,index_status_keeper},
                       {mfargs,{indexer_gsi,start_keeper,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:49.316Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_status_keeper_sup}
             started: [{pid,<0.388.0>},
                       {name,index_status_keeper_fts},
                       {mfargs,{indexer_fts,start_keeper,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:49.317Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_stats_sup}
             started: [{pid,<0.383.0>},
                       {name,index_status_keeper_sup},
                       {mfargs,{index_status_keeper_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:45:49.317Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_stats_sup}
             started: [{pid,<0.391.0>},
                       {name,index_stats_worker},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<index_stats_sup.0.21142793>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:49.318Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.381.0>},
                       {name,index_stats_sup},
                       {mfargs,{index_stats_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:45:49.323Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.393.0>},
                       {name,compaction_daemon},
                       {mfargs,{compaction_daemon,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:49.335Z,ns_1@127.0.0.1:<0.396.0>:new_concurrency_throttle:init:113]init concurrent throttle process, pid: <0.396.0>, type: kv_throttle# of available token: 1
[ns_server:debug,2021-04-19T19:45:49.338Z,ns_1@127.0.0.1:compaction_new_daemon<0.394.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_kv. Rescheduling compaction.
[error_logger:info,2021-04-19T19:45:49.338Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.394.0>},
                       {name,compaction_new_daemon},
                       {mfargs,{compaction_new_daemon,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,86400000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:49.339Z,ns_1@127.0.0.1:compaction_new_daemon<0.394.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:45:49.342Z,ns_1@127.0.0.1:compaction_new_daemon<0.394.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:45:49.343Z,ns_1@127.0.0.1:compaction_new_daemon<0.394.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:45:49.344Z,ns_1@127.0.0.1:compaction_new_daemon<0.394.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_master. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:45:49.344Z,ns_1@127.0.0.1:compaction_new_daemon<0.394.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_master too soon. Next run will be in 3600s
[error_logger:info,2021-04-19T19:45:49.345Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,cluster_logs_sup}
             started: [{pid,<0.398.0>},
                       {name,ets_holder},
                       {mfargs,
                           {cluster_logs_collection_task,
                               start_link_ets_holder,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:49.346Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.397.0>},
                       {name,cluster_logs_sup},
                       {mfargs,{cluster_logs_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:45:49.350Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.399.0>},
                       {name,remote_api},
                       {mfargs,{remote_api,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:49.357Z,ns_1@127.0.0.1:<0.400.0>:mb_master:check_master_takeover_needed:141]Sending master node question to the following nodes: []
[ns_server:debug,2021-04-19T19:45:49.357Z,ns_1@127.0.0.1:<0.400.0>:mb_master:check_master_takeover_needed:143]Got replies: []
[ns_server:debug,2021-04-19T19:45:49.357Z,ns_1@127.0.0.1:<0.400.0>:mb_master:check_master_takeover_needed:149]Was unable to discover master, not going to force mastership takeover
[user:info,2021-04-19T19:45:49.358Z,ns_1@127.0.0.1:mb_master<0.402.0>:mb_master:init:86]I'm the only node, so I'm the master.
[ns_server:debug,2021-04-19T19:45:49.379Z,ns_1@127.0.0.1:mb_master_sup<0.404.0>:misc:start_singleton:1097]start_singleton(gen_server, ns_tick, [], []): started as <0.405.0> on 'ns_1@127.0.0.1'

[error_logger:info,2021-04-19T19:45:49.379Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.405.0>},
                       {name,ns_tick},
                       {mfargs,{ns_tick,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,10},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:49.391Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_config:do_upgrade_config:716]Upgrading config by changes:
[{set,cluster_compat_version,[2,5]}]

[ns_server:info,2021-04-19T19:45:49.391Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_online_config_upgrader:upgrade_config_from_2_5_to_3_0:62]Performing online config upgrade to 3.0 version
[ns_server:debug,2021-04-19T19:45:49.391Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_config:do_upgrade_config:716]Upgrading config by changes:
[{set,cluster_compat_version,[3,0]},
 {set,rest_creds,null},
 {set,read_only_user_creds,null}]

[ns_server:info,2021-04-19T19:45:49.391Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_online_config_upgrader:upgrade_config_from_3_0_to_4_0:67]Performing online config upgrade to 4.0 version
[ns_server:debug,2021-04-19T19:45:49.391Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_config:do_upgrade_config:716]Upgrading config by changes:
[{set,cluster_compat_version,[4,0]},
 {delete,goxdcr_upgrade},
 {set,{node,'ns_1@127.0.0.1',stop_xdcr},true},
 {set,{metakv,<<"/indexing/settings/config">>},
      <<"{\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.log_level\":\"info\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\":200,\"indexer.settings.max_cpu_percent\":0,\"indexer.settings.recovery.max_rollbacks\":5,\"indexer.settings.memory_quota\":536870912}">>}]

[ns_server:info,2021-04-19T19:45:49.391Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_online_config_upgrader:upgrade_config_from_4_0_to_4_1:72]Performing online config upgrade to 4.1 version
[ns_server:debug,2021-04-19T19:45:49.391Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_config:do_upgrade_config:716]Upgrading config by changes:
[{set,cluster_compat_version,[4,1]},
 {set,{service_map,n1ql},[]},
 {set,{service_map,index},[]}]

[ns_server:info,2021-04-19T19:45:49.392Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_online_config_upgrader:upgrade_config_from_4_1_to_4_5:76]Performing online config upgrade to 4.5 version
[ns_server:debug,2021-04-19T19:45:49.392Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_config:do_upgrade_config:716]Upgrading config by changes:
[{set,cluster_compat_version,[4,5]},
 {set,{metakv,<<"/indexing/settings/config">>},
      <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.log_level\":\"info\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\":200,\"indexer.settings.max_cpu_percent\":0,\"indexer.settings.storage_mode\":\"\",\"indexer.settings.recovery.max_rollbacks\":5,\"indexer.settings.memory_quota\":536870912,\"indexer.settings.compaction.abort_exceed_interval\":false}">>},
 {set,{service_map,fts},[]}]

[ns_server:debug,2021-04-19T19:45:49.392Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_config:do_upgrade_config:716]Upgrading config by changes:
[{set,cluster_compat_version,[4,6]}]

[ns_server:debug,2021-04-19T19:45:49.393Z,ns_1@127.0.0.1:menelaus_ui_auth<0.292.0>:menelaus_ui_auth:handle_cast:194]Revoke tokens [] for role ro_admin
[ns_server:info,2021-04-19T19:45:49.393Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.160.0>:ns_ssl_services_setup:handle_info:434]Got certificate and pkey change
[ns_server:debug,2021-04-19T19:45:49.393Z,ns_1@127.0.0.1:menelaus_ui_auth<0.292.0>:menelaus_ui_auth:handle_cast:194]Revoke tokens [] for role admin
[ns_server:debug,2021-04-19T19:45:49.393Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{service_map,fts} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080749}}]}]
[ns_server:debug,2021-04-19T19:45:49.394Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{service_map,index} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080749}}]}]
[ns_server:debug,2021-04-19T19:45:49.394Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{service_map,n1ql} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080749}}]}]
[ns_server:debug,2021-04-19T19:45:49.395Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{metakv,<<"/indexing/settings/config">>} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{2,63786080749}}]}|
 <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.log_level\":\"info\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\""...>>]
[ns_server:debug,2021-04-19T19:45:49.395Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',stop_xdcr} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080749}}]}|true]
[ns_server:debug,2021-04-19T19:45:49.396Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
goxdcr_upgrade ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080749}}]}|
 '_deleted']
[ns_server:debug,2021-04-19T19:45:49.396Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
read_only_user_creds ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080749}}]}|null]
[ns_server:debug,2021-04-19T19:45:49.396Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
cluster_compat_version ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{6,63786080749}}]},4,6]
[ns_server:debug,2021-04-19T19:45:49.396Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
rest_creds ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080749}}]}|null]
[ns_server:debug,2021-04-19T19:45:49.396Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{local_changes_count,<<"360fb3d3641e00b1f4f22714c24e2a2a">>} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{3,63786080749}}]}]
[ns_server:debug,2021-04-19T19:45:49.398Z,ns_1@127.0.0.1:ns_config_rep<0.252.0>:ns_config_rep:do_push_keys:321]Replicating some config keys ([cluster_compat_version,goxdcr_upgrade,
                               read_only_user_creds,rest_creds,
                               {local_changes_count,
                                   <<"360fb3d3641e00b1f4f22714c24e2a2a">>},
                               {metakv,<<"/indexing/settings/config">>},
                               {service_map,fts},
                               {service_map,index},
                               {service_map,n1ql},
                               {node,'ns_1@127.0.0.1',stop_xdcr}]..)
[ns_server:debug,2021-04-19T19:45:49.399Z,ns_1@127.0.0.1:ns_config_rep<0.252.0>:ns_config_rep:handle_call:115]Got full synchronization request from 'ns_1@127.0.0.1'
[ns_server:debug,2021-04-19T19:45:49.400Z,ns_1@127.0.0.1:ns_config_rep<0.252.0>:ns_config_rep:handle_call:121]Fully synchronized config in 679 us
[user:warn,2021-04-19T19:45:49.400Z,ns_1@127.0.0.1:<0.407.0>:ns_orchestrator:consider_switching_compat_mode:1205]Changed cluster compat mode from undefined to [4,6]
[ns_server:debug,2021-04-19T19:45:49.401Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{local_changes_count,<<"360fb3d3641e00b1f4f22714c24e2a2a">>} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{4,63786080749}}]}]
[ns_server:debug,2021-04-19T19:45:49.401Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',stop_xdcr} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{2,63786080749}}]}|
 '_deleted']
[ns_server:debug,2021-04-19T19:45:49.401Z,ns_1@127.0.0.1:ns_config_rep<0.252.0>:ns_config_rep:do_push_keys:321]Replicating some config keys ([{local_changes_count,
                                   <<"360fb3d3641e00b1f4f22714c24e2a2a">>},
                               {node,'ns_1@127.0.0.1',stop_xdcr}]..)
[ns_server:info,2021-04-19T19:45:49.406Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.160.0>:ns_ssl_services_setup:maybe_generate_local_cert:523]Failed to read node certificate. Perhaps it wasn't created yet. Error: {error,
                                                                        {badmatch,
                                                                         {error,
                                                                          enoent}}}
[ns_server:debug,2021-04-19T19:45:49.407Z,ns_1@127.0.0.1:ns_orchestrator_sup<0.406.0>:misc:start_singleton:1097]start_singleton(gen_fsm, ns_orchestrator, [], []): started as <0.407.0> on 'ns_1@127.0.0.1'

[error_logger:info,2021-04-19T19:45:49.407Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_sup}
             started: [{pid,<0.407.0>},
                       {name,ns_orchestrator},
                       {mfargs,{ns_orchestrator,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:49.428Z,ns_1@127.0.0.1:<0.418.0>:auto_failover:init:147]init auto_failover.
[ns_server:debug,2021-04-19T19:45:49.428Z,ns_1@127.0.0.1:ns_orchestrator_sup<0.406.0>:misc:start_singleton:1097]start_singleton(gen_server, auto_failover, [], []): started as <0.418.0> on 'ns_1@127.0.0.1'

[ns_server:debug,2021-04-19T19:45:49.429Z,ns_1@127.0.0.1:<0.400.0>:restartable:start_child:98]Started child process <0.402.0>
  MFA: {mb_master,start_link,[]}
[error_logger:info,2021-04-19T19:45:49.429Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_sup}
             started: [{pid,<0.418.0>},
                       {name,auto_failover},
                       {mfargs,{auto_failover,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:49.429Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.406.0>},
                       {name,ns_orchestrator_sup},
                       {mfargs,{ns_orchestrator_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:45:49.430Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.400.0>},
                       {name,mb_master},
                       {mfargs,
                           {restartable,start_link,
                               [{mb_master,start_link,[]},infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:45:49.430Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.419.0>},
                       {name,master_activity_events_ingress},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,master_activity_events_ingress}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:49.430Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.420.0>},
                       {name,master_activity_events_timestamper},
                       {mfargs,
                           {master_activity_events,start_link_timestamper,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:49.447Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.422.0>},
                       {name,master_activity_events_pids_watcher},
                       {mfargs,
                           {master_activity_events_pids_watcher,start_link,
                               []}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:49.453Z,ns_1@127.0.0.1:ns_ports_setup<0.327.0>:ns_ports_manager:set_dynamic_children:54]Setting children [memcached,saslauthd_port,goxdcr,xdcr_proxy]
[error_logger:info,2021-04-19T19:45:49.488Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.423.0>},
                       {name,master_activity_events_keeper},
                       {mfargs,{master_activity_events_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:49.488Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.234.0>},
                       {name,ns_server_sup},
                       {mfargs,{ns_server_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2021-04-19T19:45:49.488Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.155.0>:one_shot_barrier:notify:27]Notifying on barrier menelaus_barrier
[ns_server:debug,2021-04-19T19:45:49.490Z,ns_1@127.0.0.1:menelaus_barrier<0.157.0>:one_shot_barrier:barrier_body:62]Barrier menelaus_barrier got notification from <0.155.0>
[ns_server:debug,2021-04-19T19:45:49.490Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.155.0>:one_shot_barrier:notify:32]Successfuly notified on barrier menelaus_barrier
[ns_server:debug,2021-04-19T19:45:49.491Z,ns_1@127.0.0.1:<0.154.0>:restartable:start_child:98]Started child process <0.155.0>
  MFA: {ns_server_nodes_sup,start_link,[]}
[error_logger:info,2021-04-19T19:45:49.491Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.154.0>},
                       {name,ns_server_nodes_sup},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_server_nodes_sup,start_link,[]},
                                infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2021-04-19T19:45:49.491Z,ns_1@127.0.0.1:<0.2.0>:child_erlang:child_loop:116]97: Entered child_loop
[error_logger:info,2021-04-19T19:45:49.491Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
         application: ns_server
          started_at: 'ns_1@127.0.0.1'

[ns_server:warn,2021-04-19T19:45:50.139Z,ns_1@127.0.0.1:<0.337.0>:ns_memcached:connect:1307]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[ns_server:warn,2021-04-19T19:45:50.394Z,ns_1@127.0.0.1:<0.426.0>:ns_memcached:connect:1307]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[ns_server:debug,2021-04-19T19:45:50.466Z,ns_1@127.0.0.1:json_rpc_connection-saslauthd-saslauthd-port<0.428.0>:json_rpc_connection:init:74]Observed revrpc connection: label "saslauthd-saslauthd-port", handling process <0.428.0>
[error_logger:error,2021-04-19T19:45:50.467Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.428.0>,{ok,<0.428.0>}}

[ns_server:debug,2021-04-19T19:45:50.813Z,ns_1@127.0.0.1:json_rpc_connection-goxdcr-cbauth<0.431.0>:json_rpc_connection:init:74]Observed revrpc connection: label "goxdcr-cbauth", handling process <0.431.0>
[error_logger:error,2021-04-19T19:45:50.813Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.431.0>,{ok,<0.431.0>}}

[ns_server:debug,2021-04-19T19:45:50.813Z,ns_1@127.0.0.1:menelaus_cbauth<0.323.0>:menelaus_cbauth:handle_cast:87]Observed json rpc process {"goxdcr-cbauth",<0.431.0>} started
[ns_server:debug,2021-04-19T19:45:50.813Z,ns_1@127.0.0.1:json_rpc_connection-goxdcr-cbauth<0.431.0>:json_rpc_connection:handle_call:157]sending jsonrpc call:{[{jsonrpc,<<"2.0">>},
                       {id,0},
                       {method,<<"AuthCacheSvc.UpdateDB">>},
                       {params,
                        [{[{specialUser,<<"@goxdcr-cbauth">>},
                           {nodes,
                            [{[{host,<<"127.0.0.1">>},
                               {user,<<"_admin">>},
                               {password,"*****"},
                               {ports,
                                [8091,18091,18092,8092,11207,9999,11210,
                                 11211]},
                               {local,true}]}]},
                           {buckets,[]},
                           {authCheckURL,<<"http://127.0.0.1:8091/_cbauth">>},
                           {permissionCheckURL,
                            <<"http://127.0.0.1:8091/_cbauth/checkPermission">>},
                           {ldapEnabled,true},
                           {permissionsVersion,125619376}]}]}]}
[ns_server:debug,2021-04-19T19:45:50.818Z,ns_1@127.0.0.1:json_rpc_connection-goxdcr-cbauth<0.431.0>:json_rpc_connection:handle_info:93]got response: [{<<"id">>,0},{<<"result">>,true},{<<"error">>,null}]
[stats:warn,2021-04-19T19:45:51.397Z,ns_1@127.0.0.1:<0.378.0>:base_stats_collector:latest_tick:69](Collector: global_stats_collector) Dropped 1 ticks
[ns_server:info,2021-04-19T19:45:51.462Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.160.0>:ns_ssl_services_setup:do_generate_local_cert:511]Saved local cert for node 'ns_1@127.0.0.1'
[ns_server:info,2021-04-19T19:45:51.564Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.160.0>:ns_ssl_services_setup:handle_info:437]Wrote new pem file
[ns_server:debug,2021-04-19T19:45:51.564Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.160.0>:ns_ssl_services_setup:handle_info:463]Going to notify following services: [ssl_service,capi_ssl_service,xdcr_proxy,
                                     query_svc,memcached]
[ns_server:debug,2021-04-19T19:45:51.564Z,ns_1@127.0.0.1:<0.165.0>:restartable:loop:71]Restarting child <0.167.0>
  MFA: {ns_ssl_services_setup,start_link_rest_service,[]}
  Shutdown policy: 1000
  Caller: {<0.448.0>,#Ref<0.0.0.1598>}
[ns_server:info,2021-04-19T19:45:51.564Z,ns_1@127.0.0.1:<0.451.0>:ns_ssl_services_setup:notify_service:556]Successfully notified service query_svc
[ns_server:debug,2021-04-19T19:45:51.565Z,ns_1@127.0.0.1:<0.450.0>:ns_ports_manager:restart_port_by_name:43]Requesting restart of port xdcr_proxy
[ns_server:debug,2021-04-19T19:45:51.565Z,ns_1@127.0.0.1:<0.165.0>:restartable:shutdown_child:120]Successfully terminated process <0.167.0>
[ns_server:info,2021-04-19T19:45:51.567Z,ns_1@127.0.0.1:<0.452.0>:ns_ssl_services_setup:notify_service:556]Successfully notified service memcached
[ns_server:info,2021-04-19T19:45:51.570Z,ns_1@127.0.0.1:<0.165.0>:menelaus_pluggable_ui:validate_plugin_spec:117]Loaded pluggable UI specification for fts

[ns_server:info,2021-04-19T19:45:51.571Z,ns_1@127.0.0.1:<0.165.0>:menelaus_pluggable_ui:validate_plugin_spec:117]Loaded pluggable UI specification for n1ql

[ns_server:debug,2021-04-19T19:45:51.572Z,ns_1@127.0.0.1:<0.165.0>:restartable:start_child:98]Started child process <0.453.0>
  MFA: {ns_ssl_services_setup,start_link_rest_service,[]}
[ns_server:info,2021-04-19T19:45:51.572Z,ns_1@127.0.0.1:<0.448.0>:ns_ssl_services_setup:notify_service:556]Successfully notified service ssl_service
[ns_server:info,2021-04-19T19:45:51.575Z,ns_1@127.0.0.1:<0.449.0>:ns_ssl_services_setup:notify_service:556]Successfully notified service capi_ssl_service
[user:debug,2021-04-19T19:45:53.816Z,ns_1@127.0.0.1:<0.240.0>:ns_log:crash_consumption_loop:70]Service 'xdcr_proxy' exited with status 0. Restarting. Messages: 196: Booted. Waiting for shutdown request
196: got shutdown request. Exiting
[ns_server:info,2021-04-19T19:45:53.818Z,ns_1@127.0.0.1:<0.450.0>:ns_ssl_services_setup:notify_service:556]Successfully notified service xdcr_proxy
[ns_server:info,2021-04-19T19:45:53.818Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.160.0>:ns_ssl_services_setup:handle_info:479]Succesfully notified services [memcached,query_svc,xdcr_proxy,
                               capi_ssl_service,ssl_service]
[ns_server:debug,2021-04-19T19:45:57.048Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{metakv,<<"/indexing/settings/config">>} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{3,63786080757}}]}|
 <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.log_level\":\"info\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\""...>>]
[ns_server:debug,2021-04-19T19:45:57.048Z,ns_1@127.0.0.1:<0.499.0>:ns_audit:put:248]Audit cluster_settings: [{cluster_name,<<>>},
                         {fts_memory_quota,512},
                         {index_memory_quota,512},
                         {memory_quota,300},
                         {real_userid,{[{source,anonymous},{user,<<>>}]}},
                         {remote,{[{ip,<<"127.0.0.1">>},{port,35750}]}},
                         {timestamp,<<"2021-04-19T19:45:57.048Z">>}]
[ns_server:debug,2021-04-19T19:45:57.048Z,ns_1@127.0.0.1:ns_config_rep<0.252.0>:ns_config_rep:do_push_keys:321]Replicating some config keys ([memory_quota,
                               {local_changes_count,
                                   <<"360fb3d3641e00b1f4f22714c24e2a2a">>},
                               {metakv,<<"/indexing/settings/config">>}]..)
[ns_server:debug,2021-04-19T19:45:57.049Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
memory_quota ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080757}}]}|300]
[ns_server:debug,2021-04-19T19:45:57.049Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{local_changes_count,<<"360fb3d3641e00b1f4f22714c24e2a2a">>} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{5,63786080757}}]}]
[ns_server:debug,2021-04-19T19:45:57.057Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{local_changes_count,<<"360fb3d3641e00b1f4f22714c24e2a2a">>} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{6,63786080757}}]}]
[ns_server:debug,2021-04-19T19:45:57.057Z,ns_1@127.0.0.1:ns_config_rep<0.252.0>:ns_config_rep:do_push_keys:321]Replicating some config keys ([{local_changes_count,
                                   <<"360fb3d3641e00b1f4f22714c24e2a2a">>},
                               {node,'ns_1@127.0.0.1',services}]..)
[ns_server:debug,2021-04-19T19:45:57.057Z,ns_1@127.0.0.1:<0.505.0>:ns_audit:put:248]Audit setup_node_services: [{services,[index,kv,n1ql]},
                            {node,'ns_1@127.0.0.1'},
                            {real_userid,{[{source,anonymous},{user,<<>>}]}},
                            {remote,{[{ip,<<"127.0.0.1">>},{port,35752}]}},
                            {timestamp,<<"2021-04-19T19:45:57.057Z">>}]
[ns_server:debug,2021-04-19T19:45:57.057Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',services} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080757}}]},
 index,kv,n1ql]
[ns_server:debug,2021-04-19T19:45:57.084Z,ns_1@127.0.0.1:ns_config_rep<0.252.0>:ns_config_rep:do_push_keys:321]Replicating some config keys ([rest,
                               {local_changes_count,
                                   <<"360fb3d3641e00b1f4f22714c24e2a2a">>}]..)
[ns_server:debug,2021-04-19T19:45:57.084Z,ns_1@127.0.0.1:<0.513.0>:ns_audit:put:248]Audit password_change: [{identity,{[{source,admin},
                                    {user,<<"Administrator">>}]}},
                        {real_userid,{[{source,anonymous},{user,<<>>}]}},
                        {remote,{[{ip,<<"127.0.0.1">>},{port,35754}]}},
                        {timestamp,<<"2021-04-19T19:45:57.084Z">>}]
[ns_server:debug,2021-04-19T19:45:57.084Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{local_changes_count,<<"360fb3d3641e00b1f4f22714c24e2a2a">>} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{7,63786080757}}]}]
[ns_server:debug,2021-04-19T19:45:57.084Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
rest ->
[{port,8091}]
[ns_server:debug,2021-04-19T19:45:57.084Z,ns_1@127.0.0.1:menelaus_ui_auth<0.292.0>:menelaus_ui_auth:handle_cast:194]Revoke tokens [] for role admin
[ns_server:debug,2021-04-19T19:45:57.084Z,ns_1@127.0.0.1:json_rpc_connection-goxdcr-cbauth<0.431.0>:json_rpc_connection:handle_call:157]sending jsonrpc call:{[{jsonrpc,<<"2.0">>},
                       {id,1},
                       {method,<<"AuthCacheSvc.UpdateDB">>},
                       {params,
                        [{[{specialUser,<<"@goxdcr-cbauth">>},
                           {nodes,
                            [{[{host,<<"127.0.0.1">>},
                               {user,<<"_admin">>},
                               {password,"*****"},
                               {ports,
                                [8091,18091,18092,8092,11207,9999,11210,
                                 11211]},
                               {local,true}]}]},
                           {buckets,[]},
                           {authCheckURL,<<"http://127.0.0.1:8091/_cbauth">>},
                           {permissionCheckURL,
                            <<"http://127.0.0.1:8091/_cbauth/checkPermission">>},
                           {ldapEnabled,true},
                           {permissionsVersion,125619376},
                           {admin,
                            {[{user,<<"Administrator">>},
                              {salt,<<"HwppMSHwWqqMMQC+Y570Cg==">>},
                              {mac,
                               <<"qvTNNsy5tPU9CAZI+HQuF+FPP5Y=">>}]}}]}]}]}
[ns_server:debug,2021-04-19T19:45:57.085Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{local_changes_count,<<"360fb3d3641e00b1f4f22714c24e2a2a">>} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{8,63786080757}}]}]
[ns_server:debug,2021-04-19T19:45:57.085Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
rest_creds ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{2,63786080757}}]}|
 {"Administrator",{password,"*****"}}]
[ns_server:debug,2021-04-19T19:45:57.085Z,ns_1@127.0.0.1:ns_config_rep<0.252.0>:ns_config_rep:do_push_keys:321]Replicating some config keys ([rest_creds,uuid,
                               {local_changes_count,
                                   <<"360fb3d3641e00b1f4f22714c24e2a2a">>}]..)
[ns_server:debug,2021-04-19T19:45:57.085Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{local_changes_count,<<"360fb3d3641e00b1f4f22714c24e2a2a">>} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{9,63786080757}}]}]
[ns_server:debug,2021-04-19T19:45:57.085Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
uuid ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080757}}]}|
 <<"819b5f49755d4c5571ba2861d6185103">>]
[ns_server:debug,2021-04-19T19:45:57.087Z,ns_1@127.0.0.1:json_rpc_connection-goxdcr-cbauth<0.431.0>:json_rpc_connection:handle_info:93]got response: [{<<"id">>,1},{<<"result">>,true},{<<"error">>,null}]
[error_logger:info,2021-04-19T19:45:57.090Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_stats_children_sup}
             started: [{pid,<0.519.0>},
                       {name,{indexer_gsi,index_stats_collector}},
                       {mfargs,
                           {index_stats_collector,start_link,[indexer_gsi]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:57.093Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_stats_children_sup}
             started: [{pid,<0.522.0>},
                       {name,{indexer_gsi,stats_archiver,"@index"}},
                       {mfargs,{stats_archiver,start_link,["@index"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:45:57.093Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_stats_children_sup}
             started: [{pid,<0.524.0>},
                       {name,{indexer_gsi,stats_reader,"@index"}},
                       {mfargs,{stats_reader,start_link,["@index"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:45:57.101Z,ns_1@127.0.0.1:ns_config_rep<0.252.0>:ns_config_rep:do_push_keys:321]Replicating some config keys ([{local_changes_count,
                                   <<"360fb3d3641e00b1f4f22714c24e2a2a">>},
                               {metakv,<<"/indexing/settings/config">>}]..)
[ns_server:debug,2021-04-19T19:45:57.101Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{metakv,<<"/indexing/settings/config">>} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{4,63786080757}}]}|
 <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.log_level\":\"info\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\""...>>]
[ns_server:debug,2021-04-19T19:45:57.101Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{local_changes_count,<<"360fb3d3641e00b1f4f22714c24e2a2a">>} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{10,63786080757}}]}]
[ns_server:debug,2021-04-19T19:45:57.101Z,ns_1@127.0.0.1:<0.526.0>:ns_audit:put:248]Audit modify_index_storage_mode: [{storageMode,<<"memory_optimized">>},
                                  {real_userid,
                                      {[{source,ns_server},
                                        {user,<<"Administrator">>}]}},
                                  {remote,
                                      {[{ip,<<"127.0.0.1">>},{port,35756}]}},
                                  {timestamp,<<"2021-04-19T19:45:57.101Z">>}]
[ns_server:debug,2021-04-19T19:45:57.123Z,ns_1@127.0.0.1:ns_ports_setup<0.327.0>:ns_ports_manager:set_dynamic_children:54]Setting children [memcached,moxi,projector,indexer,query,saslauthd_port,
                  goxdcr,xdcr_proxy]
[stats:error,2021-04-19T19:45:57.380Z,ns_1@127.0.0.1:query_stats_collector<0.373.0>:base_stats_collector:handle_info:109](Collector: query_stats_collector) Exception in stats collector: {error,
                                                                  {badmatch,
                                                                   {error,
                                                                    {econnrefused,
                                                                     [{lhttpc_client,
                                                                       send_request,
                                                                       1,
                                                                       [{file,
                                                                         "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                        {line,
                                                                         220}]},
                                                                      {lhttpc_client,
                                                                       execute,
                                                                       9,
                                                                       [{file,
                                                                         "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                        {line,
                                                                         169}]},
                                                                      {lhttpc_client,
                                                                       request,
                                                                       9,
                                                                       [{file,
                                                                         "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                        {line,
                                                                         92}]}]}}},
                                                                  [{query_rest,
                                                                    send,3,
                                                                    [{file,
                                                                      "src/query_rest.erl"},
                                                                     {line,
                                                                      64}]},
                                                                   {query_rest,
                                                                    do_get_stats,
                                                                    0,
                                                                    [{file,
                                                                      "src/query_rest.erl"},
                                                                     {line,
                                                                      43}]},
                                                                   {base_stats_collector,
                                                                    handle_info,
                                                                    2,
                                                                    [{file,
                                                                      "src/base_stats_collector.erl"},
                                                                     {line,
                                                                      89}]},
                                                                   {gen_server,
                                                                    handle_msg,
                                                                    5,
                                                                    [{file,
                                                                      "gen_server.erl"},
                                                                     {line,
                                                                      604}]},
                                                                   {proc_lib,
                                                                    init_p_do_apply,
                                                                    3,
                                                                    [{file,
                                                                      "proc_lib.erl"},
                                                                     {line,
                                                                      239}]}]}

[ns_server:error,2021-04-19T19:45:57.382Z,ns_1@127.0.0.1:index_stats_collector-index<0.519.0>:index_rest:get_json:42]Request to (indexer) http://127.0.0.1:9102/stats?async=true failed: {error,
                                                                     {econnrefused,
                                                                      [{lhttpc_client,
                                                                        send_request,
                                                                        1,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          220}]},
                                                                       {lhttpc_client,
                                                                        execute,
                                                                        9,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          169}]},
                                                                       {lhttpc_client,
                                                                        request,
                                                                        9,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          92}]}]}}
[user:debug,2021-04-19T19:45:58.038Z,ns_1@127.0.0.1:<0.240.0>:ns_log:crash_consumption_loop:70]Service 'xdcr_proxy' exited with status 0. Restarting. Messages: 269: Booted. Waiting for shutdown request
269: got shutdown request. Exiting
[ns_server:error,2021-04-19T19:45:58.380Z,ns_1@127.0.0.1:index_stats_collector-index<0.519.0>:index_rest:get_json:42]Request to (indexer) http://127.0.0.1:9102/stats?async=true failed: {error,
                                                                     {econnrefused,
                                                                      [{lhttpc_client,
                                                                        send_request,
                                                                        1,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          220}]},
                                                                       {lhttpc_client,
                                                                        execute,
                                                                        9,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          169}]},
                                                                       {lhttpc_client,
                                                                        request,
                                                                        9,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          92}]}]}}
[stats:error,2021-04-19T19:45:58.380Z,ns_1@127.0.0.1:query_stats_collector<0.373.0>:base_stats_collector:handle_info:109](Collector: query_stats_collector) Exception in stats collector: {error,
                                                                  {badmatch,
                                                                   {error,
                                                                    {econnrefused,
                                                                     [{lhttpc_client,
                                                                       send_request,
                                                                       1,
                                                                       [{file,
                                                                         "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                        {line,
                                                                         220}]},
                                                                      {lhttpc_client,
                                                                       execute,
                                                                       9,
                                                                       [{file,
                                                                         "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                        {line,
                                                                         169}]},
                                                                      {lhttpc_client,
                                                                       request,
                                                                       9,
                                                                       [{file,
                                                                         "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                        {line,
                                                                         92}]}]}}},
                                                                  [{query_rest,
                                                                    send,3,
                                                                    [{file,
                                                                      "src/query_rest.erl"},
                                                                     {line,
                                                                      64}]},
                                                                   {query_rest,
                                                                    do_get_stats,
                                                                    0,
                                                                    [{file,
                                                                      "src/query_rest.erl"},
                                                                     {line,
                                                                      43}]},
                                                                   {base_stats_collector,
                                                                    handle_info,
                                                                    2,
                                                                    [{file,
                                                                      "src/base_stats_collector.erl"},
                                                                     {line,
                                                                      89}]},
                                                                   {gen_server,
                                                                    handle_msg,
                                                                    5,
                                                                    [{file,
                                                                      "gen_server.erl"},
                                                                     {line,
                                                                      604}]},
                                                                   {proc_lib,
                                                                    init_p_do_apply,
                                                                    3,
                                                                    [{file,
                                                                      "proc_lib.erl"},
                                                                     {line,
                                                                      239}]}]}

[ns_server:debug,2021-04-19T19:45:58.504Z,ns_1@127.0.0.1:ns_ports_setup<0.327.0>:ns_ports_manager:set_dynamic_children:54]Setting children [memcached,moxi,projector,indexer,query,saslauthd_port,
                  goxdcr,xdcr_proxy]
[ns_server:error,2021-04-19T19:45:59.316Z,ns_1@127.0.0.1:index_status_keeper_worker<0.384.0>:index_rest:get_json:42]Request to (indexer) http://127.0.0.1:9102/getIndexStatus failed: {error,
                                                                   {econnrefused,
                                                                    [{lhttpc_client,
                                                                      send_request,
                                                                      1,
                                                                      [{file,
                                                                        "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                       {line,
                                                                        220}]},
                                                                     {lhttpc_client,
                                                                      execute,
                                                                      9,
                                                                      [{file,
                                                                        "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                       {line,
                                                                        169}]},
                                                                     {lhttpc_client,
                                                                      request,
                                                                      9,
                                                                      [{file,
                                                                        "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                       {line,
                                                                        92}]}]}}
[ns_server:error,2021-04-19T19:45:59.380Z,ns_1@127.0.0.1:index_stats_collector-index<0.519.0>:index_rest:get_json:42]Request to (indexer) http://127.0.0.1:9102/stats?async=true failed: {error,
                                                                     {econnrefused,
                                                                      [{lhttpc_client,
                                                                        send_request,
                                                                        1,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          220}]},
                                                                       {lhttpc_client,
                                                                        execute,
                                                                        9,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          169}]},
                                                                       {lhttpc_client,
                                                                        request,
                                                                        9,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          92}]}]}}
[stats:error,2021-04-19T19:45:59.381Z,ns_1@127.0.0.1:query_stats_collector<0.373.0>:base_stats_collector:handle_info:109](Collector: query_stats_collector) Exception in stats collector: {error,
                                                                  {badmatch,
                                                                   {error,
                                                                    {econnrefused,
                                                                     [{lhttpc_client,
                                                                       send_request,
                                                                       1,
                                                                       [{file,
                                                                         "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                        {line,
                                                                         220}]},
                                                                      {lhttpc_client,
                                                                       execute,
                                                                       9,
                                                                       [{file,
                                                                         "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                        {line,
                                                                         169}]},
                                                                      {lhttpc_client,
                                                                       request,
                                                                       9,
                                                                       [{file,
                                                                         "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                        {line,
                                                                         92}]}]}}},
                                                                  [{query_rest,
                                                                    send,3,
                                                                    [{file,
                                                                      "src/query_rest.erl"},
                                                                     {line,
                                                                      64}]},
                                                                   {query_rest,
                                                                    do_get_stats,
                                                                    0,
                                                                    [{file,
                                                                      "src/query_rest.erl"},
                                                                     {line,
                                                                      43}]},
                                                                   {base_stats_collector,
                                                                    handle_info,
                                                                    2,
                                                                    [{file,
                                                                      "src/base_stats_collector.erl"},
                                                                     {line,
                                                                      89}]},
                                                                   {gen_server,
                                                                    handle_msg,
                                                                    5,
                                                                    [{file,
                                                                      "gen_server.erl"},
                                                                     {line,
                                                                      604}]},
                                                                   {proc_lib,
                                                                    init_p_do_apply,
                                                                    3,
                                                                    [{file,
                                                                      "proc_lib.erl"},
                                                                     {line,
                                                                      239}]}]}

[ns_server:debug,2021-04-19T19:45:59.384Z,ns_1@127.0.0.1:<0.560.0>:service_janitor:maybe_init_simple_service:68]Created initial service map for service `index'
[ns_server:debug,2021-04-19T19:45:59.384Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{local_changes_count,<<"360fb3d3641e00b1f4f22714c24e2a2a">>} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{11,63786080759}}]}]
[ns_server:debug,2021-04-19T19:45:59.385Z,ns_1@127.0.0.1:<0.560.0>:service_janitor:maybe_init_simple_service:68]Created initial service map for service `n1ql'
[ns_server:debug,2021-04-19T19:45:59.385Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{service_map,index} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{2,63786080759}}]},
 'ns_1@127.0.0.1']
[ns_server:debug,2021-04-19T19:45:59.385Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{local_changes_count,<<"360fb3d3641e00b1f4f22714c24e2a2a">>} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{12,63786080759}}]}]
[ns_server:debug,2021-04-19T19:45:59.385Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{service_map,n1ql} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{2,63786080759}}]},
 'ns_1@127.0.0.1']
[ns_server:debug,2021-04-19T19:45:59.385Z,ns_1@127.0.0.1:ns_config_rep<0.252.0>:ns_config_rep:do_push_keys:321]Replicating some config keys ([{local_changes_count,
                                   <<"360fb3d3641e00b1f4f22714c24e2a2a">>},
                               {service_map,index},
                               {service_map,n1ql}]..)
[ns_server:debug,2021-04-19T19:45:59.385Z,ns_1@127.0.0.1:json_rpc_connection-goxdcr-cbauth<0.431.0>:json_rpc_connection:handle_call:157]sending jsonrpc call:{[{jsonrpc,<<"2.0">>},
                       {id,2},
                       {method,<<"AuthCacheSvc.UpdateDB">>},
                       {params,
                        [{[{specialUser,<<"@goxdcr-cbauth">>},
                           {nodes,
                            [{[{host,<<"127.0.0.1">>},
                               {user,<<"_admin">>},
                               {password,"*****"},
                               {ports,
                                [8091,18091,9100,9101,9102,9103,9104,9105,
                                 18092,8092,11207,9999,11210,11211,8093,
                                 18093]},
                               {local,true}]}]},
                           {buckets,[]},
                           {authCheckURL,<<"http://127.0.0.1:8091/_cbauth">>},
                           {permissionCheckURL,
                            <<"http://127.0.0.1:8091/_cbauth/checkPermission">>},
                           {ldapEnabled,true},
                           {permissionsVersion,125619376},
                           {admin,
                            {[{user,<<"Administrator">>},
                              {salt,<<"HwppMSHwWqqMMQC+Y570Cg==">>},
                              {mac,
                               <<"qvTNNsy5tPU9CAZI+HQuF+FPP5Y=">>}]}}]}]}]}
[ns_server:debug,2021-04-19T19:45:59.386Z,ns_1@127.0.0.1:json_rpc_connection-goxdcr-cbauth<0.431.0>:json_rpc_connection:handle_info:93]got response: [{<<"id">>,2},{<<"result">>,true},{<<"error">>,null}]
[ns_server:debug,2021-04-19T19:45:59.387Z,ns_1@127.0.0.1:json_rpc_connection-projector-cbauth<0.564.0>:json_rpc_connection:init:74]Observed revrpc connection: label "projector-cbauth", handling process <0.564.0>
[error_logger:error,2021-04-19T19:45:59.388Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.564.0>,{ok,<0.564.0>}}

[ns_server:debug,2021-04-19T19:45:59.388Z,ns_1@127.0.0.1:menelaus_cbauth<0.323.0>:menelaus_cbauth:handle_cast:87]Observed json rpc process {"projector-cbauth",<0.564.0>} started
[ns_server:debug,2021-04-19T19:45:59.388Z,ns_1@127.0.0.1:json_rpc_connection-projector-cbauth<0.564.0>:json_rpc_connection:handle_call:157]sending jsonrpc call:{[{jsonrpc,<<"2.0">>},
                       {id,0},
                       {method,<<"AuthCacheSvc.UpdateDB">>},
                       {params,
                        [{[{specialUser,<<"@projector-cbauth">>},
                           {nodes,
                            [{[{host,<<"127.0.0.1">>},
                               {user,<<"_admin">>},
                               {password,"*****"},
                               {ports,
                                [8091,18091,9100,9101,9102,9103,9104,9105,
                                 18092,8092,11207,9999,11210,11211,8093,
                                 18093]},
                               {local,true}]}]},
                           {buckets,[]},
                           {authCheckURL,<<"http://127.0.0.1:8091/_cbauth">>},
                           {permissionCheckURL,
                            <<"http://127.0.0.1:8091/_cbauth/checkPermission">>},
                           {ldapEnabled,true},
                           {permissionsVersion,125619376},
                           {admin,
                            {[{user,<<"Administrator">>},
                              {salt,<<"HwppMSHwWqqMMQC+Y570Cg==">>},
                              {mac,
                               <<"qvTNNsy5tPU9CAZI+HQuF+FPP5Y=">>}]}}]}]}]}
[ns_server:debug,2021-04-19T19:45:59.392Z,ns_1@127.0.0.1:json_rpc_connection-projector-cbauth<0.564.0>:json_rpc_connection:handle_info:93]got response: [{<<"id">>,0},{<<"result">>,true},{<<"error">>,null}]
[user:debug,2021-04-19T19:45:59.495Z,ns_1@127.0.0.1:<0.240.0>:ns_log:crash_consumption_loop:70]Service 'indexer' exited with status 0. Restarting. Messages: [goport] 2021/04/19 19:45:59 got new line on a stdin; terminating.
[ns_server:debug,2021-04-19T19:45:59.769Z,ns_1@127.0.0.1:json_rpc_connection-cbq-engine-cbauth<0.570.0>:json_rpc_connection:init:74]Observed revrpc connection: label "cbq-engine-cbauth", handling process <0.570.0>
[ns_server:debug,2021-04-19T19:45:59.769Z,ns_1@127.0.0.1:menelaus_cbauth<0.323.0>:menelaus_cbauth:handle_cast:87]Observed json rpc process {"cbq-engine-cbauth",<0.570.0>} started
[error_logger:error,2021-04-19T19:45:59.769Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.570.0>,{ok,<0.570.0>}}

[ns_server:debug,2021-04-19T19:45:59.769Z,ns_1@127.0.0.1:json_rpc_connection-cbq-engine-cbauth<0.570.0>:json_rpc_connection:handle_call:157]sending jsonrpc call:{[{jsonrpc,<<"2.0">>},
                       {id,0},
                       {method,<<"AuthCacheSvc.UpdateDB">>},
                       {params,
                        [{[{specialUser,<<"@cbq-engine-cbauth">>},
                           {nodes,
                            [{[{host,<<"127.0.0.1">>},
                               {user,<<"_admin">>},
                               {password,"*****"},
                               {ports,
                                [8091,18091,9100,9101,9102,9103,9104,9105,
                                 18092,8092,11207,9999,11210,11211,8093,
                                 18093]},
                               {local,true}]}]},
                           {buckets,[]},
                           {authCheckURL,<<"http://127.0.0.1:8091/_cbauth">>},
                           {permissionCheckURL,
                            <<"http://127.0.0.1:8091/_cbauth/checkPermission">>},
                           {ldapEnabled,true},
                           {permissionsVersion,125619376},
                           {admin,
                            {[{user,<<"Administrator">>},
                              {salt,<<"HwppMSHwWqqMMQC+Y570Cg==">>},
                              {mac,
                               <<"qvTNNsy5tPU9CAZI+HQuF+FPP5Y=">>}]}}]}]}]}
[ns_server:debug,2021-04-19T19:45:59.771Z,ns_1@127.0.0.1:json_rpc_connection-cbq-engine-cbauth<0.570.0>:json_rpc_connection:handle_info:93]got response: [{<<"id">>,0},{<<"result">>,true},{<<"error">>,null}]
[ns_server:error,2021-04-19T19:46:00.380Z,ns_1@127.0.0.1:index_stats_collector-index<0.519.0>:index_rest:get_json:42]Request to (indexer) http://127.0.0.1:9102/stats?async=true failed: {error,
                                                                     {econnrefused,
                                                                      [{lhttpc_client,
                                                                        send_request,
                                                                        1,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          220}]},
                                                                       {lhttpc_client,
                                                                        execute,
                                                                        9,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          169}]},
                                                                       {lhttpc_client,
                                                                        request,
                                                                        9,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          92}]}]}}
[ns_server:debug,2021-04-19T19:46:00.597Z,ns_1@127.0.0.1:json_rpc_connection-index-cbauth<0.579.0>:json_rpc_connection:init:74]Observed revrpc connection: label "index-cbauth", handling process <0.579.0>
[error_logger:error,2021-04-19T19:46:00.598Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.579.0>,{ok,<0.579.0>}}

[ns_server:debug,2021-04-19T19:46:00.598Z,ns_1@127.0.0.1:menelaus_cbauth<0.323.0>:menelaus_cbauth:handle_cast:87]Observed json rpc process {"index-cbauth",<0.579.0>} started
[ns_server:debug,2021-04-19T19:46:00.598Z,ns_1@127.0.0.1:json_rpc_connection-index-cbauth<0.579.0>:json_rpc_connection:handle_call:157]sending jsonrpc call:{[{jsonrpc,<<"2.0">>},
                       {id,0},
                       {method,<<"AuthCacheSvc.UpdateDB">>},
                       {params,
                        [{[{specialUser,<<"@index-cbauth">>},
                           {nodes,
                            [{[{host,<<"127.0.0.1">>},
                               {user,<<"_admin">>},
                               {password,"*****"},
                               {ports,
                                [8091,18091,9100,9101,9102,9103,9104,9105,
                                 18092,8092,11207,9999,11210,11211,8093,
                                 18093]},
                               {local,true}]}]},
                           {buckets,[]},
                           {authCheckURL,<<"http://127.0.0.1:8091/_cbauth">>},
                           {permissionCheckURL,
                            <<"http://127.0.0.1:8091/_cbauth/checkPermission">>},
                           {ldapEnabled,true},
                           {permissionsVersion,125619376},
                           {admin,
                            {[{user,<<"Administrator">>},
                              {salt,<<"HwppMSHwWqqMMQC+Y570Cg==">>},
                              {mac,
                               <<"qvTNNsy5tPU9CAZI+HQuF+FPP5Y=">>}]}}]}]}]}
[ns_server:debug,2021-04-19T19:46:00.599Z,ns_1@127.0.0.1:json_rpc_connection-index-cbauth<0.579.0>:json_rpc_connection:handle_info:93]got response: [{<<"id">>,0},{<<"result">>,true},{<<"error">>,null}]
[ns_server:error,2021-04-19T19:46:01.379Z,ns_1@127.0.0.1:index_stats_collector-index<0.519.0>:index_rest:get_json:42]Request to (indexer) http://127.0.0.1:9102/stats?async=true failed: {error,
                                                                     {econnrefused,
                                                                      [{lhttpc_client,
                                                                        send_request,
                                                                        1,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          220}]},
                                                                       {lhttpc_client,
                                                                        execute,
                                                                        9,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          169}]},
                                                                       {lhttpc_client,
                                                                        request,
                                                                        9,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          92}]}]}}
[ns_server:debug,2021-04-19T19:46:19.340Z,ns_1@127.0.0.1:compaction_new_daemon<0.394.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:46:19.340Z,ns_1@127.0.0.1:compaction_new_daemon<0.394.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:46:19.344Z,ns_1@127.0.0.1:compaction_new_daemon<0.394.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:46:19.344Z,ns_1@127.0.0.1:compaction_new_daemon<0.394.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[error_logger:info,2021-04-19T19:46:49.067Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.963.0>},
                       {name,disk_log_sup},
                       {mfargs,{disk_log_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:46:49.067Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.964.0>},
                       {name,disk_log_server},
                       {mfargs,{disk_log_server,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:46:49.341Z,ns_1@127.0.0.1:compaction_new_daemon<0.394.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:46:49.341Z,ns_1@127.0.0.1:compaction_new_daemon<0.394.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:46:49.345Z,ns_1@127.0.0.1:compaction_new_daemon<0.394.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:46:49.345Z,ns_1@127.0.0.1:compaction_new_daemon<0.394.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:47:19.342Z,ns_1@127.0.0.1:compaction_new_daemon<0.394.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:47:19.342Z,ns_1@127.0.0.1:compaction_new_daemon<0.394.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:47:19.346Z,ns_1@127.0.0.1:compaction_new_daemon<0.394.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:47:19.346Z,ns_1@127.0.0.1:compaction_new_daemon<0.394.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:47:49.344Z,ns_1@127.0.0.1:compaction_new_daemon<0.394.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:47:49.345Z,ns_1@127.0.0.1:compaction_new_daemon<0.394.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:47:49.347Z,ns_1@127.0.0.1:compaction_new_daemon<0.394.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:47:49.347Z,ns_1@127.0.0.1:compaction_new_daemon<0.394.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:48:19.346Z,ns_1@127.0.0.1:compaction_new_daemon<0.394.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:48:19.346Z,ns_1@127.0.0.1:compaction_new_daemon<0.394.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:48:19.348Z,ns_1@127.0.0.1:compaction_new_daemon<0.394.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:48:19.348Z,ns_1@127.0.0.1:compaction_new_daemon<0.394.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:info,2021-04-19T19:52:22.920Z,nonode@nohost:<0.88.0>:ns_server:init_logging:151]Started & configured logging
[ns_server:info,2021-04-19T19:52:22.943Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]Static config terms:
[{error_logger_mf_dir,"/opt/couchbase/var/lib/couchbase/logs"},
 {path_config_bindir,"/opt/couchbase/bin"},
 {path_config_etcdir,"/opt/couchbase/etc/couchbase"},
 {path_config_libdir,"/opt/couchbase/lib"},
 {path_config_datadir,"/opt/couchbase/var/lib/couchbase"},
 {path_config_tmpdir,"/opt/couchbase/var/lib/couchbase/tmp"},
 {path_config_secdir,"/opt/couchbase/etc/security"},
 {nodefile,"/opt/couchbase/var/lib/couchbase/couchbase-server.node"},
 {loglevel_default,debug},
 {loglevel_couchdb,info},
 {loglevel_ns_server,debug},
 {loglevel_error_logger,debug},
 {loglevel_user,debug},
 {loglevel_menelaus,debug},
 {loglevel_ns_doctor,debug},
 {loglevel_stats,debug},
 {loglevel_rebalance,debug},
 {loglevel_cluster,debug},
 {loglevel_views,debug},
 {loglevel_mapreduce_errors,debug},
 {loglevel_xdcr,debug},
 {loglevel_xdcr_trace,error},
 {loglevel_access,info},
 {disk_sink_opts,
     [{rotation,
          [{compress,true},
           {size,41943040},
           {num_files,10},
           {buffer_size_max,52428800}]}]},
 {disk_sink_opts_xdcr_trace,
     [{rotation,[{compress,false},{size,83886080},{num_files,5}]}]},
 {net_kernel_verbosity,10}]
[ns_server:warn,2021-04-19T19:52:22.944Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter error_logger_mf_dir, which is given from command line
[ns_server:warn,2021-04-19T19:52:22.944Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter path_config_bindir, which is given from command line
[ns_server:warn,2021-04-19T19:52:22.944Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter path_config_etcdir, which is given from command line
[ns_server:warn,2021-04-19T19:52:22.944Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter path_config_libdir, which is given from command line
[ns_server:warn,2021-04-19T19:52:22.944Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter path_config_datadir, which is given from command line
[ns_server:warn,2021-04-19T19:52:22.945Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter path_config_tmpdir, which is given from command line
[ns_server:warn,2021-04-19T19:52:22.945Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter path_config_secdir, which is given from command line
[ns_server:warn,2021-04-19T19:52:22.945Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter nodefile, which is given from command line
[ns_server:warn,2021-04-19T19:52:22.945Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_default, which is given from command line
[ns_server:warn,2021-04-19T19:52:22.945Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_couchdb, which is given from command line
[ns_server:warn,2021-04-19T19:52:22.945Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_ns_server, which is given from command line
[ns_server:warn,2021-04-19T19:52:22.945Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_error_logger, which is given from command line
[ns_server:warn,2021-04-19T19:52:22.945Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_user, which is given from command line
[ns_server:warn,2021-04-19T19:52:22.945Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_menelaus, which is given from command line
[ns_server:warn,2021-04-19T19:52:22.945Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_ns_doctor, which is given from command line
[ns_server:warn,2021-04-19T19:52:22.945Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_stats, which is given from command line
[ns_server:warn,2021-04-19T19:52:22.945Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_rebalance, which is given from command line
[ns_server:warn,2021-04-19T19:52:22.945Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_cluster, which is given from command line
[ns_server:warn,2021-04-19T19:52:22.945Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_views, which is given from command line
[ns_server:warn,2021-04-19T19:52:22.945Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_mapreduce_errors, which is given from command line
[ns_server:warn,2021-04-19T19:52:22.946Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_xdcr, which is given from command line
[ns_server:warn,2021-04-19T19:52:22.946Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_xdcr_trace, which is given from command line
[ns_server:warn,2021-04-19T19:52:22.946Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_access, which is given from command line
[ns_server:warn,2021-04-19T19:52:22.946Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter disk_sink_opts, which is given from command line
[ns_server:warn,2021-04-19T19:52:22.946Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter disk_sink_opts_xdcr_trace, which is given from command line
[ns_server:warn,2021-04-19T19:52:22.946Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter net_kernel_verbosity, which is given from command line
[error_logger:info,2021-04-19T19:52:22.954Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.128.0>},
                       {name,local_tasks},
                       {mfargs,{local_tasks,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:52:22.965Z,nonode@nohost:ns_server_cluster_sup<0.127.0>:log_os_info:start_link:25]OS type: {unix,linux} Version: {4,19,128}
Runtime info: [{otp_release,"R16B03-1"},
               {erl_version,"5.10.4.0.0.1"},
               {erl_version_long,
                   "Erlang R16B03-1 (erts-5.10.4.0.0.1) [source-00852da] [64-bit] [smp:8:8] [async-threads:16] [kernel-poll:true]\n"},
               {system_arch_raw,"x86_64-unknown-linux-gnu"},
               {system_arch,"x86_64-unknown-linux-gnu"},
               {localtime,{{2021,4,19},{19,52,22}}},
               {memory,
                   [{total,111061960},
                    {processes,9530720},
                    {processes_used,9530064},
                    {system,101531240},
                    {atom,331249},
                    {atom_used,310220},
                    {binary,56600},
                    {code,7694133},
                    {ets,2240600}]},
               {loaded,
                   [ns_info,log_os_info,local_tasks,restartable,
                    ns_server_cluster_sup,calendar,ale_default_formatter,
                    'ale_logger-metakv','ale_logger-rebalance',
                    'ale_logger-xdcr_trace','ale_logger-menelaus',
                    'ale_logger-stats','ale_logger-access',
                    'ale_logger-ns_server','ale_logger-user',
                    'ale_logger-ns_doctor','ale_logger-cluster',io_lib_fread,
                    'ale_logger-xdcr',otp_internal,ns_log_sink,ale_disk_sink,
                    misc,couch_util,ns_server,filelib,cpu_sup,memsup,disksup,
                    os_mon,io,release_handler,overload,alarm_handler,sasl,
                    timer,tftp_sup,httpd_sup,httpc_handler_sup,httpc_cookie,
                    inets_trace,httpc_manager,httpc,httpc_profile_sup,
                    httpc_sup,ftp_sup,inets_sup,inets_app,ssl,lhttpc_manager,
                    lhttpc_sup,lhttpc,tls_connection_sup,ssl_session_cache,
                    ssl_pkix_db,ssl_manager,ssl_sup,ssl_app,crypto_server,
                    crypto_sup,crypto_app,ale_error_logger_handler,
                    'ale_logger-ale_logger','ale_logger-error_logger',
                    beam_opcodes,beam_dict,beam_asm,beam_validator,beam_z,
                    beam_flatten,beam_trim,beam_receive,beam_bsm,beam_peep,
                    beam_dead,beam_split,beam_type,beam_bool,beam_except,
                    beam_clean,beam_utils,beam_block,beam_jump,beam_a,
                    v3_codegen,v3_life,v3_kernel,sys_core_dsetel,erl_bifs,
                    sys_core_fold,cerl_trees,sys_core_inline,core_lib,cerl,
                    v3_core,erl_bits,erl_expand_records,sys_pre_expand,sofs,
                    erl_internal,sets,ordsets,erl_lint,compile,
                    dynamic_compile,ale_utils,io_lib_pretty,io_lib_format,
                    io_lib,ale_codegen,dict,ale,ale_dynamic_sup,ale_sup,
                    ale_app,epp,ns_bootstrap,child_erlang,file_io_server,
                    orddict,erl_eval,file,c,kernel_config,user_sup,
                    supervisor_bridge,standard_error,code_server,unicode,
                    hipe_unified_loader,gb_sets,ets,binary,code,file_server,
                    net_kernel,global_group,erl_distribution,filename,
                    inet_gethost_native,os,inet_parse,inet,inet_udp,
                    inet_config,inet_db,global,gb_trees,rpc,supervisor,kernel,
                    application_master,sys,application,gen_server,erl_parse,
                    proplists,erl_scan,lists,application_controller,proc_lib,
                    gen,gen_event,error_logger,heart,error_handler,
                    erts_internal,erlang,erl_prim_loader,prim_zip,zlib,
                    prim_file,prim_inet,prim_eval,init,otp_ring0]},
               {applications,
                   [{lhttpc,"Lightweight HTTP Client","1.3.0"},
                    {os_mon,"CPO  CXC 138 46","2.2.14"},
                    {public_key,"Public key infrastructure","0.21"},
                    {asn1,"The Erlang ASN1 compiler version 2.0.4","2.0.4"},
                    {kernel,"ERTS  CXC 138 10","2.16.4"},
                    {ale,"Another Logger for Erlang","4.6.0-3573-enterprise"},
                    {inets,"INETS  CXC 138 49","5.9.8"},
                    {ns_server,"Couchbase server","4.6.0-3573-enterprise"},
                    {crypto,"CRYPTO version 2","3.2"},
                    {ssl,"Erlang/OTP SSL application","5.3.3"},
                    {sasl,"SASL  CXC 138 11","2.3.4"},
                    {stdlib,"ERTS  CXC 138 10","1.19.4"}]},
               {pre_loaded,
                   [erts_internal,erlang,erl_prim_loader,prim_zip,zlib,
                    prim_file,prim_inet,prim_eval,init,otp_ring0]},
               {process_count,94},
               {node,nonode@nohost},
               {nodes,[]},
               {registered,
                   [ftp_sup,'sink-disk_xdcr',code_server,sasl_sup,
                    'sink-disk_debug',application_controller,
                    'sink-disk_error',local_tasks,'sink-disk_default',
                    ale_stats_events,kernel_safe_sup,inets_sup,ale,
                    standard_error,error_logger,lhttpc_sup,ale_sup,
                    lhttpc_manager,timer_server,standard_error_sup,
                    release_handler,httpd_sup,ale_dynamic_sup,overload,
                    alarm_handler,init,inet_db,rex,kernel_sup,'sink-ns_log',
                    global_name_server,sasl_safe_sup,crypto_server,crypto_sup,
                    file_server_2,tftp_sup,global_group,os_mon_sup,
                    'sink-disk_metakv',cpu_sup,tls_connection_sup,memsup,
                    ssl_sup,'sink-disk_access_int',disksup,'sink-disk_access',
                    ns_server_cluster_sup,httpc_sup,ssl_manager,
                    'sink-xdcr_trace',erl_prim_loader,'sink-disk_reports',
                    httpc_profile_sup,'sink-disk_stats',httpc_manager,
                    httpc_handler_sup,'sink-disk_xdcr_errors']},
               {cookie,nocookie},
               {wordsize,8},
               {wall_clock,3}]
[ns_server:info,2021-04-19T19:52:22.978Z,nonode@nohost:ns_server_cluster_sup<0.127.0>:log_os_info:start_link:27]Manifest:
["<?xml version=\"1.0\" encoding=\"UTF-8\"?>","<manifest>",
 "  <remote fetch=\"git://github.com/blevesearch/\" name=\"blevesearch\"/>",
 "  <remote fetch=\"git://github.com/couchbase/\" name=\"couchbase\" review=\"review.couchbase.org\"/>",
 "  <remote fetch=\"ssh://git@github.com/couchbase/\" name=\"couchbase-priv\" review=\"review.couchbase.org\"/>",
 "  <remote fetch=\"git://github.com/couchbasedeps/\" name=\"couchbasedeps\" review=\"review.couchbase.org\"/>",
 "  <remote fetch=\"git://github.com/couchbaselabs/\" name=\"couchbaselabs\" review=\"review.couchbase.org\"/>",
 "  ","  <default remote=\"couchbase\" revision=\"master\"/>","  ",
 "  <project groups=\"notdefault,enterprise\" name=\"backup\" path=\"goproj/src/github.com/couchbase/backup\" remote=\"couchbase-priv\" revision=\"469a5e8cc8661f35ab4af74fe45e92a3d89febed\"/>",
 "  <project name=\"bitset\" path=\"godeps/src/github.com/willf/bitset\" remote=\"couchbasedeps\" revision=\"28a4168144bb8ac95454e1f51c84da1933681ad4\"/>",
 "  <project name=\"blance\" path=\"godeps/src/github.com/couchbase/blance\" revision=\"5ce14d13954e04262b7eabfc6978776a4018402b\"/>",
 "  <project name=\"bleve\" path=\"godeps/src/github.com/blevesearch/bleve\" remote=\"blevesearch\" revision=\"f531835d5c212ee5f95c49d2debc28e65e6d1693\"/>",
 "  <project name=\"bleve-mapping-ui\" path=\"godeps/src/github.com/blevesearch/bleve-mapping-ui\" remote=\"blevesearch\" revision=\"b0453426dc1d59918cc763a970f1ad147b22ad6a\"/>",
 "  <project name=\"blevex\" path=\"godeps/src/github.com/blevesearch/blevex\" remote=\"blevesearch\" revision=\"918d980b0d244c8230c7d8c8ee40919f8d55ef88\"/>",
 "  <project name=\"bolt\" path=\"godeps/src/github.com/boltdb/bolt\" remote=\"couchbasedeps\" revision=\"51f99c862475898df9773747d3accd05a7ca33c1\"/>",
 "  <project name=\"buffer\" path=\"godeps/src/github.com/tdewolff/buffer\" remote=\"couchbasedeps\" revision=\"43cef5ba7b6ce99cc410632dad46cf1c6c97026e\"/>",
 "  <project groups=\"notdefault,build\" name=\"build\" path=\"cbbuild\" revision=\"ccd3ae52bbf0ade5fd59adcedba2b8cbbd16cd9b\">",
 "    <annotation name=\"VERSION\" value=\"4.6.0\"/>",
 "    <annotation name=\"BLD_NUM\" value=\"3573\"/>",
 "    <annotation name=\"RELEASE\" value=\"@RELEASE@\"/>",
 "    <annotation name=\"EDITION\" value=\"@EDITION@\"/>","  </project>",
 "  <project name=\"cbauth\" path=\"godeps/src/github.com/couchbase/cbauth\" revision=\"4a6d537777f57b291a8126f94dfbe3201c1d4efc\"/>",
 "  <project name=\"cbflag\" path=\"godeps/src/github.com/couchbase/cbflag\" revision=\"ce5c10adbb78c1212aefda73a85f8cfd1c3ae7e9\"/>",
 "  <project name=\"cbft\" path=\"goproj/src/github.com/couchbase/cbft\" revision=\"99f44266178dbe423890d8dd5bb9439ef2a71318\"/>",
 "  <project name=\"cbgt\" path=\"goproj/src/github.com/couchbase/cbgt\" revision=\"10790963d9cbada17ebfff728ea9298c1c97b7c5\"/>",
 "  <project groups=\"notdefault,enterprise\" name=\"cbq-gui\" path=\"goproj/src/github.com/couchbase/cbq-gui\" remote=\"couchbase-priv\" revision=\"1e19e5e34b64ca6b43a37de6166dac6e76803848\"/>",
 "  <project name=\"clog\" path=\"godeps/src/github.com/couchbase/clog\" revision=\"eebc98233c3e032eb6b9036575d51324ab5932e6\"/>",
 "  <project name=\"context\" path=\"godeps/src/github.com/gorilla/context\" remote=\"couchbasedeps\" revision=\"215affda49addc4c8ef7e2534915df2c8c35c6cd\"/>",
 "  <project name=\"couchbase-cli\" revision=\"951668b6b2fcaa5386b31d59df5004ff667e91e8\"/>",
 "  <project name=\"couchbase-examples\" revision=\"39ee1c2451ac2f2e86a6ff308e21e1201c49cafe\"/>",
 "  <project name=\"couchdb\" revision=\"7b950cfaa3ad30c75a7fcc7f4eb30b2df1a8bd5b\"/>",
 "  <project groups=\"notdefault,packaging\" name=\"couchdbx-app\" revision=\"be5f6ebaa12ac7c0b5382deb9b1b0efa7bf80497\"/>",
 "  <project groups=\"kv\" name=\"couchstore\" revision=\"9cf71ba60cf95f8b835b1040c68c85a4ddc653ee\"/>",
 "  <project name=\"crypto\" path=\"godeps/src/golang.org/x/crypto\" remote=\"couchbasedeps\" revision=\"f23ba3a5ee43012fcb4b92e1a2a405a92554f4f2\"/>",
 "  <project name=\"cznic-b\" path=\"godeps/src/github.com/cznic/b\" remote=\"couchbasedeps\" revision=\"b96e30f1b7bd34b0b9d8760798d67eca83d7f09e\"/>",
 "  <project name=\"dparval\" path=\"godeps/src/github.com/couchbase/dparval\" revision=\"9def03782da875a2477c05bf64985db3f19f59ae\"/>",
 "  <project groups=\"kv\" name=\"ep-engine\" revision=\"e4c8bcbbf20b52b11e93665901597875e10b2070\"/>",
 "  <project groups=\"kv\" name=\"forestdb\" revision=\"1d169510a5102e81547b1d3dc423eb37db908076\"/>",
 "  <project name=\"geocouch\" revision=\"74b4bab07713b233ca2780f9a9a3f7daa1a1dff4\"/>",
 "  <project name=\"go-bindata-assetfs\" path=\"godeps/src/github.com/elazarl/go-bindata-assetfs\" remote=\"couchbasedeps\" revision=\"57eb5e1fc594ad4b0b1dbea7b286d299e0cb43c2\"/>",
 "  <project name=\"go-couchbase\" path=\"godeps/src/github.com/couchbase/go-couchbase\" revision=\"e06e5adaf45e189d4cf3e471341af0bf80bcc312\"/>",
 "  <project name=\"go-jsonpointer\" path=\"godeps/src/github.com/dustin/go-jsonpointer\" remote=\"couchbasedeps\" revision=\"75939f54b39e7dafae879e61f65438dadc5f288c\"/>",
 "  <project name=\"go-metrics\" path=\"godeps/src/github.com/rcrowley/go-metrics\" remote=\"couchbasedeps\" revision=\"dee209f2455f101a5e4e593dea94872d2c62d85d\"/>",
 "  <project name=\"go-porterstemmer\" path=\"godeps/src/github.com/blevesearch/go-porterstemmer\" remote=\"blevesearch\" revision=\"23a2c8e5cf1f380f27722c6d2ae8896431dc7d0e\"/>",
 "  <project name=\"go-slab\" path=\"godeps/src/github.com/couchbase/go-slab\" revision=\"1f5f7f282713ccfab3f46b1610cb8da34bcf676f\"/>",
 "  <project name=\"go-zookeeper\" path=\"godeps/src/github.com/samuel/go-zookeeper\" remote=\"couchbasedeps\" revision=\"fa6674abf3f4580b946a01bf7a1ce4ba8766205b\"/>",
 "  <project name=\"go_json\" path=\"godeps/src/github.com/couchbase/go_json\" revision=\"f5a178ab380eb9a1911cf9c45b4159115b564169\"/>",
 "  <project name=\"go_n1ql\" path=\"godeps/src/github.com/couchbase/go_n1ql\" revision=\"6cf4e348b127e21f56e53eb8c3faaea56afdc588\"/>",
 "  <project name=\"gocb\" path=\"godeps/src/github.com/couchbase/gocb\" revision=\"d5b1a13c1e81f1255ca8155007b470db37ddeb25\"/>",
 "  <project name=\"godbc\" path=\"godeps/src/github.com/couchbase/godbc\" revision=\"adc62033c392ca9df8b5b42c0dda237576b39f9f\"/>",
 "  <project name=\"goforestdb\" path=\"godeps/src/github.com/couchbase/goforestdb\" revision=\"0b501227de0e8c55d99ed14e900eea1a1dbaf899\"/>",
 "  <project name=\"gojson\" path=\"godeps/src/github.com/dustin/gojson\" remote=\"couchbasedeps\" revision=\"af16e0e771e2ed110f2785564ae33931de8829e4\"/>",
 "  <project name=\"golang-snappy\" path=\"godeps/src/github.com/golang/snappy\" remote=\"couchbasedeps\" revision=\"723cc1e459b8eea2dea4583200fd60757d40097a\"/>",
 "  <project name=\"goleveldb\" path=\"godeps/src/github.com/syndtr/goleveldb\" remote=\"couchbasedeps\" revision=\"fa5b5c78794bc5c18f330361059f871ae8c2b9d6\"/>",
 "  <project name=\"gomemcached\" path=\"godeps/src/github.com/couchbase/gomemcached\" revision=\"4604300463c4a379d36d1427b17d3284a93f7621\"/>",
 "  <project name=\"gometa\" path=\"goproj/src/github.com/couchbase/gometa\" revision=\"7da5634cce1de744293acf27bb2aecc13ee50cc5\"/>",
 "  <project groups=\"kv\" name=\"googletest\" remote=\"couchbasedeps\" revision=\"f397fa5ec6365329b2e82eb2d8c03a7897bbefb5\"/>",
 "  <project name=\"goskiplist\" path=\"godeps/src/github.com/ryszard/goskiplist\" remote=\"couchbasedeps\" revision=\"2dfbae5fcf46374f166f8969cb07e167f1be6273\"/>",
 "  <project name=\"gosnappy\" path=\"godeps/src/github.com/syndtr/gosnappy\" remote=\"couchbasedeps\" revision=\"156a073208e131d7d2e212cb749feae7c339e846\"/>",
 "  <project name=\"goutils\" path=\"godeps/src/github.com/couchbase/goutils\" revision=\"5823a0cbaaa9008406021dc5daf80125ea30bba6\"/>",
 "  <project name=\"goxdcr\" path=\"goproj/src/github.com/couchbase/goxdcr\" revision=\"0f66d74c38453d0c1a620588edb4ee6a8fc22577\"/>",
 "  <project name=\"gtreap\" path=\"godeps/src/github.com/steveyen/gtreap\" remote=\"couchbasedeps\" revision=\"0abe01ef9be25c4aedc174758ec2d917314d6d70\"/>",
 "  <project name=\"indexing\" path=\"goproj/src/github.com/couchbase/indexing\" revision=\"1811cdbff66216861320b7657590e961b10b2c0a\"/>",
 "  <project name=\"levigo\" path=\"godeps/src/github.com/jmhodges/levigo\" remote=\"couchbasedeps\" revision=\"1ddad808d437abb2b8a55a950ec2616caa88969b\"/>",
 "  <project name=\"liner\" path=\"godeps/src/github.com/peterh/liner\" remote=\"couchbasedeps\" revision=\"ad1edfd30321d8f006ccf05f1e0524adeb943060\"/>",
 "  <project name=\"liner\" path=\"godeps/src/github.com/sbinet/liner\" remote=\"couchbasedeps\" revision=\"d9335eee40a45a4f5d74524c90040d6fe6013d50\"/>",
 "  <project groups=\"kv\" name=\"memcached\" revision=\"45a464250e1358593fa9f11ec010ddd992f0a717\"/>",
 "  <project name=\"minify\" path=\"godeps/src/github.com/tdewolff/minify\" remote=\"couchbasedeps\" revision=\"ede45cc53f43891267b1fe7c689db9c76d4ce0fb\"/>",
 "  <project name=\"mmap-go\" path=\"godeps/src/github.com/edsrzf/mmap-go\" remote=\"couchbasedeps\" revision=\"935e0e8a636ca4ba70b713f3e38a19e1b77739e8\"/>",
 "  <project name=\"moss\" path=\"godeps/src/github.com/couchbase/moss\" revision=\"c7cc82a67cf3fe50faf9a0697516b885e4fa34b9\"/>",
 "  <project groups=\"kv\" name=\"moxi\" revision=\"363c250e6087a61bf2d4bc8d6eff3325956be731\"/>",
 "  <project name=\"mux\" path=\"godeps/src/github.com/gorilla/mux\" remote=\"couchbasedeps\" revision=\"8a875a034c69b940914d83ea03d3f1299b4d094b\"/>",
 "  <project name=\"net\" path=\"godeps/src/golang.org/x/net\" remote=\"couchbasedeps\" revision=\"8968c61983e8f51a91b8c0ef25bf739278c89634\"/>",
 "  <project name=\"npipe\" path=\"godeps/src/github.com/natefinch/npipe\" remote=\"couchbasedeps\" revision=\"272c8150302e83f23d32a355364578c9c13ab20f\"/>",
 "  <project name=\"ns_server\" revision=\"b6c99dc71308f44261bbcc80688de02942d69f19\"/>",
 "  <project name=\"parse\" path=\"godeps/src/github.com/tdewolff/parse\" remote=\"couchbasedeps\" revision=\"0334a869253aca4b3a10c56c3f3139b394aec3a9\"/>",
 "  <project groups=\"kv\" name=\"platform\" revision=\"a80097d53c779b548d8c78b0a1886b8d44591b23\"/>",
 "  <project name=\"protobuf\" path=\"godeps/src/github.com/golang/protobuf\" remote=\"couchbasedeps\" revision=\"655cdfa588ea190e901bc5590e65d5621688847c\"/>",
 "  <project name=\"query\" path=\"goproj/src/github.com/couchbase/query\" revision=\"2012f9b883199299df53dec638a2b91c21907a53\"/>",
 "  <project name=\"query-ui\" revision=\"ff1f502b2f0c544ca68d2bda60d80fc3a01d573a\"/>",
 "  <project name=\"retriever\" path=\"godeps/src/github.com/couchbase/retriever\" revision=\"e3419088e4d3b4fe3aad3b364fdbe9a154f85f17\"/>",
 "  <project name=\"segment\" path=\"godeps/src/github.com/blevesearch/segment\" remote=\"blevesearch\" revision=\"db70c57796cc8c310613541dfade3dce627d09c7\"/>",
 "  <project groups=\"kv\" name=\"sigar\" revision=\"83bd88595f558987731a1baa3330f641bc36554c\"/>",
 "  <project name=\"strconv\" path=\"godeps/src/github.com/tdewolff/strconv\" remote=\"couchbasedeps\" revision=\"9b189f5be77f33c46776f24dbddb2a7ab32af214\"/>",
 "  <project groups=\"kv\" name=\"subjson\" revision=\"65d3f053e2d968aea00b60234a42e1d1c5b9f6d2\"/>",
 "  <project groups=\"solaris,notdefault\" name=\"sys\" path=\"godeps/src/golang.org/x/sys\" remote=\"couchbasedeps\" revision=\"9d4e42a20653790449273b3c85e67d6d8bae6e2e\"/>",
 "  <project name=\"testrunner\" revision=\"d63ed33d4130ecac236711b4156d41328728e42e\"/>",
 "  <project name=\"text\" path=\"godeps/src/golang.org/x/text\" remote=\"couchbasedeps\" revision=\"601048ad6acbab6cedd582db09b8c4839ff25b15\"/>",
 "  <project groups=\"kv\" name=\"tlm\" revision=\"29fafd6b365e58e9fc43fad749ce20c900890a6b\">",
 "    <copyfile dest=\"GNUmakefile\" src=\"GNUmakefile\"/>",
 "    <copyfile dest=\"Makefile\" src=\"Makefile\"/>",
 "    <copyfile dest=\"CMakeLists.txt\" src=\"CMakeLists.txt\"/>",
 "  </project>",
 "  <project name=\"ts\" path=\"godeps/src/github.com/olekukonko/ts\" remote=\"couchbasedeps\" revision=\"ecf753e7c962639ab5a1fb46f7da627d4c0a04b8\"/>",
 "  <project groups=\"notdefault,packaging\" name=\"voltron\" remote=\"couchbase-priv\" revision=\"876e25cffb99e0ae89078a0443b179bcb5d639c2\"/>",
 "</manifest>"]

[error_logger:info,2021-04-19T19:52:22.983Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.129.0>},
                       {name,timeout_diag_logger},
                       {mfargs,{timeout_diag_logger,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:52:22.987Z,nonode@nohost:dist_manager<0.130.0>:dist_manager:read_address_config_from_path:86]Reading ip config from "/opt/couchbase/var/lib/couchbase/ip_start"
[ns_server:info,2021-04-19T19:52:22.988Z,nonode@nohost:dist_manager<0.130.0>:dist_manager:read_address_config_from_path:86]Reading ip config from "/opt/couchbase/var/lib/couchbase/ip"
[ns_server:info,2021-04-19T19:52:22.989Z,nonode@nohost:dist_manager<0.130.0>:dist_manager:init:163]ip config not found. Looks like we're brand new node
[error_logger:info,2021-04-19T19:52:22.989Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,inet_gethost_native_sup}
             started: [{pid,<0.132.0>},{mfa,{inet_gethost_native,init,[[]]}}]

[error_logger:info,2021-04-19T19:52:22.989Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.131.0>},
                       {name,inet_gethost_native_sup},
                       {mfargs,{inet_gethost_native,start_link,[]}},
                       {restart_type,temporary},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:52:23.741Z,nonode@nohost:dist_manager<0.130.0>:dist_manager:bringup:214]Attempting to bring up net_kernel with name 'ns_1@127.0.0.1'
[error_logger:info,2021-04-19T19:52:23.751Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.134.0>},
                       {name,erl_epmd},
                       {mfargs,{erl_epmd,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:23.751Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.135.0>},
                       {name,auth},
                       {mfargs,{auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:23.752Z,ns_1@127.0.0.1:dist_manager<0.130.0>:dist_manager:configure_net_kernel:255]Set net_kernel vebosity to 10 -> 0
[error_logger:info,2021-04-19T19:52:23.752Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.136.0>},
                       {name,net_kernel},
                       {mfargs,
                           {net_kernel,start_link,
                               [['ns_1@127.0.0.1',longnames]]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:23.752Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_sup}
             started: [{pid,<0.133.0>},
                       {name,net_sup_dynamic},
                       {mfargs,
                           {erl_distribution,start_link,
                               [['ns_1@127.0.0.1',longnames]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,supervisor}]

[ns_server:info,2021-04-19T19:52:23.754Z,ns_1@127.0.0.1:dist_manager<0.130.0>:dist_manager:save_node:147]saving node to "/opt/couchbase/var/lib/couchbase/couchbase-server.node"
[ns_server:debug,2021-04-19T19:52:23.769Z,ns_1@127.0.0.1:dist_manager<0.130.0>:dist_manager:bringup:228]Attempted to save node name to disk: ok
[ns_server:debug,2021-04-19T19:52:23.770Z,ns_1@127.0.0.1:dist_manager<0.130.0>:dist_manager:wait_for_node:235]Waiting for connection to node 'babysitter_of_ns_1@127.0.0.1' to be established
[error_logger:info,2021-04-19T19:52:23.770Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'babysitter_of_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:52:23.778Z,ns_1@127.0.0.1:dist_manager<0.130.0>:dist_manager:wait_for_node:244]Observed node 'babysitter_of_ns_1@127.0.0.1' to come up
[error_logger:info,2021-04-19T19:52:23.784Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.130.0>},
                       {name,dist_manager},
                       {mfargs,{dist_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:23.787Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.141.0>},
                       {name,ns_cookie_manager},
                       {mfargs,{ns_cookie_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:23.788Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.142.0>},
                       {name,ns_cluster},
                       {mfargs,{ns_cluster,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:52:23.790Z,ns_1@127.0.0.1:ns_config_sup<0.143.0>:ns_config_sup:init:32]loading static ns_config from "/opt/couchbase/etc/couchbase/config"
[error_logger:info,2021-04-19T19:52:23.790Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.144.0>},
                       {name,ns_config_events},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_config_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:23.791Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.145.0>},
                       {name,ns_config_events_local},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,ns_config_events_local}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:52:23.848Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_config:load_config:1083]Loading static config from "/opt/couchbase/etc/couchbase/config"
[ns_server:info,2021-04-19T19:52:23.856Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_config:load_config:1097]Loading dynamic config from "/opt/couchbase/var/lib/couchbase/config/config.dat"
[ns_server:debug,2021-04-19T19:52:23.874Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_config:load_config:1105]Here's full dynamic config we loaded:
[[{{service_map,n1ql},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{2,63786080759}}]},
    'ns_1@127.0.0.1']},
  {{service_map,index},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{2,63786080759}}]},
    'ns_1@127.0.0.1']},
  {{metakv,<<"/indexing/settings/config">>},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{4,63786080757}}]}|
    <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.log_level\":\"info\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\":200,\"indexer.settings.max_cpu_percent\":0,\"indexer.settings.storage_mode\":\"memory_optimized\",\"indexer.settings.recovery.max_rollbacks\":5,\"indexer.settings.memory_quota\":314572800,\"indexer.settings.compaction.abort_exceed_interval\":false}">>]},
  {uuid,
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080757}}]}|
    <<"819b5f49755d4c5571ba2861d6185103">>]},
  {rest_creds,
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{2,63786080757}}]}|
    {"Administrator",{password,"*****"}}]},
  {rest,[{port,8091}]},
  {{node,'ns_1@127.0.0.1',services},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080757}}]},
    index,kv,n1ql]},
  {memory_quota,
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080757}}]}|
    300]},
  {{node,'ns_1@127.0.0.1',stop_xdcr},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{2,63786080749}}]}|
    '_deleted']},
  {{service_map,fts},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080749}}]}]},
  {goxdcr_upgrade,
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080749}}]}|
    '_deleted']},
  {read_only_user_creds,
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080749}}]}|
    null]},
  {cluster_compat_version,
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{6,63786080749}}]},
    4,6]},
  {otp,
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080748}}]},
    {cookie,{sanitized,<<"igGdfqmbza2bbcUGcHlgLfqDrDSw4MuqpdcFvTedqb0=">>}}]},
  {cert_and_pkey,
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080742}}]}|
    {<<"-----BEGIN CERTIFICATE-----\nMIIDAjCCAeqgAwIBAgIIFndZ/vr3iFgwDQYJKoZIhvcNAQELBQAwJDEiMCAGA1UE\nAxMZQ291Y2hiYXNlIFNlcnZlciBiODgwZTU4MjAeFw0xMzAxMDEwMDAwMDBaFw00\nOTEyMzEyMzU5NTlaMCQxIjAgBgNVBAMTGUNvdWNoYmFzZSBTZXJ2ZXIgYjg4MGU1\nODIwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDPKYjrGZUDKn7xXZhz\n/CcGig/KlI7xzgbLixQnJ5VLNHQOaIcz01bkH2SuTUnIg3i9awTEc/vdraqbL7dK\neAQZEWpnUrZo8sPI/sI9nYnAJttUCQD0cmsC1X0n0uNxaGVj2i2RsOvbPM+EJHOM\nWEESG/u7+Wf4aeV43AqreUXuiGwy7huZuTMU0MK1/qM2XbG2/cv2Oj7HZ6Sqp8vH\n1jEQqyG0I2NJyGfAEvHnswY2t99lDunBJJEjf0am2BJkC23tMZPmLWoTqTT4CSuK\n1Fl1OKj/ZM5dwDwHEmks1I/q88rXRA4AYZQWDdLCM8aZvhUYP0yKj585/v/HmMN4\nkFRVAgMBAAGjODA2MA4GA1UdDwEB/wQEAwICpDATBgNVHSUEDDAKBggrBgEFBQcD\nATAPBgNVHRMBAf8EBTADAQH/MA0GCSqGSIb3DQEBCwUAA4IBAQBLvg8P2SCkc22T\n8fwRrq7jUh+N0Qo/khU0rHZqC7DKJtI9j8e3yFQcxYPCCAOYfaEO9hPDhckBwJGE\nnjoLrfPGHHWM2Tw4RHrYcJ8q5UMjPqCM422ylEzf/vRYUbC175vfo41zkR/F7TYt\napV4DiUM6YmXssYtW66yEcwsZMyDpu/kl/c7+H0yKANJugp8mJWHsnHszvBdn+FT\ns0yV4IGMUPaFMJZOwG+yVlRtAQnZufEzxSgIT0mYWk1DjU+ji8w7r8nthDJoJRqN\nObL+ZMUIupp8NnGF7xz5ll4nmeup8M8CYTnyS0L1tqQ2/Qo0mOy5bwfZuTqzHJE2\nP6fNdAiq\n-----END CERTIFICATE-----\n">>,
     <<"*****">>}]},
  {alert_limits,
   [{max_overhead_perc,50},{max_disk_used,90},{max_indexer_ram,75}]},
  {audit,
   [{auditd_enabled,false},
    {rotate_interval,86400},
    {rotate_size,20971520},
    {disabled,[]},
    {sync,[]},
    {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]},
  {auto_failover_cfg,[{enabled,false},{timeout,120},{max_nodes,1},{count,0}]},
  {autocompaction,
   [{database_fragmentation_threshold,{30,undefined}},
    {view_fragmentation_threshold,{30,undefined}}]},
  {buckets,[{configs,[]}]},
  {drop_request_memory_threshold_mib,undefined},
  {email_alerts,
   [{recipients,["root@localhost"]},
    {sender,"couchbase@localhost"},
    {enabled,false},
    {email_server,
     [{user,[]},{pass,"*****"},{host,"localhost"},{port,25},{encrypt,false}]},
    {alerts,
     [auto_failover_node,auto_failover_maximum_reached,
      auto_failover_other_nodes_down,auto_failover_cluster_too_small,
      auto_failover_disabled,ip,disk,overhead,ep_oom_errors,
      ep_item_commit_failed,audit_dropped_events,indexer_ram_max_usage,
      ep_clock_cas_drift_threshold_exceeded]}]},
  {fts_memory_quota,512},
  {index_aware_rebalance_disabled,false},
  {max_bucket_count,10},
  {memcached,[]},
  {nodes_wanted,['ns_1@127.0.0.1']},
  {remote_clusters,[]},
  {replication,[{enabled,true}]},
  {roles_definitions,
   [{admin,[],
     [{name,<<"Admin">>},
      {desc,<<"Can manage ALL cluster features including security.">>}],
     [{[],all}]},
    {ro_admin,[],
     [{name,<<"Read Only Admin">>},
      {desc,<<"Can view ALL cluster features.">>}],
     [{[{bucket,any},password],none},
      {[{bucket,any},data],none},
      {[admin,security],[read]},
      {[admin],none},
      {[],[read]}]},
    {cluster_admin,[],
     [{name,<<"Cluster Admin">>},
      {desc,<<"Can manage all cluster features EXCEPT security.">>}],
     [{[admin],none},{[],all}]},
    {bucket_admin,
     [bucket_name],
     [{name,<<"Bucket Admin">>},
      {desc,
       <<"Can manage ALL bucket features for specified buckets (incl. start/stop XDCR)">>}],
     [{[{bucket,bucket_name},xdcr],[read,execute]},
      {[{bucket,bucket_name}],all},
      {[{bucket,any},settings],[read]},
      {[{bucket,any}],none},
      {[xdcr],none},
      {[admin],none},
      {[],[read]}]},
    {bucket_sasl,
     [bucket_name],
     [],
     [{[{bucket,bucket_name},data],all},
      {[{bucket,bucket_name},views],all},
      {[{bucket,bucket_name}],[read,flush]},
      {[pools],[read]}]},
    {views_admin,
     [bucket_name],
     [{name,<<"Views Admin">>},
      {desc,<<"Can manage views for specified buckets">>}],
     [{[{bucket,bucket_name},views],all},
      {[{bucket,bucket_name},data],[read]},
      {[{bucket,any},settings],[read]},
      {[{bucket,any}],none},
      {[xdcr],none},
      {[admin],none},
      {[],[read]}]},
    {replication_admin,[],
     [{name,<<"Replication Admin">>},
      {desc,<<"Can manage ONLY XDCR features (cluster AND bucket level)">>}],
     [{[{bucket,any},xdcr],all},
      {[{bucket,any},data],[read]},
      {[{bucket,any},settings],[read]},
      {[{bucket,any}],none},
      {[xdcr],all},
      {[admin],none},
      {[],[read]}]}]},
  {server_groups,
   [[{uuid,<<"0">>},{name,<<"Group 1">>},{nodes,['ns_1@127.0.0.1']}]]},
  {set_view_update_daemon,
   [{update_interval,5000},
    {update_min_changes,5000},
    {replica_update_min_changes,5000}]},
  {{couchdb,max_parallel_indexers},4},
  {{couchdb,max_parallel_replica_indexers},2},
  {{request_limit,capi},undefined},
  {{request_limit,rest},undefined},
  {{node,'ns_1@127.0.0.1',audit},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}]},
  {{node,'ns_1@127.0.0.1',capi_port},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    8092]},
  {{node,'ns_1@127.0.0.1',compaction_daemon},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
    {check_interval,30},
    {min_db_file_size,131072},
    {min_view_file_size,20971520}]},
  {{node,'ns_1@127.0.0.1',config_version},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    {4,5}]},
  {{node,'ns_1@127.0.0.1',fts_http_port},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    8094]},
  {{node,'ns_1@127.0.0.1',indexer_admin_port},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    9100]},
  {{node,'ns_1@127.0.0.1',indexer_http_port},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    9102]},
  {{node,'ns_1@127.0.0.1',indexer_scan_port},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    9101]},
  {{node,'ns_1@127.0.0.1',indexer_stcatchup_port},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    9104]},
  {{node,'ns_1@127.0.0.1',indexer_stinit_port},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    9103]},
  {{node,'ns_1@127.0.0.1',indexer_stmaint_port},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    9105]},
  {{node,'ns_1@127.0.0.1',is_enterprise},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    true]},
  {{node,'ns_1@127.0.0.1',isasl},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
    {path,"/opt/couchbase/var/lib/couchbase/isasl.pw"}]},
  {{node,'ns_1@127.0.0.1',ldap_enabled},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    true]},
  {{node,'ns_1@127.0.0.1',membership},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    active]},
  {{node,'ns_1@127.0.0.1',memcached},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
    {port,11210},
    {dedicated_port,11209},
    {ssl_port,11207},
    {admin_user,"_admin"},
    {admin_pass,"*****"},
    {engines,
     [{membase,
       [{engine,"/opt/couchbase/lib/memcached/ep.so"},
        {static_config_string,"failpartialwarmup=false"}]},
      {memcached,
       [{engine,"/opt/couchbase/lib/memcached/default_engine.so"},
        {static_config_string,"vb0=true"}]}]},
    {config_path,"/opt/couchbase/var/lib/couchbase/config/memcached.json"},
    {audit_file,"/opt/couchbase/var/lib/couchbase/config/audit.json"},
    {log_path,"/opt/couchbase/var/lib/couchbase/logs"},
    {log_prefix,"memcached.log"},
    {log_generations,20},
    {log_cyclesize,10485760},
    {log_sleeptime,19},
    {log_rotation_period,39003}]},
  {{node,'ns_1@127.0.0.1',memcached_config},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    {[{interfaces,
       {memcached_config_mgr,omit_missing_mcd_ports,
        [{[{host,<<"*">>},{port,port},{maxconn,maxconn}]},
         {[{host,<<"*">>},
           {port,dedicated_port},
           {maxconn,dedicated_port_maxconn}]},
         {[{host,<<"*">>},
           {port,ssl_port},
           {maxconn,maxconn},
           {ssl,
            {[{key,
               <<"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem">>},
              {cert,
               <<"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem">>}]}}]}]}},
      {ssl_cipher_list,{"~s",[ssl_cipher_list]}},
      {ssl_minimum_protocol,{memcached_config_mgr,ssl_minimum_protocol,[]}},
      {connection_idle_time,connection_idle_time},
      {breakpad,
       {[{enabled,breakpad_enabled},
         {minidump_dir,{memcached_config_mgr,get_minidump_dir,[]}}]}},
      {extensions,
       [{[{module,<<"/opt/couchbase/lib/memcached/stdin_term_handler.so">>},
          {config,<<>>}]},
        {[{module,<<"/opt/couchbase/lib/memcached/file_logger.so">>},
          {config,
           {"cyclesize=~B;sleeptime=~B;filename=~s/~s",
            [log_cyclesize,log_sleeptime,log_path,log_prefix]}}]}]},
      {admin,{"~s",[admin_user]}},
      {verbosity,verbosity},
      {audit_file,{"~s",[audit_file]}},
      {dedupe_nmvb_maps,dedupe_nmvb_maps}]}]},
  {{node,'ns_1@127.0.0.1',memcached_defaults},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
    {maxconn,30000},
    {dedicated_port_maxconn,5000},
    {ssl_cipher_list,"HIGH"},
    {connection_idle_time,0},
    {verbosity,0},
    {breakpad_enabled,true},
    {breakpad_minidump_dir_path,"/opt/couchbase/var/lib/couchbase/crash"},
    {dedupe_nmvb_maps,false}]},
  {{node,'ns_1@127.0.0.1',moxi},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
    {port,11211},
    {verbosity,[]}]},
  {{node,'ns_1@127.0.0.1',ns_log},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
    {filename,"/opt/couchbase/var/lib/couchbase/ns_log"}]},
  {{node,'ns_1@127.0.0.1',port_servers},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}]},
  {{node,'ns_1@127.0.0.1',projector_port},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    9999]},
  {{node,'ns_1@127.0.0.1',query_port},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    8093]},
  {{node,'ns_1@127.0.0.1',rest},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
    {port,8091},
    {port_meta,global}]},
  {{node,'ns_1@127.0.0.1',ssl_capi_port},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    18092]},
  {{node,'ns_1@127.0.0.1',ssl_proxy_downstream_port},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    11214]},
  {{node,'ns_1@127.0.0.1',ssl_proxy_upstream_port},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    11215]},
  {{node,'ns_1@127.0.0.1',ssl_query_port},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    18093]},
  {{node,'ns_1@127.0.0.1',ssl_rest_port},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    18091]},
  {{node,'ns_1@127.0.0.1',uuid},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    <<"360fb3d3641e00b1f4f22714c24e2a2a">>]},
  {{node,'ns_1@127.0.0.1',xdcr_rest_port},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    9998]},
  {{local_changes_count,<<"360fb3d3641e00b1f4f22714c24e2a2a">>},
   [{'_vclock',
     [{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{12,63786080759}}]}]}]]
[ns_server:info,2021-04-19T19:52:23.884Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_config:load_config:1126]Here's full dynamic config we loaded + static & default config:
[{{local_changes_count,<<"360fb3d3641e00b1f4f22714c24e2a2a">>},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{12,63786080759}}]}]},
 {{node,'ns_1@127.0.0.1',xdcr_rest_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   9998]},
 {{node,'ns_1@127.0.0.1',uuid},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   <<"360fb3d3641e00b1f4f22714c24e2a2a">>]},
 {{node,'ns_1@127.0.0.1',ssl_rest_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   18091]},
 {{node,'ns_1@127.0.0.1',ssl_query_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   18093]},
 {{node,'ns_1@127.0.0.1',ssl_proxy_upstream_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   11215]},
 {{node,'ns_1@127.0.0.1',ssl_proxy_downstream_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   11214]},
 {{node,'ns_1@127.0.0.1',ssl_capi_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   18092]},
 {{node,'ns_1@127.0.0.1',rest},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
   {port,8091},
   {port_meta,global}]},
 {{node,'ns_1@127.0.0.1',query_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   8093]},
 {{node,'ns_1@127.0.0.1',projector_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   9999]},
 {{node,'ns_1@127.0.0.1',port_servers},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}]},
 {{node,'ns_1@127.0.0.1',ns_log},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
   {filename,"/opt/couchbase/var/lib/couchbase/ns_log"}]},
 {{node,'ns_1@127.0.0.1',moxi},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
   {port,11211},
   {verbosity,[]}]},
 {{node,'ns_1@127.0.0.1',memcached_defaults},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
   {maxconn,30000},
   {dedicated_port_maxconn,5000},
   {ssl_cipher_list,"HIGH"},
   {connection_idle_time,0},
   {verbosity,0},
   {breakpad_enabled,true},
   {breakpad_minidump_dir_path,"/opt/couchbase/var/lib/couchbase/crash"},
   {dedupe_nmvb_maps,false}]},
 {{node,'ns_1@127.0.0.1',memcached_config},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   {[{interfaces,
      {memcached_config_mgr,omit_missing_mcd_ports,
       [{[{host,<<"*">>},{port,port},{maxconn,maxconn}]},
        {[{host,<<"*">>},
          {port,dedicated_port},
          {maxconn,dedicated_port_maxconn}]},
        {[{host,<<"*">>},
          {port,ssl_port},
          {maxconn,maxconn},
          {ssl,
           {[{key,
              <<"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem">>},
             {cert,
              <<"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem">>}]}}]}]}},
     {ssl_cipher_list,{"~s",[ssl_cipher_list]}},
     {ssl_minimum_protocol,{memcached_config_mgr,ssl_minimum_protocol,[]}},
     {connection_idle_time,connection_idle_time},
     {breakpad,
      {[{enabled,breakpad_enabled},
        {minidump_dir,{memcached_config_mgr,get_minidump_dir,[]}}]}},
     {extensions,
      [{[{module,<<"/opt/couchbase/lib/memcached/stdin_term_handler.so">>},
         {config,<<>>}]},
       {[{module,<<"/opt/couchbase/lib/memcached/file_logger.so">>},
         {config,
          {"cyclesize=~B;sleeptime=~B;filename=~s/~s",
           [log_cyclesize,log_sleeptime,log_path,log_prefix]}}]}]},
     {admin,{"~s",[admin_user]}},
     {verbosity,verbosity},
     {audit_file,{"~s",[audit_file]}},
     {dedupe_nmvb_maps,dedupe_nmvb_maps}]}]},
 {{node,'ns_1@127.0.0.1',memcached},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
   {port,11210},
   {dedicated_port,11209},
   {ssl_port,11207},
   {admin_user,"_admin"},
   {admin_pass,"*****"},
   {engines,
    [{membase,
      [{engine,"/opt/couchbase/lib/memcached/ep.so"},
       {static_config_string,"failpartialwarmup=false"}]},
     {memcached,
      [{engine,"/opt/couchbase/lib/memcached/default_engine.so"},
       {static_config_string,"vb0=true"}]}]},
   {config_path,"/opt/couchbase/var/lib/couchbase/config/memcached.json"},
   {audit_file,"/opt/couchbase/var/lib/couchbase/config/audit.json"},
   {log_path,"/opt/couchbase/var/lib/couchbase/logs"},
   {log_prefix,"memcached.log"},
   {log_generations,20},
   {log_cyclesize,10485760},
   {log_sleeptime,19},
   {log_rotation_period,39003}]},
 {{node,'ns_1@127.0.0.1',membership},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   active]},
 {{node,'ns_1@127.0.0.1',ldap_enabled},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   true]},
 {{node,'ns_1@127.0.0.1',isasl},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
   {path,"/opt/couchbase/var/lib/couchbase/isasl.pw"}]},
 {{node,'ns_1@127.0.0.1',is_enterprise},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   true]},
 {{node,'ns_1@127.0.0.1',indexer_stmaint_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   9105]},
 {{node,'ns_1@127.0.0.1',indexer_stinit_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   9103]},
 {{node,'ns_1@127.0.0.1',indexer_stcatchup_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   9104]},
 {{node,'ns_1@127.0.0.1',indexer_scan_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   9101]},
 {{node,'ns_1@127.0.0.1',indexer_http_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   9102]},
 {{node,'ns_1@127.0.0.1',indexer_admin_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   9100]},
 {{node,'ns_1@127.0.0.1',fts_http_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   8094]},
 {{node,'ns_1@127.0.0.1',config_version},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   {4,5}]},
 {{node,'ns_1@127.0.0.1',compaction_daemon},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
   {check_interval,30},
   {min_db_file_size,131072},
   {min_view_file_size,20971520}]},
 {{node,'ns_1@127.0.0.1',capi_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   8092]},
 {{node,'ns_1@127.0.0.1',audit},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}]},
 {{request_limit,rest},undefined},
 {{request_limit,capi},undefined},
 {{couchdb,max_parallel_replica_indexers},2},
 {{couchdb,max_parallel_indexers},4},
 {set_view_update_daemon,
  [{update_interval,5000},
   {update_min_changes,5000},
   {replica_update_min_changes,5000}]},
 {server_groups,
  [[{uuid,<<"0">>},{name,<<"Group 1">>},{nodes,['ns_1@127.0.0.1']}]]},
 {roles_definitions,
  [{admin,[],
    [{name,<<"Admin">>},
     {desc,<<"Can manage ALL cluster features including security.">>}],
    [{[],all}]},
   {ro_admin,[],
    [{name,<<"Read Only Admin">>},{desc,<<"Can view ALL cluster features.">>}],
    [{[{bucket,any},password],none},
     {[{bucket,any},data],none},
     {[admin,security],[read]},
     {[admin],none},
     {[],[read]}]},
   {cluster_admin,[],
    [{name,<<"Cluster Admin">>},
     {desc,<<"Can manage all cluster features EXCEPT security.">>}],
    [{[admin],none},{[],all}]},
   {bucket_admin,
    [bucket_name],
    [{name,<<"Bucket Admin">>},
     {desc,
      <<"Can manage ALL bucket features for specified buckets (incl. start/stop XDCR)">>}],
    [{[{bucket,bucket_name},xdcr],[read,execute]},
     {[{bucket,bucket_name}],all},
     {[{bucket,any},settings],[read]},
     {[{bucket,any}],none},
     {[xdcr],none},
     {[admin],none},
     {[],[read]}]},
   {bucket_sasl,
    [bucket_name],
    [],
    [{[{bucket,bucket_name},data],all},
     {[{bucket,bucket_name},views],all},
     {[{bucket,bucket_name}],[read,flush]},
     {[pools],[read]}]},
   {views_admin,
    [bucket_name],
    [{name,<<"Views Admin">>},
     {desc,<<"Can manage views for specified buckets">>}],
    [{[{bucket,bucket_name},views],all},
     {[{bucket,bucket_name},data],[read]},
     {[{bucket,any},settings],[read]},
     {[{bucket,any}],none},
     {[xdcr],none},
     {[admin],none},
     {[],[read]}]},
   {replication_admin,[],
    [{name,<<"Replication Admin">>},
     {desc,<<"Can manage ONLY XDCR features (cluster AND bucket level)">>}],
    [{[{bucket,any},xdcr],all},
     {[{bucket,any},data],[read]},
     {[{bucket,any},settings],[read]},
     {[{bucket,any}],none},
     {[xdcr],all},
     {[admin],none},
     {[],[read]}]}]},
 {replication,[{enabled,true}]},
 {remote_clusters,[]},
 {nodes_wanted,['ns_1@127.0.0.1']},
 {memcached,[]},
 {max_bucket_count,10},
 {index_aware_rebalance_disabled,false},
 {fts_memory_quota,512},
 {email_alerts,
  [{recipients,["root@localhost"]},
   {sender,"couchbase@localhost"},
   {enabled,false},
   {email_server,
    [{user,[]},{pass,"*****"},{host,"localhost"},{port,25},{encrypt,false}]},
   {alerts,
    [auto_failover_node,auto_failover_maximum_reached,
     auto_failover_other_nodes_down,auto_failover_cluster_too_small,
     auto_failover_disabled,ip,disk,overhead,ep_oom_errors,
     ep_item_commit_failed,audit_dropped_events,indexer_ram_max_usage,
     ep_clock_cas_drift_threshold_exceeded]}]},
 {drop_request_memory_threshold_mib,undefined},
 {buckets,[{configs,[]}]},
 {autocompaction,
  [{database_fragmentation_threshold,{30,undefined}},
   {view_fragmentation_threshold,{30,undefined}}]},
 {auto_failover_cfg,[{enabled,false},{timeout,120},{max_nodes,1},{count,0}]},
 {audit,
  [{auditd_enabled,false},
   {rotate_interval,86400},
   {rotate_size,20971520},
   {disabled,[]},
   {sync,[]},
   {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]},
 {alert_limits,
  [{max_overhead_perc,50},{max_disk_used,90},{max_indexer_ram,75}]},
 {cert_and_pkey,
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080742}}]}|
   {<<"-----BEGIN CERTIFICATE-----\nMIIDAjCCAeqgAwIBAgIIFndZ/vr3iFgwDQYJKoZIhvcNAQELBQAwJDEiMCAGA1UE\nAxMZQ291Y2hiYXNlIFNlcnZlciBiODgwZTU4MjAeFw0xMzAxMDEwMDAwMDBaFw00\nOTEyMzEyMzU5NTlaMCQxIjAgBgNVBAMTGUNvdWNoYmFzZSBTZXJ2ZXIgYjg4MGU1\nODIwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDPKYjrGZUDKn7xXZhz\n/CcGig/KlI7xzgbLixQnJ5VLNHQOaIcz01bkH2SuTUnIg3i9awTEc/vdraqbL7dK\neAQZEWpnUrZo8sPI/sI9nYnAJttUCQD0cmsC1X0n0uNxaGVj2i2RsOvbPM+EJHOM\nWEESG/u7+Wf4aeV43AqreUXuiGwy7huZuTMU0MK1/qM2XbG2/cv2Oj7HZ6Sqp8vH\n1jEQqyG0I2NJyGfAEvHnswY2t99lDunBJJEjf0am2BJkC23tMZPmLWoTqTT4CSuK\n1Fl1OKj/ZM5dwDwHEmks1I/q88rXRA4AYZQWDdLCM8aZvhUYP0yKj585/v/HmMN4\nkFRVAgMBAAGjODA2MA4GA1UdDwEB/wQEAwICpDATBgNVHSUEDDAKBggrBgEFBQcD\nATAPBgNVHRMBAf8EBTADAQH/MA0GCSqGSIb3DQEBCwUAA4IBAQBLvg8P2SCkc22T\n8fwRrq7jUh+N0Qo/khU0rHZqC7DKJtI9j8e3yFQcxYPCCAOYfaEO9hPDhckBwJGE\nnjoLrfPGHHWM2Tw4RHrYcJ8q5UMjPqCM422ylEzf/vRYUbC175vfo41zkR/F7TYt\napV4DiUM6YmXssYtW66yEcwsZMyDpu/kl/c7+H0yKANJugp8mJWHsnHszvBdn+FT\ns0yV4IGMUPaFMJZOwG+yVlRtAQnZufEzxSgIT0mYWk1DjU+ji8w7r8nthDJoJRqN\nObL+ZMUIupp8NnGF7xz5ll4nmeup8M8CYTnyS0L1tqQ2/Qo0mOy5bwfZuTqzHJE2\nP6fNdAiq\n-----END CERTIFICATE-----\n">>,
    <<"*****">>}]},
 {otp,
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080748}}]},
   {cookie,{sanitized,<<"igGdfqmbza2bbcUGcHlgLfqDrDSw4MuqpdcFvTedqb0=">>}}]},
 {cluster_compat_version,
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{6,63786080749}}]},
   4,6]},
 {read_only_user_creds,
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080749}}]}|
   null]},
 {goxdcr_upgrade,
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080749}}]}|
   '_deleted']},
 {{service_map,fts},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080749}}]}]},
 {{node,'ns_1@127.0.0.1',stop_xdcr},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{2,63786080749}}]}|
   '_deleted']},
 {memory_quota,
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080757}}]}|
   300]},
 {{node,'ns_1@127.0.0.1',services},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080757}}]},
   index,kv,n1ql]},
 {rest,[{port,8091}]},
 {rest_creds,
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{2,63786080757}}]}|
   {"Administrator",{password,"*****"}}]},
 {uuid,
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080757}}]}|
   <<"819b5f49755d4c5571ba2861d6185103">>]},
 {{metakv,<<"/indexing/settings/config">>},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{4,63786080757}}]}|
   <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.log_level\":\"info\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\":200,\"indexer.settings.max_cpu_percent\":0,\"indexer.settings.storage_mode\":\"memory_optimized\",\"indexer.settings.recovery.max_rollbacks\":5,\"indexer.settings.memory_quota\":314572800,\"indexer.settings.compaction.abort_exceed_interval\":false}">>]},
 {{service_map,index},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{2,63786080759}}]},
   'ns_1@127.0.0.1']},
 {{service_map,n1ql},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{2,63786080759}}]},
   'ns_1@127.0.0.1']}]
[error_logger:info,2021-04-19T19:52:23.888Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.146.0>},
                       {name,ns_config},
                       {mfargs,
                           {ns_config,start_link,
                               ["/opt/couchbase/etc/couchbase/config",
                                ns_config_default]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:23.890Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.149.0>},
                       {name,ns_config_remote},
                       {mfargs,
                           {ns_config_replica,start_link,
                               [{local,ns_config_remote}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:23.893Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.150.0>},
                       {name,ns_config_log},
                       {mfargs,{ns_config_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:23.894Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.143.0>},
                       {name,ns_config_sup},
                       {mfargs,{ns_config_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:52:23.896Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.152.0>},
                       {name,vbucket_filter_changes_registry},
                       {mfargs,
                           {ns_process_registry,start_link,
                               [vbucket_filter_changes_registry,
                                [{terminate_command,shutdown}]]}},
                       {restart_type,permanent},
                       {shutdown,100},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:23.899Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.153.0>},
                       {name,json_rpc_connection_sup},
                       {mfargs,{json_rpc_connection_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:52:23.913Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.156.0>},
                       {name,remote_monitors},
                       {mfargs,{remote_monitors,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:23.915Z,ns_1@127.0.0.1:menelaus_barrier<0.157.0>:one_shot_barrier:barrier_body:58]Barrier menelaus_barrier has started
[error_logger:info,2021-04-19T19:52:23.915Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.157.0>},
                       {name,menelaus_barrier},
                       {mfargs,{menelaus_sup,barrier_start_link,[]}},
                       {restart_type,temporary},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:23.916Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.158.0>},
                       {name,rest_lhttpc_pool},
                       {mfargs,
                           {lhttpc_manager,start_link,
                               [[{name,rest_lhttpc_pool},
                                 {connection_timeout,120000},
                                 {pool_size,20}]]}},
                       {restart_type,{permanent,1}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:52:23.948Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.160.0>:ns_ssl_services_setup:init:370]Used ssl options:
[{keyfile,"/opt/couchbase/var/lib/couchbase/config/ssl-cert-key.pem"},
 {certfile,"/opt/couchbase/var/lib/couchbase/config/ssl-cert-key.pem"},
 {versions,[tlsv1,'tlsv1.1','tlsv1.2']},
 {cacertfile,"/opt/couchbase/var/lib/couchbase/config/ssl-cert-key.pem-ca"},
 {dh,<<48,130,1,8,2,130,1,1,0,152,202,99,248,92,201,35,238,246,5,77,93,120,10,
       118,129,36,52,111,193,167,220,49,229,106,105,152,133,121,157,73,158,
       232,153,197,197,21,171,140,30,207,52,165,45,8,221,162,21,199,183,66,
       211,247,51,224,102,214,190,130,96,253,218,193,35,43,139,145,89,200,250,
       145,92,50,80,134,135,188,205,254,148,122,136,237,220,186,147,187,104,
       159,36,147,217,117,74,35,163,145,249,175,242,18,221,124,54,140,16,246,
       169,84,252,45,47,99,136,30,60,189,203,61,86,225,117,255,4,91,46,110,
       167,173,106,51,65,10,248,94,225,223,73,40,232,140,26,11,67,170,118,190,
       67,31,127,233,39,68,88,132,171,224,62,187,207,160,189,209,101,74,8,205,
       174,146,173,80,105,144,246,25,153,86,36,24,178,163,64,202,221,95,184,
       110,244,32,226,217,34,55,188,230,55,16,216,247,173,246,139,76,187,66,
       211,159,17,46,20,18,48,80,27,250,96,189,29,214,234,241,34,69,254,147,
       103,220,133,40,164,84,8,44,241,61,164,151,9,135,41,60,75,4,202,133,173,
       72,6,69,167,89,112,174,40,229,171,2,1,2>>},
 {ciphers,[{dhe_rsa,aes_256_cbc,sha256},
           {dhe_dss,aes_256_cbc,sha256},
           {rsa,aes_256_cbc,sha256},
           {dhe_rsa,aes_128_cbc,sha256},
           {dhe_dss,aes_128_cbc,sha256},
           {rsa,aes_128_cbc,sha256},
           {dhe_rsa,aes_256_cbc,sha},
           {dhe_dss,aes_256_cbc,sha},
           {rsa,aes_256_cbc,sha},
           {dhe_rsa,'3des_ede_cbc',sha},
           {dhe_dss,'3des_ede_cbc',sha},
           {rsa,'3des_ede_cbc',sha},
           {dhe_rsa,aes_128_cbc,sha},
           {dhe_dss,aes_128_cbc,sha},
           {rsa,aes_128_cbc,sha}]}]
[error_logger:info,2021-04-19T19:52:24.085Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_ssl_services_sup}
             started: [{pid,<0.160.0>},
                       {name,ns_ssl_services_setup},
                       {mfargs,{ns_ssl_services_setup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:52:24.123Z,ns_1@127.0.0.1:<0.162.0>:menelaus_pluggable_ui:validate_plugin_spec:117]Loaded pluggable UI specification for fts

[ns_server:info,2021-04-19T19:52:24.124Z,ns_1@127.0.0.1:<0.162.0>:menelaus_pluggable_ui:validate_plugin_spec:117]Loaded pluggable UI specification for n1ql

[ns_server:debug,2021-04-19T19:52:24.148Z,ns_1@127.0.0.1:<0.162.0>:restartable:start_child:98]Started child process <0.164.0>
  MFA: {ns_ssl_services_setup,start_link_rest_service,[]}
[error_logger:info,2021-04-19T19:52:24.148Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_ssl_services_sup}
             started: [{pid,<0.162.0>},
                       {name,ns_rest_ssl_service},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_ssl_services_setup,
                                    start_link_rest_service,[]},
                                1000]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:24.149Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.159.0>},
                       {name,ns_ssl_services_sup},
                       {mfargs,{ns_ssl_services_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2021-04-19T19:52:24.162Z,ns_1@127.0.0.1:wait_link_to_couchdb_node<0.182.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:126]Waiting for ns_couchdb node to start
[error_logger:info,2021-04-19T19:52:24.162Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.181.0>},
                       {name,start_couchdb_node},
                       {mfargs,{ns_server_nodes_sup,start_couchdb_node,[]}},
                       {restart_type,{permanent,5}},
                       {shutdown,86400000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:24.162Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:52:24.163Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.185.0>,shutdown}}
[ns_server:debug,2021-04-19T19:52:24.163Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:52:24.163Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:52:24.364Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:52:24.365Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:52:24.365Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.188.0>,shutdown}}
[error_logger:info,2021-04-19T19:52:24.365Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:52:24.566Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:52:24.567Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.191.0>,shutdown}}
[ns_server:debug,2021-04-19T19:52:24.567Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:52:24.567Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:52:24.768Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:52:24.770Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:52:24.770Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.194.0>,shutdown}}
[error_logger:info,2021-04-19T19:52:24.770Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:52:24.971Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:52:24.973Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:52:24.973Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.197.0>,shutdown}}
[error_logger:info,2021-04-19T19:52:24.974Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:52:25.174Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:52:25.175Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:52:25.175Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.200.0>,shutdown}}
[error_logger:info,2021-04-19T19:52:25.175Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:52:25.376Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:52:25.378Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:52:25.378Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.203.0>,shutdown}}
[error_logger:info,2021-04-19T19:52:25.378Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:52:25.579Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:52:25.588Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.206.0>,shutdown}}
[error_logger:info,2021-04-19T19:52:25.588Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:52:25.588Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:52:25.789Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:52:25.790Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.209.0>,shutdown}}
[error_logger:info,2021-04-19T19:52:25.790Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:52:25.790Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:52:25.991Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:52:25.992Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.212.0>,shutdown}}
[error_logger:info,2021-04-19T19:52:25.993Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:52:25.993Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:52:26.194Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:52:26.195Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.215.0>,shutdown}}
[ns_server:debug,2021-04-19T19:52:26.195Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:52:26.195Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:52:26.396Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:52:26.397Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:52:26.397Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.218.0>,shutdown}}
[error_logger:info,2021-04-19T19:52:26.397Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:52:26.598Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:52:26.598Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:52:26.598Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.221.0>,shutdown}}
[error_logger:info,2021-04-19T19:52:26.598Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:52:26.799Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:52:26.976Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:52:27.180Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:52:27.381Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:52:27.584Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:52:27.795Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:52:28.007Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:52:28.219Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:52:28.422Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:52:28.623Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:52:28.826Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:52:29.028Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:52:29.230Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:52:29.431Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:52:29.633Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[error_logger:info,2021-04-19T19:52:30.260Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.240.0>},
                       {name,timer2_server},
                       {mfargs,{timer2,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:52:30.461Z,ns_1@127.0.0.1:ns_couchdb_port<0.181.0>:ns_port_server:log:210]ns_couchdb<0.181.0>: Apache CouchDB  (LogLevel=info) is starting.

[ns_server:info,2021-04-19T19:52:30.963Z,ns_1@127.0.0.1:ns_couchdb_port<0.181.0>:ns_port_server:log:210]ns_couchdb<0.181.0>: Apache CouchDB has started. Time to relax.

[error_logger:info,2021-04-19T19:52:30.991Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.182.0>},
                       {name,wait_for_couchdb_node},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<ns_server_nodes_sup.0.8580514>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:31.006Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.155.0>:ns_storage_conf:setup_db_and_ix_paths:53]Initialize db_and_ix_paths variable with [{db_path,
                                           "/opt/couchbase/var/lib/couchbase/data"},
                                          {index_path,
                                           "/opt/couchbase/var/lib/couchbase/data"}]
[error_logger:info,2021-04-19T19:52:31.021Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.243.0>},
                       {name,ns_disksup},
                       {mfargs,{ns_disksup,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:31.030Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.244.0>},
                       {name,diag_handler_worker},
                       {mfargs,{work_queue,start_link,[diag_handler_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:52:31.034Z,ns_1@127.0.0.1:ns_server_sup<0.242.0>:dir_size:start_link:39]Starting quick version of dir_size with program name: godu
[error_logger:info,2021-04-19T19:52:31.036Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.245.0>},
                       {name,dir_size},
                       {mfargs,{dir_size,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:31.041Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.246.0>},
                       {name,request_throttler},
                       {mfargs,{request_throttler,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:31.050Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.247.0>},
                       {name,ns_log},
                       {mfargs,{ns_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:31.050Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.248.0>},
                       {name,ns_crash_log_consumer},
                       {mfargs,{ns_log,start_link_crash_consumer,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:31.078Z,ns_1@127.0.0.1:ns_config_isasl_sync<0.249.0>:ns_config_isasl_sync:init:65]isasl_sync init: ["/opt/couchbase/var/lib/couchbase/isasl.pw","_admin"]
[ns_server:debug,2021-04-19T19:52:31.079Z,ns_1@127.0.0.1:ns_config_isasl_sync<0.249.0>:ns_config_isasl_sync:init:73]isasl_sync init buckets: []
[ns_server:debug,2021-04-19T19:52:31.080Z,ns_1@127.0.0.1:ns_config_isasl_sync<0.249.0>:ns_config_isasl_sync:writeSASLConf:145]Writing isasl passwd file: "/opt/couchbase/var/lib/couchbase/isasl.pw"
[ns_server:warn,2021-04-19T19:52:31.138Z,ns_1@127.0.0.1:ns_config_isasl_sync<0.249.0>:ns_memcached:connect:1307]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[ns_server:info,2021-04-19T19:52:31.192Z,ns_1@127.0.0.1:ns_couchdb_port<0.181.0>:ns_port_server:log:210]ns_couchdb<0.181.0>: 137: Booted. Waiting for shutdown request

[error_logger:info,2021-04-19T19:52:32.140Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.249.0>},
                       {name,ns_config_isasl_sync},
                       {mfargs,{ns_config_isasl_sync,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.140Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.251.0>},
                       {name,ns_log_events},
                       {mfargs,{gen_event,start_link,[{local,ns_log_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:32.143Z,ns_1@127.0.0.1:ns_node_disco<0.254.0>:ns_node_disco:init:138]Initting ns_node_disco with []
[ns_server:debug,2021-04-19T19:52:32.143Z,ns_1@127.0.0.1:ns_cookie_manager<0.141.0>:ns_cookie_manager:do_cookie_sync:115]ns_cookie_manager do_cookie_sync
[error_logger:info,2021-04-19T19:52:32.143Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.253.0>},
                       {name,ns_node_disco_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,ns_node_disco_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[user:info,2021-04-19T19:52:32.143Z,ns_1@127.0.0.1:ns_cookie_manager<0.141.0>:ns_cookie_manager:do_cookie_sync:134]Node 'ns_1@127.0.0.1' synchronized otp cookie {sanitized,
                                               <<"igGdfqmbza2bbcUGcHlgLfqDrDSw4MuqpdcFvTedqb0=">>} from cluster
[ns_server:debug,2021-04-19T19:52:32.144Z,ns_1@127.0.0.1:<0.255.0>:ns_node_disco:do_nodes_wanted_updated_fun:224]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"igGdfqmbza2bbcUGcHlgLfqDrDSw4MuqpdcFvTedqb0=">>}
[ns_server:debug,2021-04-19T19:52:32.148Z,ns_1@127.0.0.1:<0.255.0>:ns_node_disco:do_nodes_wanted_updated_fun:230]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"igGdfqmbza2bbcUGcHlgLfqDrDSw4MuqpdcFvTedqb0=">>}
[error_logger:info,2021-04-19T19:52:32.148Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.254.0>},
                       {name,ns_node_disco},
                       {mfargs,{ns_node_disco,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.151Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.256.0>},
                       {name,ns_node_disco_log},
                       {mfargs,{ns_node_disco_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.154Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.257.0>},
                       {name,ns_node_disco_conf_events},
                       {mfargs,{ns_node_disco_conf_events,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:32.158Z,ns_1@127.0.0.1:ns_config_rep<0.259.0>:ns_config_rep:init:68]init pulling
[ns_server:debug,2021-04-19T19:52:32.158Z,ns_1@127.0.0.1:ns_config_rep<0.259.0>:ns_config_rep:init:70]init pushing
[error_logger:info,2021-04-19T19:52:32.158Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.258.0>},
                       {name,ns_config_rep_merger},
                       {mfargs,{ns_config_rep,start_link_merger,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:32.159Z,ns_1@127.0.0.1:ns_config_rep<0.259.0>:ns_config_rep:init:74]init reannouncing
[ns_server:debug,2021-04-19T19:52:32.159Z,ns_1@127.0.0.1:ns_config_events<0.144.0>:ns_node_disco_conf_events:handle_event:44]ns_node_disco_conf_events config on nodes_wanted
[ns_server:debug,2021-04-19T19:52:32.160Z,ns_1@127.0.0.1:ns_cookie_manager<0.141.0>:ns_cookie_manager:do_cookie_sync:115]ns_cookie_manager do_cookie_sync
[ns_server:debug,2021-04-19T19:52:32.160Z,ns_1@127.0.0.1:ns_config_events<0.144.0>:ns_node_disco_conf_events:handle_event:50]ns_node_disco_conf_events config on otp
[ns_server:debug,2021-04-19T19:52:32.160Z,ns_1@127.0.0.1:ns_cookie_manager<0.141.0>:ns_cookie_manager:do_cookie_sync:115]ns_cookie_manager do_cookie_sync
[ns_server:debug,2021-04-19T19:52:32.160Z,ns_1@127.0.0.1:<0.263.0>:ns_node_disco:do_nodes_wanted_updated_fun:224]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"igGdfqmbza2bbcUGcHlgLfqDrDSw4MuqpdcFvTedqb0=">>}
[ns_server:debug,2021-04-19T19:52:32.160Z,ns_1@127.0.0.1:<0.264.0>:ns_node_disco:do_nodes_wanted_updated_fun:224]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"igGdfqmbza2bbcUGcHlgLfqDrDSw4MuqpdcFvTedqb0=">>}
[ns_server:debug,2021-04-19T19:52:32.160Z,ns_1@127.0.0.1:<0.263.0>:ns_node_disco:do_nodes_wanted_updated_fun:230]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"igGdfqmbza2bbcUGcHlgLfqDrDSw4MuqpdcFvTedqb0=">>}
[ns_server:debug,2021-04-19T19:52:32.160Z,ns_1@127.0.0.1:<0.264.0>:ns_node_disco:do_nodes_wanted_updated_fun:230]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"igGdfqmbza2bbcUGcHlgLfqDrDSw4MuqpdcFvTedqb0=">>}
[ns_server:debug,2021-04-19T19:52:32.160Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
alert_limits ->
[{max_overhead_perc,50},{max_disk_used,90},{max_indexer_ram,75}]
[ns_server:debug,2021-04-19T19:52:32.160Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
audit ->
[{auditd_enabled,false},
 {rotate_interval,86400},
 {rotate_size,20971520},
 {disabled,[]},
 {sync,[]},
 {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]
[ns_server:debug,2021-04-19T19:52:32.161Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
auto_failover_cfg ->
[{enabled,false},{timeout,120},{max_nodes,1},{count,0}]
[ns_server:debug,2021-04-19T19:52:32.161Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
autocompaction ->
[{database_fragmentation_threshold,{30,undefined}},
 {view_fragmentation_threshold,{30,undefined}}]
[ns_server:debug,2021-04-19T19:52:32.161Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
buckets ->
[[],{configs,[]}]
[ns_server:debug,2021-04-19T19:52:32.161Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
cert_and_pkey ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080742}}]}|
 {<<"-----BEGIN CERTIFICATE-----\nMIIDAjCCAeqgAwIBAgIIFndZ/vr3iFgwDQYJKoZIhvcNAQELBQAwJDEiMCAGA1UE\nAxMZQ291Y2hiYXNlIFNlcnZlciBiODgwZTU4MjAeFw0xMzAxMDEwMDAwMDBaFw00\nOTEyMzEyMzU5NTlaMCQxIjAgBgNVBAMTGUNvdWNoYmFzZSBTZXJ2ZXIgYjg4MGU1\nODIwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDPKYjrGZUDKn7xXZhz\n/CcGig/KlI7xzgbLixQnJ5VLNHQOaIcz01bkH2SuTUnIg3i9awTEc/vdraqbL7dK\neAQZEWpnUrZo8sPI/sI9nYnAJttUCQD"...>>,
  <<"*****">>}]
[ns_server:debug,2021-04-19T19:52:32.161Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
cluster_compat_version ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{6,63786080749}}]},4,6]
[ns_server:debug,2021-04-19T19:52:32.162Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
drop_request_memory_threshold_mib ->
undefined
[ns_server:debug,2021-04-19T19:52:32.162Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
email_alerts ->
[{recipients,["root@localhost"]},
 {sender,"couchbase@localhost"},
 {enabled,false},
 {email_server,[{user,[]},
                {pass,"*****"},
                {host,"localhost"},
                {port,25},
                {encrypt,false}]},
 {alerts,[auto_failover_node,auto_failover_maximum_reached,
          auto_failover_other_nodes_down,auto_failover_cluster_too_small,
          auto_failover_disabled,ip,disk,overhead,ep_oom_errors,
          ep_item_commit_failed,audit_dropped_events,indexer_ram_max_usage,
          ep_clock_cas_drift_threshold_exceeded]}]
[ns_server:debug,2021-04-19T19:52:32.162Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
fts_memory_quota ->
512
[ns_server:debug,2021-04-19T19:52:32.162Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
goxdcr_upgrade ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080749}}]}|
 '_deleted']
[ns_server:debug,2021-04-19T19:52:32.162Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
index_aware_rebalance_disabled ->
false
[ns_server:debug,2021-04-19T19:52:32.162Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
max_bucket_count ->
10
[ns_server:debug,2021-04-19T19:52:32.163Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
memcached ->
[]
[ns_server:debug,2021-04-19T19:52:32.163Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
memory_quota ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080757}}]}|300]
[ns_server:debug,2021-04-19T19:52:32.163Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
nodes_wanted ->
['ns_1@127.0.0.1']
[error_logger:info,2021-04-19T19:52:32.163Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.259.0>},
                       {name,ns_config_rep},
                       {mfargs,{ns_config_rep,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:32.163Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
otp ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080748}}]},
 {cookie,{sanitized,<<"igGdfqmbza2bbcUGcHlgLfqDrDSw4MuqpdcFvTedqb0=">>}}]
[ns_server:debug,2021-04-19T19:52:32.163Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
read_only_user_creds ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080749}}]}|null]
[ns_server:debug,2021-04-19T19:52:32.163Z,ns_1@127.0.0.1:ns_config_rep<0.259.0>:ns_config_rep:do_push_keys:321]Replicating some config keys ([alert_limits,audit,auto_failover_cfg,
                               autocompaction,buckets,cert_and_pkey,
                               cluster_compat_version,
                               drop_request_memory_threshold_mib,email_alerts,
                               fts_memory_quota,goxdcr_upgrade,
                               index_aware_rebalance_disabled,
                               max_bucket_count,memcached,memory_quota,
                               nodes_wanted,otp,read_only_user_creds,
                               remote_clusters,replication,rest,rest_creds,
                               roles_definitions,server_groups,
                               set_view_update_daemon,uuid,
                               {couchdb,max_parallel_indexers},
                               {couchdb,max_parallel_replica_indexers},
                               {local_changes_count,
                                   <<"360fb3d3641e00b1f4f22714c24e2a2a">>},
                               {metakv,<<"/indexing/settings/config">>},
                               {request_limit,capi},
                               {request_limit,rest},
                               {service_map,fts},
                               {service_map,index},
                               {service_map,n1ql},
                               {node,'ns_1@127.0.0.1',audit},
                               {node,'ns_1@127.0.0.1',capi_port},
                               {node,'ns_1@127.0.0.1',compaction_daemon},
                               {node,'ns_1@127.0.0.1',config_version},
                               {node,'ns_1@127.0.0.1',fts_http_port},
                               {node,'ns_1@127.0.0.1',indexer_admin_port},
                               {node,'ns_1@127.0.0.1',indexer_http_port},
                               {node,'ns_1@127.0.0.1',indexer_scan_port},
                               {node,'ns_1@127.0.0.1',indexer_stcatchup_port},
                               {node,'ns_1@127.0.0.1',indexer_stinit_port},
                               {node,'ns_1@127.0.0.1',indexer_stmaint_port},
                               {node,'ns_1@127.0.0.1',is_enterprise},
                               {node,'ns_1@127.0.0.1',isasl},
                               {node,'ns_1@127.0.0.1',ldap_enabled},
                               {node,'ns_1@127.0.0.1',membership},
                               {node,'ns_1@127.0.0.1',memcached},
                               {node,'ns_1@127.0.0.1',memcached_config},
                               {node,'ns_1@127.0.0.1',memcached_defaults},
                               {node,'ns_1@127.0.0.1',moxi},
                               {node,'ns_1@127.0.0.1',ns_log},
                               {node,'ns_1@127.0.0.1',port_servers},
                               {node,'ns_1@127.0.0.1',projector_port},
                               {node,'ns_1@127.0.0.1',query_port},
                               {node,'ns_1@127.0.0.1',rest},
                               {node,'ns_1@127.0.0.1',services},
                               {node,'ns_1@127.0.0.1',ssl_capi_port},
                               {node,'ns_1@127.0.0.1',
                                   ssl_proxy_downstream_port},
                               {node,'ns_1@127.0.0.1',ssl_proxy_upstream_port},
                               {node,'ns_1@127.0.0.1',ssl_query_port}]..)
[ns_server:debug,2021-04-19T19:52:32.163Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
remote_clusters ->
[]
[error_logger:info,2021-04-19T19:52:32.163Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.252.0>},
                       {name,ns_node_disco_sup},
                       {mfargs,{ns_node_disco_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2021-04-19T19:52:32.164Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
replication ->
[{enabled,true}]
[ns_server:debug,2021-04-19T19:52:32.164Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
rest ->
[{port,8091}]
[ns_server:debug,2021-04-19T19:52:32.164Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
rest_creds ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{2,63786080757}}]}|
 {"Administrator",{password,"*****"}}]
[ns_server:debug,2021-04-19T19:52:32.165Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
roles_definitions ->
[{admin,[],
        [{name,<<"Admin">>},
         {desc,<<"Can manage ALL cluster features including security.">>}],
        [{[],all}]},
 {ro_admin,[],
           [{name,<<"Read Only Admin">>},
            {desc,<<"Can view ALL cluster features.">>}],
           [{[{bucket,any},password],none},
            {[{bucket,any},data],none},
            {[admin,security],[read]},
            {[admin],none},
            {[],[read]}]},
 {cluster_admin,[],
                [{name,<<"Cluster Admin">>},
                 {desc,<<"Can manage all cluster features EXCEPT security.">>}],
                [{[admin],none},{[],all}]},
 {bucket_admin,[bucket_name],
               [{name,<<"Bucket Admin">>},
                {desc,<<"Can manage ALL bucket features for specified buckets (incl. start/stop XDCR)">>}],
               [{[{bucket,bucket_name},xdcr],[read,execute]},
                {[{bucket,bucket_name}],all},
                {[{bucket,any},settings],[read]},
                {[{bucket,any}],none},
                {[xdcr],none},
                {[admin],none},
                {[],[read]}]},
 {bucket_sasl,[bucket_name],
              [],
              [{[{bucket,bucket_name},data],all},
               {[{bucket,bucket_name},views],all},
               {[{bucket,bucket_name}],[read,flush]},
               {[pools],[read]}]},
 {views_admin,[bucket_name],
              [{name,<<"Views Admin">>},
               {desc,<<"Can manage views for specified buckets">>}],
              [{[{bucket,bucket_name},views],all},
               {[{bucket,bucket_name},data],[read]},
               {[{bucket,any},settings],[read]},
               {[{bucket,any}],none},
               {[xdcr],none},
               {[admin],none},
               {[],[read]}]},
 {replication_admin,[],
                    [{name,<<"Replication Admin">>},
                     {desc,<<"Can manage ONLY XDCR features (cluster AND bucket level)">>}],
                    [{[{bucket,any},xdcr],all},
                     {[{bucket,any},data],[read]},
                     {[{bucket,any},settings],[read]},
                     {[{bucket,any}],none},
                     {[xdcr],all},
                     {[admin],none},
                     {[],[read]}]}]
[ns_server:debug,2021-04-19T19:52:32.165Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
server_groups ->
[[{uuid,<<"0">>},{name,<<"Group 1">>},{nodes,['ns_1@127.0.0.1']}]]
[ns_server:debug,2021-04-19T19:52:32.165Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
set_view_update_daemon ->
[{update_interval,5000},
 {update_min_changes,5000},
 {replica_update_min_changes,5000}]
[ns_server:debug,2021-04-19T19:52:32.165Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
uuid ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080757}}]}|
 <<"819b5f49755d4c5571ba2861d6185103">>]
[ns_server:debug,2021-04-19T19:52:32.165Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{couchdb,max_parallel_indexers} ->
4
[ns_server:debug,2021-04-19T19:52:32.166Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{couchdb,max_parallel_replica_indexers} ->
2
[ns_server:debug,2021-04-19T19:52:32.166Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{local_changes_count,<<"360fb3d3641e00b1f4f22714c24e2a2a">>} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{12,63786080759}}]}]
[ns_server:debug,2021-04-19T19:52:32.166Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{metakv,<<"/indexing/settings/config">>} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{4,63786080757}}]}|
 <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.log_level\":\"info\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\""...>>]
[ns_server:debug,2021-04-19T19:52:32.166Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{request_limit,capi} ->
undefined
[ns_server:debug,2021-04-19T19:52:32.166Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{request_limit,rest} ->
undefined
[ns_server:debug,2021-04-19T19:52:32.167Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{service_map,fts} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080749}}]}]
[ns_server:debug,2021-04-19T19:52:32.167Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{service_map,index} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{2,63786080759}}]},
 'ns_1@127.0.0.1']
[ns_server:debug,2021-04-19T19:52:32.167Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{service_map,n1ql} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{2,63786080759}}]},
 'ns_1@127.0.0.1']
[ns_server:debug,2021-04-19T19:52:32.167Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',audit} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}]
[ns_server:debug,2021-04-19T19:52:32.167Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',capi_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|8092]
[ns_server:debug,2021-04-19T19:52:32.168Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',compaction_daemon} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
 {check_interval,30},
 {min_db_file_size,131072},
 {min_view_file_size,20971520}]
[ns_server:debug,2021-04-19T19:52:32.168Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',config_version} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|{4,5}]
[error_logger:info,2021-04-19T19:52:32.167Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.267.0>},
                       {name,vbucket_map_mirror},
                       {mfargs,{vbucket_map_mirror,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:32.168Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',fts_http_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|8094]
[ns_server:debug,2021-04-19T19:52:32.168Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',indexer_admin_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|9100]
[ns_server:debug,2021-04-19T19:52:32.168Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',indexer_http_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|9102]
[ns_server:debug,2021-04-19T19:52:32.168Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',indexer_scan_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|9101]
[ns_server:debug,2021-04-19T19:52:32.169Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',indexer_stcatchup_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|9104]
[ns_server:debug,2021-04-19T19:52:32.169Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',indexer_stinit_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|9103]
[ns_server:debug,2021-04-19T19:52:32.169Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',indexer_stmaint_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|9105]
[ns_server:debug,2021-04-19T19:52:32.169Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',is_enterprise} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|true]
[ns_server:debug,2021-04-19T19:52:32.169Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',isasl} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
 {path,"/opt/couchbase/var/lib/couchbase/isasl.pw"}]
[ns_server:debug,2021-04-19T19:52:32.170Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ldap_enabled} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|true]
[ns_server:debug,2021-04-19T19:52:32.170Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',membership} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
 active]
[ns_server:debug,2021-04-19T19:52:32.170Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',memcached} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
 {port,11210},
 {dedicated_port,11209},
 {ssl_port,11207},
 {admin_user,"_admin"},
 {admin_pass,"*****"},
 {engines,[{membase,[{engine,"/opt/couchbase/lib/memcached/ep.so"},
                     {static_config_string,"failpartialwarmup=false"}]},
           {memcached,[{engine,"/opt/couchbase/lib/memcached/default_engine.so"},
                       {static_config_string,"vb0=true"}]}]},
 {config_path,"/opt/couchbase/var/lib/couchbase/config/memcached.json"},
 {audit_file,"/opt/couchbase/var/lib/couchbase/config/audit.json"},
 {log_path,"/opt/couchbase/var/lib/couchbase/logs"},
 {log_prefix,"memcached.log"},
 {log_generations,20},
 {log_cyclesize,10485760},
 {log_sleeptime,19},
 {log_rotation_period,39003}]
[ns_server:debug,2021-04-19T19:52:32.171Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',memcached_config} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
 {[{interfaces,
    {memcached_config_mgr,omit_missing_mcd_ports,
     [{[{host,<<"*">>},{port,port},{maxconn,maxconn}]},
      {[{host,<<"*">>},
        {port,dedicated_port},
        {maxconn,dedicated_port_maxconn}]},
      {[{host,<<"*">>},
        {port,ssl_port},
        {maxconn,maxconn},
        {ssl,
         {[{key,
            <<"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem">>},
           {cert,
            <<"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem">>}]}}]}]}},
   {ssl_cipher_list,{"~s",[ssl_cipher_list]}},
   {ssl_minimum_protocol,{memcached_config_mgr,ssl_minimum_protocol,[]}},
   {connection_idle_time,connection_idle_time},
   {breakpad,
    {[{enabled,breakpad_enabled},
      {minidump_dir,{memcached_config_mgr,get_minidump_dir,[]}}]}},
   {extensions,
    [{[{module,<<"/opt/couchbase/lib/memcached/stdin_term_handler.so">>},
       {config,<<>>}]},
     {[{module,<<"/opt/couchbase/lib/memcached/file_logger.so">>},
       {config,
        {"cyclesize=~B;sleeptime=~B;filename=~s/~s",
         [log_cyclesize,log_sleeptime,log_path,log_prefix]}}]}]},
   {admin,{"~s",[admin_user]}},
   {verbosity,verbosity},
   {audit_file,{"~s",[audit_file]}},
   {dedupe_nmvb_maps,dedupe_nmvb_maps}]}]
[ns_server:debug,2021-04-19T19:52:32.171Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',memcached_defaults} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
 {maxconn,30000},
 {dedicated_port_maxconn,5000},
 {ssl_cipher_list,"HIGH"},
 {connection_idle_time,0},
 {verbosity,0},
 {breakpad_enabled,true},
 {breakpad_minidump_dir_path,"/opt/couchbase/var/lib/couchbase/crash"},
 {dedupe_nmvb_maps,false}]
[ns_server:debug,2021-04-19T19:52:32.171Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',moxi} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
 {port,11211},
 {verbosity,[]}]
[ns_server:debug,2021-04-19T19:52:32.172Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ns_log} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
 {filename,"/opt/couchbase/var/lib/couchbase/ns_log"}]
[ns_server:debug,2021-04-19T19:52:32.172Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',port_servers} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}]
[ns_server:debug,2021-04-19T19:52:32.172Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',projector_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|9999]
[ns_server:debug,2021-04-19T19:52:32.172Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',query_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|8093]
[ns_server:debug,2021-04-19T19:52:32.172Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',rest} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
 {port,8091},
 {port_meta,global}]
[ns_server:debug,2021-04-19T19:52:32.172Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',services} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080757}}]},
 index,kv,n1ql]
[error_logger:info,2021-04-19T19:52:32.172Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.269.0>},
                       {name,bucket_info_cache},
                       {mfargs,{bucket_info_cache,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:32.172Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ssl_capi_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|18092]
[error_logger:info,2021-04-19T19:52:32.173Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.272.0>},
                       {name,ns_tick_event},
                       {mfargs,{gen_event,start_link,[{local,ns_tick_event}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:32.173Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ssl_proxy_downstream_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|11214]
[error_logger:info,2021-04-19T19:52:32.173Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.273.0>},
                       {name,buckets_events},
                       {mfargs,
                           {gen_event,start_link,[{local,buckets_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:32.173Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ssl_proxy_upstream_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|11215]
[ns_server:debug,2021-04-19T19:52:32.173Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ssl_query_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|18093]
[ns_server:debug,2021-04-19T19:52:32.173Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ssl_rest_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|18091]
[ns_server:debug,2021-04-19T19:52:32.174Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',stop_xdcr} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{2,63786080749}}]}|
 '_deleted']
[ns_server:debug,2021-04-19T19:52:32.174Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',uuid} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
 <<"360fb3d3641e00b1f4f22714c24e2a2a">>]
[ns_server:debug,2021-04-19T19:52:32.174Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',xdcr_rest_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|9998]
[ns_server:debug,2021-04-19T19:52:32.179Z,ns_1@127.0.0.1:ns_log_events<0.251.0>:ns_mail_log:init:44]ns_mail_log started up
[error_logger:info,2021-04-19T19:52:32.179Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_mail_sup}
             started: [{pid,<0.275.0>},
                       {name,ns_mail_log},
                       {mfargs,{ns_mail_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.179Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.274.0>},
                       {name,ns_mail_sup},
                       {mfargs,{ns_mail_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:52:32.179Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.276.0>},
                       {name,ns_stats_event},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_stats_event}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.182Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.277.0>},
                       {name,samples_loader_tasks},
                       {mfargs,{samples_loader_tasks,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.190Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_heart_sup}
             started: [{pid,<0.279.0>},
                       {name,ns_heart},
                       {mfargs,{ns_heart,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.190Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_heart_sup}
             started: [{pid,<0.281.0>},
                       {name,ns_heart_slow_updater},
                       {mfargs,{ns_heart,start_link_slow_updater,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.190Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.278.0>},
                       {name,ns_heart_sup},
                       {mfargs,{ns_heart_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:52:32.192Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_doctor_sup}
             started: [{pid,<0.285.0>},
                       {name,ns_doctor_events},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_doctor_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:32.196Z,ns_1@127.0.0.1:ns_heart<0.279.0>:ns_heart:grab_latest_stats:259]Ignoring failure to grab "@system" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,117}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,255}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,249}]},
                 {ns_heart,update_current_status,1,
                           [{file,"src/ns_heart.erl"},{line,186}]},
                 {ns_heart,handle_info,2,
                           [{file,"src/ns_heart.erl"},{line,118}]}]}}

[ns_server:debug,2021-04-19T19:52:32.196Z,ns_1@127.0.0.1:ns_heart<0.279.0>:ns_heart:grab_latest_stats:259]Ignoring failure to grab "@system-processes" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-processes-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,117}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,255}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,249}]},
                 {ns_heart,update_current_status,1,
                           [{file,"src/ns_heart.erl"},{line,186}]}]}}

[ns_server:debug,2021-04-19T19:52:32.202Z,ns_1@127.0.0.1:<0.282.0>:restartable:start_child:98]Started child process <0.284.0>
  MFA: {ns_doctor_sup,start_link,[]}
[error_logger:info,2021-04-19T19:52:32.202Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_doctor_sup}
             started: [{pid,<0.286.0>},
                       {name,ns_doctor},
                       {mfargs,{ns_doctor,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.202Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.282.0>},
                       {name,ns_doctor_sup},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_doctor_sup,start_link,[]},infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2021-04-19T19:52:32.246Z,ns_1@127.0.0.1:ns_heart<0.279.0>:ns_heart:grab_index_status:373]ignoring failure to get index status: {exit,
                                       {noproc,
                                        {gen_server,call,
                                         ['index_status_keeper-index',
                                          get_status,2000]}}}
[{gen_server,call,3,[{file,"gen_server.erl"},{line,188}]},
 {ns_heart,grab_index_status,0,[{file,"src/ns_heart.erl"},{line,370}]},
 {ns_heart,current_status_slow_inner,0,[{file,"src/ns_heart.erl"},{line,280}]},
 {ns_heart,current_status_slow,1,[{file,"src/ns_heart.erl"},{line,249}]},
 {ns_heart,update_current_status,1,[{file,"src/ns_heart.erl"},{line,186}]},
 {ns_heart,handle_info,2,[{file,"src/ns_heart.erl"},{line,118}]},
 {gen_server,handle_msg,5,[{file,"gen_server.erl"},{line,604}]},
 {proc_lib,init_p_do_apply,3,[{file,"proc_lib.erl"},{line,239}]}]
[error_logger:info,2021-04-19T19:52:32.249Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.291.0>},
                       {name,disk_log_sup},
                       {mfargs,{disk_log_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:52:32.249Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.292.0>},
                       {name,disk_log_server},
                       {mfargs,{disk_log_server,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.264Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.289.0>},
                       {name,remote_clusters_info},
                       {mfargs,{remote_clusters_info,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.264Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.295.0>},
                       {name,master_activity_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,master_activity_events}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.270Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.296.0>},
                       {name,xdcr_ckpt_store},
                       {mfargs,{simple_store,start_link,[xdcr_ckpt_data]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.270Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.297.0>},
                       {name,metakv_worker},
                       {mfargs,{work_queue,start_link,[metakv_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.270Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.298.0>},
                       {name,index_events},
                       {mfargs,{gen_event,start_link,[{local,index_events}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.277Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.299.0>},
                       {name,index_settings_manager},
                       {mfargs,{index_settings_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.284Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.303.0>},
                       {name,menelaus_ui_auth},
                       {mfargs,{menelaus_ui_auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.293Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.305.0>},
                       {name,menelaus_local_auth},
                       {mfargs,{menelaus_local_auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:32.299Z,ns_1@127.0.0.1:ns_heart<0.279.0>:goxdcr_rest:get_from_goxdcr:163]Goxdcr is temporary not available. Return empty list.
[error_logger:info,2021-04-19T19:52:32.306Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.306.0>},
                       {name,menelaus_web_cache},
                       {mfargs,{menelaus_web_cache,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:32.312Z,ns_1@127.0.0.1:ns_heart<0.279.0>:cluster_logs_collection_task:maybe_build_cluster_logs_task:43]Ignoring exception trying to read cluster_logs_collection_task_status table: error:badarg
[error_logger:info,2021-04-19T19:52:32.314Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.308.0>},
                       {name,menelaus_stats_gatherer},
                       {mfargs,{menelaus_stats_gatherer,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:52:32.315Z,ns_1@127.0.0.1:ns_couchdb_port<0.181.0>:ns_port_server:log:210]ns_couchdb<0.181.0>: working as port

[error_logger:info,2021-04-19T19:52:32.315Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.309.0>},
                       {name,json_rpc_events},
                       {mfargs,
                           {gen_event,start_link,[{local,json_rpc_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:52:32.317Z,ns_1@127.0.0.1:menelaus_sup<0.301.0>:menelaus_pluggable_ui:validate_plugin_spec:117]Loaded pluggable UI specification for fts

[ns_server:info,2021-04-19T19:52:32.318Z,ns_1@127.0.0.1:menelaus_sup<0.301.0>:menelaus_pluggable_ui:validate_plugin_spec:117]Loaded pluggable UI specification for n1ql

[error_logger:info,2021-04-19T19:52:32.318Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.310.0>},
                       {name,menelaus_web},
                       {mfargs,{menelaus_web,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.323Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.327.0>},
                       {name,menelaus_event},
                       {mfargs,{menelaus_event,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:32.327Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.281.0>:ns_heart:grab_latest_stats:259]Ignoring failure to grab "@system" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,117}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,255}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,249}]},
                 {ns_heart,slow_updater_loop,0,
                           [{file,"src/ns_heart.erl"},{line,243}]},
                 {proc_lib,init_p_do_apply,3,
                           [{file,"proc_lib.erl"},{line,239}]}]}}

[ns_server:debug,2021-04-19T19:52:32.328Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.281.0>:ns_heart:grab_latest_stats:259]Ignoring failure to grab "@system-processes" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-processes-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,117}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,255}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,249}]},
                 {ns_heart,slow_updater_loop,0,
                           [{file,"src/ns_heart.erl"},{line,243}]}]}}

[ns_server:debug,2021-04-19T19:52:32.328Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.281.0>:ns_heart:grab_index_status:373]ignoring failure to get index status: {exit,
                                       {noproc,
                                        {gen_server,call,
                                         ['index_status_keeper-index',
                                          get_status,2000]}}}
[{gen_server,call,3,[{file,"gen_server.erl"},{line,188}]},
 {ns_heart,grab_index_status,0,[{file,"src/ns_heart.erl"},{line,370}]},
 {ns_heart,current_status_slow_inner,0,[{file,"src/ns_heart.erl"},{line,280}]},
 {ns_heart,current_status_slow,1,[{file,"src/ns_heart.erl"},{line,249}]},
 {ns_heart,slow_updater_loop,0,[{file,"src/ns_heart.erl"},{line,243}]},
 {proc_lib,init_p_do_apply,3,[{file,"proc_lib.erl"},{line,239}]}]
[ns_server:debug,2021-04-19T19:52:32.330Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.281.0>:goxdcr_rest:get_from_goxdcr:163]Goxdcr is temporary not available. Return empty list.
[ns_server:debug,2021-04-19T19:52:32.330Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.281.0>:cluster_logs_collection_task:maybe_build_cluster_logs_task:43]Ignoring exception trying to read cluster_logs_collection_task_status table: error:badarg
[error_logger:info,2021-04-19T19:52:32.330Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.333.0>},
                       {name,hot_keys_keeper},
                       {mfargs,{hot_keys_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.335Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.335.0>},
                       {name,menelaus_web_alerts_srv},
                       {mfargs,{menelaus_web_alerts_srv,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[user:info,2021-04-19T19:52:32.342Z,ns_1@127.0.0.1:ns_server_sup<0.242.0>:menelaus_sup:start_link:46]Couchbase Server has started on web port 8091 on node 'ns_1@127.0.0.1'. Version: "4.6.0-3573-enterprise".
[error_logger:info,2021-04-19T19:52:32.342Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.336.0>},
                       {name,menelaus_cbauth},
                       {mfargs,{menelaus_cbauth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.342Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.301.0>},
                       {name,menelaus},
                       {mfargs,{menelaus_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:52:32.343Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.340.0>},
                       {name,ns_ports_setup},
                       {mfargs,{ns_ports_setup,start,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.346Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_agent_sup}
             started: [{pid,<0.343.0>},
                       {name,service_agent_children_sup},
                       {mfargs,
                           {supervisor,start_link,
                               [{local,service_agent_children_sup},
                                service_agent_sup,child]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:52:32.346Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_agent_sup}
             started: [{pid,<0.344.0>},
                       {name,service_agent_worker},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<service_agent_sup.0.29791682>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.346Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.342.0>},
                       {name,service_agent_sup},
                       {mfargs,{service_agent_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:52:32.365Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.346.0>},
                       {name,ns_memcached_sockets_pool},
                       {mfargs,{ns_memcached_sockets_pool,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:32.365Z,ns_1@127.0.0.1:ns_audit_cfg<0.347.0>:ns_audit_cfg:write_audit_json:158]Writing new content to "/opt/couchbase/var/lib/couchbase/config/audit.json" : [{auditd_enabled,
                                                                                false},
                                                                               {disabled,
                                                                                []},
                                                                               {log_path,
                                                                                "/opt/couchbase/var/lib/couchbase/logs"},
                                                                               {rotate_interval,
                                                                                86400},
                                                                               {rotate_size,
                                                                                20971520},
                                                                               {sync,
                                                                                []},
                                                                               {version,
                                                                                1},
                                                                               {descriptors_path,
                                                                                "/opt/couchbase/etc/security"}]
[ns_server:debug,2021-04-19T19:52:32.376Z,ns_1@127.0.0.1:ns_ports_setup<0.340.0>:ns_ports_manager:set_dynamic_children:54]Setting children [memcached,moxi,projector,indexer,query,saslauthd_port,
                  goxdcr,xdcr_proxy]
[ns_server:debug,2021-04-19T19:52:32.389Z,ns_1@127.0.0.1:ns_audit_cfg<0.347.0>:ns_audit_cfg:handle_info:107]Instruct memcached to reload audit config
[error_logger:info,2021-04-19T19:52:32.389Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.347.0>},
                       {name,ns_audit_cfg},
                       {mfargs,{ns_audit_cfg,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:warn,2021-04-19T19:52:32.390Z,ns_1@127.0.0.1:<0.349.0>:ns_memcached:connect:1307]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[ns_server:debug,2021-04-19T19:52:32.393Z,ns_1@127.0.0.1:memcached_config_mgr<0.351.0>:memcached_config_mgr:init:44]waiting for completion of initial ns_ports_setup round
[error_logger:info,2021-04-19T19:52:32.394Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.351.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:52:32.397Z,ns_1@127.0.0.1:<0.352.0>:ns_memcached_log_rotator:init:28]Starting log rotator on "/opt/couchbase/var/lib/couchbase/logs"/"memcached.log"* with an initial period of 39003ms
[error_logger:info,2021-04-19T19:52:32.397Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.352.0>},
                       {name,ns_memcached_log_rotator},
                       {mfargs,{ns_memcached_log_rotator,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.403Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.353.0>},
                       {name,memcached_clients_pool},
                       {mfargs,{memcached_clients_pool,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.408Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.354.0>},
                       {name,proxied_memcached_clients_pool},
                       {mfargs,{proxied_memcached_clients_pool,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.408Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.355.0>},
                       {name,xdc_lhttpc_pool},
                       {mfargs,
                           {lhttpc_manager,start_link,
                               [[{name,xdc_lhttpc_pool},
                                 {connection_timeout,120000},
                                 {pool_size,200}]]}},
                       {restart_type,{permanent,1}},
                       {shutdown,10000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.411Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.356.0>},
                       {name,ns_null_connection_pool},
                       {mfargs,
                           {ns_null_connection_pool,start_link,
                               [ns_null_connection_pool]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.422Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {<0.357.0>,xdcr_sup}
             started: [{pid,<0.358.0>},
                       {name,xdc_stats_holder},
                       {mfargs,
                           {proc_lib,start_link,
                               [xdcr_sup,link_stats_holder_body,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.427Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {<0.357.0>,xdcr_sup}
             started: [{pid,<0.359.0>},
                       {name,xdc_replication_sup},
                       {mfargs,{xdc_replication_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2021-04-19T19:52:32.432Z,ns_1@127.0.0.1:xdc_rep_manager<0.360.0>:ns_couchdb_api:wait_for_doc_manager:298]Start waiting for doc manager
[error_logger:info,2021-04-19T19:52:32.432Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {<0.357.0>,xdcr_sup}
             started: [{pid,<0.360.0>},
                       {name,xdc_rep_manager},
                       {mfargs,{xdc_rep_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,30000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:32.440Z,ns_1@127.0.0.1:xdcr_doc_replicator<0.362.0>:ns_couchdb_api:wait_for_doc_manager:298]Start waiting for doc manager
[ns_server:debug,2021-04-19T19:52:32.440Z,ns_1@127.0.0.1:xdc_rdoc_replication_srv<0.363.0>:ns_couchdb_api:wait_for_doc_manager:298]Start waiting for doc manager
[error_logger:info,2021-04-19T19:52:32.440Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {<0.357.0>,xdcr_sup}
             started: [{pid,<0.362.0>},
                       {name,xdc_rdoc_replicator},
                       {mfargs,{doc_replicator,start_link_xdcr,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.440Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {<0.357.0>,xdcr_sup}
             started: [{pid,<0.363.0>},
                       {name,xdc_rdoc_replication_srv},
                       {mfargs,{doc_replication_srv,start_link_xdcr,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:32.444Z,ns_1@127.0.0.1:<0.357.0>:xdc_rdoc_manager:start_link_remote:42]Starting xdc_rdoc_manager on 'couchdb_ns_1@127.0.0.1' with following links: [<0.362.0>,
                                                                             <0.363.0>,
                                                                             <0.360.0>]
[ns_server:debug,2021-04-19T19:52:32.449Z,ns_1@127.0.0.1:xdcr_doc_replicator<0.362.0>:ns_couchdb_api:wait_for_doc_manager:301]Received doc manager registration from <11633.255.0>
[ns_server:debug,2021-04-19T19:52:32.449Z,ns_1@127.0.0.1:xdc_rdoc_replication_srv<0.363.0>:ns_couchdb_api:wait_for_doc_manager:301]Received doc manager registration from <11633.255.0>
[ns_server:debug,2021-04-19T19:52:32.449Z,ns_1@127.0.0.1:xdc_rep_manager<0.360.0>:ns_couchdb_api:wait_for_doc_manager:301]Received doc manager registration from <11633.255.0>
[error_logger:info,2021-04-19T19:52:32.449Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {<0.357.0>,xdcr_sup}
             started: [{pid,<11633.255.0>},
                       {name,xdc_rdoc_manager},
                       {mfargs,
                           {xdc_rdoc_manager,start_link_remote,
                               ['couchdb_ns_1@127.0.0.1']}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.449Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.357.0>},
                       {name,xdcr_sup},
                       {mfargs,{xdcr_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:52:32.458Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.365.0>},
                       {name,xdcr_dcp_sockets_pool},
                       {mfargs,{xdcr_dcp_sockets_pool,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.461Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_worker_sup}
             started: [{pid,<0.367.0>},
                       {name,ns_bucket_worker},
                       {mfargs,{work_queue,start_link,[ns_bucket_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.465Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_sup}
             started: [{pid,<0.369.0>},
                       {name,buckets_observing_subscription},
                       {mfargs,{ns_bucket_sup,subscribe_on_config_events,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.466Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_worker_sup}
             started: [{pid,<0.368.0>},
                       {name,ns_bucket_sup},
                       {mfargs,{ns_bucket_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:52:32.466Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.366.0>},
                       {name,ns_bucket_worker_sup},
                       {mfargs,{ns_bucket_worker_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:52:32.471Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.370.0>},
                       {name,system_stats_collector},
                       {mfargs,{system_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:32.473Z,ns_1@127.0.0.1:xdcr_doc_replicator<0.362.0>:doc_replicator:loop:64]doing replicate_newnodes_docs
[error_logger:info,2021-04-19T19:52:32.474Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.374.0>},
                       {name,{stats_archiver,"@system"}},
                       {mfargs,{stats_archiver,start_link,["@system"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.479Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.376.0>},
                       {name,{stats_reader,"@system"}},
                       {mfargs,{stats_reader,start_link,["@system"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.482Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.377.0>},
                       {name,{stats_archiver,"@system-processes"}},
                       {mfargs,
                           {stats_archiver,start_link,["@system-processes"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.482Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.379.0>},
                       {name,{stats_reader,"@system-processes"}},
                       {mfargs,
                           {stats_reader,start_link,["@system-processes"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.503Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.380.0>},
                       {name,{stats_archiver,"@query"}},
                       {mfargs,{stats_archiver,start_link,["@query"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.503Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.382.0>},
                       {name,{stats_reader,"@query"}},
                       {mfargs,{stats_reader,start_link,["@query"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.508Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.383.0>},
                       {name,query_stats_collector},
                       {mfargs,{query_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.545Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.385.0>},
                       {name,{stats_archiver,"@global"}},
                       {mfargs,{stats_archiver,start_link,["@global"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.545Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.387.0>},
                       {name,{stats_reader,"@global"}},
                       {mfargs,{stats_reader,start_link,["@global"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.550Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.388.0>},
                       {name,global_stats_collector},
                       {mfargs,{global_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.564Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.390.0>},
                       {name,goxdcr_status_keeper},
                       {mfargs,{goxdcr_status_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:32.565Z,ns_1@127.0.0.1:goxdcr_status_keeper<0.390.0>:goxdcr_rest:get_from_goxdcr:163]Goxdcr is temporary not available. Return empty list.
[ns_server:debug,2021-04-19T19:52:32.568Z,ns_1@127.0.0.1:goxdcr_status_keeper<0.390.0>:goxdcr_rest:get_from_goxdcr:163]Goxdcr is temporary not available. Return empty list.
[error_logger:info,2021-04-19T19:52:32.574Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_stats_sup}
             started: [{pid,<0.394.0>},
                       {name,index_stats_children_sup},
                       {mfargs,
                           {supervisor,start_link,
                               [{local,index_stats_children_sup},
                                index_stats_sup,child]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:52:32.580Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_status_keeper_sup}
             started: [{pid,<0.396.0>},
                       {name,index_status_keeper_worker},
                       {mfargs,
                           {work_queue,start_link,
                               [index_status_keeper_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.582Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_status_keeper_sup}
             started: [{pid,<0.397.0>},
                       {name,index_status_keeper},
                       {mfargs,{indexer_gsi,start_keeper,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:error,2021-04-19T19:52:32.593Z,ns_1@127.0.0.1:index_status_keeper_worker<0.396.0>:index_rest:get_json:42]Request to (indexer) http://127.0.0.1:9102/getIndexStatus failed: {error,
                                                                   {econnrefused,
                                                                    [{lhttpc_client,
                                                                      send_request,
                                                                      1,
                                                                      [{file,
                                                                        "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                       {line,
                                                                        220}]},
                                                                     {lhttpc_client,
                                                                      execute,
                                                                      9,
                                                                      [{file,
                                                                        "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                       {line,
                                                                        169}]},
                                                                     {lhttpc_client,
                                                                      request,
                                                                      9,
                                                                      [{file,
                                                                        "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                       {line,
                                                                        92}]}]}}
[error_logger:info,2021-04-19T19:52:32.597Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_status_keeper_sup}
             started: [{pid,<0.401.0>},
                       {name,index_status_keeper_fts},
                       {mfargs,{indexer_fts,start_keeper,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.598Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_stats_sup}
             started: [{pid,<0.395.0>},
                       {name,index_status_keeper_sup},
                       {mfargs,{index_status_keeper_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:52:32.598Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_stats_sup}
             started: [{pid,<0.404.0>},
                       {name,index_stats_worker},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<index_stats_sup.0.21142793>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.599Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.393.0>},
                       {name,index_stats_sup},
                       {mfargs,{index_stats_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:52:32.623Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_stats_children_sup}
             started: [{pid,<0.406.0>},
                       {name,{indexer_gsi,index_stats_collector}},
                       {mfargs,
                           {index_stats_collector,start_link,[indexer_gsi]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.630Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.410.0>},
                       {name,compaction_daemon},
                       {mfargs,{compaction_daemon,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.646Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_stats_children_sup}
             started: [{pid,<0.409.0>},
                       {name,{indexer_gsi,stats_archiver,"@index"}},
                       {mfargs,{stats_archiver,start_link,["@index"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.647Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_stats_children_sup}
             started: [{pid,<0.414.0>},
                       {name,{indexer_gsi,stats_reader,"@index"}},
                       {mfargs,{stats_reader,start_link,["@index"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:32.662Z,ns_1@127.0.0.1:<0.415.0>:new_concurrency_throttle:init:113]init concurrent throttle process, pid: <0.415.0>, type: kv_throttle# of available token: 1
[ns_server:debug,2021-04-19T19:52:32.680Z,ns_1@127.0.0.1:compaction_new_daemon<0.411.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:52:32.680Z,ns_1@127.0.0.1:compaction_new_daemon<0.411.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[error_logger:info,2021-04-19T19:52:32.680Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.411.0>},
                       {name,compaction_new_daemon},
                       {mfargs,{compaction_new_daemon,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,86400000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:32.680Z,ns_1@127.0.0.1:compaction_new_daemon<0.411.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:52:32.680Z,ns_1@127.0.0.1:compaction_new_daemon<0.411.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:52:32.680Z,ns_1@127.0.0.1:compaction_new_daemon<0.411.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_master. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:52:32.681Z,ns_1@127.0.0.1:compaction_new_daemon<0.411.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_master too soon. Next run will be in 3600s
[error_logger:info,2021-04-19T19:52:32.698Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,cluster_logs_sup}
             started: [{pid,<0.417.0>},
                       {name,ets_holder},
                       {mfargs,
                           {cluster_logs_collection_task,
                               start_link_ets_holder,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.699Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.416.0>},
                       {name,cluster_logs_sup},
                       {mfargs,{cluster_logs_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:52:32.703Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.418.0>},
                       {name,remote_api},
                       {mfargs,{remote_api,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:32.715Z,ns_1@127.0.0.1:<0.419.0>:mb_master:check_master_takeover_needed:141]Sending master node question to the following nodes: []
[ns_server:debug,2021-04-19T19:52:32.715Z,ns_1@127.0.0.1:<0.419.0>:mb_master:check_master_takeover_needed:143]Got replies: []
[ns_server:debug,2021-04-19T19:52:32.715Z,ns_1@127.0.0.1:<0.419.0>:mb_master:check_master_takeover_needed:149]Was unable to discover master, not going to force mastership takeover
[user:info,2021-04-19T19:52:32.716Z,ns_1@127.0.0.1:mb_master<0.421.0>:mb_master:init:86]I'm the only node, so I'm the master.
[ns_server:debug,2021-04-19T19:52:32.743Z,ns_1@127.0.0.1:mb_master_sup<0.423.0>:misc:start_singleton:1097]start_singleton(gen_server, ns_tick, [], []): started as <0.424.0> on 'ns_1@127.0.0.1'

[error_logger:info,2021-04-19T19:52:32.744Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.424.0>},
                       {name,ns_tick},
                       {mfargs,{ns_tick,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,10},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:32.751Z,ns_1@127.0.0.1:ns_orchestrator_sup<0.425.0>:misc:start_singleton:1097]start_singleton(gen_fsm, ns_orchestrator, [], []): started as <0.426.0> on 'ns_1@127.0.0.1'

[error_logger:info,2021-04-19T19:52:32.751Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_sup}
             started: [{pid,<0.426.0>},
                       {name,ns_orchestrator},
                       {mfargs,{ns_orchestrator,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:32.767Z,ns_1@127.0.0.1:<0.428.0>:auto_failover:init:147]init auto_failover.
[ns_server:debug,2021-04-19T19:52:32.767Z,ns_1@127.0.0.1:ns_orchestrator_sup<0.425.0>:misc:start_singleton:1097]start_singleton(gen_server, auto_failover, [], []): started as <0.428.0> on 'ns_1@127.0.0.1'

[ns_server:debug,2021-04-19T19:52:32.768Z,ns_1@127.0.0.1:<0.419.0>:restartable:start_child:98]Started child process <0.421.0>
  MFA: {mb_master,start_link,[]}
[error_logger:info,2021-04-19T19:52:32.768Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_sup}
             started: [{pid,<0.428.0>},
                       {name,auto_failover},
                       {mfargs,{auto_failover,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.768Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.425.0>},
                       {name,ns_orchestrator_sup},
                       {mfargs,{ns_orchestrator_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:52:32.768Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.419.0>},
                       {name,mb_master},
                       {mfargs,
                           {restartable,start_link,
                               [{mb_master,start_link,[]},infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:52:32.769Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.429.0>},
                       {name,master_activity_events_ingress},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,master_activity_events_ingress}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.769Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.430.0>},
                       {name,master_activity_events_timestamper},
                       {mfargs,
                           {master_activity_events,start_link_timestamper,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.778Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.431.0>},
                       {name,master_activity_events_pids_watcher},
                       {mfargs,
                           {master_activity_events_pids_watcher,start_link,
                               []}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:52:32.809Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.155.0>:one_shot_barrier:notify:27]Notifying on barrier menelaus_barrier
[ns_server:debug,2021-04-19T19:52:32.809Z,ns_1@127.0.0.1:menelaus_barrier<0.157.0>:one_shot_barrier:barrier_body:62]Barrier menelaus_barrier got notification from <0.155.0>
[ns_server:debug,2021-04-19T19:52:32.809Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.155.0>:one_shot_barrier:notify:32]Successfuly notified on barrier menelaus_barrier
[ns_server:debug,2021-04-19T19:52:32.809Z,ns_1@127.0.0.1:<0.154.0>:restartable:start_child:98]Started child process <0.155.0>
  MFA: {ns_server_nodes_sup,start_link,[]}
[ns_server:debug,2021-04-19T19:52:32.810Z,ns_1@127.0.0.1:<0.2.0>:child_erlang:child_loop:116]97: Entered child_loop
[error_logger:info,2021-04-19T19:52:32.810Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.432.0>},
                       {name,master_activity_events_keeper},
                       {mfargs,{master_activity_events_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:52:32.810Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.242.0>},
                       {name,ns_server_sup},
                       {mfargs,{ns_server_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:52:32.810Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.154.0>},
                       {name,ns_server_nodes_sup},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_server_nodes_sup,start_link,[]},
                                infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:52:32.811Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
         application: ns_server
          started_at: 'ns_1@127.0.0.1'

[ns_server:debug,2021-04-19T19:52:33.375Z,ns_1@127.0.0.1:ns_ports_setup<0.340.0>:ns_ports_setup:set_children:72]Monitor ns_child_ports_sup <11632.72.0>
[ns_server:debug,2021-04-19T19:52:33.375Z,ns_1@127.0.0.1:memcached_config_mgr<0.351.0>:memcached_config_mgr:init:46]ns_ports_setup seems to be ready
[ns_server:warn,2021-04-19T19:52:33.396Z,ns_1@127.0.0.1:<0.349.0>:ns_memcached:connect:1307]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[ns_server:debug,2021-04-19T19:52:33.396Z,ns_1@127.0.0.1:memcached_config_mgr<0.351.0>:memcached_config_mgr:find_port_pid_loop:119]Found memcached port <11632.79.0>
[ns_server:debug,2021-04-19T19:52:33.441Z,ns_1@127.0.0.1:memcached_config_mgr<0.351.0>:memcached_config_mgr:init:77]wrote memcached config to /opt/couchbase/var/lib/couchbase/config/memcached.json. Will activate memcached port server
[ns_server:debug,2021-04-19T19:52:33.459Z,ns_1@127.0.0.1:memcached_config_mgr<0.351.0>:memcached_config_mgr:init:80]activated memcached port server
[ns_server:error,2021-04-19T19:52:33.757Z,ns_1@127.0.0.1:index_stats_collector-index<0.406.0>:index_rest:get_json:42]Request to (indexer) http://127.0.0.1:9102/stats?async=true failed: {error,
                                                                     {econnrefused,
                                                                      [{lhttpc_client,
                                                                        send_request,
                                                                        1,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          220}]},
                                                                       {lhttpc_client,
                                                                        execute,
                                                                        9,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          169}]},
                                                                       {lhttpc_client,
                                                                        request,
                                                                        9,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          92}]}]}}
[stats:error,2021-04-19T19:52:33.757Z,ns_1@127.0.0.1:query_stats_collector<0.383.0>:base_stats_collector:handle_info:109](Collector: query_stats_collector) Exception in stats collector: {error,
                                                                  {badmatch,
                                                                   {error,
                                                                    {econnrefused,
                                                                     [{lhttpc_client,
                                                                       send_request,
                                                                       1,
                                                                       [{file,
                                                                         "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                        {line,
                                                                         220}]},
                                                                      {lhttpc_client,
                                                                       execute,
                                                                       9,
                                                                       [{file,
                                                                         "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                        {line,
                                                                         169}]},
                                                                      {lhttpc_client,
                                                                       request,
                                                                       9,
                                                                       [{file,
                                                                         "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                        {line,
                                                                         92}]}]}}},
                                                                  [{query_rest,
                                                                    send,3,
                                                                    [{file,
                                                                      "src/query_rest.erl"},
                                                                     {line,
                                                                      64}]},
                                                                   {query_rest,
                                                                    do_get_stats,
                                                                    0,
                                                                    [{file,
                                                                      "src/query_rest.erl"},
                                                                     {line,
                                                                      43}]},
                                                                   {base_stats_collector,
                                                                    handle_info,
                                                                    2,
                                                                    [{file,
                                                                      "src/base_stats_collector.erl"},
                                                                     {line,
                                                                      89}]},
                                                                   {gen_server,
                                                                    handle_msg,
                                                                    5,
                                                                    [{file,
                                                                      "gen_server.erl"},
                                                                     {line,
                                                                      604}]},
                                                                   {proc_lib,
                                                                    init_p_do_apply,
                                                                    3,
                                                                    [{file,
                                                                      "proc_lib.erl"},
                                                                     {line,
                                                                      239}]}]}

[ns_server:warn,2021-04-19T19:52:33.767Z,ns_1@127.0.0.1:<0.439.0>:ns_memcached:connect:1307]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[ns_server:debug,2021-04-19T19:52:34.318Z,ns_1@127.0.0.1:json_rpc_connection-projector-cbauth<0.443.0>:json_rpc_connection:init:74]Observed revrpc connection: label "projector-cbauth", handling process <0.443.0>
[error_logger:error,2021-04-19T19:52:34.318Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.443.0>,{ok,<0.443.0>}}

[ns_server:debug,2021-04-19T19:52:34.318Z,ns_1@127.0.0.1:menelaus_cbauth<0.336.0>:menelaus_cbauth:handle_cast:87]Observed json rpc process {"projector-cbauth",<0.443.0>} started
[ns_server:debug,2021-04-19T19:52:34.326Z,ns_1@127.0.0.1:json_rpc_connection-projector-cbauth<0.443.0>:json_rpc_connection:handle_call:157]sending jsonrpc call:{[{jsonrpc,<<"2.0">>},
                       {id,0},
                       {method,<<"AuthCacheSvc.UpdateDB">>},
                       {params,
                        [{[{specialUser,<<"@projector-cbauth">>},
                           {nodes,
                            [{[{host,<<"127.0.0.1">>},
                               {user,<<"_admin">>},
                               {password,"*****"},
                               {ports,
                                [8091,18091,9100,9101,9102,9103,9104,9105,
                                 18092,8092,11207,9999,11210,11211,8093,
                                 18093]},
                               {local,true}]}]},
                           {buckets,[]},
                           {authCheckURL,<<"http://127.0.0.1:8091/_cbauth">>},
                           {permissionCheckURL,
                            <<"http://127.0.0.1:8091/_cbauth/checkPermission">>},
                           {ldapEnabled,true},
                           {permissionsVersion,125619376},
                           {admin,
                            {[{user,<<"Administrator">>},
                              {salt,<<"HwppMSHwWqqMMQC+Y570Cg==">>},
                              {mac,
                               <<"qvTNNsy5tPU9CAZI+HQuF+FPP5Y=">>}]}}]}]}]}
[ns_server:debug,2021-04-19T19:52:34.329Z,ns_1@127.0.0.1:json_rpc_connection-projector-cbauth<0.443.0>:json_rpc_connection:handle_info:93]got response: [{<<"id">>,0},{<<"result">>,true},{<<"error">>,null}]
[ns_server:warn,2021-04-19T19:52:34.397Z,ns_1@127.0.0.1:<0.349.0>:ns_memcached:connect:1307]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[ns_server:debug,2021-04-19T19:52:34.479Z,ns_1@127.0.0.1:json_rpc_connection-index-cbauth<0.448.0>:json_rpc_connection:init:74]Observed revrpc connection: label "index-cbauth", handling process <0.448.0>
[ns_server:debug,2021-04-19T19:52:34.480Z,ns_1@127.0.0.1:menelaus_cbauth<0.336.0>:menelaus_cbauth:handle_cast:87]Observed json rpc process {"index-cbauth",<0.448.0>} started
[error_logger:error,2021-04-19T19:52:34.480Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.448.0>,{ok,<0.448.0>}}

[ns_server:debug,2021-04-19T19:52:34.480Z,ns_1@127.0.0.1:json_rpc_connection-index-cbauth<0.448.0>:json_rpc_connection:handle_call:157]sending jsonrpc call:{[{jsonrpc,<<"2.0">>},
                       {id,0},
                       {method,<<"AuthCacheSvc.UpdateDB">>},
                       {params,
                        [{[{specialUser,<<"@index-cbauth">>},
                           {nodes,
                            [{[{host,<<"127.0.0.1">>},
                               {user,<<"_admin">>},
                               {password,"*****"},
                               {ports,
                                [8091,18091,9100,9101,9102,9103,9104,9105,
                                 18092,8092,11207,9999,11210,11211,8093,
                                 18093]},
                               {local,true}]}]},
                           {buckets,[]},
                           {authCheckURL,<<"http://127.0.0.1:8091/_cbauth">>},
                           {permissionCheckURL,
                            <<"http://127.0.0.1:8091/_cbauth/checkPermission">>},
                           {ldapEnabled,true},
                           {permissionsVersion,125619376},
                           {admin,
                            {[{user,<<"Administrator">>},
                              {salt,<<"HwppMSHwWqqMMQC+Y570Cg==">>},
                              {mac,
                               <<"qvTNNsy5tPU9CAZI+HQuF+FPP5Y=">>}]}}]}]}]}
[ns_server:debug,2021-04-19T19:52:34.482Z,ns_1@127.0.0.1:json_rpc_connection-index-cbauth<0.448.0>:json_rpc_connection:handle_info:93]got response: [{<<"id">>,0},{<<"result">>,true},{<<"error">>,null}]
[ns_server:debug,2021-04-19T19:52:34.636Z,ns_1@127.0.0.1:json_rpc_connection-cbq-engine-cbauth<0.455.0>:json_rpc_connection:init:74]Observed revrpc connection: label "cbq-engine-cbauth", handling process <0.455.0>
[error_logger:error,2021-04-19T19:52:34.636Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.455.0>,{ok,<0.455.0>}}

[ns_server:debug,2021-04-19T19:52:34.636Z,ns_1@127.0.0.1:menelaus_cbauth<0.336.0>:menelaus_cbauth:handle_cast:87]Observed json rpc process {"cbq-engine-cbauth",<0.455.0>} started
[ns_server:debug,2021-04-19T19:52:34.637Z,ns_1@127.0.0.1:json_rpc_connection-cbq-engine-cbauth<0.455.0>:json_rpc_connection:handle_call:157]sending jsonrpc call:{[{jsonrpc,<<"2.0">>},
                       {id,0},
                       {method,<<"AuthCacheSvc.UpdateDB">>},
                       {params,
                        [{[{specialUser,<<"@cbq-engine-cbauth">>},
                           {nodes,
                            [{[{host,<<"127.0.0.1">>},
                               {user,<<"_admin">>},
                               {password,"*****"},
                               {ports,
                                [8091,18091,9100,9101,9102,9103,9104,9105,
                                 18092,8092,11207,9999,11210,11211,8093,
                                 18093]},
                               {local,true}]}]},
                           {buckets,[]},
                           {authCheckURL,<<"http://127.0.0.1:8091/_cbauth">>},
                           {permissionCheckURL,
                            <<"http://127.0.0.1:8091/_cbauth/checkPermission">>},
                           {ldapEnabled,true},
                           {permissionsVersion,125619376},
                           {admin,
                            {[{user,<<"Administrator">>},
                              {salt,<<"HwppMSHwWqqMMQC+Y570Cg==">>},
                              {mac,
                               <<"qvTNNsy5tPU9CAZI+HQuF+FPP5Y=">>}]}}]}]}]}
[ns_server:debug,2021-04-19T19:52:34.638Z,ns_1@127.0.0.1:json_rpc_connection-cbq-engine-cbauth<0.455.0>:json_rpc_connection:handle_info:93]got response: [{<<"id">>,0},{<<"result">>,true},{<<"error">>,null}]
[ns_server:debug,2021-04-19T19:52:34.670Z,ns_1@127.0.0.1:json_rpc_connection-saslauthd-saslauthd-port<0.460.0>:json_rpc_connection:init:74]Observed revrpc connection: label "saslauthd-saslauthd-port", handling process <0.460.0>
[error_logger:error,2021-04-19T19:52:34.671Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.460.0>,{ok,<0.460.0>}}

[ns_server:error,2021-04-19T19:52:34.744Z,ns_1@127.0.0.1:index_stats_collector-index<0.406.0>:index_rest:get_json:42]Request to (indexer) http://127.0.0.1:9102/stats?async=true failed: {error,
                                                                     {econnrefused,
                                                                      [{lhttpc_client,
                                                                        send_request,
                                                                        1,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          220}]},
                                                                       {lhttpc_client,
                                                                        execute,
                                                                        9,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          169}]},
                                                                       {lhttpc_client,
                                                                        request,
                                                                        9,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          92}]}]}}
[ns_server:warn,2021-04-19T19:52:34.768Z,ns_1@127.0.0.1:<0.439.0>:ns_memcached:connect:1307]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[ns_server:debug,2021-04-19T19:52:34.892Z,ns_1@127.0.0.1:json_rpc_connection-goxdcr-cbauth<0.467.0>:json_rpc_connection:init:74]Observed revrpc connection: label "goxdcr-cbauth", handling process <0.467.0>
[ns_server:debug,2021-04-19T19:52:34.892Z,ns_1@127.0.0.1:menelaus_cbauth<0.336.0>:menelaus_cbauth:handle_cast:87]Observed json rpc process {"goxdcr-cbauth",<0.467.0>} started
[error_logger:error,2021-04-19T19:52:34.892Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.467.0>,{ok,<0.467.0>}}

[ns_server:debug,2021-04-19T19:52:34.892Z,ns_1@127.0.0.1:json_rpc_connection-goxdcr-cbauth<0.467.0>:json_rpc_connection:handle_call:157]sending jsonrpc call:{[{jsonrpc,<<"2.0">>},
                       {id,0},
                       {method,<<"AuthCacheSvc.UpdateDB">>},
                       {params,
                        [{[{specialUser,<<"@goxdcr-cbauth">>},
                           {nodes,
                            [{[{host,<<"127.0.0.1">>},
                               {user,<<"_admin">>},
                               {password,"*****"},
                               {ports,
                                [8091,18091,9100,9101,9102,9103,9104,9105,
                                 18092,8092,11207,9999,11210,11211,8093,
                                 18093]},
                               {local,true}]}]},
                           {buckets,[]},
                           {authCheckURL,<<"http://127.0.0.1:8091/_cbauth">>},
                           {permissionCheckURL,
                            <<"http://127.0.0.1:8091/_cbauth/checkPermission">>},
                           {ldapEnabled,true},
                           {permissionsVersion,125619376},
                           {admin,
                            {[{user,<<"Administrator">>},
                              {salt,<<"HwppMSHwWqqMMQC+Y570Cg==">>},
                              {mac,
                               <<"qvTNNsy5tPU9CAZI+HQuF+FPP5Y=">>}]}}]}]}]}
[ns_server:debug,2021-04-19T19:52:34.894Z,ns_1@127.0.0.1:json_rpc_connection-goxdcr-cbauth<0.467.0>:json_rpc_connection:handle_info:93]got response: [{<<"id">>,0},{<<"result">>,true},{<<"error">>,null}]
[stats:warn,2021-04-19T19:52:35.772Z,ns_1@127.0.0.1:<0.388.0>:base_stats_collector:latest_tick:69](Collector: global_stats_collector) Dropped 2 ticks
[ns_server:debug,2021-04-19T19:52:38.406Z,ns_1@127.0.0.1:ns_config_rep<0.259.0>:ns_config_rep:do_push_keys:321]Replicating some config keys ([{local_changes_count,
                                   <<"360fb3d3641e00b1f4f22714c24e2a2a">>},
                               {metakv,<<"/indexing/settings/config">>}]..)
[ns_server:debug,2021-04-19T19:52:38.406Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{metakv,<<"/indexing/settings/config">>} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{5,63786081158}}]}|
 <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.log_level\":\"info\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\""...>>]
[ns_server:debug,2021-04-19T19:52:38.406Z,ns_1@127.0.0.1:<0.514.0>:ns_audit:put:248]Audit modify_index_storage_mode: [{storageMode,<<"memory_optimized">>},
                                  {real_userid,
                                      {[{source,ns_server},
                                        {user,<<"Administrator">>}]}},
                                  {remote,
                                      {[{ip,<<"127.0.0.1">>},{port,36264}]}},
                                  {timestamp,<<"2021-04-19T19:52:38.406Z">>}]
[ns_server:debug,2021-04-19T19:52:38.406Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{local_changes_count,<<"360fb3d3641e00b1f4f22714c24e2a2a">>} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{13,63786081158}}]}]
[ns_server:debug,2021-04-19T19:53:02.681Z,ns_1@127.0.0.1:compaction_new_daemon<0.411.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:53:02.681Z,ns_1@127.0.0.1:compaction_new_daemon<0.411.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:53:02.682Z,ns_1@127.0.0.1:compaction_new_daemon<0.411.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:53:02.682Z,ns_1@127.0.0.1:compaction_new_daemon<0.411.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:53:32.682Z,ns_1@127.0.0.1:compaction_new_daemon<0.411.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:53:32.682Z,ns_1@127.0.0.1:compaction_new_daemon<0.411.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:53:32.682Z,ns_1@127.0.0.1:compaction_new_daemon<0.411.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:53:32.682Z,ns_1@127.0.0.1:compaction_new_daemon<0.411.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:info,2021-04-19T19:54:10.821Z,nonode@nohost:<0.88.0>:ns_server:init_logging:151]Started & configured logging
[ns_server:info,2021-04-19T19:54:10.850Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]Static config terms:
[{error_logger_mf_dir,"/opt/couchbase/var/lib/couchbase/logs"},
 {path_config_bindir,"/opt/couchbase/bin"},
 {path_config_etcdir,"/opt/couchbase/etc/couchbase"},
 {path_config_libdir,"/opt/couchbase/lib"},
 {path_config_datadir,"/opt/couchbase/var/lib/couchbase"},
 {path_config_tmpdir,"/opt/couchbase/var/lib/couchbase/tmp"},
 {path_config_secdir,"/opt/couchbase/etc/security"},
 {nodefile,"/opt/couchbase/var/lib/couchbase/couchbase-server.node"},
 {loglevel_default,debug},
 {loglevel_couchdb,info},
 {loglevel_ns_server,debug},
 {loglevel_error_logger,debug},
 {loglevel_user,debug},
 {loglevel_menelaus,debug},
 {loglevel_ns_doctor,debug},
 {loglevel_stats,debug},
 {loglevel_rebalance,debug},
 {loglevel_cluster,debug},
 {loglevel_views,debug},
 {loglevel_mapreduce_errors,debug},
 {loglevel_xdcr,debug},
 {loglevel_xdcr_trace,error},
 {loglevel_access,info},
 {disk_sink_opts,
     [{rotation,
          [{compress,true},
           {size,41943040},
           {num_files,10},
           {buffer_size_max,52428800}]}]},
 {disk_sink_opts_xdcr_trace,
     [{rotation,[{compress,false},{size,83886080},{num_files,5}]}]},
 {net_kernel_verbosity,10}]
[ns_server:warn,2021-04-19T19:54:10.851Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter error_logger_mf_dir, which is given from command line
[ns_server:warn,2021-04-19T19:54:10.851Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter path_config_bindir, which is given from command line
[ns_server:warn,2021-04-19T19:54:10.851Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter path_config_etcdir, which is given from command line
[ns_server:warn,2021-04-19T19:54:10.852Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter path_config_libdir, which is given from command line
[ns_server:warn,2021-04-19T19:54:10.852Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter path_config_datadir, which is given from command line
[ns_server:warn,2021-04-19T19:54:10.852Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter path_config_tmpdir, which is given from command line
[ns_server:warn,2021-04-19T19:54:10.852Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter path_config_secdir, which is given from command line
[ns_server:warn,2021-04-19T19:54:10.852Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter nodefile, which is given from command line
[ns_server:warn,2021-04-19T19:54:10.852Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_default, which is given from command line
[ns_server:warn,2021-04-19T19:54:10.852Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_couchdb, which is given from command line
[ns_server:warn,2021-04-19T19:54:10.853Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_ns_server, which is given from command line
[ns_server:warn,2021-04-19T19:54:10.853Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_error_logger, which is given from command line
[ns_server:warn,2021-04-19T19:54:10.853Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_user, which is given from command line
[ns_server:warn,2021-04-19T19:54:10.853Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_menelaus, which is given from command line
[ns_server:warn,2021-04-19T19:54:10.853Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_ns_doctor, which is given from command line
[ns_server:warn,2021-04-19T19:54:10.853Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_stats, which is given from command line
[ns_server:warn,2021-04-19T19:54:10.854Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_rebalance, which is given from command line
[ns_server:warn,2021-04-19T19:54:10.854Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_cluster, which is given from command line
[ns_server:warn,2021-04-19T19:54:10.854Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_views, which is given from command line
[ns_server:warn,2021-04-19T19:54:10.854Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_mapreduce_errors, which is given from command line
[ns_server:warn,2021-04-19T19:54:10.854Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_xdcr, which is given from command line
[ns_server:warn,2021-04-19T19:54:10.854Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_xdcr_trace, which is given from command line
[ns_server:warn,2021-04-19T19:54:10.855Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_access, which is given from command line
[ns_server:warn,2021-04-19T19:54:10.855Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter disk_sink_opts, which is given from command line
[ns_server:warn,2021-04-19T19:54:10.855Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter disk_sink_opts_xdcr_trace, which is given from command line
[ns_server:warn,2021-04-19T19:54:10.855Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter net_kernel_verbosity, which is given from command line
[error_logger:info,2021-04-19T19:54:10.866Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.128.0>},
                       {name,local_tasks},
                       {mfargs,{local_tasks,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:54:10.876Z,nonode@nohost:ns_server_cluster_sup<0.127.0>:log_os_info:start_link:25]OS type: {unix,linux} Version: {4,19,128}
Runtime info: [{otp_release,"R16B03-1"},
               {erl_version,"5.10.4.0.0.1"},
               {erl_version_long,
                   "Erlang R16B03-1 (erts-5.10.4.0.0.1) [source-00852da] [64-bit] [smp:8:8] [async-threads:16] [kernel-poll:true]\n"},
               {system_arch_raw,"x86_64-unknown-linux-gnu"},
               {system_arch,"x86_64-unknown-linux-gnu"},
               {localtime,{{2021,4,19},{19,54,10}}},
               {memory,
                   [{total,111202968},
                    {processes,9670464},
                    {processes_used,9669632},
                    {system,101532504},
                    {atom,331249},
                    {atom_used,310220},
                    {binary,55040},
                    {code,7694133},
                    {ets,2240600}]},
               {loaded,
                   [ns_info,log_os_info,local_tasks,restartable,
                    ns_server_cluster_sup,calendar,ale_default_formatter,
                    'ale_logger-metakv','ale_logger-rebalance',
                    'ale_logger-xdcr_trace','ale_logger-menelaus',
                    'ale_logger-stats','ale_logger-access',
                    'ale_logger-ns_server','ale_logger-user',
                    'ale_logger-ns_doctor','ale_logger-cluster',io_lib_fread,
                    'ale_logger-xdcr',otp_internal,ns_log_sink,ale_disk_sink,
                    misc,couch_util,ns_server,filelib,cpu_sup,memsup,disksup,
                    os_mon,io,release_handler,overload,alarm_handler,sasl,
                    timer,tftp_sup,httpd_sup,httpc_handler_sup,httpc_cookie,
                    inets_trace,httpc_manager,httpc,httpc_profile_sup,
                    httpc_sup,ftp_sup,inets_sup,inets_app,ssl,lhttpc_manager,
                    lhttpc_sup,lhttpc,tls_connection_sup,ssl_session_cache,
                    ssl_pkix_db,ssl_manager,ssl_sup,ssl_app,crypto_server,
                    crypto_sup,crypto_app,ale_error_logger_handler,
                    'ale_logger-ale_logger','ale_logger-error_logger',
                    beam_opcodes,beam_dict,beam_asm,beam_validator,beam_z,
                    beam_flatten,beam_trim,beam_receive,beam_bsm,beam_peep,
                    beam_dead,beam_split,beam_type,beam_bool,beam_except,
                    beam_clean,beam_utils,beam_block,beam_jump,beam_a,
                    v3_codegen,v3_life,v3_kernel,sys_core_dsetel,erl_bifs,
                    sys_core_fold,cerl_trees,sys_core_inline,core_lib,cerl,
                    v3_core,erl_bits,erl_expand_records,sys_pre_expand,sofs,
                    erl_internal,sets,ordsets,erl_lint,compile,
                    dynamic_compile,ale_utils,io_lib_pretty,io_lib_format,
                    io_lib,ale_codegen,dict,ale,ale_dynamic_sup,ale_sup,
                    ale_app,epp,ns_bootstrap,child_erlang,file_io_server,
                    orddict,erl_eval,file,c,kernel_config,user_sup,
                    supervisor_bridge,standard_error,code_server,unicode,
                    hipe_unified_loader,gb_sets,ets,binary,code,file_server,
                    net_kernel,global_group,erl_distribution,filename,
                    inet_gethost_native,os,inet_parse,inet,inet_udp,
                    inet_config,inet_db,global,gb_trees,rpc,supervisor,kernel,
                    application_master,sys,application,gen_server,erl_parse,
                    proplists,erl_scan,lists,application_controller,proc_lib,
                    gen,gen_event,error_logger,heart,error_handler,
                    erts_internal,erlang,erl_prim_loader,prim_zip,zlib,
                    prim_file,prim_inet,prim_eval,init,otp_ring0]},
               {applications,
                   [{lhttpc,"Lightweight HTTP Client","1.3.0"},
                    {os_mon,"CPO  CXC 138 46","2.2.14"},
                    {public_key,"Public key infrastructure","0.21"},
                    {asn1,"The Erlang ASN1 compiler version 2.0.4","2.0.4"},
                    {kernel,"ERTS  CXC 138 10","2.16.4"},
                    {ale,"Another Logger for Erlang","4.6.0-3573-enterprise"},
                    {inets,"INETS  CXC 138 49","5.9.8"},
                    {ns_server,"Couchbase server","4.6.0-3573-enterprise"},
                    {crypto,"CRYPTO version 2","3.2"},
                    {ssl,"Erlang/OTP SSL application","5.3.3"},
                    {sasl,"SASL  CXC 138 11","2.3.4"},
                    {stdlib,"ERTS  CXC 138 10","1.19.4"}]},
               {pre_loaded,
                   [erts_internal,erlang,erl_prim_loader,prim_zip,zlib,
                    prim_file,prim_inet,prim_eval,init,otp_ring0]},
               {process_count,94},
               {node,nonode@nohost},
               {nodes,[]},
               {registered,
                   [ftp_sup,'sink-disk_xdcr',code_server,sasl_sup,
                    'sink-disk_debug',application_controller,
                    'sink-disk_error',local_tasks,'sink-disk_default',
                    ale_stats_events,kernel_safe_sup,inets_sup,ale,
                    standard_error,error_logger,lhttpc_sup,ale_sup,
                    lhttpc_manager,timer_server,standard_error_sup,
                    release_handler,httpd_sup,ale_dynamic_sup,overload,
                    alarm_handler,init,inet_db,rex,kernel_sup,'sink-ns_log',
                    global_name_server,sasl_safe_sup,crypto_server,crypto_sup,
                    file_server_2,tftp_sup,global_group,os_mon_sup,
                    'sink-disk_metakv',cpu_sup,tls_connection_sup,memsup,
                    ssl_sup,'sink-disk_access_int',disksup,'sink-disk_access',
                    ns_server_cluster_sup,httpc_sup,ssl_manager,
                    'sink-xdcr_trace',erl_prim_loader,'sink-disk_reports',
                    httpc_profile_sup,'sink-disk_stats',httpc_manager,
                    httpc_handler_sup,'sink-disk_xdcr_errors']},
               {cookie,nocookie},
               {wordsize,8},
               {wall_clock,4}]
[ns_server:info,2021-04-19T19:54:10.893Z,nonode@nohost:ns_server_cluster_sup<0.127.0>:log_os_info:start_link:27]Manifest:
["<?xml version=\"1.0\" encoding=\"UTF-8\"?>","<manifest>",
 "  <remote fetch=\"git://github.com/blevesearch/\" name=\"blevesearch\"/>",
 "  <remote fetch=\"git://github.com/couchbase/\" name=\"couchbase\" review=\"review.couchbase.org\"/>",
 "  <remote fetch=\"ssh://git@github.com/couchbase/\" name=\"couchbase-priv\" review=\"review.couchbase.org\"/>",
 "  <remote fetch=\"git://github.com/couchbasedeps/\" name=\"couchbasedeps\" review=\"review.couchbase.org\"/>",
 "  <remote fetch=\"git://github.com/couchbaselabs/\" name=\"couchbaselabs\" review=\"review.couchbase.org\"/>",
 "  ","  <default remote=\"couchbase\" revision=\"master\"/>","  ",
 "  <project groups=\"notdefault,enterprise\" name=\"backup\" path=\"goproj/src/github.com/couchbase/backup\" remote=\"couchbase-priv\" revision=\"469a5e8cc8661f35ab4af74fe45e92a3d89febed\"/>",
 "  <project name=\"bitset\" path=\"godeps/src/github.com/willf/bitset\" remote=\"couchbasedeps\" revision=\"28a4168144bb8ac95454e1f51c84da1933681ad4\"/>",
 "  <project name=\"blance\" path=\"godeps/src/github.com/couchbase/blance\" revision=\"5ce14d13954e04262b7eabfc6978776a4018402b\"/>",
 "  <project name=\"bleve\" path=\"godeps/src/github.com/blevesearch/bleve\" remote=\"blevesearch\" revision=\"f531835d5c212ee5f95c49d2debc28e65e6d1693\"/>",
 "  <project name=\"bleve-mapping-ui\" path=\"godeps/src/github.com/blevesearch/bleve-mapping-ui\" remote=\"blevesearch\" revision=\"b0453426dc1d59918cc763a970f1ad147b22ad6a\"/>",
 "  <project name=\"blevex\" path=\"godeps/src/github.com/blevesearch/blevex\" remote=\"blevesearch\" revision=\"918d980b0d244c8230c7d8c8ee40919f8d55ef88\"/>",
 "  <project name=\"bolt\" path=\"godeps/src/github.com/boltdb/bolt\" remote=\"couchbasedeps\" revision=\"51f99c862475898df9773747d3accd05a7ca33c1\"/>",
 "  <project name=\"buffer\" path=\"godeps/src/github.com/tdewolff/buffer\" remote=\"couchbasedeps\" revision=\"43cef5ba7b6ce99cc410632dad46cf1c6c97026e\"/>",
 "  <project groups=\"notdefault,build\" name=\"build\" path=\"cbbuild\" revision=\"ccd3ae52bbf0ade5fd59adcedba2b8cbbd16cd9b\">",
 "    <annotation name=\"VERSION\" value=\"4.6.0\"/>",
 "    <annotation name=\"BLD_NUM\" value=\"3573\"/>",
 "    <annotation name=\"RELEASE\" value=\"@RELEASE@\"/>",
 "    <annotation name=\"EDITION\" value=\"@EDITION@\"/>","  </project>",
 "  <project name=\"cbauth\" path=\"godeps/src/github.com/couchbase/cbauth\" revision=\"4a6d537777f57b291a8126f94dfbe3201c1d4efc\"/>",
 "  <project name=\"cbflag\" path=\"godeps/src/github.com/couchbase/cbflag\" revision=\"ce5c10adbb78c1212aefda73a85f8cfd1c3ae7e9\"/>",
 "  <project name=\"cbft\" path=\"goproj/src/github.com/couchbase/cbft\" revision=\"99f44266178dbe423890d8dd5bb9439ef2a71318\"/>",
 "  <project name=\"cbgt\" path=\"goproj/src/github.com/couchbase/cbgt\" revision=\"10790963d9cbada17ebfff728ea9298c1c97b7c5\"/>",
 "  <project groups=\"notdefault,enterprise\" name=\"cbq-gui\" path=\"goproj/src/github.com/couchbase/cbq-gui\" remote=\"couchbase-priv\" revision=\"1e19e5e34b64ca6b43a37de6166dac6e76803848\"/>",
 "  <project name=\"clog\" path=\"godeps/src/github.com/couchbase/clog\" revision=\"eebc98233c3e032eb6b9036575d51324ab5932e6\"/>",
 "  <project name=\"context\" path=\"godeps/src/github.com/gorilla/context\" remote=\"couchbasedeps\" revision=\"215affda49addc4c8ef7e2534915df2c8c35c6cd\"/>",
 "  <project name=\"couchbase-cli\" revision=\"951668b6b2fcaa5386b31d59df5004ff667e91e8\"/>",
 "  <project name=\"couchbase-examples\" revision=\"39ee1c2451ac2f2e86a6ff308e21e1201c49cafe\"/>",
 "  <project name=\"couchdb\" revision=\"7b950cfaa3ad30c75a7fcc7f4eb30b2df1a8bd5b\"/>",
 "  <project groups=\"notdefault,packaging\" name=\"couchdbx-app\" revision=\"be5f6ebaa12ac7c0b5382deb9b1b0efa7bf80497\"/>",
 "  <project groups=\"kv\" name=\"couchstore\" revision=\"9cf71ba60cf95f8b835b1040c68c85a4ddc653ee\"/>",
 "  <project name=\"crypto\" path=\"godeps/src/golang.org/x/crypto\" remote=\"couchbasedeps\" revision=\"f23ba3a5ee43012fcb4b92e1a2a405a92554f4f2\"/>",
 "  <project name=\"cznic-b\" path=\"godeps/src/github.com/cznic/b\" remote=\"couchbasedeps\" revision=\"b96e30f1b7bd34b0b9d8760798d67eca83d7f09e\"/>",
 "  <project name=\"dparval\" path=\"godeps/src/github.com/couchbase/dparval\" revision=\"9def03782da875a2477c05bf64985db3f19f59ae\"/>",
 "  <project groups=\"kv\" name=\"ep-engine\" revision=\"e4c8bcbbf20b52b11e93665901597875e10b2070\"/>",
 "  <project groups=\"kv\" name=\"forestdb\" revision=\"1d169510a5102e81547b1d3dc423eb37db908076\"/>",
 "  <project name=\"geocouch\" revision=\"74b4bab07713b233ca2780f9a9a3f7daa1a1dff4\"/>",
 "  <project name=\"go-bindata-assetfs\" path=\"godeps/src/github.com/elazarl/go-bindata-assetfs\" remote=\"couchbasedeps\" revision=\"57eb5e1fc594ad4b0b1dbea7b286d299e0cb43c2\"/>",
 "  <project name=\"go-couchbase\" path=\"godeps/src/github.com/couchbase/go-couchbase\" revision=\"e06e5adaf45e189d4cf3e471341af0bf80bcc312\"/>",
 "  <project name=\"go-jsonpointer\" path=\"godeps/src/github.com/dustin/go-jsonpointer\" remote=\"couchbasedeps\" revision=\"75939f54b39e7dafae879e61f65438dadc5f288c\"/>",
 "  <project name=\"go-metrics\" path=\"godeps/src/github.com/rcrowley/go-metrics\" remote=\"couchbasedeps\" revision=\"dee209f2455f101a5e4e593dea94872d2c62d85d\"/>",
 "  <project name=\"go-porterstemmer\" path=\"godeps/src/github.com/blevesearch/go-porterstemmer\" remote=\"blevesearch\" revision=\"23a2c8e5cf1f380f27722c6d2ae8896431dc7d0e\"/>",
 "  <project name=\"go-slab\" path=\"godeps/src/github.com/couchbase/go-slab\" revision=\"1f5f7f282713ccfab3f46b1610cb8da34bcf676f\"/>",
 "  <project name=\"go-zookeeper\" path=\"godeps/src/github.com/samuel/go-zookeeper\" remote=\"couchbasedeps\" revision=\"fa6674abf3f4580b946a01bf7a1ce4ba8766205b\"/>",
 "  <project name=\"go_json\" path=\"godeps/src/github.com/couchbase/go_json\" revision=\"f5a178ab380eb9a1911cf9c45b4159115b564169\"/>",
 "  <project name=\"go_n1ql\" path=\"godeps/src/github.com/couchbase/go_n1ql\" revision=\"6cf4e348b127e21f56e53eb8c3faaea56afdc588\"/>",
 "  <project name=\"gocb\" path=\"godeps/src/github.com/couchbase/gocb\" revision=\"d5b1a13c1e81f1255ca8155007b470db37ddeb25\"/>",
 "  <project name=\"godbc\" path=\"godeps/src/github.com/couchbase/godbc\" revision=\"adc62033c392ca9df8b5b42c0dda237576b39f9f\"/>",
 "  <project name=\"goforestdb\" path=\"godeps/src/github.com/couchbase/goforestdb\" revision=\"0b501227de0e8c55d99ed14e900eea1a1dbaf899\"/>",
 "  <project name=\"gojson\" path=\"godeps/src/github.com/dustin/gojson\" remote=\"couchbasedeps\" revision=\"af16e0e771e2ed110f2785564ae33931de8829e4\"/>",
 "  <project name=\"golang-snappy\" path=\"godeps/src/github.com/golang/snappy\" remote=\"couchbasedeps\" revision=\"723cc1e459b8eea2dea4583200fd60757d40097a\"/>",
 "  <project name=\"goleveldb\" path=\"godeps/src/github.com/syndtr/goleveldb\" remote=\"couchbasedeps\" revision=\"fa5b5c78794bc5c18f330361059f871ae8c2b9d6\"/>",
 "  <project name=\"gomemcached\" path=\"godeps/src/github.com/couchbase/gomemcached\" revision=\"4604300463c4a379d36d1427b17d3284a93f7621\"/>",
 "  <project name=\"gometa\" path=\"goproj/src/github.com/couchbase/gometa\" revision=\"7da5634cce1de744293acf27bb2aecc13ee50cc5\"/>",
 "  <project groups=\"kv\" name=\"googletest\" remote=\"couchbasedeps\" revision=\"f397fa5ec6365329b2e82eb2d8c03a7897bbefb5\"/>",
 "  <project name=\"goskiplist\" path=\"godeps/src/github.com/ryszard/goskiplist\" remote=\"couchbasedeps\" revision=\"2dfbae5fcf46374f166f8969cb07e167f1be6273\"/>",
 "  <project name=\"gosnappy\" path=\"godeps/src/github.com/syndtr/gosnappy\" remote=\"couchbasedeps\" revision=\"156a073208e131d7d2e212cb749feae7c339e846\"/>",
 "  <project name=\"goutils\" path=\"godeps/src/github.com/couchbase/goutils\" revision=\"5823a0cbaaa9008406021dc5daf80125ea30bba6\"/>",
 "  <project name=\"goxdcr\" path=\"goproj/src/github.com/couchbase/goxdcr\" revision=\"0f66d74c38453d0c1a620588edb4ee6a8fc22577\"/>",
 "  <project name=\"gtreap\" path=\"godeps/src/github.com/steveyen/gtreap\" remote=\"couchbasedeps\" revision=\"0abe01ef9be25c4aedc174758ec2d917314d6d70\"/>",
 "  <project name=\"indexing\" path=\"goproj/src/github.com/couchbase/indexing\" revision=\"1811cdbff66216861320b7657590e961b10b2c0a\"/>",
 "  <project name=\"levigo\" path=\"godeps/src/github.com/jmhodges/levigo\" remote=\"couchbasedeps\" revision=\"1ddad808d437abb2b8a55a950ec2616caa88969b\"/>",
 "  <project name=\"liner\" path=\"godeps/src/github.com/peterh/liner\" remote=\"couchbasedeps\" revision=\"ad1edfd30321d8f006ccf05f1e0524adeb943060\"/>",
 "  <project name=\"liner\" path=\"godeps/src/github.com/sbinet/liner\" remote=\"couchbasedeps\" revision=\"d9335eee40a45a4f5d74524c90040d6fe6013d50\"/>",
 "  <project groups=\"kv\" name=\"memcached\" revision=\"45a464250e1358593fa9f11ec010ddd992f0a717\"/>",
 "  <project name=\"minify\" path=\"godeps/src/github.com/tdewolff/minify\" remote=\"couchbasedeps\" revision=\"ede45cc53f43891267b1fe7c689db9c76d4ce0fb\"/>",
 "  <project name=\"mmap-go\" path=\"godeps/src/github.com/edsrzf/mmap-go\" remote=\"couchbasedeps\" revision=\"935e0e8a636ca4ba70b713f3e38a19e1b77739e8\"/>",
 "  <project name=\"moss\" path=\"godeps/src/github.com/couchbase/moss\" revision=\"c7cc82a67cf3fe50faf9a0697516b885e4fa34b9\"/>",
 "  <project groups=\"kv\" name=\"moxi\" revision=\"363c250e6087a61bf2d4bc8d6eff3325956be731\"/>",
 "  <project name=\"mux\" path=\"godeps/src/github.com/gorilla/mux\" remote=\"couchbasedeps\" revision=\"8a875a034c69b940914d83ea03d3f1299b4d094b\"/>",
 "  <project name=\"net\" path=\"godeps/src/golang.org/x/net\" remote=\"couchbasedeps\" revision=\"8968c61983e8f51a91b8c0ef25bf739278c89634\"/>",
 "  <project name=\"npipe\" path=\"godeps/src/github.com/natefinch/npipe\" remote=\"couchbasedeps\" revision=\"272c8150302e83f23d32a355364578c9c13ab20f\"/>",
 "  <project name=\"ns_server\" revision=\"b6c99dc71308f44261bbcc80688de02942d69f19\"/>",
 "  <project name=\"parse\" path=\"godeps/src/github.com/tdewolff/parse\" remote=\"couchbasedeps\" revision=\"0334a869253aca4b3a10c56c3f3139b394aec3a9\"/>",
 "  <project groups=\"kv\" name=\"platform\" revision=\"a80097d53c779b548d8c78b0a1886b8d44591b23\"/>",
 "  <project name=\"protobuf\" path=\"godeps/src/github.com/golang/protobuf\" remote=\"couchbasedeps\" revision=\"655cdfa588ea190e901bc5590e65d5621688847c\"/>",
 "  <project name=\"query\" path=\"goproj/src/github.com/couchbase/query\" revision=\"2012f9b883199299df53dec638a2b91c21907a53\"/>",
 "  <project name=\"query-ui\" revision=\"ff1f502b2f0c544ca68d2bda60d80fc3a01d573a\"/>",
 "  <project name=\"retriever\" path=\"godeps/src/github.com/couchbase/retriever\" revision=\"e3419088e4d3b4fe3aad3b364fdbe9a154f85f17\"/>",
 "  <project name=\"segment\" path=\"godeps/src/github.com/blevesearch/segment\" remote=\"blevesearch\" revision=\"db70c57796cc8c310613541dfade3dce627d09c7\"/>",
 "  <project groups=\"kv\" name=\"sigar\" revision=\"83bd88595f558987731a1baa3330f641bc36554c\"/>",
 "  <project name=\"strconv\" path=\"godeps/src/github.com/tdewolff/strconv\" remote=\"couchbasedeps\" revision=\"9b189f5be77f33c46776f24dbddb2a7ab32af214\"/>",
 "  <project groups=\"kv\" name=\"subjson\" revision=\"65d3f053e2d968aea00b60234a42e1d1c5b9f6d2\"/>",
 "  <project groups=\"solaris,notdefault\" name=\"sys\" path=\"godeps/src/golang.org/x/sys\" remote=\"couchbasedeps\" revision=\"9d4e42a20653790449273b3c85e67d6d8bae6e2e\"/>",
 "  <project name=\"testrunner\" revision=\"d63ed33d4130ecac236711b4156d41328728e42e\"/>",
 "  <project name=\"text\" path=\"godeps/src/golang.org/x/text\" remote=\"couchbasedeps\" revision=\"601048ad6acbab6cedd582db09b8c4839ff25b15\"/>",
 "  <project groups=\"kv\" name=\"tlm\" revision=\"29fafd6b365e58e9fc43fad749ce20c900890a6b\">",
 "    <copyfile dest=\"GNUmakefile\" src=\"GNUmakefile\"/>",
 "    <copyfile dest=\"Makefile\" src=\"Makefile\"/>",
 "    <copyfile dest=\"CMakeLists.txt\" src=\"CMakeLists.txt\"/>",
 "  </project>",
 "  <project name=\"ts\" path=\"godeps/src/github.com/olekukonko/ts\" remote=\"couchbasedeps\" revision=\"ecf753e7c962639ab5a1fb46f7da627d4c0a04b8\"/>",
 "  <project groups=\"notdefault,packaging\" name=\"voltron\" remote=\"couchbase-priv\" revision=\"876e25cffb99e0ae89078a0443b179bcb5d639c2\"/>",
 "</manifest>"]

[error_logger:info,2021-04-19T19:54:10.900Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.129.0>},
                       {name,timeout_diag_logger},
                       {mfargs,{timeout_diag_logger,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:54:10.905Z,nonode@nohost:dist_manager<0.130.0>:dist_manager:read_address_config_from_path:86]Reading ip config from "/opt/couchbase/var/lib/couchbase/ip_start"
[ns_server:info,2021-04-19T19:54:10.906Z,nonode@nohost:dist_manager<0.130.0>:dist_manager:read_address_config_from_path:86]Reading ip config from "/opt/couchbase/var/lib/couchbase/ip"
[ns_server:info,2021-04-19T19:54:10.908Z,nonode@nohost:dist_manager<0.130.0>:dist_manager:init:163]ip config not found. Looks like we're brand new node
[error_logger:info,2021-04-19T19:54:10.908Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,inet_gethost_native_sup}
             started: [{pid,<0.132.0>},{mfa,{inet_gethost_native,init,[[]]}}]

[error_logger:info,2021-04-19T19:54:10.909Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.131.0>},
                       {name,inet_gethost_native_sup},
                       {mfargs,{inet_gethost_native,start_link,[]}},
                       {restart_type,temporary},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:54:11.946Z,nonode@nohost:dist_manager<0.130.0>:dist_manager:bringup:214]Attempting to bring up net_kernel with name 'ns_1@127.0.0.1'
[error_logger:info,2021-04-19T19:54:11.957Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.134.0>},
                       {name,erl_epmd},
                       {mfargs,{erl_epmd,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:11.957Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.135.0>},
                       {name,auth},
                       {mfargs,{auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:11.958Z,ns_1@127.0.0.1:dist_manager<0.130.0>:dist_manager:configure_net_kernel:255]Set net_kernel vebosity to 10 -> 0
[error_logger:info,2021-04-19T19:54:11.958Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.136.0>},
                       {name,net_kernel},
                       {mfargs,
                           {net_kernel,start_link,
                               [['ns_1@127.0.0.1',longnames]]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:11.958Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_sup}
             started: [{pid,<0.133.0>},
                       {name,net_sup_dynamic},
                       {mfargs,
                           {erl_distribution,start_link,
                               [['ns_1@127.0.0.1',longnames]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,supervisor}]

[ns_server:info,2021-04-19T19:54:11.961Z,ns_1@127.0.0.1:dist_manager<0.130.0>:dist_manager:save_node:147]saving node to "/opt/couchbase/var/lib/couchbase/couchbase-server.node"
[ns_server:debug,2021-04-19T19:54:11.982Z,ns_1@127.0.0.1:dist_manager<0.130.0>:dist_manager:bringup:228]Attempted to save node name to disk: ok
[ns_server:debug,2021-04-19T19:54:11.982Z,ns_1@127.0.0.1:dist_manager<0.130.0>:dist_manager:wait_for_node:235]Waiting for connection to node 'babysitter_of_ns_1@127.0.0.1' to be established
[error_logger:info,2021-04-19T19:54:11.983Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'babysitter_of_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:54:11.995Z,ns_1@127.0.0.1:dist_manager<0.130.0>:dist_manager:wait_for_node:244]Observed node 'babysitter_of_ns_1@127.0.0.1' to come up
[error_logger:info,2021-04-19T19:54:12.003Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.130.0>},
                       {name,dist_manager},
                       {mfargs,{dist_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:12.006Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.141.0>},
                       {name,ns_cookie_manager},
                       {mfargs,{ns_cookie_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:12.007Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.142.0>},
                       {name,ns_cluster},
                       {mfargs,{ns_cluster,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:54:12.010Z,ns_1@127.0.0.1:ns_config_sup<0.143.0>:ns_config_sup:init:32]loading static ns_config from "/opt/couchbase/etc/couchbase/config"
[error_logger:info,2021-04-19T19:54:12.010Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.144.0>},
                       {name,ns_config_events},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_config_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:12.010Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.145.0>},
                       {name,ns_config_events_local},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,ns_config_events_local}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:54:12.082Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_config:load_config:1083]Loading static config from "/opt/couchbase/etc/couchbase/config"
[ns_server:info,2021-04-19T19:54:12.090Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_config:load_config:1097]Loading dynamic config from "/opt/couchbase/var/lib/couchbase/config/config.dat"
[ns_server:debug,2021-04-19T19:54:12.109Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_config:load_config:1105]Here's full dynamic config we loaded:
[[{{metakv,<<"/indexing/settings/config">>},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{5,63786081158}}]}|
    <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.log_level\":\"info\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\":200,\"indexer.settings.max_cpu_percent\":0,\"indexer.settings.storage_mode\":\"memory_optimized\",\"indexer.settings.recovery.max_rollbacks\":5,\"indexer.settings.memory_quota\":314572800,\"indexer.settings.compaction.abort_exceed_interval\":false}">>]},
  {alert_limits,
   [{max_overhead_perc,50},{max_disk_used,90},{max_indexer_ram,75}]},
  {audit,
   [{auditd_enabled,false},
    {rotate_interval,86400},
    {rotate_size,20971520},
    {disabled,[]},
    {sync,[]},
    {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]},
  {auto_failover_cfg,[{enabled,false},{timeout,120},{max_nodes,1},{count,0}]},
  {autocompaction,
   [{database_fragmentation_threshold,{30,undefined}},
    {view_fragmentation_threshold,{30,undefined}}]},
  {buckets,[{configs,[]}]},
  {cert_and_pkey,
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080742}}]}|
    {<<"-----BEGIN CERTIFICATE-----\nMIIDAjCCAeqgAwIBAgIIFndZ/vr3iFgwDQYJKoZIhvcNAQELBQAwJDEiMCAGA1UE\nAxMZQ291Y2hiYXNlIFNlcnZlciBiODgwZTU4MjAeFw0xMzAxMDEwMDAwMDBaFw00\nOTEyMzEyMzU5NTlaMCQxIjAgBgNVBAMTGUNvdWNoYmFzZSBTZXJ2ZXIgYjg4MGU1\nODIwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDPKYjrGZUDKn7xXZhz\n/CcGig/KlI7xzgbLixQnJ5VLNHQOaIcz01bkH2SuTUnIg3i9awTEc/vdraqbL7dK\neAQZEWpnUrZo8sPI/sI9nYnAJttUCQD0cmsC1X0n0uNxaGVj2i2RsOvbPM+EJHOM\nWEESG/u7+Wf4aeV43AqreUXuiGwy7huZuTMU0MK1/qM2XbG2/cv2Oj7HZ6Sqp8vH\n1jEQqyG0I2NJyGfAEvHnswY2t99lDunBJJEjf0am2BJkC23tMZPmLWoTqTT4CSuK\n1Fl1OKj/ZM5dwDwHEmks1I/q88rXRA4AYZQWDdLCM8aZvhUYP0yKj585/v/HmMN4\nkFRVAgMBAAGjODA2MA4GA1UdDwEB/wQEAwICpDATBgNVHSUEDDAKBggrBgEFBQcD\nATAPBgNVHRMBAf8EBTADAQH/MA0GCSqGSIb3DQEBCwUAA4IBAQBLvg8P2SCkc22T\n8fwRrq7jUh+N0Qo/khU0rHZqC7DKJtI9j8e3yFQcxYPCCAOYfaEO9hPDhckBwJGE\nnjoLrfPGHHWM2Tw4RHrYcJ8q5UMjPqCM422ylEzf/vRYUbC175vfo41zkR/F7TYt\napV4DiUM6YmXssYtW66yEcwsZMyDpu/kl/c7+H0yKANJugp8mJWHsnHszvBdn+FT\ns0yV4IGMUPaFMJZOwG+yVlRtAQnZufEzxSgIT0mYWk1DjU+ji8w7r8nthDJoJRqN\nObL+ZMUIupp8NnGF7xz5ll4nmeup8M8CYTnyS0L1tqQ2/Qo0mOy5bwfZuTqzHJE2\nP6fNdAiq\n-----END CERTIFICATE-----\n">>,
     <<"*****">>}]},
  {cluster_compat_version,
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{6,63786080749}}]},
    4,6]},
  {drop_request_memory_threshold_mib,undefined},
  {email_alerts,
   [{recipients,["root@localhost"]},
    {sender,"couchbase@localhost"},
    {enabled,false},
    {email_server,
     [{user,[]},{pass,"*****"},{host,"localhost"},{port,25},{encrypt,false}]},
    {alerts,
     [auto_failover_node,auto_failover_maximum_reached,
      auto_failover_other_nodes_down,auto_failover_cluster_too_small,
      auto_failover_disabled,ip,disk,overhead,ep_oom_errors,
      ep_item_commit_failed,audit_dropped_events,indexer_ram_max_usage,
      ep_clock_cas_drift_threshold_exceeded]}]},
  {fts_memory_quota,512},
  {goxdcr_upgrade,
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080749}}]}|
    '_deleted']},
  {index_aware_rebalance_disabled,false},
  {max_bucket_count,10},
  {memcached,[]},
  {memory_quota,
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080757}}]}|
    300]},
  {nodes_wanted,['ns_1@127.0.0.1']},
  {otp,
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080748}}]},
    {cookie,{sanitized,<<"igGdfqmbza2bbcUGcHlgLfqDrDSw4MuqpdcFvTedqb0=">>}}]},
  {read_only_user_creds,
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080749}}]}|
    null]},
  {remote_clusters,[]},
  {replication,[{enabled,true}]},
  {rest,[{port,8091}]},
  {rest_creds,
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{2,63786080757}}]}|
    {"Administrator",{password,"*****"}}]},
  {roles_definitions,
   [{admin,[],
     [{name,<<"Admin">>},
      {desc,<<"Can manage ALL cluster features including security.">>}],
     [{[],all}]},
    {ro_admin,[],
     [{name,<<"Read Only Admin">>},
      {desc,<<"Can view ALL cluster features.">>}],
     [{[{bucket,any},password],none},
      {[{bucket,any},data],none},
      {[admin,security],[read]},
      {[admin],none},
      {[],[read]}]},
    {cluster_admin,[],
     [{name,<<"Cluster Admin">>},
      {desc,<<"Can manage all cluster features EXCEPT security.">>}],
     [{[admin],none},{[],all}]},
    {bucket_admin,
     [bucket_name],
     [{name,<<"Bucket Admin">>},
      {desc,
       <<"Can manage ALL bucket features for specified buckets (incl. start/stop XDCR)">>}],
     [{[{bucket,bucket_name},xdcr],[read,execute]},
      {[{bucket,bucket_name}],all},
      {[{bucket,any},settings],[read]},
      {[{bucket,any}],none},
      {[xdcr],none},
      {[admin],none},
      {[],[read]}]},
    {bucket_sasl,
     [bucket_name],
     [],
     [{[{bucket,bucket_name},data],all},
      {[{bucket,bucket_name},views],all},
      {[{bucket,bucket_name}],[read,flush]},
      {[pools],[read]}]},
    {views_admin,
     [bucket_name],
     [{name,<<"Views Admin">>},
      {desc,<<"Can manage views for specified buckets">>}],
     [{[{bucket,bucket_name},views],all},
      {[{bucket,bucket_name},data],[read]},
      {[{bucket,any},settings],[read]},
      {[{bucket,any}],none},
      {[xdcr],none},
      {[admin],none},
      {[],[read]}]},
    {replication_admin,[],
     [{name,<<"Replication Admin">>},
      {desc,<<"Can manage ONLY XDCR features (cluster AND bucket level)">>}],
     [{[{bucket,any},xdcr],all},
      {[{bucket,any},data],[read]},
      {[{bucket,any},settings],[read]},
      {[{bucket,any}],none},
      {[xdcr],all},
      {[admin],none},
      {[],[read]}]}]},
  {server_groups,
   [[{uuid,<<"0">>},{name,<<"Group 1">>},{nodes,['ns_1@127.0.0.1']}]]},
  {set_view_update_daemon,
   [{update_interval,5000},
    {update_min_changes,5000},
    {replica_update_min_changes,5000}]},
  {uuid,
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080757}}]}|
    <<"819b5f49755d4c5571ba2861d6185103">>]},
  {{couchdb,max_parallel_indexers},4},
  {{couchdb,max_parallel_replica_indexers},2},
  {{local_changes_count,<<"360fb3d3641e00b1f4f22714c24e2a2a">>},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{13,63786081158}}]}]},
  {{request_limit,capi},undefined},
  {{request_limit,rest},undefined},
  {{service_map,fts},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080749}}]}]},
  {{service_map,index},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{2,63786080759}}]},
    'ns_1@127.0.0.1']},
  {{service_map,n1ql},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{2,63786080759}}]},
    'ns_1@127.0.0.1']},
  {{node,'ns_1@127.0.0.1',audit},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}]},
  {{node,'ns_1@127.0.0.1',capi_port},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    8092]},
  {{node,'ns_1@127.0.0.1',compaction_daemon},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
    {check_interval,30},
    {min_db_file_size,131072},
    {min_view_file_size,20971520}]},
  {{node,'ns_1@127.0.0.1',config_version},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    {4,5}]},
  {{node,'ns_1@127.0.0.1',fts_http_port},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    8094]},
  {{node,'ns_1@127.0.0.1',indexer_admin_port},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    9100]},
  {{node,'ns_1@127.0.0.1',indexer_http_port},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    9102]},
  {{node,'ns_1@127.0.0.1',indexer_scan_port},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    9101]},
  {{node,'ns_1@127.0.0.1',indexer_stcatchup_port},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    9104]},
  {{node,'ns_1@127.0.0.1',indexer_stinit_port},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    9103]},
  {{node,'ns_1@127.0.0.1',indexer_stmaint_port},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    9105]},
  {{node,'ns_1@127.0.0.1',is_enterprise},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    true]},
  {{node,'ns_1@127.0.0.1',isasl},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
    {path,"/opt/couchbase/var/lib/couchbase/isasl.pw"}]},
  {{node,'ns_1@127.0.0.1',ldap_enabled},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    true]},
  {{node,'ns_1@127.0.0.1',membership},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    active]},
  {{node,'ns_1@127.0.0.1',memcached},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
    {port,11210},
    {dedicated_port,11209},
    {ssl_port,11207},
    {admin_user,"_admin"},
    {admin_pass,"*****"},
    {engines,
     [{membase,
       [{engine,"/opt/couchbase/lib/memcached/ep.so"},
        {static_config_string,"failpartialwarmup=false"}]},
      {memcached,
       [{engine,"/opt/couchbase/lib/memcached/default_engine.so"},
        {static_config_string,"vb0=true"}]}]},
    {config_path,"/opt/couchbase/var/lib/couchbase/config/memcached.json"},
    {audit_file,"/opt/couchbase/var/lib/couchbase/config/audit.json"},
    {log_path,"/opt/couchbase/var/lib/couchbase/logs"},
    {log_prefix,"memcached.log"},
    {log_generations,20},
    {log_cyclesize,10485760},
    {log_sleeptime,19},
    {log_rotation_period,39003}]},
  {{node,'ns_1@127.0.0.1',memcached_config},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    {[{interfaces,
       {memcached_config_mgr,omit_missing_mcd_ports,
        [{[{host,<<"*">>},{port,port},{maxconn,maxconn}]},
         {[{host,<<"*">>},
           {port,dedicated_port},
           {maxconn,dedicated_port_maxconn}]},
         {[{host,<<"*">>},
           {port,ssl_port},
           {maxconn,maxconn},
           {ssl,
            {[{key,
               <<"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem">>},
              {cert,
               <<"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem">>}]}}]}]}},
      {ssl_cipher_list,{"~s",[ssl_cipher_list]}},
      {ssl_minimum_protocol,{memcached_config_mgr,ssl_minimum_protocol,[]}},
      {connection_idle_time,connection_idle_time},
      {breakpad,
       {[{enabled,breakpad_enabled},
         {minidump_dir,{memcached_config_mgr,get_minidump_dir,[]}}]}},
      {extensions,
       [{[{module,<<"/opt/couchbase/lib/memcached/stdin_term_handler.so">>},
          {config,<<>>}]},
        {[{module,<<"/opt/couchbase/lib/memcached/file_logger.so">>},
          {config,
           {"cyclesize=~B;sleeptime=~B;filename=~s/~s",
            [log_cyclesize,log_sleeptime,log_path,log_prefix]}}]}]},
      {admin,{"~s",[admin_user]}},
      {verbosity,verbosity},
      {audit_file,{"~s",[audit_file]}},
      {dedupe_nmvb_maps,dedupe_nmvb_maps}]}]},
  {{node,'ns_1@127.0.0.1',memcached_defaults},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
    {maxconn,30000},
    {dedicated_port_maxconn,5000},
    {ssl_cipher_list,"HIGH"},
    {connection_idle_time,0},
    {verbosity,0},
    {breakpad_enabled,true},
    {breakpad_minidump_dir_path,"/opt/couchbase/var/lib/couchbase/crash"},
    {dedupe_nmvb_maps,false}]},
  {{node,'ns_1@127.0.0.1',moxi},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
    {port,11211},
    {verbosity,[]}]},
  {{node,'ns_1@127.0.0.1',ns_log},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
    {filename,"/opt/couchbase/var/lib/couchbase/ns_log"}]},
  {{node,'ns_1@127.0.0.1',port_servers},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}]},
  {{node,'ns_1@127.0.0.1',projector_port},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    9999]},
  {{node,'ns_1@127.0.0.1',query_port},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    8093]},
  {{node,'ns_1@127.0.0.1',rest},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
    {port,8091},
    {port_meta,global}]},
  {{node,'ns_1@127.0.0.1',services},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080757}}]},
    index,kv,n1ql]},
  {{node,'ns_1@127.0.0.1',ssl_capi_port},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    18092]},
  {{node,'ns_1@127.0.0.1',ssl_proxy_downstream_port},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    11214]},
  {{node,'ns_1@127.0.0.1',ssl_proxy_upstream_port},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    11215]},
  {{node,'ns_1@127.0.0.1',ssl_query_port},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    18093]},
  {{node,'ns_1@127.0.0.1',ssl_rest_port},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    18091]},
  {{node,'ns_1@127.0.0.1',stop_xdcr},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{2,63786080749}}]}|
    '_deleted']},
  {{node,'ns_1@127.0.0.1',uuid},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    <<"360fb3d3641e00b1f4f22714c24e2a2a">>]},
  {{node,'ns_1@127.0.0.1',xdcr_rest_port},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    9998]}]]
[ns_server:info,2021-04-19T19:54:12.119Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_config:load_config:1126]Here's full dynamic config we loaded + static & default config:
[{{node,'ns_1@127.0.0.1',xdcr_rest_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   9998]},
 {{node,'ns_1@127.0.0.1',uuid},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   <<"360fb3d3641e00b1f4f22714c24e2a2a">>]},
 {{node,'ns_1@127.0.0.1',stop_xdcr},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{2,63786080749}}]}|
   '_deleted']},
 {{node,'ns_1@127.0.0.1',ssl_rest_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   18091]},
 {{node,'ns_1@127.0.0.1',ssl_query_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   18093]},
 {{node,'ns_1@127.0.0.1',ssl_proxy_upstream_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   11215]},
 {{node,'ns_1@127.0.0.1',ssl_proxy_downstream_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   11214]},
 {{node,'ns_1@127.0.0.1',ssl_capi_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   18092]},
 {{node,'ns_1@127.0.0.1',services},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080757}}]},
   index,kv,n1ql]},
 {{node,'ns_1@127.0.0.1',rest},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
   {port,8091},
   {port_meta,global}]},
 {{node,'ns_1@127.0.0.1',query_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   8093]},
 {{node,'ns_1@127.0.0.1',projector_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   9999]},
 {{node,'ns_1@127.0.0.1',port_servers},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}]},
 {{node,'ns_1@127.0.0.1',ns_log},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
   {filename,"/opt/couchbase/var/lib/couchbase/ns_log"}]},
 {{node,'ns_1@127.0.0.1',moxi},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
   {port,11211},
   {verbosity,[]}]},
 {{node,'ns_1@127.0.0.1',memcached_defaults},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
   {maxconn,30000},
   {dedicated_port_maxconn,5000},
   {ssl_cipher_list,"HIGH"},
   {connection_idle_time,0},
   {verbosity,0},
   {breakpad_enabled,true},
   {breakpad_minidump_dir_path,"/opt/couchbase/var/lib/couchbase/crash"},
   {dedupe_nmvb_maps,false}]},
 {{node,'ns_1@127.0.0.1',memcached_config},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   {[{interfaces,
      {memcached_config_mgr,omit_missing_mcd_ports,
       [{[{host,<<"*">>},{port,port},{maxconn,maxconn}]},
        {[{host,<<"*">>},
          {port,dedicated_port},
          {maxconn,dedicated_port_maxconn}]},
        {[{host,<<"*">>},
          {port,ssl_port},
          {maxconn,maxconn},
          {ssl,
           {[{key,
              <<"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem">>},
             {cert,
              <<"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem">>}]}}]}]}},
     {ssl_cipher_list,{"~s",[ssl_cipher_list]}},
     {ssl_minimum_protocol,{memcached_config_mgr,ssl_minimum_protocol,[]}},
     {connection_idle_time,connection_idle_time},
     {breakpad,
      {[{enabled,breakpad_enabled},
        {minidump_dir,{memcached_config_mgr,get_minidump_dir,[]}}]}},
     {extensions,
      [{[{module,<<"/opt/couchbase/lib/memcached/stdin_term_handler.so">>},
         {config,<<>>}]},
       {[{module,<<"/opt/couchbase/lib/memcached/file_logger.so">>},
         {config,
          {"cyclesize=~B;sleeptime=~B;filename=~s/~s",
           [log_cyclesize,log_sleeptime,log_path,log_prefix]}}]}]},
     {admin,{"~s",[admin_user]}},
     {verbosity,verbosity},
     {audit_file,{"~s",[audit_file]}},
     {dedupe_nmvb_maps,dedupe_nmvb_maps}]}]},
 {{node,'ns_1@127.0.0.1',memcached},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
   {port,11210},
   {dedicated_port,11209},
   {ssl_port,11207},
   {admin_user,"_admin"},
   {admin_pass,"*****"},
   {engines,
    [{membase,
      [{engine,"/opt/couchbase/lib/memcached/ep.so"},
       {static_config_string,"failpartialwarmup=false"}]},
     {memcached,
      [{engine,"/opt/couchbase/lib/memcached/default_engine.so"},
       {static_config_string,"vb0=true"}]}]},
   {config_path,"/opt/couchbase/var/lib/couchbase/config/memcached.json"},
   {audit_file,"/opt/couchbase/var/lib/couchbase/config/audit.json"},
   {log_path,"/opt/couchbase/var/lib/couchbase/logs"},
   {log_prefix,"memcached.log"},
   {log_generations,20},
   {log_cyclesize,10485760},
   {log_sleeptime,19},
   {log_rotation_period,39003}]},
 {{node,'ns_1@127.0.0.1',membership},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   active]},
 {{node,'ns_1@127.0.0.1',ldap_enabled},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   true]},
 {{node,'ns_1@127.0.0.1',isasl},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
   {path,"/opt/couchbase/var/lib/couchbase/isasl.pw"}]},
 {{node,'ns_1@127.0.0.1',is_enterprise},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   true]},
 {{node,'ns_1@127.0.0.1',indexer_stmaint_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   9105]},
 {{node,'ns_1@127.0.0.1',indexer_stinit_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   9103]},
 {{node,'ns_1@127.0.0.1',indexer_stcatchup_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   9104]},
 {{node,'ns_1@127.0.0.1',indexer_scan_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   9101]},
 {{node,'ns_1@127.0.0.1',indexer_http_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   9102]},
 {{node,'ns_1@127.0.0.1',indexer_admin_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   9100]},
 {{node,'ns_1@127.0.0.1',fts_http_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   8094]},
 {{node,'ns_1@127.0.0.1',config_version},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   {4,5}]},
 {{node,'ns_1@127.0.0.1',compaction_daemon},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
   {check_interval,30},
   {min_db_file_size,131072},
   {min_view_file_size,20971520}]},
 {{node,'ns_1@127.0.0.1',capi_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   8092]},
 {{node,'ns_1@127.0.0.1',audit},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}]},
 {{service_map,n1ql},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{2,63786080759}}]},
   'ns_1@127.0.0.1']},
 {{service_map,index},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{2,63786080759}}]},
   'ns_1@127.0.0.1']},
 {{service_map,fts},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080749}}]}]},
 {{request_limit,rest},undefined},
 {{request_limit,capi},undefined},
 {{local_changes_count,<<"360fb3d3641e00b1f4f22714c24e2a2a">>},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{13,63786081158}}]}]},
 {{couchdb,max_parallel_replica_indexers},2},
 {{couchdb,max_parallel_indexers},4},
 {uuid,
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080757}}]}|
   <<"819b5f49755d4c5571ba2861d6185103">>]},
 {set_view_update_daemon,
  [{update_interval,5000},
   {update_min_changes,5000},
   {replica_update_min_changes,5000}]},
 {server_groups,
  [[{uuid,<<"0">>},{name,<<"Group 1">>},{nodes,['ns_1@127.0.0.1']}]]},
 {roles_definitions,
  [{admin,[],
    [{name,<<"Admin">>},
     {desc,<<"Can manage ALL cluster features including security.">>}],
    [{[],all}]},
   {ro_admin,[],
    [{name,<<"Read Only Admin">>},{desc,<<"Can view ALL cluster features.">>}],
    [{[{bucket,any},password],none},
     {[{bucket,any},data],none},
     {[admin,security],[read]},
     {[admin],none},
     {[],[read]}]},
   {cluster_admin,[],
    [{name,<<"Cluster Admin">>},
     {desc,<<"Can manage all cluster features EXCEPT security.">>}],
    [{[admin],none},{[],all}]},
   {bucket_admin,
    [bucket_name],
    [{name,<<"Bucket Admin">>},
     {desc,
      <<"Can manage ALL bucket features for specified buckets (incl. start/stop XDCR)">>}],
    [{[{bucket,bucket_name},xdcr],[read,execute]},
     {[{bucket,bucket_name}],all},
     {[{bucket,any},settings],[read]},
     {[{bucket,any}],none},
     {[xdcr],none},
     {[admin],none},
     {[],[read]}]},
   {bucket_sasl,
    [bucket_name],
    [],
    [{[{bucket,bucket_name},data],all},
     {[{bucket,bucket_name},views],all},
     {[{bucket,bucket_name}],[read,flush]},
     {[pools],[read]}]},
   {views_admin,
    [bucket_name],
    [{name,<<"Views Admin">>},
     {desc,<<"Can manage views for specified buckets">>}],
    [{[{bucket,bucket_name},views],all},
     {[{bucket,bucket_name},data],[read]},
     {[{bucket,any},settings],[read]},
     {[{bucket,any}],none},
     {[xdcr],none},
     {[admin],none},
     {[],[read]}]},
   {replication_admin,[],
    [{name,<<"Replication Admin">>},
     {desc,<<"Can manage ONLY XDCR features (cluster AND bucket level)">>}],
    [{[{bucket,any},xdcr],all},
     {[{bucket,any},data],[read]},
     {[{bucket,any},settings],[read]},
     {[{bucket,any}],none},
     {[xdcr],all},
     {[admin],none},
     {[],[read]}]}]},
 {rest_creds,
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{2,63786080757}}]}|
   {"Administrator",{password,"*****"}}]},
 {rest,[{port,8091}]},
 {replication,[{enabled,true}]},
 {remote_clusters,[]},
 {read_only_user_creds,
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080749}}]}|
   null]},
 {otp,
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080748}}]},
   {cookie,{sanitized,<<"igGdfqmbza2bbcUGcHlgLfqDrDSw4MuqpdcFvTedqb0=">>}}]},
 {nodes_wanted,['ns_1@127.0.0.1']},
 {memory_quota,
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080757}}]}|
   300]},
 {memcached,[]},
 {max_bucket_count,10},
 {index_aware_rebalance_disabled,false},
 {goxdcr_upgrade,
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080749}}]}|
   '_deleted']},
 {fts_memory_quota,512},
 {email_alerts,
  [{recipients,["root@localhost"]},
   {sender,"couchbase@localhost"},
   {enabled,false},
   {email_server,
    [{user,[]},{pass,"*****"},{host,"localhost"},{port,25},{encrypt,false}]},
   {alerts,
    [auto_failover_node,auto_failover_maximum_reached,
     auto_failover_other_nodes_down,auto_failover_cluster_too_small,
     auto_failover_disabled,ip,disk,overhead,ep_oom_errors,
     ep_item_commit_failed,audit_dropped_events,indexer_ram_max_usage,
     ep_clock_cas_drift_threshold_exceeded]}]},
 {drop_request_memory_threshold_mib,undefined},
 {cluster_compat_version,
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{6,63786080749}}]},
   4,6]},
 {cert_and_pkey,
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080742}}]}|
   {<<"-----BEGIN CERTIFICATE-----\nMIIDAjCCAeqgAwIBAgIIFndZ/vr3iFgwDQYJKoZIhvcNAQELBQAwJDEiMCAGA1UE\nAxMZQ291Y2hiYXNlIFNlcnZlciBiODgwZTU4MjAeFw0xMzAxMDEwMDAwMDBaFw00\nOTEyMzEyMzU5NTlaMCQxIjAgBgNVBAMTGUNvdWNoYmFzZSBTZXJ2ZXIgYjg4MGU1\nODIwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDPKYjrGZUDKn7xXZhz\n/CcGig/KlI7xzgbLixQnJ5VLNHQOaIcz01bkH2SuTUnIg3i9awTEc/vdraqbL7dK\neAQZEWpnUrZo8sPI/sI9nYnAJttUCQD0cmsC1X0n0uNxaGVj2i2RsOvbPM+EJHOM\nWEESG/u7+Wf4aeV43AqreUXuiGwy7huZuTMU0MK1/qM2XbG2/cv2Oj7HZ6Sqp8vH\n1jEQqyG0I2NJyGfAEvHnswY2t99lDunBJJEjf0am2BJkC23tMZPmLWoTqTT4CSuK\n1Fl1OKj/ZM5dwDwHEmks1I/q88rXRA4AYZQWDdLCM8aZvhUYP0yKj585/v/HmMN4\nkFRVAgMBAAGjODA2MA4GA1UdDwEB/wQEAwICpDATBgNVHSUEDDAKBggrBgEFBQcD\nATAPBgNVHRMBAf8EBTADAQH/MA0GCSqGSIb3DQEBCwUAA4IBAQBLvg8P2SCkc22T\n8fwRrq7jUh+N0Qo/khU0rHZqC7DKJtI9j8e3yFQcxYPCCAOYfaEO9hPDhckBwJGE\nnjoLrfPGHHWM2Tw4RHrYcJ8q5UMjPqCM422ylEzf/vRYUbC175vfo41zkR/F7TYt\napV4DiUM6YmXssYtW66yEcwsZMyDpu/kl/c7+H0yKANJugp8mJWHsnHszvBdn+FT\ns0yV4IGMUPaFMJZOwG+yVlRtAQnZufEzxSgIT0mYWk1DjU+ji8w7r8nthDJoJRqN\nObL+ZMUIupp8NnGF7xz5ll4nmeup8M8CYTnyS0L1tqQ2/Qo0mOy5bwfZuTqzHJE2\nP6fNdAiq\n-----END CERTIFICATE-----\n">>,
    <<"*****">>}]},
 {buckets,[{configs,[]}]},
 {autocompaction,
  [{database_fragmentation_threshold,{30,undefined}},
   {view_fragmentation_threshold,{30,undefined}}]},
 {auto_failover_cfg,[{enabled,false},{timeout,120},{max_nodes,1},{count,0}]},
 {audit,
  [{auditd_enabled,false},
   {rotate_interval,86400},
   {rotate_size,20971520},
   {disabled,[]},
   {sync,[]},
   {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]},
 {alert_limits,
  [{max_overhead_perc,50},{max_disk_used,90},{max_indexer_ram,75}]},
 {{metakv,<<"/indexing/settings/config">>},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{5,63786081158}}]}|
   <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.log_level\":\"info\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\":200,\"indexer.settings.max_cpu_percent\":0,\"indexer.settings.storage_mode\":\"memory_optimized\",\"indexer.settings.recovery.max_rollbacks\":5,\"indexer.settings.memory_quota\":314572800,\"indexer.settings.compaction.abort_exceed_interval\":false}">>]}]
[error_logger:info,2021-04-19T19:54:12.123Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.146.0>},
                       {name,ns_config},
                       {mfargs,
                           {ns_config,start_link,
                               ["/opt/couchbase/etc/couchbase/config",
                                ns_config_default]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:12.125Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.149.0>},
                       {name,ns_config_remote},
                       {mfargs,
                           {ns_config_replica,start_link,
                               [{local,ns_config_remote}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:12.129Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.150.0>},
                       {name,ns_config_log},
                       {mfargs,{ns_config_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:12.129Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.143.0>},
                       {name,ns_config_sup},
                       {mfargs,{ns_config_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:54:12.132Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.152.0>},
                       {name,vbucket_filter_changes_registry},
                       {mfargs,
                           {ns_process_registry,start_link,
                               [vbucket_filter_changes_registry,
                                [{terminate_command,shutdown}]]}},
                       {restart_type,permanent},
                       {shutdown,100},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:12.136Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.153.0>},
                       {name,json_rpc_connection_sup},
                       {mfargs,{json_rpc_connection_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:54:12.154Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.156.0>},
                       {name,remote_monitors},
                       {mfargs,{remote_monitors,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:12.157Z,ns_1@127.0.0.1:menelaus_barrier<0.157.0>:one_shot_barrier:barrier_body:58]Barrier menelaus_barrier has started
[error_logger:info,2021-04-19T19:54:12.158Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.157.0>},
                       {name,menelaus_barrier},
                       {mfargs,{menelaus_sup,barrier_start_link,[]}},
                       {restart_type,temporary},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:12.158Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.158.0>},
                       {name,rest_lhttpc_pool},
                       {mfargs,
                           {lhttpc_manager,start_link,
                               [[{name,rest_lhttpc_pool},
                                 {connection_timeout,120000},
                                 {pool_size,20}]]}},
                       {restart_type,{permanent,1}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:54:12.199Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.160.0>:ns_ssl_services_setup:init:370]Used ssl options:
[{keyfile,"/opt/couchbase/var/lib/couchbase/config/ssl-cert-key.pem"},
 {certfile,"/opt/couchbase/var/lib/couchbase/config/ssl-cert-key.pem"},
 {versions,[tlsv1,'tlsv1.1','tlsv1.2']},
 {cacertfile,"/opt/couchbase/var/lib/couchbase/config/ssl-cert-key.pem-ca"},
 {dh,<<48,130,1,8,2,130,1,1,0,152,202,99,248,92,201,35,238,246,5,77,93,120,10,
       118,129,36,52,111,193,167,220,49,229,106,105,152,133,121,157,73,158,
       232,153,197,197,21,171,140,30,207,52,165,45,8,221,162,21,199,183,66,
       211,247,51,224,102,214,190,130,96,253,218,193,35,43,139,145,89,200,250,
       145,92,50,80,134,135,188,205,254,148,122,136,237,220,186,147,187,104,
       159,36,147,217,117,74,35,163,145,249,175,242,18,221,124,54,140,16,246,
       169,84,252,45,47,99,136,30,60,189,203,61,86,225,117,255,4,91,46,110,
       167,173,106,51,65,10,248,94,225,223,73,40,232,140,26,11,67,170,118,190,
       67,31,127,233,39,68,88,132,171,224,62,187,207,160,189,209,101,74,8,205,
       174,146,173,80,105,144,246,25,153,86,36,24,178,163,64,202,221,95,184,
       110,244,32,226,217,34,55,188,230,55,16,216,247,173,246,139,76,187,66,
       211,159,17,46,20,18,48,80,27,250,96,189,29,214,234,241,34,69,254,147,
       103,220,133,40,164,84,8,44,241,61,164,151,9,135,41,60,75,4,202,133,173,
       72,6,69,167,89,112,174,40,229,171,2,1,2>>},
 {ciphers,[{dhe_rsa,aes_256_cbc,sha256},
           {dhe_dss,aes_256_cbc,sha256},
           {rsa,aes_256_cbc,sha256},
           {dhe_rsa,aes_128_cbc,sha256},
           {dhe_dss,aes_128_cbc,sha256},
           {rsa,aes_128_cbc,sha256},
           {dhe_rsa,aes_256_cbc,sha},
           {dhe_dss,aes_256_cbc,sha},
           {rsa,aes_256_cbc,sha},
           {dhe_rsa,'3des_ede_cbc',sha},
           {dhe_dss,'3des_ede_cbc',sha},
           {rsa,'3des_ede_cbc',sha},
           {dhe_rsa,aes_128_cbc,sha},
           {dhe_dss,aes_128_cbc,sha},
           {rsa,aes_128_cbc,sha}]}]
[error_logger:info,2021-04-19T19:54:12.304Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_ssl_services_sup}
             started: [{pid,<0.160.0>},
                       {name,ns_ssl_services_setup},
                       {mfargs,{ns_ssl_services_setup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:54:12.352Z,ns_1@127.0.0.1:<0.162.0>:menelaus_pluggable_ui:validate_plugin_spec:117]Loaded pluggable UI specification for fts

[ns_server:info,2021-04-19T19:54:12.352Z,ns_1@127.0.0.1:<0.162.0>:menelaus_pluggable_ui:validate_plugin_spec:117]Loaded pluggable UI specification for n1ql

[ns_server:debug,2021-04-19T19:54:12.378Z,ns_1@127.0.0.1:<0.162.0>:restartable:start_child:98]Started child process <0.164.0>
  MFA: {ns_ssl_services_setup,start_link_rest_service,[]}
[error_logger:info,2021-04-19T19:54:12.379Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_ssl_services_sup}
             started: [{pid,<0.162.0>},
                       {name,ns_rest_ssl_service},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_ssl_services_setup,
                                    start_link_rest_service,[]},
                                1000]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:12.379Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.159.0>},
                       {name,ns_ssl_services_sup},
                       {mfargs,{ns_ssl_services_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2021-04-19T19:54:12.396Z,ns_1@127.0.0.1:wait_link_to_couchdb_node<0.182.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:126]Waiting for ns_couchdb node to start
[error_logger:info,2021-04-19T19:54:12.396Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.181.0>},
                       {name,start_couchdb_node},
                       {mfargs,{ns_server_nodes_sup,start_couchdb_node,[]}},
                       {restart_type,{permanent,5}},
                       {shutdown,86400000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:12.397Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:54:12.397Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:54:12.397Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.185.0>,shutdown}}
[error_logger:info,2021-04-19T19:54:12.397Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:54:12.598Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:54:12.599Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.188.0>,shutdown}}
[ns_server:debug,2021-04-19T19:54:12.599Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:54:12.599Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:54:12.800Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:54:12.801Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:54:12.801Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.191.0>,shutdown}}
[error_logger:info,2021-04-19T19:54:12.802Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:54:13.002Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:54:13.003Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:54:13.003Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.194.0>,shutdown}}
[error_logger:info,2021-04-19T19:54:13.003Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:54:13.204Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:54:13.205Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.197.0>,shutdown}}
[ns_server:debug,2021-04-19T19:54:13.206Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:54:13.206Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:54:13.407Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:54:13.408Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.200.0>,shutdown}}
[ns_server:debug,2021-04-19T19:54:13.408Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:54:13.408Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:54:13.609Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:54:13.610Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.203.0>,shutdown}}
[ns_server:debug,2021-04-19T19:54:13.610Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:54:13.610Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:54:13.812Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:54:13.828Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.206.0>,shutdown}}
[ns_server:debug,2021-04-19T19:54:13.828Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:54:13.828Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:54:14.029Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:54:14.033Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:54:14.033Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.209.0>,shutdown}}
[error_logger:info,2021-04-19T19:54:14.033Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:54:14.234Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:54:14.235Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:54:14.235Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.212.0>,shutdown}}
[error_logger:info,2021-04-19T19:54:14.235Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:54:14.436Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:54:14.437Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:54:14.437Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.215.0>,shutdown}}
[error_logger:info,2021-04-19T19:54:14.437Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:54:14.638Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:54:14.639Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:54:14.639Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.218.0>,shutdown}}
[error_logger:info,2021-04-19T19:54:14.639Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:54:14.840Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:54:14.841Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:54:14.841Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.221.0>,shutdown}}
[error_logger:info,2021-04-19T19:54:14.841Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:54:15.042Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:54:15.043Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.224.0>,shutdown}}
[ns_server:debug,2021-04-19T19:54:15.043Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:54:15.043Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:54:15.244Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:54:15.245Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:54:15.245Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.227.0>,shutdown}}
[error_logger:info,2021-04-19T19:54:15.245Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:54:15.446Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:54:15.447Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T19:54:15.447Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.230.0>,shutdown}}
[error_logger:info,2021-04-19T19:54:15.447Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T19:54:15.648Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T19:54:15.701Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:54:15.902Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:54:16.104Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:54:16.305Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:54:16.516Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:54:16.728Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:54:16.929Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:54:17.135Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:54:17.336Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:54:17.538Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:54:17.742Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:54:17.943Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:54:18.146Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:54:18.347Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:54:18.552Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:54:18.754Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:54:18.956Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T19:54:19.159Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[error_logger:info,2021-04-19T19:54:19.769Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.253.0>},
                       {name,timer2_server},
                       {mfargs,{timer2,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:54:19.970Z,ns_1@127.0.0.1:ns_couchdb_port<0.181.0>:ns_port_server:log:210]ns_couchdb<0.181.0>: Apache CouchDB  (LogLevel=info) is starting.

[ns_server:info,2021-04-19T19:54:20.520Z,ns_1@127.0.0.1:ns_couchdb_port<0.181.0>:ns_port_server:log:210]ns_couchdb<0.181.0>: Apache CouchDB has started. Time to relax.

[error_logger:info,2021-04-19T19:54:20.535Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.182.0>},
                       {name,wait_for_couchdb_node},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<ns_server_nodes_sup.0.8580514>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:20.546Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.155.0>:ns_storage_conf:setup_db_and_ix_paths:53]Initialize db_and_ix_paths variable with [{db_path,
                                           "/opt/couchbase/var/lib/couchbase/data"},
                                          {index_path,
                                           "/opt/couchbase/var/lib/couchbase/data"}]
[error_logger:info,2021-04-19T19:54:20.564Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.256.0>},
                       {name,ns_disksup},
                       {mfargs,{ns_disksup,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:20.568Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.257.0>},
                       {name,diag_handler_worker},
                       {mfargs,{work_queue,start_link,[diag_handler_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:54:20.573Z,ns_1@127.0.0.1:ns_server_sup<0.255.0>:dir_size:start_link:39]Starting quick version of dir_size with program name: godu
[error_logger:info,2021-04-19T19:54:20.577Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.258.0>},
                       {name,dir_size},
                       {mfargs,{dir_size,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:20.603Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.259.0>},
                       {name,request_throttler},
                       {mfargs,{request_throttler,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:20.621Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.260.0>},
                       {name,ns_log},
                       {mfargs,{ns_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:20.636Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.261.0>},
                       {name,ns_crash_log_consumer},
                       {mfargs,{ns_log,start_link_crash_consumer,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:20.658Z,ns_1@127.0.0.1:ns_config_isasl_sync<0.262.0>:ns_config_isasl_sync:init:65]isasl_sync init: ["/opt/couchbase/var/lib/couchbase/isasl.pw","_admin"]
[ns_server:debug,2021-04-19T19:54:20.658Z,ns_1@127.0.0.1:ns_config_isasl_sync<0.262.0>:ns_config_isasl_sync:init:73]isasl_sync init buckets: []
[ns_server:debug,2021-04-19T19:54:20.661Z,ns_1@127.0.0.1:ns_config_isasl_sync<0.262.0>:ns_config_isasl_sync:writeSASLConf:145]Writing isasl passwd file: "/opt/couchbase/var/lib/couchbase/isasl.pw"
[ns_server:warn,2021-04-19T19:54:20.718Z,ns_1@127.0.0.1:ns_config_isasl_sync<0.262.0>:ns_memcached:connect:1307]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[ns_server:info,2021-04-19T19:54:20.736Z,ns_1@127.0.0.1:ns_couchdb_port<0.181.0>:ns_port_server:log:210]ns_couchdb<0.181.0>: 138: Booted. Waiting for shutdown request

[error_logger:info,2021-04-19T19:54:21.720Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.262.0>},
                       {name,ns_config_isasl_sync},
                       {mfargs,{ns_config_isasl_sync,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:21.720Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.264.0>},
                       {name,ns_log_events},
                       {mfargs,{gen_event,start_link,[{local,ns_log_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:21.724Z,ns_1@127.0.0.1:ns_node_disco<0.267.0>:ns_node_disco:init:138]Initting ns_node_disco with []
[ns_server:debug,2021-04-19T19:54:21.724Z,ns_1@127.0.0.1:ns_cookie_manager<0.141.0>:ns_cookie_manager:do_cookie_sync:115]ns_cookie_manager do_cookie_sync
[error_logger:info,2021-04-19T19:54:21.724Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.266.0>},
                       {name,ns_node_disco_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,ns_node_disco_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[user:info,2021-04-19T19:54:21.725Z,ns_1@127.0.0.1:ns_cookie_manager<0.141.0>:ns_cookie_manager:do_cookie_sync:134]Node 'ns_1@127.0.0.1' synchronized otp cookie {sanitized,
                                               <<"igGdfqmbza2bbcUGcHlgLfqDrDSw4MuqpdcFvTedqb0=">>} from cluster
[ns_server:debug,2021-04-19T19:54:21.725Z,ns_1@127.0.0.1:<0.268.0>:ns_node_disco:do_nodes_wanted_updated_fun:224]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"igGdfqmbza2bbcUGcHlgLfqDrDSw4MuqpdcFvTedqb0=">>}
[ns_server:debug,2021-04-19T19:54:21.729Z,ns_1@127.0.0.1:<0.268.0>:ns_node_disco:do_nodes_wanted_updated_fun:230]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"igGdfqmbza2bbcUGcHlgLfqDrDSw4MuqpdcFvTedqb0=">>}
[error_logger:info,2021-04-19T19:54:21.730Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.267.0>},
                       {name,ns_node_disco},
                       {mfargs,{ns_node_disco,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:21.735Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.269.0>},
                       {name,ns_node_disco_log},
                       {mfargs,{ns_node_disco_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:21.740Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.270.0>},
                       {name,ns_node_disco_conf_events},
                       {mfargs,{ns_node_disco_conf_events,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:21.747Z,ns_1@127.0.0.1:ns_config_rep<0.272.0>:ns_config_rep:init:68]init pulling
[ns_server:debug,2021-04-19T19:54:21.747Z,ns_1@127.0.0.1:ns_config_rep<0.272.0>:ns_config_rep:init:70]init pushing
[error_logger:info,2021-04-19T19:54:21.747Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.271.0>},
                       {name,ns_config_rep_merger},
                       {mfargs,{ns_config_rep,start_link_merger,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:21.750Z,ns_1@127.0.0.1:ns_config_rep<0.272.0>:ns_config_rep:init:74]init reannouncing
[ns_server:debug,2021-04-19T19:54:21.751Z,ns_1@127.0.0.1:ns_config_events<0.144.0>:ns_node_disco_conf_events:handle_event:44]ns_node_disco_conf_events config on nodes_wanted
[ns_server:debug,2021-04-19T19:54:21.751Z,ns_1@127.0.0.1:ns_config_events<0.144.0>:ns_node_disco_conf_events:handle_event:50]ns_node_disco_conf_events config on otp
[ns_server:debug,2021-04-19T19:54:21.751Z,ns_1@127.0.0.1:ns_cookie_manager<0.141.0>:ns_cookie_manager:do_cookie_sync:115]ns_cookie_manager do_cookie_sync
[ns_server:debug,2021-04-19T19:54:21.751Z,ns_1@127.0.0.1:ns_cookie_manager<0.141.0>:ns_cookie_manager:do_cookie_sync:115]ns_cookie_manager do_cookie_sync
[ns_server:debug,2021-04-19T19:54:21.751Z,ns_1@127.0.0.1:<0.276.0>:ns_node_disco:do_nodes_wanted_updated_fun:224]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"igGdfqmbza2bbcUGcHlgLfqDrDSw4MuqpdcFvTedqb0=">>}
[ns_server:debug,2021-04-19T19:54:21.751Z,ns_1@127.0.0.1:<0.277.0>:ns_node_disco:do_nodes_wanted_updated_fun:224]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"igGdfqmbza2bbcUGcHlgLfqDrDSw4MuqpdcFvTedqb0=">>}
[ns_server:debug,2021-04-19T19:54:21.752Z,ns_1@127.0.0.1:<0.276.0>:ns_node_disco:do_nodes_wanted_updated_fun:230]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"igGdfqmbza2bbcUGcHlgLfqDrDSw4MuqpdcFvTedqb0=">>}
[ns_server:debug,2021-04-19T19:54:21.752Z,ns_1@127.0.0.1:<0.277.0>:ns_node_disco:do_nodes_wanted_updated_fun:230]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"igGdfqmbza2bbcUGcHlgLfqDrDSw4MuqpdcFvTedqb0=">>}
[ns_server:debug,2021-04-19T19:54:21.752Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
alert_limits ->
[{max_overhead_perc,50},{max_disk_used,90},{max_indexer_ram,75}]
[ns_server:debug,2021-04-19T19:54:21.752Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
audit ->
[{auditd_enabled,false},
 {rotate_interval,86400},
 {rotate_size,20971520},
 {disabled,[]},
 {sync,[]},
 {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]
[ns_server:debug,2021-04-19T19:54:21.753Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
auto_failover_cfg ->
[{enabled,false},{timeout,120},{max_nodes,1},{count,0}]
[ns_server:debug,2021-04-19T19:54:21.753Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
autocompaction ->
[{database_fragmentation_threshold,{30,undefined}},
 {view_fragmentation_threshold,{30,undefined}}]
[ns_server:debug,2021-04-19T19:54:21.753Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
buckets ->
[[],{configs,[]}]
[ns_server:debug,2021-04-19T19:54:21.753Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
cert_and_pkey ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080742}}]}|
 {<<"-----BEGIN CERTIFICATE-----\nMIIDAjCCAeqgAwIBAgIIFndZ/vr3iFgwDQYJKoZIhvcNAQELBQAwJDEiMCAGA1UE\nAxMZQ291Y2hiYXNlIFNlcnZlciBiODgwZTU4MjAeFw0xMzAxMDEwMDAwMDBaFw00\nOTEyMzEyMzU5NTlaMCQxIjAgBgNVBAMTGUNvdWNoYmFzZSBTZXJ2ZXIgYjg4MGU1\nODIwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDPKYjrGZUDKn7xXZhz\n/CcGig/KlI7xzgbLixQnJ5VLNHQOaIcz01bkH2SuTUnIg3i9awTEc/vdraqbL7dK\neAQZEWpnUrZo8sPI/sI9nYnAJttUCQD"...>>,
  <<"*****">>}]
[ns_server:debug,2021-04-19T19:54:21.754Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
cluster_compat_version ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{6,63786080749}}]},4,6]
[ns_server:debug,2021-04-19T19:54:21.754Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
drop_request_memory_threshold_mib ->
undefined
[ns_server:debug,2021-04-19T19:54:21.754Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
email_alerts ->
[{recipients,["root@localhost"]},
 {sender,"couchbase@localhost"},
 {enabled,false},
 {email_server,[{user,[]},
                {pass,"*****"},
                {host,"localhost"},
                {port,25},
                {encrypt,false}]},
 {alerts,[auto_failover_node,auto_failover_maximum_reached,
          auto_failover_other_nodes_down,auto_failover_cluster_too_small,
          auto_failover_disabled,ip,disk,overhead,ep_oom_errors,
          ep_item_commit_failed,audit_dropped_events,indexer_ram_max_usage,
          ep_clock_cas_drift_threshold_exceeded]}]
[ns_server:debug,2021-04-19T19:54:21.754Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
fts_memory_quota ->
512
[ns_server:debug,2021-04-19T19:54:21.754Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
goxdcr_upgrade ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080749}}]}|
 '_deleted']
[ns_server:debug,2021-04-19T19:54:21.754Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
index_aware_rebalance_disabled ->
false
[ns_server:debug,2021-04-19T19:54:21.754Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
max_bucket_count ->
10
[ns_server:debug,2021-04-19T19:54:21.754Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
memcached ->
[]
[ns_server:debug,2021-04-19T19:54:21.755Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
memory_quota ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080757}}]}|300]
[ns_server:debug,2021-04-19T19:54:21.755Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
nodes_wanted ->
['ns_1@127.0.0.1']
[ns_server:debug,2021-04-19T19:54:21.755Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
otp ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080748}}]},
 {cookie,{sanitized,<<"igGdfqmbza2bbcUGcHlgLfqDrDSw4MuqpdcFvTedqb0=">>}}]
[ns_server:debug,2021-04-19T19:54:21.755Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
read_only_user_creds ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080749}}]}|null]
[ns_server:debug,2021-04-19T19:54:21.756Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
remote_clusters ->
[]
[ns_server:debug,2021-04-19T19:54:21.756Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
replication ->
[{enabled,true}]
[ns_server:debug,2021-04-19T19:54:21.756Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
rest ->
[{port,8091}]
[ns_server:debug,2021-04-19T19:54:21.756Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
rest_creds ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{2,63786080757}}]}|
 {"Administrator",{password,"*****"}}]
[ns_server:debug,2021-04-19T19:54:21.757Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
roles_definitions ->
[{admin,[],
        [{name,<<"Admin">>},
         {desc,<<"Can manage ALL cluster features including security.">>}],
        [{[],all}]},
 {ro_admin,[],
           [{name,<<"Read Only Admin">>},
            {desc,<<"Can view ALL cluster features.">>}],
           [{[{bucket,any},password],none},
            {[{bucket,any},data],none},
            {[admin,security],[read]},
            {[admin],none},
            {[],[read]}]},
 {cluster_admin,[],
                [{name,<<"Cluster Admin">>},
                 {desc,<<"Can manage all cluster features EXCEPT security.">>}],
                [{[admin],none},{[],all}]},
 {bucket_admin,[bucket_name],
               [{name,<<"Bucket Admin">>},
                {desc,<<"Can manage ALL bucket features for specified buckets (incl. start/stop XDCR)">>}],
               [{[{bucket,bucket_name},xdcr],[read,execute]},
                {[{bucket,bucket_name}],all},
                {[{bucket,any},settings],[read]},
                {[{bucket,any}],none},
                {[xdcr],none},
                {[admin],none},
                {[],[read]}]},
 {bucket_sasl,[bucket_name],
              [],
              [{[{bucket,bucket_name},data],all},
               {[{bucket,bucket_name},views],all},
               {[{bucket,bucket_name}],[read,flush]},
               {[pools],[read]}]},
 {views_admin,[bucket_name],
              [{name,<<"Views Admin">>},
               {desc,<<"Can manage views for specified buckets">>}],
              [{[{bucket,bucket_name},views],all},
               {[{bucket,bucket_name},data],[read]},
               {[{bucket,any},settings],[read]},
               {[{bucket,any}],none},
               {[xdcr],none},
               {[admin],none},
               {[],[read]}]},
 {replication_admin,[],
                    [{name,<<"Replication Admin">>},
                     {desc,<<"Can manage ONLY XDCR features (cluster AND bucket level)">>}],
                    [{[{bucket,any},xdcr],all},
                     {[{bucket,any},data],[read]},
                     {[{bucket,any},settings],[read]},
                     {[{bucket,any}],none},
                     {[xdcr],all},
                     {[admin],none},
                     {[],[read]}]}]
[ns_server:debug,2021-04-19T19:54:21.758Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
server_groups ->
[[{uuid,<<"0">>},{name,<<"Group 1">>},{nodes,['ns_1@127.0.0.1']}]]
[ns_server:debug,2021-04-19T19:54:21.758Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
set_view_update_daemon ->
[{update_interval,5000},
 {update_min_changes,5000},
 {replica_update_min_changes,5000}]
[ns_server:debug,2021-04-19T19:54:21.758Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
uuid ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080757}}]}|
 <<"819b5f49755d4c5571ba2861d6185103">>]
[ns_server:debug,2021-04-19T19:54:21.758Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{couchdb,max_parallel_indexers} ->
4
[ns_server:debug,2021-04-19T19:54:21.758Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{couchdb,max_parallel_replica_indexers} ->
2
[ns_server:debug,2021-04-19T19:54:21.758Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{local_changes_count,<<"360fb3d3641e00b1f4f22714c24e2a2a">>} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{13,63786081158}}]}]
[error_logger:info,2021-04-19T19:54:21.758Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.272.0>},
                       {name,ns_config_rep},
                       {mfargs,{ns_config_rep,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:21.759Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{metakv,<<"/indexing/settings/config">>} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{5,63786081158}}]}|
 <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.log_level\":\"info\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\""...>>]
[error_logger:info,2021-04-19T19:54:21.759Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.265.0>},
                       {name,ns_node_disco_sup},
                       {mfargs,{ns_node_disco_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2021-04-19T19:54:21.759Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{request_limit,capi} ->
undefined
[ns_server:debug,2021-04-19T19:54:21.759Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{request_limit,rest} ->
undefined
[ns_server:debug,2021-04-19T19:54:21.758Z,ns_1@127.0.0.1:ns_config_rep<0.272.0>:ns_config_rep:do_push_keys:321]Replicating some config keys ([alert_limits,audit,auto_failover_cfg,
                               autocompaction,buckets,cert_and_pkey,
                               cluster_compat_version,
                               drop_request_memory_threshold_mib,email_alerts,
                               fts_memory_quota,goxdcr_upgrade,
                               index_aware_rebalance_disabled,
                               max_bucket_count,memcached,memory_quota,
                               nodes_wanted,otp,read_only_user_creds,
                               remote_clusters,replication,rest,rest_creds,
                               roles_definitions,server_groups,
                               set_view_update_daemon,uuid,
                               {couchdb,max_parallel_indexers},
                               {couchdb,max_parallel_replica_indexers},
                               {local_changes_count,
                                   <<"360fb3d3641e00b1f4f22714c24e2a2a">>},
                               {metakv,<<"/indexing/settings/config">>},
                               {request_limit,capi},
                               {request_limit,rest},
                               {service_map,fts},
                               {service_map,index},
                               {service_map,n1ql},
                               {node,'ns_1@127.0.0.1',audit},
                               {node,'ns_1@127.0.0.1',capi_port},
                               {node,'ns_1@127.0.0.1',compaction_daemon},
                               {node,'ns_1@127.0.0.1',config_version},
                               {node,'ns_1@127.0.0.1',fts_http_port},
                               {node,'ns_1@127.0.0.1',indexer_admin_port},
                               {node,'ns_1@127.0.0.1',indexer_http_port},
                               {node,'ns_1@127.0.0.1',indexer_scan_port},
                               {node,'ns_1@127.0.0.1',indexer_stcatchup_port},
                               {node,'ns_1@127.0.0.1',indexer_stinit_port},
                               {node,'ns_1@127.0.0.1',indexer_stmaint_port},
                               {node,'ns_1@127.0.0.1',is_enterprise},
                               {node,'ns_1@127.0.0.1',isasl},
                               {node,'ns_1@127.0.0.1',ldap_enabled},
                               {node,'ns_1@127.0.0.1',membership},
                               {node,'ns_1@127.0.0.1',memcached},
                               {node,'ns_1@127.0.0.1',memcached_config},
                               {node,'ns_1@127.0.0.1',memcached_defaults},
                               {node,'ns_1@127.0.0.1',moxi},
                               {node,'ns_1@127.0.0.1',ns_log},
                               {node,'ns_1@127.0.0.1',port_servers},
                               {node,'ns_1@127.0.0.1',projector_port},
                               {node,'ns_1@127.0.0.1',query_port},
                               {node,'ns_1@127.0.0.1',rest},
                               {node,'ns_1@127.0.0.1',services},
                               {node,'ns_1@127.0.0.1',ssl_capi_port},
                               {node,'ns_1@127.0.0.1',
                                   ssl_proxy_downstream_port},
                               {node,'ns_1@127.0.0.1',ssl_proxy_upstream_port},
                               {node,'ns_1@127.0.0.1',ssl_query_port}]..)
[ns_server:debug,2021-04-19T19:54:21.759Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{service_map,fts} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080749}}]}]
[ns_server:debug,2021-04-19T19:54:21.759Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{service_map,index} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{2,63786080759}}]},
 'ns_1@127.0.0.1']
[ns_server:debug,2021-04-19T19:54:21.760Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{service_map,n1ql} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{2,63786080759}}]},
 'ns_1@127.0.0.1']
[ns_server:debug,2021-04-19T19:54:21.760Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',audit} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}]
[ns_server:debug,2021-04-19T19:54:21.760Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',capi_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|8092]
[ns_server:debug,2021-04-19T19:54:21.760Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',compaction_daemon} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
 {check_interval,30},
 {min_db_file_size,131072},
 {min_view_file_size,20971520}]
[ns_server:debug,2021-04-19T19:54:21.761Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',config_version} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|{4,5}]
[ns_server:debug,2021-04-19T19:54:21.761Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',fts_http_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|8094]
[ns_server:debug,2021-04-19T19:54:21.761Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',indexer_admin_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|9100]
[ns_server:debug,2021-04-19T19:54:21.761Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',indexer_http_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|9102]
[ns_server:debug,2021-04-19T19:54:21.761Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',indexer_scan_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|9101]
[ns_server:debug,2021-04-19T19:54:21.761Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',indexer_stcatchup_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|9104]
[ns_server:debug,2021-04-19T19:54:21.762Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',indexer_stinit_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|9103]
[ns_server:debug,2021-04-19T19:54:21.762Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',indexer_stmaint_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|9105]
[ns_server:debug,2021-04-19T19:54:21.762Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',is_enterprise} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|true]
[ns_server:debug,2021-04-19T19:54:21.762Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',isasl} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
 {path,"/opt/couchbase/var/lib/couchbase/isasl.pw"}]
[ns_server:debug,2021-04-19T19:54:21.762Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ldap_enabled} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|true]
[ns_server:debug,2021-04-19T19:54:21.763Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',membership} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
 active]
[ns_server:debug,2021-04-19T19:54:21.764Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',memcached} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
 {port,11210},
 {dedicated_port,11209},
 {ssl_port,11207},
 {admin_user,"_admin"},
 {admin_pass,"*****"},
 {engines,[{membase,[{engine,"/opt/couchbase/lib/memcached/ep.so"},
                     {static_config_string,"failpartialwarmup=false"}]},
           {memcached,[{engine,"/opt/couchbase/lib/memcached/default_engine.so"},
                       {static_config_string,"vb0=true"}]}]},
 {config_path,"/opt/couchbase/var/lib/couchbase/config/memcached.json"},
 {audit_file,"/opt/couchbase/var/lib/couchbase/config/audit.json"},
 {log_path,"/opt/couchbase/var/lib/couchbase/logs"},
 {log_prefix,"memcached.log"},
 {log_generations,20},
 {log_cyclesize,10485760},
 {log_sleeptime,19},
 {log_rotation_period,39003}]
[error_logger:info,2021-04-19T19:54:21.764Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.280.0>},
                       {name,vbucket_map_mirror},
                       {mfargs,{vbucket_map_mirror,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:21.765Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',memcached_config} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
 {[{interfaces,
    {memcached_config_mgr,omit_missing_mcd_ports,
     [{[{host,<<"*">>},{port,port},{maxconn,maxconn}]},
      {[{host,<<"*">>},
        {port,dedicated_port},
        {maxconn,dedicated_port_maxconn}]},
      {[{host,<<"*">>},
        {port,ssl_port},
        {maxconn,maxconn},
        {ssl,
         {[{key,
            <<"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem">>},
           {cert,
            <<"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem">>}]}}]}]}},
   {ssl_cipher_list,{"~s",[ssl_cipher_list]}},
   {ssl_minimum_protocol,{memcached_config_mgr,ssl_minimum_protocol,[]}},
   {connection_idle_time,connection_idle_time},
   {breakpad,
    {[{enabled,breakpad_enabled},
      {minidump_dir,{memcached_config_mgr,get_minidump_dir,[]}}]}},
   {extensions,
    [{[{module,<<"/opt/couchbase/lib/memcached/stdin_term_handler.so">>},
       {config,<<>>}]},
     {[{module,<<"/opt/couchbase/lib/memcached/file_logger.so">>},
       {config,
        {"cyclesize=~B;sleeptime=~B;filename=~s/~s",
         [log_cyclesize,log_sleeptime,log_path,log_prefix]}}]}]},
   {admin,{"~s",[admin_user]}},
   {verbosity,verbosity},
   {audit_file,{"~s",[audit_file]}},
   {dedupe_nmvb_maps,dedupe_nmvb_maps}]}]
[ns_server:debug,2021-04-19T19:54:21.765Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',memcached_defaults} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
 {maxconn,30000},
 {dedicated_port_maxconn,5000},
 {ssl_cipher_list,"HIGH"},
 {connection_idle_time,0},
 {verbosity,0},
 {breakpad_enabled,true},
 {breakpad_minidump_dir_path,"/opt/couchbase/var/lib/couchbase/crash"},
 {dedupe_nmvb_maps,false}]
[ns_server:debug,2021-04-19T19:54:21.766Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',moxi} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
 {port,11211},
 {verbosity,[]}]
[ns_server:debug,2021-04-19T19:54:21.766Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ns_log} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
 {filename,"/opt/couchbase/var/lib/couchbase/ns_log"}]
[ns_server:debug,2021-04-19T19:54:21.766Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',port_servers} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}]
[ns_server:debug,2021-04-19T19:54:21.767Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',projector_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|9999]
[ns_server:debug,2021-04-19T19:54:21.767Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',query_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|8093]
[ns_server:debug,2021-04-19T19:54:21.767Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',rest} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
 {port,8091},
 {port_meta,global}]
[ns_server:debug,2021-04-19T19:54:21.767Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',services} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080757}}]},
 index,kv,n1ql]
[ns_server:debug,2021-04-19T19:54:21.767Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ssl_capi_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|18092]
[ns_server:debug,2021-04-19T19:54:21.768Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ssl_proxy_downstream_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|11214]
[ns_server:debug,2021-04-19T19:54:21.768Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ssl_proxy_upstream_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|11215]
[ns_server:debug,2021-04-19T19:54:21.768Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ssl_query_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|18093]
[ns_server:debug,2021-04-19T19:54:21.768Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ssl_rest_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|18091]
[ns_server:debug,2021-04-19T19:54:21.768Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',stop_xdcr} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{2,63786080749}}]}|
 '_deleted']
[ns_server:debug,2021-04-19T19:54:21.769Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',uuid} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
 <<"360fb3d3641e00b1f4f22714c24e2a2a">>]
[ns_server:debug,2021-04-19T19:54:21.769Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',xdcr_rest_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|9998]
[error_logger:info,2021-04-19T19:54:21.770Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.282.0>},
                       {name,bucket_info_cache},
                       {mfargs,{bucket_info_cache,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:21.771Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.285.0>},
                       {name,ns_tick_event},
                       {mfargs,{gen_event,start_link,[{local,ns_tick_event}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:21.771Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.286.0>},
                       {name,buckets_events},
                       {mfargs,
                           {gen_event,start_link,[{local,buckets_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:21.788Z,ns_1@127.0.0.1:ns_log_events<0.264.0>:ns_mail_log:init:44]ns_mail_log started up
[error_logger:info,2021-04-19T19:54:21.788Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_mail_sup}
             started: [{pid,<0.288.0>},
                       {name,ns_mail_log},
                       {mfargs,{ns_mail_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:21.788Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.287.0>},
                       {name,ns_mail_sup},
                       {mfargs,{ns_mail_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:54:21.789Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.289.0>},
                       {name,ns_stats_event},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_stats_event}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:21.793Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.290.0>},
                       {name,samples_loader_tasks},
                       {mfargs,{samples_loader_tasks,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:21.806Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_heart_sup}
             started: [{pid,<0.292.0>},
                       {name,ns_heart},
                       {mfargs,{ns_heart,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:21.806Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_heart_sup}
             started: [{pid,<0.295.0>},
                       {name,ns_heart_slow_updater},
                       {mfargs,{ns_heart,start_link_slow_updater,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:21.807Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.291.0>},
                       {name,ns_heart_sup},
                       {mfargs,{ns_heart_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2021-04-19T19:54:21.811Z,ns_1@127.0.0.1:ns_heart<0.292.0>:ns_heart:grab_latest_stats:259]Ignoring failure to grab "@system" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,117}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,255}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,249}]},
                 {ns_heart,update_current_status,1,
                           [{file,"src/ns_heart.erl"},{line,186}]},
                 {ns_heart,handle_info,2,
                           [{file,"src/ns_heart.erl"},{line,118}]}]}}

[ns_server:debug,2021-04-19T19:54:21.812Z,ns_1@127.0.0.1:ns_heart<0.292.0>:ns_heart:grab_latest_stats:259]Ignoring failure to grab "@system-processes" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-processes-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,117}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,255}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,249}]},
                 {ns_heart,update_current_status,1,
                           [{file,"src/ns_heart.erl"},{line,186}]}]}}

[error_logger:info,2021-04-19T19:54:21.815Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_doctor_sup}
             started: [{pid,<0.298.0>},
                       {name,ns_doctor_events},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_doctor_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:21.831Z,ns_1@127.0.0.1:<0.296.0>:restartable:start_child:98]Started child process <0.297.0>
  MFA: {ns_doctor_sup,start_link,[]}
[error_logger:info,2021-04-19T19:54:21.831Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_doctor_sup}
             started: [{pid,<0.299.0>},
                       {name,ns_doctor},
                       {mfargs,{ns_doctor,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:21.832Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.296.0>},
                       {name,ns_doctor_sup},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_doctor_sup,start_link,[]},infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2021-04-19T19:54:21.869Z,ns_1@127.0.0.1:ns_heart<0.292.0>:ns_heart:grab_index_status:373]ignoring failure to get index status: {exit,
                                       {noproc,
                                        {gen_server,call,
                                         ['index_status_keeper-index',
                                          get_status,2000]}}}
[{gen_server,call,3,[{file,"gen_server.erl"},{line,188}]},
 {ns_heart,grab_index_status,0,[{file,"src/ns_heart.erl"},{line,370}]},
 {ns_heart,current_status_slow_inner,0,[{file,"src/ns_heart.erl"},{line,280}]},
 {ns_heart,current_status_slow,1,[{file,"src/ns_heart.erl"},{line,249}]},
 {ns_heart,update_current_status,1,[{file,"src/ns_heart.erl"},{line,186}]},
 {ns_heart,handle_info,2,[{file,"src/ns_heart.erl"},{line,118}]},
 {gen_server,handle_msg,5,[{file,"gen_server.erl"},{line,604}]},
 {proc_lib,init_p_do_apply,3,[{file,"proc_lib.erl"},{line,239}]}]
[error_logger:info,2021-04-19T19:54:21.878Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.304.0>},
                       {name,disk_log_sup},
                       {mfargs,{disk_log_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:54:21.878Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.305.0>},
                       {name,disk_log_server},
                       {mfargs,{disk_log_server,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:21.894Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.302.0>},
                       {name,remote_clusters_info},
                       {mfargs,{remote_clusters_info,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:21.894Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.308.0>},
                       {name,master_activity_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,master_activity_events}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:21.899Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.309.0>},
                       {name,xdcr_ckpt_store},
                       {mfargs,{simple_store,start_link,[xdcr_ckpt_data]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:21.899Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.310.0>},
                       {name,metakv_worker},
                       {mfargs,{work_queue,start_link,[metakv_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:21.899Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.311.0>},
                       {name,index_events},
                       {mfargs,{gen_event,start_link,[{local,index_events}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:21.907Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.312.0>},
                       {name,index_settings_manager},
                       {mfargs,{index_settings_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:21.914Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.316.0>},
                       {name,menelaus_ui_auth},
                       {mfargs,{menelaus_ui_auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:21.924Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.318.0>},
                       {name,menelaus_local_auth},
                       {mfargs,{menelaus_local_auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:21.931Z,ns_1@127.0.0.1:ns_heart<0.292.0>:goxdcr_rest:get_from_goxdcr:163]Goxdcr is temporary not available. Return empty list.
[error_logger:info,2021-04-19T19:54:21.938Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.319.0>},
                       {name,menelaus_web_cache},
                       {mfargs,{menelaus_web_cache,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:21.945Z,ns_1@127.0.0.1:ns_heart<0.292.0>:cluster_logs_collection_task:maybe_build_cluster_logs_task:43]Ignoring exception trying to read cluster_logs_collection_task_status table: error:badarg
[error_logger:info,2021-04-19T19:54:21.949Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.321.0>},
                       {name,menelaus_stats_gatherer},
                       {mfargs,{menelaus_stats_gatherer,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:21.950Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.322.0>},
                       {name,json_rpc_events},
                       {mfargs,
                           {gen_event,start_link,[{local,json_rpc_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:54:21.952Z,ns_1@127.0.0.1:menelaus_sup<0.314.0>:menelaus_pluggable_ui:validate_plugin_spec:117]Loaded pluggable UI specification for fts

[ns_server:info,2021-04-19T19:54:21.953Z,ns_1@127.0.0.1:menelaus_sup<0.314.0>:menelaus_pluggable_ui:validate_plugin_spec:117]Loaded pluggable UI specification for n1ql

[error_logger:info,2021-04-19T19:54:21.954Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.323.0>},
                       {name,menelaus_web},
                       {mfargs,{menelaus_web,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:21.957Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.340.0>},
                       {name,menelaus_event},
                       {mfargs,{menelaus_event,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:21.960Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.341.0>},
                       {name,hot_keys_keeper},
                       {mfargs,{hot_keys_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:21.966Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.295.0>:ns_heart:grab_latest_stats:259]Ignoring failure to grab "@system" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,117}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,255}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,249}]},
                 {ns_heart,slow_updater_loop,0,
                           [{file,"src/ns_heart.erl"},{line,243}]},
                 {proc_lib,init_p_do_apply,3,
                           [{file,"proc_lib.erl"},{line,239}]}]}}

[ns_server:debug,2021-04-19T19:54:21.967Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.295.0>:ns_heart:grab_latest_stats:259]Ignoring failure to grab "@system-processes" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-processes-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,117}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,255}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,249}]},
                 {ns_heart,slow_updater_loop,0,
                           [{file,"src/ns_heart.erl"},{line,243}]}]}}

[ns_server:debug,2021-04-19T19:54:21.967Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.295.0>:ns_heart:grab_index_status:373]ignoring failure to get index status: {exit,
                                       {noproc,
                                        {gen_server,call,
                                         ['index_status_keeper-index',
                                          get_status,2000]}}}
[{gen_server,call,3,[{file,"gen_server.erl"},{line,188}]},
 {ns_heart,grab_index_status,0,[{file,"src/ns_heart.erl"},{line,370}]},
 {ns_heart,current_status_slow_inner,0,[{file,"src/ns_heart.erl"},{line,280}]},
 {ns_heart,current_status_slow,1,[{file,"src/ns_heart.erl"},{line,249}]},
 {ns_heart,slow_updater_loop,0,[{file,"src/ns_heart.erl"},{line,243}]},
 {proc_lib,init_p_do_apply,3,[{file,"proc_lib.erl"},{line,239}]}]
[ns_server:debug,2021-04-19T19:54:21.968Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.295.0>:goxdcr_rest:get_from_goxdcr:163]Goxdcr is temporary not available. Return empty list.
[ns_server:debug,2021-04-19T19:54:21.968Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.295.0>:cluster_logs_collection_task:maybe_build_cluster_logs_task:43]Ignoring exception trying to read cluster_logs_collection_task_status table: error:badarg
[error_logger:info,2021-04-19T19:54:21.969Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.348.0>},
                       {name,menelaus_web_alerts_srv},
                       {mfargs,{menelaus_web_alerts_srv,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:21.973Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.349.0>},
                       {name,menelaus_cbauth},
                       {mfargs,{menelaus_cbauth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[user:info,2021-04-19T19:54:21.974Z,ns_1@127.0.0.1:ns_server_sup<0.255.0>:menelaus_sup:start_link:46]Couchbase Server has started on web port 8091 on node 'ns_1@127.0.0.1'. Version: "4.6.0-3573-enterprise".
[error_logger:info,2021-04-19T19:54:21.974Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.314.0>},
                       {name,menelaus},
                       {mfargs,{menelaus_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:54:21.974Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.353.0>},
                       {name,ns_ports_setup},
                       {mfargs,{ns_ports_setup,start,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:21.978Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_agent_sup}
             started: [{pid,<0.356.0>},
                       {name,service_agent_children_sup},
                       {mfargs,
                           {supervisor,start_link,
                               [{local,service_agent_children_sup},
                                service_agent_sup,child]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:54:21.978Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_agent_sup}
             started: [{pid,<0.357.0>},
                       {name,service_agent_worker},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<service_agent_sup.0.29791682>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:21.979Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.355.0>},
                       {name,service_agent_sup},
                       {mfargs,{service_agent_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:54:22.002Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.359.0>},
                       {name,ns_memcached_sockets_pool},
                       {mfargs,{ns_memcached_sockets_pool,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:22.002Z,ns_1@127.0.0.1:ns_audit_cfg<0.360.0>:ns_audit_cfg:write_audit_json:158]Writing new content to "/opt/couchbase/var/lib/couchbase/config/audit.json" : [{auditd_enabled,
                                                                                false},
                                                                               {disabled,
                                                                                []},
                                                                               {log_path,
                                                                                "/opt/couchbase/var/lib/couchbase/logs"},
                                                                               {rotate_interval,
                                                                                86400},
                                                                               {rotate_size,
                                                                                20971520},
                                                                               {sync,
                                                                                []},
                                                                               {version,
                                                                                1},
                                                                               {descriptors_path,
                                                                                "/opt/couchbase/etc/security"}]
[ns_server:debug,2021-04-19T19:54:22.012Z,ns_1@127.0.0.1:ns_ports_setup<0.353.0>:ns_ports_manager:set_dynamic_children:54]Setting children [memcached,moxi,projector,indexer,query,saslauthd_port,
                  goxdcr,xdcr_proxy]
[ns_server:debug,2021-04-19T19:54:22.021Z,ns_1@127.0.0.1:ns_audit_cfg<0.360.0>:ns_audit_cfg:handle_info:107]Instruct memcached to reload audit config
[error_logger:info,2021-04-19T19:54:22.021Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.360.0>},
                       {name,ns_audit_cfg},
                       {mfargs,{ns_audit_cfg,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:warn,2021-04-19T19:54:22.022Z,ns_1@127.0.0.1:<0.362.0>:ns_memcached:connect:1307]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[ns_server:debug,2021-04-19T19:54:22.026Z,ns_1@127.0.0.1:memcached_config_mgr<0.364.0>:memcached_config_mgr:init:44]waiting for completion of initial ns_ports_setup round
[error_logger:info,2021-04-19T19:54:22.026Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.364.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:54:22.030Z,ns_1@127.0.0.1:<0.365.0>:ns_memcached_log_rotator:init:28]Starting log rotator on "/opt/couchbase/var/lib/couchbase/logs"/"memcached.log"* with an initial period of 39003ms
[error_logger:info,2021-04-19T19:54:22.030Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.365.0>},
                       {name,ns_memcached_log_rotator},
                       {mfargs,{ns_memcached_log_rotator,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T19:54:22.034Z,ns_1@127.0.0.1:ns_couchdb_port<0.181.0>:ns_port_server:log:210]ns_couchdb<0.181.0>: working as port

[error_logger:info,2021-04-19T19:54:22.034Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.366.0>},
                       {name,memcached_clients_pool},
                       {mfargs,{memcached_clients_pool,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:22.037Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.367.0>},
                       {name,proxied_memcached_clients_pool},
                       {mfargs,{proxied_memcached_clients_pool,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:22.038Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.368.0>},
                       {name,xdc_lhttpc_pool},
                       {mfargs,
                           {lhttpc_manager,start_link,
                               [[{name,xdc_lhttpc_pool},
                                 {connection_timeout,120000},
                                 {pool_size,200}]]}},
                       {restart_type,{permanent,1}},
                       {shutdown,10000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:22.042Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.369.0>},
                       {name,ns_null_connection_pool},
                       {mfargs,
                           {ns_null_connection_pool,start_link,
                               [ns_null_connection_pool]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:22.050Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {<0.370.0>,xdcr_sup}
             started: [{pid,<0.371.0>},
                       {name,xdc_stats_holder},
                       {mfargs,
                           {proc_lib,start_link,
                               [xdcr_sup,link_stats_holder_body,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:22.053Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {<0.370.0>,xdcr_sup}
             started: [{pid,<0.372.0>},
                       {name,xdc_replication_sup},
                       {mfargs,{xdc_replication_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2021-04-19T19:54:22.058Z,ns_1@127.0.0.1:xdc_rep_manager<0.373.0>:ns_couchdb_api:wait_for_doc_manager:298]Start waiting for doc manager
[error_logger:info,2021-04-19T19:54:22.058Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {<0.370.0>,xdcr_sup}
             started: [{pid,<0.373.0>},
                       {name,xdc_rep_manager},
                       {mfargs,{xdc_rep_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,30000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:22.065Z,ns_1@127.0.0.1:xdcr_doc_replicator<0.375.0>:ns_couchdb_api:wait_for_doc_manager:298]Start waiting for doc manager
[ns_server:debug,2021-04-19T19:54:22.066Z,ns_1@127.0.0.1:xdc_rdoc_replication_srv<0.376.0>:ns_couchdb_api:wait_for_doc_manager:298]Start waiting for doc manager
[error_logger:info,2021-04-19T19:54:22.066Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {<0.370.0>,xdcr_sup}
             started: [{pid,<0.375.0>},
                       {name,xdc_rdoc_replicator},
                       {mfargs,{doc_replicator,start_link_xdcr,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:22.066Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {<0.370.0>,xdcr_sup}
             started: [{pid,<0.376.0>},
                       {name,xdc_rdoc_replication_srv},
                       {mfargs,{doc_replication_srv,start_link_xdcr,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:22.069Z,ns_1@127.0.0.1:<0.370.0>:xdc_rdoc_manager:start_link_remote:42]Starting xdc_rdoc_manager on 'couchdb_ns_1@127.0.0.1' with following links: [<0.375.0>,
                                                                             <0.376.0>,
                                                                             <0.373.0>]
[ns_server:debug,2021-04-19T19:54:22.075Z,ns_1@127.0.0.1:xdc_rdoc_replication_srv<0.376.0>:ns_couchdb_api:wait_for_doc_manager:301]Received doc manager registration from <11633.259.0>
[ns_server:debug,2021-04-19T19:54:22.075Z,ns_1@127.0.0.1:xdcr_doc_replicator<0.375.0>:ns_couchdb_api:wait_for_doc_manager:301]Received doc manager registration from <11633.259.0>
[ns_server:debug,2021-04-19T19:54:22.075Z,ns_1@127.0.0.1:xdc_rep_manager<0.373.0>:ns_couchdb_api:wait_for_doc_manager:301]Received doc manager registration from <11633.259.0>
[error_logger:info,2021-04-19T19:54:22.075Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {<0.370.0>,xdcr_sup}
             started: [{pid,<11633.259.0>},
                       {name,xdc_rdoc_manager},
                       {mfargs,
                           {xdc_rdoc_manager,start_link_remote,
                               ['couchdb_ns_1@127.0.0.1']}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:22.075Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.370.0>},
                       {name,xdcr_sup},
                       {mfargs,{xdcr_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:54:22.078Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.378.0>},
                       {name,xdcr_dcp_sockets_pool},
                       {mfargs,{xdcr_dcp_sockets_pool,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:22.082Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_worker_sup}
             started: [{pid,<0.380.0>},
                       {name,ns_bucket_worker},
                       {mfargs,{work_queue,start_link,[ns_bucket_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:22.087Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_sup}
             started: [{pid,<0.382.0>},
                       {name,buckets_observing_subscription},
                       {mfargs,{ns_bucket_sup,subscribe_on_config_events,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:22.087Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_worker_sup}
             started: [{pid,<0.381.0>},
                       {name,ns_bucket_sup},
                       {mfargs,{ns_bucket_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:54:22.088Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.379.0>},
                       {name,ns_bucket_worker_sup},
                       {mfargs,{ns_bucket_worker_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:54:22.093Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.383.0>},
                       {name,system_stats_collector},
                       {mfargs,{system_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:22.095Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.387.0>},
                       {name,{stats_archiver,"@system"}},
                       {mfargs,{stats_archiver,start_link,["@system"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:22.098Z,ns_1@127.0.0.1:xdcr_doc_replicator<0.375.0>:doc_replicator:loop:64]doing replicate_newnodes_docs
[error_logger:info,2021-04-19T19:54:22.101Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.389.0>},
                       {name,{stats_reader,"@system"}},
                       {mfargs,{stats_reader,start_link,["@system"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:22.103Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.390.0>},
                       {name,{stats_archiver,"@system-processes"}},
                       {mfargs,
                           {stats_archiver,start_link,["@system-processes"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:22.104Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.392.0>},
                       {name,{stats_reader,"@system-processes"}},
                       {mfargs,
                           {stats_reader,start_link,["@system-processes"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:22.122Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.393.0>},
                       {name,{stats_archiver,"@query"}},
                       {mfargs,{stats_archiver,start_link,["@query"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:22.122Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.395.0>},
                       {name,{stats_reader,"@query"}},
                       {mfargs,{stats_reader,start_link,["@query"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:22.134Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.396.0>},
                       {name,query_stats_collector},
                       {mfargs,{query_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:22.170Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.398.0>},
                       {name,{stats_archiver,"@global"}},
                       {mfargs,{stats_archiver,start_link,["@global"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:22.171Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.400.0>},
                       {name,{stats_reader,"@global"}},
                       {mfargs,{stats_reader,start_link,["@global"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:22.174Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.401.0>},
                       {name,global_stats_collector},
                       {mfargs,{global_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:22.179Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.403.0>},
                       {name,goxdcr_status_keeper},
                       {mfargs,{goxdcr_status_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:22.180Z,ns_1@127.0.0.1:goxdcr_status_keeper<0.403.0>:goxdcr_rest:get_from_goxdcr:163]Goxdcr is temporary not available. Return empty list.
[ns_server:debug,2021-04-19T19:54:22.182Z,ns_1@127.0.0.1:goxdcr_status_keeper<0.403.0>:goxdcr_rest:get_from_goxdcr:163]Goxdcr is temporary not available. Return empty list.
[error_logger:info,2021-04-19T19:54:22.184Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_stats_sup}
             started: [{pid,<0.407.0>},
                       {name,index_stats_children_sup},
                       {mfargs,
                           {supervisor,start_link,
                               [{local,index_stats_children_sup},
                                index_stats_sup,child]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:54:22.189Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_status_keeper_sup}
             started: [{pid,<0.409.0>},
                       {name,index_status_keeper_worker},
                       {mfargs,
                           {work_queue,start_link,
                               [index_status_keeper_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:22.190Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_status_keeper_sup}
             started: [{pid,<0.410.0>},
                       {name,index_status_keeper},
                       {mfargs,{indexer_gsi,start_keeper,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:error,2021-04-19T19:54:22.194Z,ns_1@127.0.0.1:index_status_keeper_worker<0.409.0>:index_rest:get_json:42]Request to (indexer) http://127.0.0.1:9102/getIndexStatus failed: {error,
                                                                   {econnrefused,
                                                                    [{lhttpc_client,
                                                                      send_request,
                                                                      1,
                                                                      [{file,
                                                                        "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                       {line,
                                                                        220}]},
                                                                     {lhttpc_client,
                                                                      execute,
                                                                      9,
                                                                      [{file,
                                                                        "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                       {line,
                                                                        169}]},
                                                                     {lhttpc_client,
                                                                      request,
                                                                      9,
                                                                      [{file,
                                                                        "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                       {line,
                                                                        92}]}]}}
[error_logger:info,2021-04-19T19:54:22.199Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_status_keeper_sup}
             started: [{pid,<0.414.0>},
                       {name,index_status_keeper_fts},
                       {mfargs,{indexer_fts,start_keeper,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:22.200Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_stats_sup}
             started: [{pid,<0.408.0>},
                       {name,index_status_keeper_sup},
                       {mfargs,{index_status_keeper_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:54:22.200Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_stats_sup}
             started: [{pid,<0.417.0>},
                       {name,index_stats_worker},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<index_stats_sup.0.21142793>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:22.201Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.406.0>},
                       {name,index_stats_sup},
                       {mfargs,{index_stats_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:54:22.211Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_stats_children_sup}
             started: [{pid,<0.419.0>},
                       {name,{indexer_gsi,index_stats_collector}},
                       {mfargs,
                           {index_stats_collector,start_link,[indexer_gsi]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:22.218Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.423.0>},
                       {name,compaction_daemon},
                       {mfargs,{compaction_daemon,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:22.244Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_stats_children_sup}
             started: [{pid,<0.422.0>},
                       {name,{indexer_gsi,stats_archiver,"@index"}},
                       {mfargs,{stats_archiver,start_link,["@index"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:22.244Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_stats_children_sup}
             started: [{pid,<0.427.0>},
                       {name,{indexer_gsi,stats_reader,"@index"}},
                       {mfargs,{stats_reader,start_link,["@index"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:22.246Z,ns_1@127.0.0.1:<0.428.0>:new_concurrency_throttle:init:113]init concurrent throttle process, pid: <0.428.0>, type: kv_throttle# of available token: 1
[ns_server:debug,2021-04-19T19:54:22.252Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:54:22.253Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[error_logger:info,2021-04-19T19:54:22.252Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.424.0>},
                       {name,compaction_new_daemon},
                       {mfargs,{compaction_new_daemon,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,86400000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:22.253Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:54:22.254Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:54:22.254Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_master. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:54:22.254Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_master too soon. Next run will be in 3600s
[error_logger:info,2021-04-19T19:54:22.259Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,cluster_logs_sup}
             started: [{pid,<0.430.0>},
                       {name,ets_holder},
                       {mfargs,
                           {cluster_logs_collection_task,
                               start_link_ets_holder,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:22.261Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.429.0>},
                       {name,cluster_logs_sup},
                       {mfargs,{cluster_logs_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:54:22.266Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.431.0>},
                       {name,remote_api},
                       {mfargs,{remote_api,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:22.275Z,ns_1@127.0.0.1:<0.432.0>:mb_master:check_master_takeover_needed:141]Sending master node question to the following nodes: []
[ns_server:debug,2021-04-19T19:54:22.275Z,ns_1@127.0.0.1:<0.432.0>:mb_master:check_master_takeover_needed:143]Got replies: []
[ns_server:debug,2021-04-19T19:54:22.275Z,ns_1@127.0.0.1:<0.432.0>:mb_master:check_master_takeover_needed:149]Was unable to discover master, not going to force mastership takeover
[user:info,2021-04-19T19:54:22.275Z,ns_1@127.0.0.1:mb_master<0.434.0>:mb_master:init:86]I'm the only node, so I'm the master.
[ns_server:debug,2021-04-19T19:54:22.299Z,ns_1@127.0.0.1:mb_master_sup<0.436.0>:misc:start_singleton:1097]start_singleton(gen_server, ns_tick, [], []): started as <0.437.0> on 'ns_1@127.0.0.1'

[error_logger:info,2021-04-19T19:54:22.299Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.437.0>},
                       {name,ns_tick},
                       {mfargs,{ns_tick,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,10},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:22.304Z,ns_1@127.0.0.1:ns_orchestrator_sup<0.438.0>:misc:start_singleton:1097]start_singleton(gen_fsm, ns_orchestrator, [], []): started as <0.439.0> on 'ns_1@127.0.0.1'

[error_logger:info,2021-04-19T19:54:22.305Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_sup}
             started: [{pid,<0.439.0>},
                       {name,ns_orchestrator},
                       {mfargs,{ns_orchestrator,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:22.314Z,ns_1@127.0.0.1:<0.441.0>:auto_failover:init:147]init auto_failover.
[ns_server:debug,2021-04-19T19:54:22.314Z,ns_1@127.0.0.1:ns_orchestrator_sup<0.438.0>:misc:start_singleton:1097]start_singleton(gen_server, auto_failover, [], []): started as <0.441.0> on 'ns_1@127.0.0.1'

[ns_server:debug,2021-04-19T19:54:22.315Z,ns_1@127.0.0.1:<0.432.0>:restartable:start_child:98]Started child process <0.434.0>
  MFA: {mb_master,start_link,[]}
[error_logger:info,2021-04-19T19:54:22.315Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_sup}
             started: [{pid,<0.441.0>},
                       {name,auto_failover},
                       {mfargs,{auto_failover,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:22.315Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.438.0>},
                       {name,ns_orchestrator_sup},
                       {mfargs,{ns_orchestrator_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:54:22.315Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.432.0>},
                       {name,mb_master},
                       {mfargs,
                           {restartable,start_link,
                               [{mb_master,start_link,[]},infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:54:22.315Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.442.0>},
                       {name,master_activity_events_ingress},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,master_activity_events_ingress}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:22.316Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.443.0>},
                       {name,master_activity_events_timestamper},
                       {mfargs,
                           {master_activity_events,start_link_timestamper,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2021-04-19T19:54:22.321Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.444.0>},
                       {name,master_activity_events_pids_watcher},
                       {mfargs,
                           {master_activity_events_pids_watcher,start_link,
                               []}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:22.360Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.155.0>:one_shot_barrier:notify:27]Notifying on barrier menelaus_barrier
[ns_server:debug,2021-04-19T19:54:22.361Z,ns_1@127.0.0.1:menelaus_barrier<0.157.0>:one_shot_barrier:barrier_body:62]Barrier menelaus_barrier got notification from <0.155.0>
[error_logger:info,2021-04-19T19:54:22.360Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.445.0>},
                       {name,master_activity_events_keeper},
                       {mfargs,{master_activity_events_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T19:54:22.361Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.155.0>:one_shot_barrier:notify:32]Successfuly notified on barrier menelaus_barrier
[ns_server:debug,2021-04-19T19:54:22.361Z,ns_1@127.0.0.1:<0.154.0>:restartable:start_child:98]Started child process <0.155.0>
  MFA: {ns_server_nodes_sup,start_link,[]}
[error_logger:info,2021-04-19T19:54:22.361Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.255.0>},
                       {name,ns_server_sup},
                       {mfargs,{ns_server_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2021-04-19T19:54:22.361Z,ns_1@127.0.0.1:<0.2.0>:child_erlang:child_loop:116]98: Entered child_loop
[error_logger:info,2021-04-19T19:54:22.361Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.154.0>},
                       {name,ns_server_nodes_sup},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_server_nodes_sup,start_link,[]},
                                infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T19:54:22.362Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
         application: ns_server
          started_at: 'ns_1@127.0.0.1'

[ns_server:debug,2021-04-19T19:54:22.868Z,ns_1@127.0.0.1:ns_ports_setup<0.353.0>:ns_ports_setup:set_children:72]Monitor ns_child_ports_sup <11632.72.0>
[ns_server:debug,2021-04-19T19:54:22.869Z,ns_1@127.0.0.1:memcached_config_mgr<0.364.0>:memcached_config_mgr:init:46]ns_ports_setup seems to be ready
[ns_server:debug,2021-04-19T19:54:22.881Z,ns_1@127.0.0.1:memcached_config_mgr<0.364.0>:memcached_config_mgr:find_port_pid_loop:119]Found memcached port <11632.79.0>
[ns_server:debug,2021-04-19T19:54:22.929Z,ns_1@127.0.0.1:memcached_config_mgr<0.364.0>:memcached_config_mgr:init:77]wrote memcached config to /opt/couchbase/var/lib/couchbase/config/memcached.json. Will activate memcached port server
[ns_server:debug,2021-04-19T19:54:22.957Z,ns_1@127.0.0.1:memcached_config_mgr<0.364.0>:memcached_config_mgr:init:80]activated memcached port server
[ns_server:warn,2021-04-19T19:54:23.025Z,ns_1@127.0.0.1:<0.362.0>:ns_memcached:connect:1307]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[stats:error,2021-04-19T19:54:23.303Z,ns_1@127.0.0.1:query_stats_collector<0.396.0>:base_stats_collector:handle_info:109](Collector: query_stats_collector) Exception in stats collector: {error,
                                                                  {badmatch,
                                                                   {error,
                                                                    {econnrefused,
                                                                     [{lhttpc_client,
                                                                       send_request,
                                                                       1,
                                                                       [{file,
                                                                         "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                        {line,
                                                                         220}]},
                                                                      {lhttpc_client,
                                                                       execute,
                                                                       9,
                                                                       [{file,
                                                                         "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                        {line,
                                                                         169}]},
                                                                      {lhttpc_client,
                                                                       request,
                                                                       9,
                                                                       [{file,
                                                                         "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                        {line,
                                                                         92}]}]}}},
                                                                  [{query_rest,
                                                                    send,3,
                                                                    [{file,
                                                                      "src/query_rest.erl"},
                                                                     {line,
                                                                      64}]},
                                                                   {query_rest,
                                                                    do_get_stats,
                                                                    0,
                                                                    [{file,
                                                                      "src/query_rest.erl"},
                                                                     {line,
                                                                      43}]},
                                                                   {base_stats_collector,
                                                                    handle_info,
                                                                    2,
                                                                    [{file,
                                                                      "src/base_stats_collector.erl"},
                                                                     {line,
                                                                      89}]},
                                                                   {gen_server,
                                                                    handle_msg,
                                                                    5,
                                                                    [{file,
                                                                      "gen_server.erl"},
                                                                     {line,
                                                                      604}]},
                                                                   {proc_lib,
                                                                    init_p_do_apply,
                                                                    3,
                                                                    [{file,
                                                                      "proc_lib.erl"},
                                                                     {line,
                                                                      239}]}]}

[ns_server:error,2021-04-19T19:54:23.304Z,ns_1@127.0.0.1:index_stats_collector-index<0.419.0>:index_rest:get_json:42]Request to (indexer) http://127.0.0.1:9102/stats?async=true failed: {error,
                                                                     {econnrefused,
                                                                      [{lhttpc_client,
                                                                        send_request,
                                                                        1,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          220}]},
                                                                       {lhttpc_client,
                                                                        execute,
                                                                        9,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          169}]},
                                                                       {lhttpc_client,
                                                                        request,
                                                                        9,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          92}]}]}}
[ns_server:warn,2021-04-19T19:54:23.340Z,ns_1@127.0.0.1:<0.452.0>:ns_memcached:connect:1307]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[ns_server:warn,2021-04-19T19:54:24.027Z,ns_1@127.0.0.1:<0.362.0>:ns_memcached:connect:1307]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[ns_server:error,2021-04-19T19:54:24.301Z,ns_1@127.0.0.1:index_stats_collector-index<0.419.0>:index_rest:get_json:42]Request to (indexer) http://127.0.0.1:9102/stats?async=true failed: {error,
                                                                     {econnrefused,
                                                                      [{lhttpc_client,
                                                                        send_request,
                                                                        1,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          220}]},
                                                                       {lhttpc_client,
                                                                        execute,
                                                                        9,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          169}]},
                                                                       {lhttpc_client,
                                                                        request,
                                                                        9,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          92}]}]}}
[stats:error,2021-04-19T19:54:24.301Z,ns_1@127.0.0.1:query_stats_collector<0.396.0>:base_stats_collector:handle_info:109](Collector: query_stats_collector) Exception in stats collector: {error,
                                                                  {badmatch,
                                                                   {error,
                                                                    {econnrefused,
                                                                     [{lhttpc_client,
                                                                       send_request,
                                                                       1,
                                                                       [{file,
                                                                         "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                        {line,
                                                                         220}]},
                                                                      {lhttpc_client,
                                                                       execute,
                                                                       9,
                                                                       [{file,
                                                                         "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                        {line,
                                                                         169}]},
                                                                      {lhttpc_client,
                                                                       request,
                                                                       9,
                                                                       [{file,
                                                                         "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                        {line,
                                                                         92}]}]}}},
                                                                  [{query_rest,
                                                                    send,3,
                                                                    [{file,
                                                                      "src/query_rest.erl"},
                                                                     {line,
                                                                      64}]},
                                                                   {query_rest,
                                                                    do_get_stats,
                                                                    0,
                                                                    [{file,
                                                                      "src/query_rest.erl"},
                                                                     {line,
                                                                      43}]},
                                                                   {base_stats_collector,
                                                                    handle_info,
                                                                    2,
                                                                    [{file,
                                                                      "src/base_stats_collector.erl"},
                                                                     {line,
                                                                      89}]},
                                                                   {gen_server,
                                                                    handle_msg,
                                                                    5,
                                                                    [{file,
                                                                      "gen_server.erl"},
                                                                     {line,
                                                                      604}]},
                                                                   {proc_lib,
                                                                    init_p_do_apply,
                                                                    3,
                                                                    [{file,
                                                                      "proc_lib.erl"},
                                                                     {line,
                                                                      239}]}]}

[ns_server:debug,2021-04-19T19:54:24.340Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{metakv,<<"/indexing/settings/config">>} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{6,63786081264}}]}|
 <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.log_level\":\"info\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\""...>>]
[ns_server:debug,2021-04-19T19:54:24.340Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{local_changes_count,<<"360fb3d3641e00b1f4f22714c24e2a2a">>} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{14,63786081264}}]}]
[ns_server:debug,2021-04-19T19:54:24.340Z,ns_1@127.0.0.1:ns_config_rep<0.272.0>:ns_config_rep:do_push_keys:321]Replicating some config keys ([{local_changes_count,
                                   <<"360fb3d3641e00b1f4f22714c24e2a2a">>},
                               {metakv,<<"/indexing/settings/config">>}]..)
[ns_server:debug,2021-04-19T19:54:24.341Z,ns_1@127.0.0.1:<0.464.0>:ns_audit:put:248]Audit modify_index_storage_mode: [{storageMode,<<"memory_optimized">>},
                                  {real_userid,
                                      {[{source,ns_server},
                                        {user,<<"Administrator">>}]}},
                                  {remote,
                                      {[{ip,<<"127.0.0.1">>},{port,36516}]}},
                                  {timestamp,<<"2021-04-19T19:54:24.340Z">>}]
[ns_server:warn,2021-04-19T19:54:24.343Z,ns_1@127.0.0.1:<0.452.0>:ns_memcached:connect:1307]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[ns_server:warn,2021-04-19T19:54:24.343Z,ns_1@127.0.0.1:<0.467.0>:ns_memcached:connect:1307]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[ns_server:debug,2021-04-19T19:54:24.470Z,ns_1@127.0.0.1:json_rpc_connection-projector-cbauth<0.470.0>:json_rpc_connection:init:74]Observed revrpc connection: label "projector-cbauth", handling process <0.470.0>
[ns_server:debug,2021-04-19T19:54:24.472Z,ns_1@127.0.0.1:menelaus_cbauth<0.349.0>:menelaus_cbauth:handle_cast:87]Observed json rpc process {"projector-cbauth",<0.470.0>} started
[error_logger:error,2021-04-19T19:54:24.472Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.470.0>,{ok,<0.470.0>}}

[ns_server:debug,2021-04-19T19:54:24.493Z,ns_1@127.0.0.1:json_rpc_connection-projector-cbauth<0.470.0>:json_rpc_connection:handle_call:157]sending jsonrpc call:{[{jsonrpc,<<"2.0">>},
                       {id,0},
                       {method,<<"AuthCacheSvc.UpdateDB">>},
                       {params,
                        [{[{specialUser,<<"@projector-cbauth">>},
                           {nodes,
                            [{[{host,<<"127.0.0.1">>},
                               {user,<<"_admin">>},
                               {password,"*****"},
                               {ports,
                                [8091,18091,9100,9101,9102,9103,9104,9105,
                                 18092,8092,11207,9999,11210,11211,8093,
                                 18093]},
                               {local,true}]}]},
                           {buckets,[]},
                           {authCheckURL,<<"http://127.0.0.1:8091/_cbauth">>},
                           {permissionCheckURL,
                            <<"http://127.0.0.1:8091/_cbauth/checkPermission">>},
                           {ldapEnabled,true},
                           {permissionsVersion,125619376},
                           {admin,
                            {[{user,<<"Administrator">>},
                              {salt,<<"HwppMSHwWqqMMQC+Y570Cg==">>},
                              {mac,
                               <<"qvTNNsy5tPU9CAZI+HQuF+FPP5Y=">>}]}}]}]}]}
[ns_server:debug,2021-04-19T19:54:24.508Z,ns_1@127.0.0.1:json_rpc_connection-projector-cbauth<0.470.0>:json_rpc_connection:handle_info:93]got response: [{<<"id">>,0},{<<"result">>,true},{<<"error">>,null}]
[ns_server:debug,2021-04-19T19:54:24.585Z,ns_1@127.0.0.1:json_rpc_connection-index-cbauth<0.474.0>:json_rpc_connection:init:74]Observed revrpc connection: label "index-cbauth", handling process <0.474.0>
[error_logger:error,2021-04-19T19:54:24.585Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.474.0>,{ok,<0.474.0>}}

[ns_server:debug,2021-04-19T19:54:24.585Z,ns_1@127.0.0.1:menelaus_cbauth<0.349.0>:menelaus_cbauth:handle_cast:87]Observed json rpc process {"index-cbauth",<0.474.0>} started
[ns_server:debug,2021-04-19T19:54:24.585Z,ns_1@127.0.0.1:json_rpc_connection-index-cbauth<0.474.0>:json_rpc_connection:handle_call:157]sending jsonrpc call:{[{jsonrpc,<<"2.0">>},
                       {id,0},
                       {method,<<"AuthCacheSvc.UpdateDB">>},
                       {params,
                        [{[{specialUser,<<"@index-cbauth">>},
                           {nodes,
                            [{[{host,<<"127.0.0.1">>},
                               {user,<<"_admin">>},
                               {password,"*****"},
                               {ports,
                                [8091,18091,9100,9101,9102,9103,9104,9105,
                                 18092,8092,11207,9999,11210,11211,8093,
                                 18093]},
                               {local,true}]}]},
                           {buckets,[]},
                           {authCheckURL,<<"http://127.0.0.1:8091/_cbauth">>},
                           {permissionCheckURL,
                            <<"http://127.0.0.1:8091/_cbauth/checkPermission">>},
                           {ldapEnabled,true},
                           {permissionsVersion,125619376},
                           {admin,
                            {[{user,<<"Administrator">>},
                              {salt,<<"HwppMSHwWqqMMQC+Y570Cg==">>},
                              {mac,
                               <<"qvTNNsy5tPU9CAZI+HQuF+FPP5Y=">>}]}}]}]}]}
[ns_server:debug,2021-04-19T19:54:24.588Z,ns_1@127.0.0.1:json_rpc_connection-index-cbauth<0.474.0>:json_rpc_connection:handle_info:93]got response: [{<<"id">>,0},{<<"result">>,true},{<<"error">>,null}]
[ns_server:debug,2021-04-19T19:54:24.614Z,ns_1@127.0.0.1:json_rpc_connection-cbq-engine-cbauth<0.478.0>:json_rpc_connection:init:74]Observed revrpc connection: label "cbq-engine-cbauth", handling process <0.478.0>
[error_logger:error,2021-04-19T19:54:24.615Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.478.0>,{ok,<0.478.0>}}

[ns_server:debug,2021-04-19T19:54:24.615Z,ns_1@127.0.0.1:menelaus_cbauth<0.349.0>:menelaus_cbauth:handle_cast:87]Observed json rpc process {"cbq-engine-cbauth",<0.478.0>} started
[ns_server:debug,2021-04-19T19:54:24.615Z,ns_1@127.0.0.1:json_rpc_connection-cbq-engine-cbauth<0.478.0>:json_rpc_connection:handle_call:157]sending jsonrpc call:{[{jsonrpc,<<"2.0">>},
                       {id,0},
                       {method,<<"AuthCacheSvc.UpdateDB">>},
                       {params,
                        [{[{specialUser,<<"@cbq-engine-cbauth">>},
                           {nodes,
                            [{[{host,<<"127.0.0.1">>},
                               {user,<<"_admin">>},
                               {password,"*****"},
                               {ports,
                                [8091,18091,9100,9101,9102,9103,9104,9105,
                                 18092,8092,11207,9999,11210,11211,8093,
                                 18093]},
                               {local,true}]}]},
                           {buckets,[]},
                           {authCheckURL,<<"http://127.0.0.1:8091/_cbauth">>},
                           {permissionCheckURL,
                            <<"http://127.0.0.1:8091/_cbauth/checkPermission">>},
                           {ldapEnabled,true},
                           {permissionsVersion,125619376},
                           {admin,
                            {[{user,<<"Administrator">>},
                              {salt,<<"HwppMSHwWqqMMQC+Y570Cg==">>},
                              {mac,
                               <<"qvTNNsy5tPU9CAZI+HQuF+FPP5Y=">>}]}}]}]}]}
[ns_server:debug,2021-04-19T19:54:24.618Z,ns_1@127.0.0.1:json_rpc_connection-cbq-engine-cbauth<0.478.0>:json_rpc_connection:handle_info:93]got response: [{<<"id">>,0},{<<"result">>,true},{<<"error">>,null}]
[ns_server:debug,2021-04-19T19:54:24.667Z,ns_1@127.0.0.1:json_rpc_connection-saslauthd-saslauthd-port<0.483.0>:json_rpc_connection:init:74]Observed revrpc connection: label "saslauthd-saslauthd-port", handling process <0.483.0>
[error_logger:error,2021-04-19T19:54:24.668Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.483.0>,{ok,<0.483.0>}}

[ns_server:debug,2021-04-19T19:54:24.854Z,ns_1@127.0.0.1:json_rpc_connection-goxdcr-cbauth<0.490.0>:json_rpc_connection:init:74]Observed revrpc connection: label "goxdcr-cbauth", handling process <0.490.0>
[ns_server:debug,2021-04-19T19:54:24.854Z,ns_1@127.0.0.1:menelaus_cbauth<0.349.0>:menelaus_cbauth:handle_cast:87]Observed json rpc process {"goxdcr-cbauth",<0.490.0>} started
[ns_server:debug,2021-04-19T19:54:24.855Z,ns_1@127.0.0.1:json_rpc_connection-goxdcr-cbauth<0.490.0>:json_rpc_connection:handle_call:157]sending jsonrpc call:{[{jsonrpc,<<"2.0">>},
                       {id,0},
                       {method,<<"AuthCacheSvc.UpdateDB">>},
                       {params,
                        [{[{specialUser,<<"@goxdcr-cbauth">>},
                           {nodes,
                            [{[{host,<<"127.0.0.1">>},
                               {user,<<"_admin">>},
                               {password,"*****"},
                               {ports,
                                [8091,18091,9100,9101,9102,9103,9104,9105,
                                 18092,8092,11207,9999,11210,11211,8093,
                                 18093]},
                               {local,true}]}]},
                           {buckets,[]},
                           {authCheckURL,<<"http://127.0.0.1:8091/_cbauth">>},
                           {permissionCheckURL,
                            <<"http://127.0.0.1:8091/_cbauth/checkPermission">>},
                           {ldapEnabled,true},
                           {permissionsVersion,125619376},
                           {admin,
                            {[{user,<<"Administrator">>},
                              {salt,<<"HwppMSHwWqqMMQC+Y570Cg==">>},
                              {mac,
                               <<"qvTNNsy5tPU9CAZI+HQuF+FPP5Y=">>}]}}]}]}]}
[error_logger:error,2021-04-19T19:54:24.855Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.490.0>,{ok,<0.490.0>}}

[ns_server:debug,2021-04-19T19:54:24.857Z,ns_1@127.0.0.1:json_rpc_connection-goxdcr-cbauth<0.490.0>:json_rpc_connection:handle_info:93]got response: [{<<"id">>,0},{<<"result">>,true},{<<"error">>,null}]
[ns_server:warn,2021-04-19T19:54:25.028Z,ns_1@127.0.0.1:<0.362.0>:ns_memcached:connect:1307]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[ns_server:error,2021-04-19T19:54:25.300Z,ns_1@127.0.0.1:index_stats_collector-index<0.419.0>:index_rest:get_json:42]Request to (indexer) http://127.0.0.1:9102/stats?async=true failed: {error,
                                                                     {econnrefused,
                                                                      [{lhttpc_client,
                                                                        send_request,
                                                                        1,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          220}]},
                                                                       {lhttpc_client,
                                                                        execute,
                                                                        9,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          169}]},
                                                                       {lhttpc_client,
                                                                        request,
                                                                        9,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          92}]}]}}
[stats:warn,2021-04-19T19:54:25.356Z,ns_1@127.0.0.1:<0.401.0>:base_stats_collector:latest_tick:69](Collector: global_stats_collector) Dropped 2 ticks
[ns_server:debug,2021-04-19T19:54:52.254Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:54:52.254Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:54:52.254Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:54:52.254Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:55:22.255Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:55:22.255Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:55:22.256Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:55:22.256Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:55:52.257Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:55:52.258Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:55:52.258Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:55:52.258Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:56:22.259Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:56:22.259Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:56:22.259Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:56:22.259Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:56:52.260Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:56:52.260Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:56:52.260Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:56:52.260Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:57:22.261Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:57:22.261Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:57:22.261Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:57:22.262Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:57:52.262Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:57:52.263Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:57:52.263Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:57:52.264Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:58:22.264Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:58:22.264Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T19:58:22.265Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2021-04-19T19:58:22.265Z,ns_1@127.0.0.1:compaction_new_daemon<0.424.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:info,2021-04-19T20:01:41.963Z,nonode@nohost:<0.88.0>:ns_server:init_logging:151]Started & configured logging
[ns_server:info,2021-04-19T20:01:41.976Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]Static config terms:
[{error_logger_mf_dir,"/opt/couchbase/var/lib/couchbase/logs"},
 {path_config_bindir,"/opt/couchbase/bin"},
 {path_config_etcdir,"/opt/couchbase/etc/couchbase"},
 {path_config_libdir,"/opt/couchbase/lib"},
 {path_config_datadir,"/opt/couchbase/var/lib/couchbase"},
 {path_config_tmpdir,"/opt/couchbase/var/lib/couchbase/tmp"},
 {path_config_secdir,"/opt/couchbase/etc/security"},
 {nodefile,"/opt/couchbase/var/lib/couchbase/couchbase-server.node"},
 {loglevel_default,debug},
 {loglevel_couchdb,info},
 {loglevel_ns_server,debug},
 {loglevel_error_logger,debug},
 {loglevel_user,debug},
 {loglevel_menelaus,debug},
 {loglevel_ns_doctor,debug},
 {loglevel_stats,debug},
 {loglevel_rebalance,debug},
 {loglevel_cluster,debug},
 {loglevel_views,debug},
 {loglevel_mapreduce_errors,debug},
 {loglevel_xdcr,debug},
 {loglevel_xdcr_trace,error},
 {loglevel_access,info},
 {disk_sink_opts,
     [{rotation,
          [{compress,true},
           {size,41943040},
           {num_files,10},
           {buffer_size_max,52428800}]}]},
 {disk_sink_opts_xdcr_trace,
     [{rotation,[{compress,false},{size,83886080},{num_files,5}]}]},
 {net_kernel_verbosity,10}]
[ns_server:warn,2021-04-19T20:01:41.976Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter error_logger_mf_dir, which is given from command line
[ns_server:warn,2021-04-19T20:01:41.976Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter path_config_bindir, which is given from command line
[ns_server:warn,2021-04-19T20:01:41.976Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter path_config_etcdir, which is given from command line
[ns_server:warn,2021-04-19T20:01:41.976Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter path_config_libdir, which is given from command line
[ns_server:warn,2021-04-19T20:01:41.977Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter path_config_datadir, which is given from command line
[ns_server:warn,2021-04-19T20:01:41.977Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter path_config_tmpdir, which is given from command line
[ns_server:warn,2021-04-19T20:01:41.977Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter path_config_secdir, which is given from command line
[ns_server:warn,2021-04-19T20:01:41.977Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter nodefile, which is given from command line
[ns_server:warn,2021-04-19T20:01:41.977Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_default, which is given from command line
[ns_server:warn,2021-04-19T20:01:41.977Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_couchdb, which is given from command line
[ns_server:warn,2021-04-19T20:01:41.977Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_ns_server, which is given from command line
[ns_server:warn,2021-04-19T20:01:41.977Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_error_logger, which is given from command line
[ns_server:warn,2021-04-19T20:01:41.977Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_user, which is given from command line
[ns_server:warn,2021-04-19T20:01:41.977Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_menelaus, which is given from command line
[ns_server:warn,2021-04-19T20:01:41.977Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_ns_doctor, which is given from command line
[ns_server:warn,2021-04-19T20:01:41.977Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_stats, which is given from command line
[ns_server:warn,2021-04-19T20:01:41.977Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_rebalance, which is given from command line
[ns_server:warn,2021-04-19T20:01:41.977Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_cluster, which is given from command line
[ns_server:warn,2021-04-19T20:01:41.977Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_views, which is given from command line
[ns_server:warn,2021-04-19T20:01:41.977Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_mapreduce_errors, which is given from command line
[ns_server:warn,2021-04-19T20:01:41.977Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_xdcr, which is given from command line
[ns_server:warn,2021-04-19T20:01:41.977Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_xdcr_trace, which is given from command line
[ns_server:warn,2021-04-19T20:01:41.978Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter loglevel_access, which is given from command line
[ns_server:warn,2021-04-19T20:01:41.978Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter disk_sink_opts, which is given from command line
[ns_server:warn,2021-04-19T20:01:41.978Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter disk_sink_opts_xdcr_trace, which is given from command line
[ns_server:warn,2021-04-19T20:01:41.978Z,nonode@nohost:<0.88.0>:ns_server:log_pending:32]not overriding parameter net_kernel_verbosity, which is given from command line
[error_logger:info,2021-04-19T20:01:41.986Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.128.0>},
                       {name,local_tasks},
                       {mfargs,{local_tasks,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:info,2021-04-19T20:01:41.993Z,nonode@nohost:ns_server_cluster_sup<0.127.0>:log_os_info:start_link:25]OS type: {unix,linux} Version: {4,19,128}
Runtime info: [{otp_release,"R16B03-1"},
               {erl_version,"5.10.4.0.0.1"},
               {erl_version_long,
                   "Erlang R16B03-1 (erts-5.10.4.0.0.1) [source-00852da] [64-bit] [smp:8:8] [async-threads:16] [kernel-poll:true]\n"},
               {system_arch_raw,"x86_64-unknown-linux-gnu"},
               {system_arch,"x86_64-unknown-linux-gnu"},
               {localtime,{{2021,4,19},{20,1,41}}},
               {memory,
                   [{total,111105384},
                    {processes,9575032},
                    {processes_used,9574056},
                    {system,101530352},
                    {atom,331249},
                    {atom_used,310220},
                    {binary,54032},
                    {code,7694133},
                    {ets,2240656}]},
               {loaded,
                   [ns_info,log_os_info,local_tasks,restartable,
                    ns_server_cluster_sup,calendar,ale_default_formatter,
                    'ale_logger-metakv','ale_logger-rebalance',
                    'ale_logger-xdcr_trace','ale_logger-menelaus',
                    'ale_logger-stats','ale_logger-access',
                    'ale_logger-ns_server','ale_logger-user',
                    'ale_logger-ns_doctor',io_lib_fread,'ale_logger-cluster',
                    'ale_logger-xdcr',otp_internal,ns_log_sink,ale_disk_sink,
                    misc,couch_util,ns_server,filelib,cpu_sup,memsup,disksup,
                    os_mon,io,release_handler,overload,alarm_handler,sasl,
                    timer,tftp_sup,httpd_sup,httpc_handler_sup,httpc_cookie,
                    inets_trace,httpc_manager,httpc,httpc_profile_sup,
                    httpc_sup,ftp_sup,inets_sup,inets_app,ssl,lhttpc_manager,
                    lhttpc_sup,lhttpc,tls_connection_sup,ssl_session_cache,
                    ssl_pkix_db,ssl_manager,ssl_sup,ssl_app,crypto_server,
                    crypto_sup,crypto_app,ale_error_logger_handler,
                    'ale_logger-ale_logger','ale_logger-error_logger',
                    beam_opcodes,beam_dict,beam_asm,beam_validator,beam_z,
                    beam_flatten,beam_trim,beam_receive,beam_bsm,beam_peep,
                    beam_dead,beam_split,beam_type,beam_bool,beam_except,
                    beam_clean,beam_utils,beam_block,beam_jump,beam_a,
                    v3_codegen,v3_life,v3_kernel,sys_core_dsetel,erl_bifs,
                    sys_core_fold,cerl_trees,sys_core_inline,core_lib,cerl,
                    v3_core,erl_bits,erl_expand_records,sys_pre_expand,sofs,
                    erl_internal,sets,ordsets,erl_lint,compile,
                    dynamic_compile,ale_utils,io_lib_pretty,io_lib_format,
                    io_lib,ale_codegen,dict,ale,ale_dynamic_sup,ale_sup,
                    ale_app,epp,ns_bootstrap,child_erlang,file_io_server,
                    orddict,erl_eval,file,c,kernel_config,user_sup,
                    supervisor_bridge,standard_error,code_server,unicode,
                    hipe_unified_loader,gb_sets,ets,binary,code,file_server,
                    net_kernel,global_group,erl_distribution,filename,
                    inet_gethost_native,os,inet_parse,inet,inet_udp,
                    inet_config,inet_db,global,gb_trees,rpc,supervisor,kernel,
                    application_master,sys,application,gen_server,erl_parse,
                    proplists,erl_scan,lists,application_controller,proc_lib,
                    gen,gen_event,error_logger,heart,error_handler,
                    erts_internal,erlang,erl_prim_loader,prim_zip,zlib,
                    prim_file,prim_inet,prim_eval,init,otp_ring0]},
               {applications,
                   [{lhttpc,"Lightweight HTTP Client","1.3.0"},
                    {os_mon,"CPO  CXC 138 46","2.2.14"},
                    {public_key,"Public key infrastructure","0.21"},
                    {asn1,"The Erlang ASN1 compiler version 2.0.4","2.0.4"},
                    {kernel,"ERTS  CXC 138 10","2.16.4"},
                    {ale,"Another Logger for Erlang","4.6.0-3573-enterprise"},
                    {inets,"INETS  CXC 138 49","5.9.8"},
                    {ns_server,"Couchbase server","4.6.0-3573-enterprise"},
                    {crypto,"CRYPTO version 2","3.2"},
                    {ssl,"Erlang/OTP SSL application","5.3.3"},
                    {sasl,"SASL  CXC 138 11","2.3.4"},
                    {stdlib,"ERTS  CXC 138 10","1.19.4"}]},
               {pre_loaded,
                   [erts_internal,erlang,erl_prim_loader,prim_zip,zlib,
                    prim_file,prim_inet,prim_eval,init,otp_ring0]},
               {process_count,94},
               {node,nonode@nohost},
               {nodes,[]},
               {registered,
                   [ftp_sup,'sink-disk_xdcr',code_server,sasl_sup,
                    'sink-disk_debug',application_controller,
                    'sink-disk_error',local_tasks,'sink-disk_default',
                    ale_stats_events,kernel_safe_sup,inets_sup,ale,
                    standard_error,error_logger,lhttpc_sup,ale_sup,
                    lhttpc_manager,timer_server,standard_error_sup,
                    release_handler,httpd_sup,ale_dynamic_sup,overload,
                    alarm_handler,init,inet_db,rex,kernel_sup,'sink-ns_log',
                    global_name_server,sasl_safe_sup,crypto_server,crypto_sup,
                    file_server_2,tftp_sup,global_group,os_mon_sup,
                    'sink-disk_metakv',cpu_sup,tls_connection_sup,memsup,
                    ssl_sup,'sink-disk_access_int',disksup,'sink-disk_access',
                    ns_server_cluster_sup,httpc_sup,ssl_manager,
                    'sink-xdcr_trace',erl_prim_loader,'sink-disk_reports',
                    httpc_profile_sup,'sink-disk_stats',httpc_manager,
                    httpc_handler_sup,'sink-disk_xdcr_errors']},
               {cookie,nocookie},
               {wordsize,8},
               {wall_clock,3}]
[ns_server:info,2021-04-19T20:01:42.005Z,nonode@nohost:ns_server_cluster_sup<0.127.0>:log_os_info:start_link:27]Manifest:
["<?xml version=\"1.0\" encoding=\"UTF-8\"?>","<manifest>",
 "  <remote fetch=\"git://github.com/blevesearch/\" name=\"blevesearch\"/>",
 "  <remote fetch=\"git://github.com/couchbase/\" name=\"couchbase\" review=\"review.couchbase.org\"/>",
 "  <remote fetch=\"ssh://git@github.com/couchbase/\" name=\"couchbase-priv\" review=\"review.couchbase.org\"/>",
 "  <remote fetch=\"git://github.com/couchbasedeps/\" name=\"couchbasedeps\" review=\"review.couchbase.org\"/>",
 "  <remote fetch=\"git://github.com/couchbaselabs/\" name=\"couchbaselabs\" review=\"review.couchbase.org\"/>",
 "  ","  <default remote=\"couchbase\" revision=\"master\"/>","  ",
 "  <project groups=\"notdefault,enterprise\" name=\"backup\" path=\"goproj/src/github.com/couchbase/backup\" remote=\"couchbase-priv\" revision=\"469a5e8cc8661f35ab4af74fe45e92a3d89febed\"/>",
 "  <project name=\"bitset\" path=\"godeps/src/github.com/willf/bitset\" remote=\"couchbasedeps\" revision=\"28a4168144bb8ac95454e1f51c84da1933681ad4\"/>",
 "  <project name=\"blance\" path=\"godeps/src/github.com/couchbase/blance\" revision=\"5ce14d13954e04262b7eabfc6978776a4018402b\"/>",
 "  <project name=\"bleve\" path=\"godeps/src/github.com/blevesearch/bleve\" remote=\"blevesearch\" revision=\"f531835d5c212ee5f95c49d2debc28e65e6d1693\"/>",
 "  <project name=\"bleve-mapping-ui\" path=\"godeps/src/github.com/blevesearch/bleve-mapping-ui\" remote=\"blevesearch\" revision=\"b0453426dc1d59918cc763a970f1ad147b22ad6a\"/>",
 "  <project name=\"blevex\" path=\"godeps/src/github.com/blevesearch/blevex\" remote=\"blevesearch\" revision=\"918d980b0d244c8230c7d8c8ee40919f8d55ef88\"/>",
 "  <project name=\"bolt\" path=\"godeps/src/github.com/boltdb/bolt\" remote=\"couchbasedeps\" revision=\"51f99c862475898df9773747d3accd05a7ca33c1\"/>",
 "  <project name=\"buffer\" path=\"godeps/src/github.com/tdewolff/buffer\" remote=\"couchbasedeps\" revision=\"43cef5ba7b6ce99cc410632dad46cf1c6c97026e\"/>",
 "  <project groups=\"notdefault,build\" name=\"build\" path=\"cbbuild\" revision=\"ccd3ae52bbf0ade5fd59adcedba2b8cbbd16cd9b\">",
 "    <annotation name=\"VERSION\" value=\"4.6.0\"/>",
 "    <annotation name=\"BLD_NUM\" value=\"3573\"/>",
 "    <annotation name=\"RELEASE\" value=\"@RELEASE@\"/>",
 "    <annotation name=\"EDITION\" value=\"@EDITION@\"/>","  </project>",
 "  <project name=\"cbauth\" path=\"godeps/src/github.com/couchbase/cbauth\" revision=\"4a6d537777f57b291a8126f94dfbe3201c1d4efc\"/>",
 "  <project name=\"cbflag\" path=\"godeps/src/github.com/couchbase/cbflag\" revision=\"ce5c10adbb78c1212aefda73a85f8cfd1c3ae7e9\"/>",
 "  <project name=\"cbft\" path=\"goproj/src/github.com/couchbase/cbft\" revision=\"99f44266178dbe423890d8dd5bb9439ef2a71318\"/>",
 "  <project name=\"cbgt\" path=\"goproj/src/github.com/couchbase/cbgt\" revision=\"10790963d9cbada17ebfff728ea9298c1c97b7c5\"/>",
 "  <project groups=\"notdefault,enterprise\" name=\"cbq-gui\" path=\"goproj/src/github.com/couchbase/cbq-gui\" remote=\"couchbase-priv\" revision=\"1e19e5e34b64ca6b43a37de6166dac6e76803848\"/>",
 "  <project name=\"clog\" path=\"godeps/src/github.com/couchbase/clog\" revision=\"eebc98233c3e032eb6b9036575d51324ab5932e6\"/>",
 "  <project name=\"context\" path=\"godeps/src/github.com/gorilla/context\" remote=\"couchbasedeps\" revision=\"215affda49addc4c8ef7e2534915df2c8c35c6cd\"/>",
 "  <project name=\"couchbase-cli\" revision=\"951668b6b2fcaa5386b31d59df5004ff667e91e8\"/>",
 "  <project name=\"couchbase-examples\" revision=\"39ee1c2451ac2f2e86a6ff308e21e1201c49cafe\"/>",
 "  <project name=\"couchdb\" revision=\"7b950cfaa3ad30c75a7fcc7f4eb30b2df1a8bd5b\"/>",
 "  <project groups=\"notdefault,packaging\" name=\"couchdbx-app\" revision=\"be5f6ebaa12ac7c0b5382deb9b1b0efa7bf80497\"/>",
 "  <project groups=\"kv\" name=\"couchstore\" revision=\"9cf71ba60cf95f8b835b1040c68c85a4ddc653ee\"/>",
 "  <project name=\"crypto\" path=\"godeps/src/golang.org/x/crypto\" remote=\"couchbasedeps\" revision=\"f23ba3a5ee43012fcb4b92e1a2a405a92554f4f2\"/>",
 "  <project name=\"cznic-b\" path=\"godeps/src/github.com/cznic/b\" remote=\"couchbasedeps\" revision=\"b96e30f1b7bd34b0b9d8760798d67eca83d7f09e\"/>",
 "  <project name=\"dparval\" path=\"godeps/src/github.com/couchbase/dparval\" revision=\"9def03782da875a2477c05bf64985db3f19f59ae\"/>",
 "  <project groups=\"kv\" name=\"ep-engine\" revision=\"e4c8bcbbf20b52b11e93665901597875e10b2070\"/>",
 "  <project groups=\"kv\" name=\"forestdb\" revision=\"1d169510a5102e81547b1d3dc423eb37db908076\"/>",
 "  <project name=\"geocouch\" revision=\"74b4bab07713b233ca2780f9a9a3f7daa1a1dff4\"/>",
 "  <project name=\"go-bindata-assetfs\" path=\"godeps/src/github.com/elazarl/go-bindata-assetfs\" remote=\"couchbasedeps\" revision=\"57eb5e1fc594ad4b0b1dbea7b286d299e0cb43c2\"/>",
 "  <project name=\"go-couchbase\" path=\"godeps/src/github.com/couchbase/go-couchbase\" revision=\"e06e5adaf45e189d4cf3e471341af0bf80bcc312\"/>",
 "  <project name=\"go-jsonpointer\" path=\"godeps/src/github.com/dustin/go-jsonpointer\" remote=\"couchbasedeps\" revision=\"75939f54b39e7dafae879e61f65438dadc5f288c\"/>",
 "  <project name=\"go-metrics\" path=\"godeps/src/github.com/rcrowley/go-metrics\" remote=\"couchbasedeps\" revision=\"dee209f2455f101a5e4e593dea94872d2c62d85d\"/>",
 "  <project name=\"go-porterstemmer\" path=\"godeps/src/github.com/blevesearch/go-porterstemmer\" remote=\"blevesearch\" revision=\"23a2c8e5cf1f380f27722c6d2ae8896431dc7d0e\"/>",
 "  <project name=\"go-slab\" path=\"godeps/src/github.com/couchbase/go-slab\" revision=\"1f5f7f282713ccfab3f46b1610cb8da34bcf676f\"/>",
 "  <project name=\"go-zookeeper\" path=\"godeps/src/github.com/samuel/go-zookeeper\" remote=\"couchbasedeps\" revision=\"fa6674abf3f4580b946a01bf7a1ce4ba8766205b\"/>",
 "  <project name=\"go_json\" path=\"godeps/src/github.com/couchbase/go_json\" revision=\"f5a178ab380eb9a1911cf9c45b4159115b564169\"/>",
 "  <project name=\"go_n1ql\" path=\"godeps/src/github.com/couchbase/go_n1ql\" revision=\"6cf4e348b127e21f56e53eb8c3faaea56afdc588\"/>",
 "  <project name=\"gocb\" path=\"godeps/src/github.com/couchbase/gocb\" revision=\"d5b1a13c1e81f1255ca8155007b470db37ddeb25\"/>",
 "  <project name=\"godbc\" path=\"godeps/src/github.com/couchbase/godbc\" revision=\"adc62033c392ca9df8b5b42c0dda237576b39f9f\"/>",
 "  <project name=\"goforestdb\" path=\"godeps/src/github.com/couchbase/goforestdb\" revision=\"0b501227de0e8c55d99ed14e900eea1a1dbaf899\"/>",
 "  <project name=\"gojson\" path=\"godeps/src/github.com/dustin/gojson\" remote=\"couchbasedeps\" revision=\"af16e0e771e2ed110f2785564ae33931de8829e4\"/>",
 "  <project name=\"golang-snappy\" path=\"godeps/src/github.com/golang/snappy\" remote=\"couchbasedeps\" revision=\"723cc1e459b8eea2dea4583200fd60757d40097a\"/>",
 "  <project name=\"goleveldb\" path=\"godeps/src/github.com/syndtr/goleveldb\" remote=\"couchbasedeps\" revision=\"fa5b5c78794bc5c18f330361059f871ae8c2b9d6\"/>",
 "  <project name=\"gomemcached\" path=\"godeps/src/github.com/couchbase/gomemcached\" revision=\"4604300463c4a379d36d1427b17d3284a93f7621\"/>",
 "  <project name=\"gometa\" path=\"goproj/src/github.com/couchbase/gometa\" revision=\"7da5634cce1de744293acf27bb2aecc13ee50cc5\"/>",
 "  <project groups=\"kv\" name=\"googletest\" remote=\"couchbasedeps\" revision=\"f397fa5ec6365329b2e82eb2d8c03a7897bbefb5\"/>",
 "  <project name=\"goskiplist\" path=\"godeps/src/github.com/ryszard/goskiplist\" remote=\"couchbasedeps\" revision=\"2dfbae5fcf46374f166f8969cb07e167f1be6273\"/>",
 "  <project name=\"gosnappy\" path=\"godeps/src/github.com/syndtr/gosnappy\" remote=\"couchbasedeps\" revision=\"156a073208e131d7d2e212cb749feae7c339e846\"/>",
 "  <project name=\"goutils\" path=\"godeps/src/github.com/couchbase/goutils\" revision=\"5823a0cbaaa9008406021dc5daf80125ea30bba6\"/>",
 "  <project name=\"goxdcr\" path=\"goproj/src/github.com/couchbase/goxdcr\" revision=\"0f66d74c38453d0c1a620588edb4ee6a8fc22577\"/>",
 "  <project name=\"gtreap\" path=\"godeps/src/github.com/steveyen/gtreap\" remote=\"couchbasedeps\" revision=\"0abe01ef9be25c4aedc174758ec2d917314d6d70\"/>",
 "  <project name=\"indexing\" path=\"goproj/src/github.com/couchbase/indexing\" revision=\"1811cdbff66216861320b7657590e961b10b2c0a\"/>",
 "  <project name=\"levigo\" path=\"godeps/src/github.com/jmhodges/levigo\" remote=\"couchbasedeps\" revision=\"1ddad808d437abb2b8a55a950ec2616caa88969b\"/>",
 "  <project name=\"liner\" path=\"godeps/src/github.com/peterh/liner\" remote=\"couchbasedeps\" revision=\"ad1edfd30321d8f006ccf05f1e0524adeb943060\"/>",
 "  <project name=\"liner\" path=\"godeps/src/github.com/sbinet/liner\" remote=\"couchbasedeps\" revision=\"d9335eee40a45a4f5d74524c90040d6fe6013d50\"/>",
 "  <project groups=\"kv\" name=\"memcached\" revision=\"45a464250e1358593fa9f11ec010ddd992f0a717\"/>",
 "  <project name=\"minify\" path=\"godeps/src/github.com/tdewolff/minify\" remote=\"couchbasedeps\" revision=\"ede45cc53f43891267b1fe7c689db9c76d4ce0fb\"/>",
 "  <project name=\"mmap-go\" path=\"godeps/src/github.com/edsrzf/mmap-go\" remote=\"couchbasedeps\" revision=\"935e0e8a636ca4ba70b713f3e38a19e1b77739e8\"/>",
 "  <project name=\"moss\" path=\"godeps/src/github.com/couchbase/moss\" revision=\"c7cc82a67cf3fe50faf9a0697516b885e4fa34b9\"/>",
 "  <project groups=\"kv\" name=\"moxi\" revision=\"363c250e6087a61bf2d4bc8d6eff3325956be731\"/>",
 "  <project name=\"mux\" path=\"godeps/src/github.com/gorilla/mux\" remote=\"couchbasedeps\" revision=\"8a875a034c69b940914d83ea03d3f1299b4d094b\"/>",
 "  <project name=\"net\" path=\"godeps/src/golang.org/x/net\" remote=\"couchbasedeps\" revision=\"8968c61983e8f51a91b8c0ef25bf739278c89634\"/>",
 "  <project name=\"npipe\" path=\"godeps/src/github.com/natefinch/npipe\" remote=\"couchbasedeps\" revision=\"272c8150302e83f23d32a355364578c9c13ab20f\"/>",
 "  <project name=\"ns_server\" revision=\"b6c99dc71308f44261bbcc80688de02942d69f19\"/>",
 "  <project name=\"parse\" path=\"godeps/src/github.com/tdewolff/parse\" remote=\"couchbasedeps\" revision=\"0334a869253aca4b3a10c56c3f3139b394aec3a9\"/>",
 "  <project groups=\"kv\" name=\"platform\" revision=\"a80097d53c779b548d8c78b0a1886b8d44591b23\"/>",
 "  <project name=\"protobuf\" path=\"godeps/src/github.com/golang/protobuf\" remote=\"couchbasedeps\" revision=\"655cdfa588ea190e901bc5590e65d5621688847c\"/>",
 "  <project name=\"query\" path=\"goproj/src/github.com/couchbase/query\" revision=\"2012f9b883199299df53dec638a2b91c21907a53\"/>",
 "  <project name=\"query-ui\" revision=\"ff1f502b2f0c544ca68d2bda60d80fc3a01d573a\"/>",
 "  <project name=\"retriever\" path=\"godeps/src/github.com/couchbase/retriever\" revision=\"e3419088e4d3b4fe3aad3b364fdbe9a154f85f17\"/>",
 "  <project name=\"segment\" path=\"godeps/src/github.com/blevesearch/segment\" remote=\"blevesearch\" revision=\"db70c57796cc8c310613541dfade3dce627d09c7\"/>",
 "  <project groups=\"kv\" name=\"sigar\" revision=\"83bd88595f558987731a1baa3330f641bc36554c\"/>",
 "  <project name=\"strconv\" path=\"godeps/src/github.com/tdewolff/strconv\" remote=\"couchbasedeps\" revision=\"9b189f5be77f33c46776f24dbddb2a7ab32af214\"/>",
 "  <project groups=\"kv\" name=\"subjson\" revision=\"65d3f053e2d968aea00b60234a42e1d1c5b9f6d2\"/>",
 "  <project groups=\"solaris,notdefault\" name=\"sys\" path=\"godeps/src/golang.org/x/sys\" remote=\"couchbasedeps\" revision=\"9d4e42a20653790449273b3c85e67d6d8bae6e2e\"/>",
 "  <project name=\"testrunner\" revision=\"d63ed33d4130ecac236711b4156d41328728e42e\"/>",
 "  <project name=\"text\" path=\"godeps/src/golang.org/x/text\" remote=\"couchbasedeps\" revision=\"601048ad6acbab6cedd582db09b8c4839ff25b15\"/>",
 "  <project groups=\"kv\" name=\"tlm\" revision=\"29fafd6b365e58e9fc43fad749ce20c900890a6b\">",
 "    <copyfile dest=\"GNUmakefile\" src=\"GNUmakefile\"/>",
 "    <copyfile dest=\"Makefile\" src=\"Makefile\"/>",
 "    <copyfile dest=\"CMakeLists.txt\" src=\"CMakeLists.txt\"/>",
 "  </project>",
 "  <project name=\"ts\" path=\"godeps/src/github.com/olekukonko/ts\" remote=\"couchbasedeps\" revision=\"ecf753e7c962639ab5a1fb46f7da627d4c0a04b8\"/>",
 "  <project groups=\"notdefault,packaging\" name=\"voltron\" remote=\"couchbase-priv\" revision=\"876e25cffb99e0ae89078a0443b179bcb5d639c2\"/>",
 "</manifest>"]

[error_logger:info,2021-04-19T20:01:42.010Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.129.0>},
                       {name,timeout_diag_logger},
                       {mfargs,{timeout_diag_logger,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T20:01:42.013Z,nonode@nohost:dist_manager<0.130.0>:dist_manager:read_address_config_from_path:86]Reading ip config from "/opt/couchbase/var/lib/couchbase/ip_start"
[ns_server:info,2021-04-19T20:01:42.013Z,nonode@nohost:dist_manager<0.130.0>:dist_manager:read_address_config_from_path:86]Reading ip config from "/opt/couchbase/var/lib/couchbase/ip"
[ns_server:info,2021-04-19T20:01:42.014Z,nonode@nohost:dist_manager<0.130.0>:dist_manager:init:163]ip config not found. Looks like we're brand new node
[error_logger:info,2021-04-19T20:01:42.015Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,inet_gethost_native_sup}
             started: [{pid,<0.132.0>},{mfa,{inet_gethost_native,init,[[]]}}]

[error_logger:info,2021-04-19T20:01:42.015Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.131.0>},
                       {name,inet_gethost_native_sup},
                       {mfargs,{inet_gethost_native,start_link,[]}},
                       {restart_type,temporary},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T20:01:42.715Z,nonode@nohost:dist_manager<0.130.0>:dist_manager:bringup:214]Attempting to bring up net_kernel with name 'ns_1@127.0.0.1'
[error_logger:info,2021-04-19T20:01:42.725Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.134.0>},
                       {name,erl_epmd},
                       {mfargs,{erl_epmd,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:42.725Z,nonode@nohost:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.135.0>},
                       {name,auth},
                       {mfargs,{auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:42.725Z,ns_1@127.0.0.1:dist_manager<0.130.0>:dist_manager:configure_net_kernel:255]Set net_kernel vebosity to 10 -> 0
[error_logger:info,2021-04-19T20:01:42.725Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,net_sup}
             started: [{pid,<0.136.0>},
                       {name,net_kernel},
                       {mfargs,
                           {net_kernel,start_link,
                               [['ns_1@127.0.0.1',longnames]]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:42.725Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_sup}
             started: [{pid,<0.133.0>},
                       {name,net_sup_dynamic},
                       {mfargs,
                           {erl_distribution,start_link,
                               [['ns_1@127.0.0.1',longnames]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,supervisor}]

[ns_server:info,2021-04-19T20:01:42.728Z,ns_1@127.0.0.1:dist_manager<0.130.0>:dist_manager:save_node:147]saving node to "/opt/couchbase/var/lib/couchbase/couchbase-server.node"
[ns_server:debug,2021-04-19T20:01:42.750Z,ns_1@127.0.0.1:dist_manager<0.130.0>:dist_manager:bringup:228]Attempted to save node name to disk: ok
[ns_server:debug,2021-04-19T20:01:42.750Z,ns_1@127.0.0.1:dist_manager<0.130.0>:dist_manager:wait_for_node:235]Waiting for connection to node 'babysitter_of_ns_1@127.0.0.1' to be established
[error_logger:info,2021-04-19T20:01:42.750Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'babysitter_of_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T20:01:42.759Z,ns_1@127.0.0.1:dist_manager<0.130.0>:dist_manager:wait_for_node:244]Observed node 'babysitter_of_ns_1@127.0.0.1' to come up
[error_logger:info,2021-04-19T20:01:42.765Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.130.0>},
                       {name,dist_manager},
                       {mfargs,{dist_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:42.767Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.141.0>},
                       {name,ns_cookie_manager},
                       {mfargs,{ns_cookie_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:42.768Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.142.0>},
                       {name,ns_cluster},
                       {mfargs,{ns_cluster,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T20:01:42.770Z,ns_1@127.0.0.1:ns_config_sup<0.143.0>:ns_config_sup:init:32]loading static ns_config from "/opt/couchbase/etc/couchbase/config"
[error_logger:info,2021-04-19T20:01:42.770Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.144.0>},
                       {name,ns_config_events},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_config_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:42.770Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.145.0>},
                       {name,ns_config_events_local},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,ns_config_events_local}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:info,2021-04-19T20:01:42.820Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_config:load_config:1083]Loading static config from "/opt/couchbase/etc/couchbase/config"
[ns_server:info,2021-04-19T20:01:42.827Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_config:load_config:1097]Loading dynamic config from "/opt/couchbase/var/lib/couchbase/config/config.dat"
[ns_server:debug,2021-04-19T20:01:42.841Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_config:load_config:1105]Here's full dynamic config we loaded:
[[{{metakv,<<"/indexing/settings/config">>},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{6,63786081264}}]}|
    <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.log_level\":\"info\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\":200,\"indexer.settings.max_cpu_percent\":0,\"indexer.settings.storage_mode\":\"memory_optimized\",\"indexer.settings.recovery.max_rollbacks\":5,\"indexer.settings.memory_quota\":314572800,\"indexer.settings.compaction.abort_exceed_interval\":false}">>]},
  {alert_limits,
   [{max_overhead_perc,50},{max_disk_used,90},{max_indexer_ram,75}]},
  {audit,
   [{auditd_enabled,false},
    {rotate_interval,86400},
    {rotate_size,20971520},
    {disabled,[]},
    {sync,[]},
    {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]},
  {auto_failover_cfg,[{enabled,false},{timeout,120},{max_nodes,1},{count,0}]},
  {autocompaction,
   [{database_fragmentation_threshold,{30,undefined}},
    {view_fragmentation_threshold,{30,undefined}}]},
  {buckets,[{configs,[]}]},
  {cert_and_pkey,
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080742}}]}|
    {<<"-----BEGIN CERTIFICATE-----\nMIIDAjCCAeqgAwIBAgIIFndZ/vr3iFgwDQYJKoZIhvcNAQELBQAwJDEiMCAGA1UE\nAxMZQ291Y2hiYXNlIFNlcnZlciBiODgwZTU4MjAeFw0xMzAxMDEwMDAwMDBaFw00\nOTEyMzEyMzU5NTlaMCQxIjAgBgNVBAMTGUNvdWNoYmFzZSBTZXJ2ZXIgYjg4MGU1\nODIwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDPKYjrGZUDKn7xXZhz\n/CcGig/KlI7xzgbLixQnJ5VLNHQOaIcz01bkH2SuTUnIg3i9awTEc/vdraqbL7dK\neAQZEWpnUrZo8sPI/sI9nYnAJttUCQD0cmsC1X0n0uNxaGVj2i2RsOvbPM+EJHOM\nWEESG/u7+Wf4aeV43AqreUXuiGwy7huZuTMU0MK1/qM2XbG2/cv2Oj7HZ6Sqp8vH\n1jEQqyG0I2NJyGfAEvHnswY2t99lDunBJJEjf0am2BJkC23tMZPmLWoTqTT4CSuK\n1Fl1OKj/ZM5dwDwHEmks1I/q88rXRA4AYZQWDdLCM8aZvhUYP0yKj585/v/HmMN4\nkFRVAgMBAAGjODA2MA4GA1UdDwEB/wQEAwICpDATBgNVHSUEDDAKBggrBgEFBQcD\nATAPBgNVHRMBAf8EBTADAQH/MA0GCSqGSIb3DQEBCwUAA4IBAQBLvg8P2SCkc22T\n8fwRrq7jUh+N0Qo/khU0rHZqC7DKJtI9j8e3yFQcxYPCCAOYfaEO9hPDhckBwJGE\nnjoLrfPGHHWM2Tw4RHrYcJ8q5UMjPqCM422ylEzf/vRYUbC175vfo41zkR/F7TYt\napV4DiUM6YmXssYtW66yEcwsZMyDpu/kl/c7+H0yKANJugp8mJWHsnHszvBdn+FT\ns0yV4IGMUPaFMJZOwG+yVlRtAQnZufEzxSgIT0mYWk1DjU+ji8w7r8nthDJoJRqN\nObL+ZMUIupp8NnGF7xz5ll4nmeup8M8CYTnyS0L1tqQ2/Qo0mOy5bwfZuTqzHJE2\nP6fNdAiq\n-----END CERTIFICATE-----\n">>,
     <<"*****">>}]},
  {cluster_compat_version,
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{6,63786080749}}]},
    4,6]},
  {drop_request_memory_threshold_mib,undefined},
  {email_alerts,
   [{recipients,["root@localhost"]},
    {sender,"couchbase@localhost"},
    {enabled,false},
    {email_server,
     [{user,[]},{pass,"*****"},{host,"localhost"},{port,25},{encrypt,false}]},
    {alerts,
     [auto_failover_node,auto_failover_maximum_reached,
      auto_failover_other_nodes_down,auto_failover_cluster_too_small,
      auto_failover_disabled,ip,disk,overhead,ep_oom_errors,
      ep_item_commit_failed,audit_dropped_events,indexer_ram_max_usage,
      ep_clock_cas_drift_threshold_exceeded]}]},
  {fts_memory_quota,512},
  {goxdcr_upgrade,
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080749}}]}|
    '_deleted']},
  {index_aware_rebalance_disabled,false},
  {max_bucket_count,10},
  {memcached,[]},
  {memory_quota,
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080757}}]}|
    300]},
  {nodes_wanted,['ns_1@127.0.0.1']},
  {otp,
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080748}}]},
    {cookie,{sanitized,<<"igGdfqmbza2bbcUGcHlgLfqDrDSw4MuqpdcFvTedqb0=">>}}]},
  {read_only_user_creds,
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080749}}]}|
    null]},
  {remote_clusters,[]},
  {replication,[{enabled,true}]},
  {rest,[{port,8091}]},
  {rest_creds,
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{2,63786080757}}]}|
    {"Administrator",{password,"*****"}}]},
  {roles_definitions,
   [{admin,[],
     [{name,<<"Admin">>},
      {desc,<<"Can manage ALL cluster features including security.">>}],
     [{[],all}]},
    {ro_admin,[],
     [{name,<<"Read Only Admin">>},
      {desc,<<"Can view ALL cluster features.">>}],
     [{[{bucket,any},password],none},
      {[{bucket,any},data],none},
      {[admin,security],[read]},
      {[admin],none},
      {[],[read]}]},
    {cluster_admin,[],
     [{name,<<"Cluster Admin">>},
      {desc,<<"Can manage all cluster features EXCEPT security.">>}],
     [{[admin],none},{[],all}]},
    {bucket_admin,
     [bucket_name],
     [{name,<<"Bucket Admin">>},
      {desc,
       <<"Can manage ALL bucket features for specified buckets (incl. start/stop XDCR)">>}],
     [{[{bucket,bucket_name},xdcr],[read,execute]},
      {[{bucket,bucket_name}],all},
      {[{bucket,any},settings],[read]},
      {[{bucket,any}],none},
      {[xdcr],none},
      {[admin],none},
      {[],[read]}]},
    {bucket_sasl,
     [bucket_name],
     [],
     [{[{bucket,bucket_name},data],all},
      {[{bucket,bucket_name},views],all},
      {[{bucket,bucket_name}],[read,flush]},
      {[pools],[read]}]},
    {views_admin,
     [bucket_name],
     [{name,<<"Views Admin">>},
      {desc,<<"Can manage views for specified buckets">>}],
     [{[{bucket,bucket_name},views],all},
      {[{bucket,bucket_name},data],[read]},
      {[{bucket,any},settings],[read]},
      {[{bucket,any}],none},
      {[xdcr],none},
      {[admin],none},
      {[],[read]}]},
    {replication_admin,[],
     [{name,<<"Replication Admin">>},
      {desc,<<"Can manage ONLY XDCR features (cluster AND bucket level)">>}],
     [{[{bucket,any},xdcr],all},
      {[{bucket,any},data],[read]},
      {[{bucket,any},settings],[read]},
      {[{bucket,any}],none},
      {[xdcr],all},
      {[admin],none},
      {[],[read]}]}]},
  {server_groups,
   [[{uuid,<<"0">>},{name,<<"Group 1">>},{nodes,['ns_1@127.0.0.1']}]]},
  {set_view_update_daemon,
   [{update_interval,5000},
    {update_min_changes,5000},
    {replica_update_min_changes,5000}]},
  {uuid,
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080757}}]}|
    <<"819b5f49755d4c5571ba2861d6185103">>]},
  {{couchdb,max_parallel_indexers},4},
  {{couchdb,max_parallel_replica_indexers},2},
  {{local_changes_count,<<"360fb3d3641e00b1f4f22714c24e2a2a">>},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{14,63786081264}}]}]},
  {{request_limit,capi},undefined},
  {{request_limit,rest},undefined},
  {{service_map,fts},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080749}}]}]},
  {{service_map,index},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{2,63786080759}}]},
    'ns_1@127.0.0.1']},
  {{service_map,n1ql},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{2,63786080759}}]},
    'ns_1@127.0.0.1']},
  {{node,'ns_1@127.0.0.1',audit},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}]},
  {{node,'ns_1@127.0.0.1',capi_port},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    8092]},
  {{node,'ns_1@127.0.0.1',compaction_daemon},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
    {check_interval,30},
    {min_db_file_size,131072},
    {min_view_file_size,20971520}]},
  {{node,'ns_1@127.0.0.1',config_version},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    {4,5}]},
  {{node,'ns_1@127.0.0.1',fts_http_port},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    8094]},
  {{node,'ns_1@127.0.0.1',indexer_admin_port},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    9100]},
  {{node,'ns_1@127.0.0.1',indexer_http_port},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    9102]},
  {{node,'ns_1@127.0.0.1',indexer_scan_port},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    9101]},
  {{node,'ns_1@127.0.0.1',indexer_stcatchup_port},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    9104]},
  {{node,'ns_1@127.0.0.1',indexer_stinit_port},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    9103]},
  {{node,'ns_1@127.0.0.1',indexer_stmaint_port},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    9105]},
  {{node,'ns_1@127.0.0.1',is_enterprise},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    true]},
  {{node,'ns_1@127.0.0.1',isasl},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
    {path,"/opt/couchbase/var/lib/couchbase/isasl.pw"}]},
  {{node,'ns_1@127.0.0.1',ldap_enabled},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    true]},
  {{node,'ns_1@127.0.0.1',membership},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    active]},
  {{node,'ns_1@127.0.0.1',memcached},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
    {port,11210},
    {dedicated_port,11209},
    {ssl_port,11207},
    {admin_user,"_admin"},
    {admin_pass,"*****"},
    {engines,
     [{membase,
       [{engine,"/opt/couchbase/lib/memcached/ep.so"},
        {static_config_string,"failpartialwarmup=false"}]},
      {memcached,
       [{engine,"/opt/couchbase/lib/memcached/default_engine.so"},
        {static_config_string,"vb0=true"}]}]},
    {config_path,"/opt/couchbase/var/lib/couchbase/config/memcached.json"},
    {audit_file,"/opt/couchbase/var/lib/couchbase/config/audit.json"},
    {log_path,"/opt/couchbase/var/lib/couchbase/logs"},
    {log_prefix,"memcached.log"},
    {log_generations,20},
    {log_cyclesize,10485760},
    {log_sleeptime,19},
    {log_rotation_period,39003}]},
  {{node,'ns_1@127.0.0.1',memcached_config},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    {[{interfaces,
       {memcached_config_mgr,omit_missing_mcd_ports,
        [{[{host,<<"*">>},{port,port},{maxconn,maxconn}]},
         {[{host,<<"*">>},
           {port,dedicated_port},
           {maxconn,dedicated_port_maxconn}]},
         {[{host,<<"*">>},
           {port,ssl_port},
           {maxconn,maxconn},
           {ssl,
            {[{key,
               <<"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem">>},
              {cert,
               <<"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem">>}]}}]}]}},
      {ssl_cipher_list,{"~s",[ssl_cipher_list]}},
      {ssl_minimum_protocol,{memcached_config_mgr,ssl_minimum_protocol,[]}},
      {connection_idle_time,connection_idle_time},
      {breakpad,
       {[{enabled,breakpad_enabled},
         {minidump_dir,{memcached_config_mgr,get_minidump_dir,[]}}]}},
      {extensions,
       [{[{module,<<"/opt/couchbase/lib/memcached/stdin_term_handler.so">>},
          {config,<<>>}]},
        {[{module,<<"/opt/couchbase/lib/memcached/file_logger.so">>},
          {config,
           {"cyclesize=~B;sleeptime=~B;filename=~s/~s",
            [log_cyclesize,log_sleeptime,log_path,log_prefix]}}]}]},
      {admin,{"~s",[admin_user]}},
      {verbosity,verbosity},
      {audit_file,{"~s",[audit_file]}},
      {dedupe_nmvb_maps,dedupe_nmvb_maps}]}]},
  {{node,'ns_1@127.0.0.1',memcached_defaults},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
    {maxconn,30000},
    {dedicated_port_maxconn,5000},
    {ssl_cipher_list,"HIGH"},
    {connection_idle_time,0},
    {verbosity,0},
    {breakpad_enabled,true},
    {breakpad_minidump_dir_path,"/opt/couchbase/var/lib/couchbase/crash"},
    {dedupe_nmvb_maps,false}]},
  {{node,'ns_1@127.0.0.1',moxi},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
    {port,11211},
    {verbosity,[]}]},
  {{node,'ns_1@127.0.0.1',ns_log},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
    {filename,"/opt/couchbase/var/lib/couchbase/ns_log"}]},
  {{node,'ns_1@127.0.0.1',port_servers},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}]},
  {{node,'ns_1@127.0.0.1',projector_port},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    9999]},
  {{node,'ns_1@127.0.0.1',query_port},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    8093]},
  {{node,'ns_1@127.0.0.1',rest},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
    {port,8091},
    {port_meta,global}]},
  {{node,'ns_1@127.0.0.1',services},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080757}}]},
    index,kv,n1ql]},
  {{node,'ns_1@127.0.0.1',ssl_capi_port},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    18092]},
  {{node,'ns_1@127.0.0.1',ssl_proxy_downstream_port},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    11214]},
  {{node,'ns_1@127.0.0.1',ssl_proxy_upstream_port},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    11215]},
  {{node,'ns_1@127.0.0.1',ssl_query_port},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    18093]},
  {{node,'ns_1@127.0.0.1',ssl_rest_port},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    18091]},
  {{node,'ns_1@127.0.0.1',stop_xdcr},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{2,63786080749}}]}|
    '_deleted']},
  {{node,'ns_1@127.0.0.1',uuid},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    <<"360fb3d3641e00b1f4f22714c24e2a2a">>]},
  {{node,'ns_1@127.0.0.1',xdcr_rest_port},
   [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
    9998]}]]
[ns_server:info,2021-04-19T20:01:42.848Z,ns_1@127.0.0.1:ns_config<0.146.0>:ns_config:load_config:1126]Here's full dynamic config we loaded + static & default config:
[{{node,'ns_1@127.0.0.1',xdcr_rest_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   9998]},
 {{node,'ns_1@127.0.0.1',uuid},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   <<"360fb3d3641e00b1f4f22714c24e2a2a">>]},
 {{node,'ns_1@127.0.0.1',stop_xdcr},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{2,63786080749}}]}|
   '_deleted']},
 {{node,'ns_1@127.0.0.1',ssl_rest_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   18091]},
 {{node,'ns_1@127.0.0.1',ssl_query_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   18093]},
 {{node,'ns_1@127.0.0.1',ssl_proxy_upstream_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   11215]},
 {{node,'ns_1@127.0.0.1',ssl_proxy_downstream_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   11214]},
 {{node,'ns_1@127.0.0.1',ssl_capi_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   18092]},
 {{node,'ns_1@127.0.0.1',services},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080757}}]},
   index,kv,n1ql]},
 {{node,'ns_1@127.0.0.1',rest},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
   {port,8091},
   {port_meta,global}]},
 {{node,'ns_1@127.0.0.1',query_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   8093]},
 {{node,'ns_1@127.0.0.1',projector_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   9999]},
 {{node,'ns_1@127.0.0.1',port_servers},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}]},
 {{node,'ns_1@127.0.0.1',ns_log},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
   {filename,"/opt/couchbase/var/lib/couchbase/ns_log"}]},
 {{node,'ns_1@127.0.0.1',moxi},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
   {port,11211},
   {verbosity,[]}]},
 {{node,'ns_1@127.0.0.1',memcached_defaults},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
   {maxconn,30000},
   {dedicated_port_maxconn,5000},
   {ssl_cipher_list,"HIGH"},
   {connection_idle_time,0},
   {verbosity,0},
   {breakpad_enabled,true},
   {breakpad_minidump_dir_path,"/opt/couchbase/var/lib/couchbase/crash"},
   {dedupe_nmvb_maps,false}]},
 {{node,'ns_1@127.0.0.1',memcached_config},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   {[{interfaces,
      {memcached_config_mgr,omit_missing_mcd_ports,
       [{[{host,<<"*">>},{port,port},{maxconn,maxconn}]},
        {[{host,<<"*">>},
          {port,dedicated_port},
          {maxconn,dedicated_port_maxconn}]},
        {[{host,<<"*">>},
          {port,ssl_port},
          {maxconn,maxconn},
          {ssl,
           {[{key,
              <<"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem">>},
             {cert,
              <<"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem">>}]}}]}]}},
     {ssl_cipher_list,{"~s",[ssl_cipher_list]}},
     {ssl_minimum_protocol,{memcached_config_mgr,ssl_minimum_protocol,[]}},
     {connection_idle_time,connection_idle_time},
     {breakpad,
      {[{enabled,breakpad_enabled},
        {minidump_dir,{memcached_config_mgr,get_minidump_dir,[]}}]}},
     {extensions,
      [{[{module,<<"/opt/couchbase/lib/memcached/stdin_term_handler.so">>},
         {config,<<>>}]},
       {[{module,<<"/opt/couchbase/lib/memcached/file_logger.so">>},
         {config,
          {"cyclesize=~B;sleeptime=~B;filename=~s/~s",
           [log_cyclesize,log_sleeptime,log_path,log_prefix]}}]}]},
     {admin,{"~s",[admin_user]}},
     {verbosity,verbosity},
     {audit_file,{"~s",[audit_file]}},
     {dedupe_nmvb_maps,dedupe_nmvb_maps}]}]},
 {{node,'ns_1@127.0.0.1',memcached},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
   {port,11210},
   {dedicated_port,11209},
   {ssl_port,11207},
   {admin_user,"_admin"},
   {admin_pass,"*****"},
   {engines,
    [{membase,
      [{engine,"/opt/couchbase/lib/memcached/ep.so"},
       {static_config_string,"failpartialwarmup=false"}]},
     {memcached,
      [{engine,"/opt/couchbase/lib/memcached/default_engine.so"},
       {static_config_string,"vb0=true"}]}]},
   {config_path,"/opt/couchbase/var/lib/couchbase/config/memcached.json"},
   {audit_file,"/opt/couchbase/var/lib/couchbase/config/audit.json"},
   {log_path,"/opt/couchbase/var/lib/couchbase/logs"},
   {log_prefix,"memcached.log"},
   {log_generations,20},
   {log_cyclesize,10485760},
   {log_sleeptime,19},
   {log_rotation_period,39003}]},
 {{node,'ns_1@127.0.0.1',membership},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   active]},
 {{node,'ns_1@127.0.0.1',ldap_enabled},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   true]},
 {{node,'ns_1@127.0.0.1',isasl},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
   {path,"/opt/couchbase/var/lib/couchbase/isasl.pw"}]},
 {{node,'ns_1@127.0.0.1',is_enterprise},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   true]},
 {{node,'ns_1@127.0.0.1',indexer_stmaint_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   9105]},
 {{node,'ns_1@127.0.0.1',indexer_stinit_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   9103]},
 {{node,'ns_1@127.0.0.1',indexer_stcatchup_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   9104]},
 {{node,'ns_1@127.0.0.1',indexer_scan_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   9101]},
 {{node,'ns_1@127.0.0.1',indexer_http_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   9102]},
 {{node,'ns_1@127.0.0.1',indexer_admin_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   9100]},
 {{node,'ns_1@127.0.0.1',fts_http_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   8094]},
 {{node,'ns_1@127.0.0.1',config_version},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   {4,5}]},
 {{node,'ns_1@127.0.0.1',compaction_daemon},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
   {check_interval,30},
   {min_db_file_size,131072},
   {min_view_file_size,20971520}]},
 {{node,'ns_1@127.0.0.1',capi_port},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
   8092]},
 {{node,'ns_1@127.0.0.1',audit},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}]},
 {{service_map,n1ql},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{2,63786080759}}]},
   'ns_1@127.0.0.1']},
 {{service_map,index},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{2,63786080759}}]},
   'ns_1@127.0.0.1']},
 {{service_map,fts},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080749}}]}]},
 {{request_limit,rest},undefined},
 {{request_limit,capi},undefined},
 {{local_changes_count,<<"360fb3d3641e00b1f4f22714c24e2a2a">>},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{14,63786081264}}]}]},
 {{couchdb,max_parallel_replica_indexers},2},
 {{couchdb,max_parallel_indexers},4},
 {uuid,
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080757}}]}|
   <<"819b5f49755d4c5571ba2861d6185103">>]},
 {set_view_update_daemon,
  [{update_interval,5000},
   {update_min_changes,5000},
   {replica_update_min_changes,5000}]},
 {server_groups,
  [[{uuid,<<"0">>},{name,<<"Group 1">>},{nodes,['ns_1@127.0.0.1']}]]},
 {roles_definitions,
  [{admin,[],
    [{name,<<"Admin">>},
     {desc,<<"Can manage ALL cluster features including security.">>}],
    [{[],all}]},
   {ro_admin,[],
    [{name,<<"Read Only Admin">>},{desc,<<"Can view ALL cluster features.">>}],
    [{[{bucket,any},password],none},
     {[{bucket,any},data],none},
     {[admin,security],[read]},
     {[admin],none},
     {[],[read]}]},
   {cluster_admin,[],
    [{name,<<"Cluster Admin">>},
     {desc,<<"Can manage all cluster features EXCEPT security.">>}],
    [{[admin],none},{[],all}]},
   {bucket_admin,
    [bucket_name],
    [{name,<<"Bucket Admin">>},
     {desc,
      <<"Can manage ALL bucket features for specified buckets (incl. start/stop XDCR)">>}],
    [{[{bucket,bucket_name},xdcr],[read,execute]},
     {[{bucket,bucket_name}],all},
     {[{bucket,any},settings],[read]},
     {[{bucket,any}],none},
     {[xdcr],none},
     {[admin],none},
     {[],[read]}]},
   {bucket_sasl,
    [bucket_name],
    [],
    [{[{bucket,bucket_name},data],all},
     {[{bucket,bucket_name},views],all},
     {[{bucket,bucket_name}],[read,flush]},
     {[pools],[read]}]},
   {views_admin,
    [bucket_name],
    [{name,<<"Views Admin">>},
     {desc,<<"Can manage views for specified buckets">>}],
    [{[{bucket,bucket_name},views],all},
     {[{bucket,bucket_name},data],[read]},
     {[{bucket,any},settings],[read]},
     {[{bucket,any}],none},
     {[xdcr],none},
     {[admin],none},
     {[],[read]}]},
   {replication_admin,[],
    [{name,<<"Replication Admin">>},
     {desc,<<"Can manage ONLY XDCR features (cluster AND bucket level)">>}],
    [{[{bucket,any},xdcr],all},
     {[{bucket,any},data],[read]},
     {[{bucket,any},settings],[read]},
     {[{bucket,any}],none},
     {[xdcr],all},
     {[admin],none},
     {[],[read]}]}]},
 {rest_creds,
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{2,63786080757}}]}|
   {"Administrator",{password,"*****"}}]},
 {rest,[{port,8091}]},
 {replication,[{enabled,true}]},
 {remote_clusters,[]},
 {read_only_user_creds,
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080749}}]}|
   null]},
 {otp,
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080748}}]},
   {cookie,{sanitized,<<"igGdfqmbza2bbcUGcHlgLfqDrDSw4MuqpdcFvTedqb0=">>}}]},
 {nodes_wanted,['ns_1@127.0.0.1']},
 {memory_quota,
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080757}}]}|
   300]},
 {memcached,[]},
 {max_bucket_count,10},
 {index_aware_rebalance_disabled,false},
 {goxdcr_upgrade,
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080749}}]}|
   '_deleted']},
 {fts_memory_quota,512},
 {email_alerts,
  [{recipients,["root@localhost"]},
   {sender,"couchbase@localhost"},
   {enabled,false},
   {email_server,
    [{user,[]},{pass,"*****"},{host,"localhost"},{port,25},{encrypt,false}]},
   {alerts,
    [auto_failover_node,auto_failover_maximum_reached,
     auto_failover_other_nodes_down,auto_failover_cluster_too_small,
     auto_failover_disabled,ip,disk,overhead,ep_oom_errors,
     ep_item_commit_failed,audit_dropped_events,indexer_ram_max_usage,
     ep_clock_cas_drift_threshold_exceeded]}]},
 {drop_request_memory_threshold_mib,undefined},
 {cluster_compat_version,
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{6,63786080749}}]},
   4,6]},
 {cert_and_pkey,
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080742}}]}|
   {<<"-----BEGIN CERTIFICATE-----\nMIIDAjCCAeqgAwIBAgIIFndZ/vr3iFgwDQYJKoZIhvcNAQELBQAwJDEiMCAGA1UE\nAxMZQ291Y2hiYXNlIFNlcnZlciBiODgwZTU4MjAeFw0xMzAxMDEwMDAwMDBaFw00\nOTEyMzEyMzU5NTlaMCQxIjAgBgNVBAMTGUNvdWNoYmFzZSBTZXJ2ZXIgYjg4MGU1\nODIwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDPKYjrGZUDKn7xXZhz\n/CcGig/KlI7xzgbLixQnJ5VLNHQOaIcz01bkH2SuTUnIg3i9awTEc/vdraqbL7dK\neAQZEWpnUrZo8sPI/sI9nYnAJttUCQD0cmsC1X0n0uNxaGVj2i2RsOvbPM+EJHOM\nWEESG/u7+Wf4aeV43AqreUXuiGwy7huZuTMU0MK1/qM2XbG2/cv2Oj7HZ6Sqp8vH\n1jEQqyG0I2NJyGfAEvHnswY2t99lDunBJJEjf0am2BJkC23tMZPmLWoTqTT4CSuK\n1Fl1OKj/ZM5dwDwHEmks1I/q88rXRA4AYZQWDdLCM8aZvhUYP0yKj585/v/HmMN4\nkFRVAgMBAAGjODA2MA4GA1UdDwEB/wQEAwICpDATBgNVHSUEDDAKBggrBgEFBQcD\nATAPBgNVHRMBAf8EBTADAQH/MA0GCSqGSIb3DQEBCwUAA4IBAQBLvg8P2SCkc22T\n8fwRrq7jUh+N0Qo/khU0rHZqC7DKJtI9j8e3yFQcxYPCCAOYfaEO9hPDhckBwJGE\nnjoLrfPGHHWM2Tw4RHrYcJ8q5UMjPqCM422ylEzf/vRYUbC175vfo41zkR/F7TYt\napV4DiUM6YmXssYtW66yEcwsZMyDpu/kl/c7+H0yKANJugp8mJWHsnHszvBdn+FT\ns0yV4IGMUPaFMJZOwG+yVlRtAQnZufEzxSgIT0mYWk1DjU+ji8w7r8nthDJoJRqN\nObL+ZMUIupp8NnGF7xz5ll4nmeup8M8CYTnyS0L1tqQ2/Qo0mOy5bwfZuTqzHJE2\nP6fNdAiq\n-----END CERTIFICATE-----\n">>,
    <<"*****">>}]},
 {buckets,[{configs,[]}]},
 {autocompaction,
  [{database_fragmentation_threshold,{30,undefined}},
   {view_fragmentation_threshold,{30,undefined}}]},
 {auto_failover_cfg,[{enabled,false},{timeout,120},{max_nodes,1},{count,0}]},
 {audit,
  [{auditd_enabled,false},
   {rotate_interval,86400},
   {rotate_size,20971520},
   {disabled,[]},
   {sync,[]},
   {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]},
 {alert_limits,
  [{max_overhead_perc,50},{max_disk_used,90},{max_indexer_ram,75}]},
 {{metakv,<<"/indexing/settings/config">>},
  [{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{6,63786081264}}]}|
   <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.log_level\":\"info\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\":200,\"indexer.settings.max_cpu_percent\":0,\"indexer.settings.storage_mode\":\"memory_optimized\",\"indexer.settings.recovery.max_rollbacks\":5,\"indexer.settings.memory_quota\":314572800,\"indexer.settings.compaction.abort_exceed_interval\":false}">>]}]
[error_logger:info,2021-04-19T20:01:42.851Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.146.0>},
                       {name,ns_config},
                       {mfargs,
                           {ns_config,start_link,
                               ["/opt/couchbase/etc/couchbase/config",
                                ns_config_default]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:42.853Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.149.0>},
                       {name,ns_config_remote},
                       {mfargs,
                           {ns_config_replica,start_link,
                               [{local,ns_config_remote}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:42.856Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_config_sup}
             started: [{pid,<0.150.0>},
                       {name,ns_config_log},
                       {mfargs,{ns_config_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:42.856Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.143.0>},
                       {name,ns_config_sup},
                       {mfargs,{ns_config_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T20:01:42.858Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.152.0>},
                       {name,vbucket_filter_changes_registry},
                       {mfargs,
                           {ns_process_registry,start_link,
                               [vbucket_filter_changes_registry,
                                [{terminate_command,shutdown}]]}},
                       {restart_type,permanent},
                       {shutdown,100},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:42.860Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.153.0>},
                       {name,json_rpc_connection_sup},
                       {mfargs,{json_rpc_connection_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T20:01:42.874Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.156.0>},
                       {name,remote_monitors},
                       {mfargs,{remote_monitors,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:42.876Z,ns_1@127.0.0.1:menelaus_barrier<0.157.0>:one_shot_barrier:barrier_body:58]Barrier menelaus_barrier has started
[error_logger:info,2021-04-19T20:01:42.876Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.157.0>},
                       {name,menelaus_barrier},
                       {mfargs,{menelaus_sup,barrier_start_link,[]}},
                       {restart_type,temporary},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:42.876Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.158.0>},
                       {name,rest_lhttpc_pool},
                       {mfargs,
                           {lhttpc_manager,start_link,
                               [[{name,rest_lhttpc_pool},
                                 {connection_timeout,120000},
                                 {pool_size,20}]]}},
                       {restart_type,{permanent,1}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T20:01:42.906Z,ns_1@127.0.0.1:ns_ssl_services_setup<0.160.0>:ns_ssl_services_setup:init:370]Used ssl options:
[{keyfile,"/opt/couchbase/var/lib/couchbase/config/ssl-cert-key.pem"},
 {certfile,"/opt/couchbase/var/lib/couchbase/config/ssl-cert-key.pem"},
 {versions,[tlsv1,'tlsv1.1','tlsv1.2']},
 {cacertfile,"/opt/couchbase/var/lib/couchbase/config/ssl-cert-key.pem-ca"},
 {dh,<<48,130,1,8,2,130,1,1,0,152,202,99,248,92,201,35,238,246,5,77,93,120,10,
       118,129,36,52,111,193,167,220,49,229,106,105,152,133,121,157,73,158,
       232,153,197,197,21,171,140,30,207,52,165,45,8,221,162,21,199,183,66,
       211,247,51,224,102,214,190,130,96,253,218,193,35,43,139,145,89,200,250,
       145,92,50,80,134,135,188,205,254,148,122,136,237,220,186,147,187,104,
       159,36,147,217,117,74,35,163,145,249,175,242,18,221,124,54,140,16,246,
       169,84,252,45,47,99,136,30,60,189,203,61,86,225,117,255,4,91,46,110,
       167,173,106,51,65,10,248,94,225,223,73,40,232,140,26,11,67,170,118,190,
       67,31,127,233,39,68,88,132,171,224,62,187,207,160,189,209,101,74,8,205,
       174,146,173,80,105,144,246,25,153,86,36,24,178,163,64,202,221,95,184,
       110,244,32,226,217,34,55,188,230,55,16,216,247,173,246,139,76,187,66,
       211,159,17,46,20,18,48,80,27,250,96,189,29,214,234,241,34,69,254,147,
       103,220,133,40,164,84,8,44,241,61,164,151,9,135,41,60,75,4,202,133,173,
       72,6,69,167,89,112,174,40,229,171,2,1,2>>},
 {ciphers,[{dhe_rsa,aes_256_cbc,sha256},
           {dhe_dss,aes_256_cbc,sha256},
           {rsa,aes_256_cbc,sha256},
           {dhe_rsa,aes_128_cbc,sha256},
           {dhe_dss,aes_128_cbc,sha256},
           {rsa,aes_128_cbc,sha256},
           {dhe_rsa,aes_256_cbc,sha},
           {dhe_dss,aes_256_cbc,sha},
           {rsa,aes_256_cbc,sha},
           {dhe_rsa,'3des_ede_cbc',sha},
           {dhe_dss,'3des_ede_cbc',sha},
           {rsa,'3des_ede_cbc',sha},
           {dhe_rsa,aes_128_cbc,sha},
           {dhe_dss,aes_128_cbc,sha},
           {rsa,aes_128_cbc,sha}]}]
[error_logger:info,2021-04-19T20:01:42.992Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_ssl_services_sup}
             started: [{pid,<0.160.0>},
                       {name,ns_ssl_services_setup},
                       {mfargs,{ns_ssl_services_setup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T20:01:43.029Z,ns_1@127.0.0.1:<0.162.0>:menelaus_pluggable_ui:validate_plugin_spec:117]Loaded pluggable UI specification for fts

[ns_server:info,2021-04-19T20:01:43.030Z,ns_1@127.0.0.1:<0.162.0>:menelaus_pluggable_ui:validate_plugin_spec:117]Loaded pluggable UI specification for n1ql

[ns_server:debug,2021-04-19T20:01:43.054Z,ns_1@127.0.0.1:<0.162.0>:restartable:start_child:98]Started child process <0.164.0>
  MFA: {ns_ssl_services_setup,start_link_rest_service,[]}
[error_logger:info,2021-04-19T20:01:43.054Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_ssl_services_sup}
             started: [{pid,<0.162.0>},
                       {name,ns_rest_ssl_service},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_ssl_services_setup,
                                    start_link_rest_service,[]},
                                1000]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:43.054Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.159.0>},
                       {name,ns_ssl_services_sup},
                       {mfargs,{ns_ssl_services_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2021-04-19T20:01:43.068Z,ns_1@127.0.0.1:wait_link_to_couchdb_node<0.182.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:126]Waiting for ns_couchdb node to start
[error_logger:info,2021-04-19T20:01:43.068Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.181.0>},
                       {name,start_couchdb_node},
                       {mfargs,{ns_server_nodes_sup,start_couchdb_node,[]}},
                       {restart_type,{permanent,5}},
                       {shutdown,86400000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:43.069Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T20:01:43.070Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.185.0>,shutdown}}
[ns_server:debug,2021-04-19T20:01:43.070Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T20:01:43.070Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T20:01:43.271Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T20:01:43.271Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.188.0>,shutdown}}
[ns_server:debug,2021-04-19T20:01:43.272Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T20:01:43.272Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T20:01:43.473Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T20:01:43.474Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.191.0>,shutdown}}
[ns_server:debug,2021-04-19T20:01:43.474Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T20:01:43.474Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T20:01:43.675Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T20:01:43.676Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T20:01:43.676Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.194.0>,shutdown}}
[error_logger:info,2021-04-19T20:01:43.676Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T20:01:43.877Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T20:01:43.878Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T20:01:43.878Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.197.0>,shutdown}}
[error_logger:info,2021-04-19T20:01:43.878Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T20:01:44.079Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T20:01:44.081Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.200.0>,shutdown}}
[ns_server:debug,2021-04-19T20:01:44.081Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T20:01:44.081Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T20:01:44.282Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T20:01:44.283Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.203.0>,shutdown}}
[ns_server:debug,2021-04-19T20:01:44.283Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T20:01:44.283Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T20:01:44.484Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T20:01:44.485Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T20:01:44.485Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.206.0>,shutdown}}
[error_logger:info,2021-04-19T20:01:44.485Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T20:01:44.686Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T20:01:44.687Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T20:01:44.687Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.209.0>,shutdown}}
[error_logger:info,2021-04-19T20:01:44.687Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T20:01:44.888Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T20:01:44.889Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T20:01:44.889Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.212.0>,shutdown}}
[error_logger:info,2021-04-19T20:01:44.889Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T20:01:45.090Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T20:01:45.090Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T20:01:45.090Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.215.0>,shutdown}}
[error_logger:info,2021-04-19T20:01:45.091Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T20:01:45.292Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T20:01:45.292Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T20:01:45.292Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.218.0>,shutdown}}
[error_logger:info,2021-04-19T20:01:45.293Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T20:01:45.493Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T20:01:45.493Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{'EXIT',<0.221.0>,shutdown}}
[ns_server:debug,2021-04-19T20:01:45.493Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: {badrpc,nodedown}
[error_logger:info,2021-04-19T20:01:45.493Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{net_kernel,875,nodedown,'couchdb_ns_1@127.0.0.1'}}
[error_logger:info,2021-04-19T20:01:45.695Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================INFO REPORT=========================
{net_kernel,{connect,normal,'couchdb_ns_1@127.0.0.1'}}
[ns_server:debug,2021-04-19T20:01:45.764Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T20:01:45.965Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T20:01:46.166Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T20:01:46.367Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T20:01:46.568Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T20:01:46.770Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T20:01:46.971Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T20:01:47.173Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[ns_server:debug,2021-04-19T20:01:47.375Z,ns_1@127.0.0.1:<0.183.0>:ns_server_nodes_sup:do_wait_link_to_couchdb_node:140]ns_couchdb is not ready: false
[error_logger:info,2021-04-19T20:01:47.844Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.235.0>},
                       {name,timer2_server},
                       {mfargs,{timer2,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T20:01:48.045Z,ns_1@127.0.0.1:ns_couchdb_port<0.181.0>:ns_port_server:log:210]ns_couchdb<0.181.0>: Apache CouchDB  (LogLevel=info) is starting.

[error_logger:info,2021-04-19T20:01:48.443Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.182.0>},
                       {name,wait_for_couchdb_node},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<ns_server_nodes_sup.0.8580514>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:48.453Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.155.0>:ns_storage_conf:setup_db_and_ix_paths:53]Initialize db_and_ix_paths variable with [{db_path,
                                           "/opt/couchbase/var/lib/couchbase/data"},
                                          {index_path,
                                           "/opt/couchbase/var/lib/couchbase/data"}]
[ns_server:info,2021-04-19T20:01:48.461Z,ns_1@127.0.0.1:ns_couchdb_port<0.181.0>:ns_port_server:log:210]ns_couchdb<0.181.0>: Apache CouchDB has started. Time to relax.
ns_couchdb<0.181.0>: 137: Booted. Waiting for shutdown request

[error_logger:info,2021-04-19T20:01:48.468Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.238.0>},
                       {name,ns_disksup},
                       {mfargs,{ns_disksup,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:48.472Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.239.0>},
                       {name,diag_handler_worker},
                       {mfargs,{work_queue,start_link,[diag_handler_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T20:01:48.476Z,ns_1@127.0.0.1:ns_server_sup<0.237.0>:dir_size:start_link:39]Starting quick version of dir_size with program name: godu
[error_logger:info,2021-04-19T20:01:48.495Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.240.0>},
                       {name,dir_size},
                       {mfargs,{dir_size,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:48.500Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.241.0>},
                       {name,request_throttler},
                       {mfargs,{request_throttler,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:48.514Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.242.0>},
                       {name,ns_log},
                       {mfargs,{ns_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:48.514Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.243.0>},
                       {name,ns_crash_log_consumer},
                       {mfargs,{ns_log,start_link_crash_consumer,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:48.538Z,ns_1@127.0.0.1:ns_config_isasl_sync<0.244.0>:ns_config_isasl_sync:init:65]isasl_sync init: ["/opt/couchbase/var/lib/couchbase/isasl.pw","_admin"]
[ns_server:debug,2021-04-19T20:01:48.538Z,ns_1@127.0.0.1:ns_config_isasl_sync<0.244.0>:ns_config_isasl_sync:init:73]isasl_sync init buckets: []
[ns_server:debug,2021-04-19T20:01:48.540Z,ns_1@127.0.0.1:ns_config_isasl_sync<0.244.0>:ns_config_isasl_sync:writeSASLConf:145]Writing isasl passwd file: "/opt/couchbase/var/lib/couchbase/isasl.pw"
[ns_server:warn,2021-04-19T20:01:48.587Z,ns_1@127.0.0.1:ns_config_isasl_sync<0.244.0>:ns_memcached:connect:1307]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[error_logger:info,2021-04-19T20:01:49.589Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.244.0>},
                       {name,ns_config_isasl_sync},
                       {mfargs,{ns_config_isasl_sync,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:49.589Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.246.0>},
                       {name,ns_log_events},
                       {mfargs,{gen_event,start_link,[{local,ns_log_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:49.591Z,ns_1@127.0.0.1:ns_node_disco<0.249.0>:ns_node_disco:init:138]Initting ns_node_disco with []
[error_logger:info,2021-04-19T20:01:49.591Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.248.0>},
                       {name,ns_node_disco_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,ns_node_disco_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:49.591Z,ns_1@127.0.0.1:ns_cookie_manager<0.141.0>:ns_cookie_manager:do_cookie_sync:115]ns_cookie_manager do_cookie_sync
[user:info,2021-04-19T20:01:49.592Z,ns_1@127.0.0.1:ns_cookie_manager<0.141.0>:ns_cookie_manager:do_cookie_sync:134]Node 'ns_1@127.0.0.1' synchronized otp cookie {sanitized,
                                               <<"igGdfqmbza2bbcUGcHlgLfqDrDSw4MuqpdcFvTedqb0=">>} from cluster
[ns_server:debug,2021-04-19T20:01:49.592Z,ns_1@127.0.0.1:<0.250.0>:ns_node_disco:do_nodes_wanted_updated_fun:224]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"igGdfqmbza2bbcUGcHlgLfqDrDSw4MuqpdcFvTedqb0=">>}
[ns_server:debug,2021-04-19T20:01:49.595Z,ns_1@127.0.0.1:<0.250.0>:ns_node_disco:do_nodes_wanted_updated_fun:230]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"igGdfqmbza2bbcUGcHlgLfqDrDSw4MuqpdcFvTedqb0=">>}
[error_logger:info,2021-04-19T20:01:49.596Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.249.0>},
                       {name,ns_node_disco},
                       {mfargs,{ns_node_disco,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:49.598Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.251.0>},
                       {name,ns_node_disco_log},
                       {mfargs,{ns_node_disco_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:49.601Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.252.0>},
                       {name,ns_node_disco_conf_events},
                       {mfargs,{ns_node_disco_conf_events,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:49.604Z,ns_1@127.0.0.1:ns_config_rep<0.254.0>:ns_config_rep:init:68]init pulling
[error_logger:info,2021-04-19T20:01:49.604Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.253.0>},
                       {name,ns_config_rep_merger},
                       {mfargs,{ns_config_rep,start_link_merger,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:49.604Z,ns_1@127.0.0.1:ns_config_rep<0.254.0>:ns_config_rep:init:70]init pushing
[ns_server:debug,2021-04-19T20:01:49.605Z,ns_1@127.0.0.1:ns_config_rep<0.254.0>:ns_config_rep:init:74]init reannouncing
[ns_server:debug,2021-04-19T20:01:49.605Z,ns_1@127.0.0.1:ns_config_events<0.144.0>:ns_node_disco_conf_events:handle_event:44]ns_node_disco_conf_events config on nodes_wanted
[ns_server:debug,2021-04-19T20:01:49.605Z,ns_1@127.0.0.1:ns_config_events<0.144.0>:ns_node_disco_conf_events:handle_event:50]ns_node_disco_conf_events config on otp
[ns_server:debug,2021-04-19T20:01:49.605Z,ns_1@127.0.0.1:ns_cookie_manager<0.141.0>:ns_cookie_manager:do_cookie_sync:115]ns_cookie_manager do_cookie_sync
[ns_server:debug,2021-04-19T20:01:49.606Z,ns_1@127.0.0.1:ns_cookie_manager<0.141.0>:ns_cookie_manager:do_cookie_sync:115]ns_cookie_manager do_cookie_sync
[ns_server:debug,2021-04-19T20:01:49.606Z,ns_1@127.0.0.1:<0.258.0>:ns_node_disco:do_nodes_wanted_updated_fun:224]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"igGdfqmbza2bbcUGcHlgLfqDrDSw4MuqpdcFvTedqb0=">>}
[ns_server:debug,2021-04-19T20:01:49.606Z,ns_1@127.0.0.1:<0.259.0>:ns_node_disco:do_nodes_wanted_updated_fun:224]ns_node_disco: nodes_wanted updated: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                       <<"igGdfqmbza2bbcUGcHlgLfqDrDSw4MuqpdcFvTedqb0=">>}
[ns_server:debug,2021-04-19T20:01:49.606Z,ns_1@127.0.0.1:<0.258.0>:ns_node_disco:do_nodes_wanted_updated_fun:230]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"igGdfqmbza2bbcUGcHlgLfqDrDSw4MuqpdcFvTedqb0=">>}
[ns_server:debug,2021-04-19T20:01:49.606Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
alert_limits ->
[{max_overhead_perc,50},{max_disk_used,90},{max_indexer_ram,75}]
[ns_server:debug,2021-04-19T20:01:49.606Z,ns_1@127.0.0.1:<0.259.0>:ns_node_disco:do_nodes_wanted_updated_fun:230]ns_node_disco: nodes_wanted pong: ['ns_1@127.0.0.1'], with cookie: {sanitized,
                                                                    <<"igGdfqmbza2bbcUGcHlgLfqDrDSw4MuqpdcFvTedqb0=">>}
[ns_server:debug,2021-04-19T20:01:49.606Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
audit ->
[{auditd_enabled,false},
 {rotate_interval,86400},
 {rotate_size,20971520},
 {disabled,[]},
 {sync,[]},
 {log_path,"/opt/couchbase/var/lib/couchbase/logs"}]
[ns_server:debug,2021-04-19T20:01:49.607Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
auto_failover_cfg ->
[{enabled,false},{timeout,120},{max_nodes,1},{count,0}]
[ns_server:debug,2021-04-19T20:01:49.607Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
autocompaction ->
[{database_fragmentation_threshold,{30,undefined}},
 {view_fragmentation_threshold,{30,undefined}}]
[ns_server:debug,2021-04-19T20:01:49.607Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
buckets ->
[[],{configs,[]}]
[ns_server:debug,2021-04-19T20:01:49.607Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
cert_and_pkey ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080742}}]}|
 {<<"-----BEGIN CERTIFICATE-----\nMIIDAjCCAeqgAwIBAgIIFndZ/vr3iFgwDQYJKoZIhvcNAQELBQAwJDEiMCAGA1UE\nAxMZQ291Y2hiYXNlIFNlcnZlciBiODgwZTU4MjAeFw0xMzAxMDEwMDAwMDBaFw00\nOTEyMzEyMzU5NTlaMCQxIjAgBgNVBAMTGUNvdWNoYmFzZSBTZXJ2ZXIgYjg4MGU1\nODIwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDPKYjrGZUDKn7xXZhz\n/CcGig/KlI7xzgbLixQnJ5VLNHQOaIcz01bkH2SuTUnIg3i9awTEc/vdraqbL7dK\neAQZEWpnUrZo8sPI/sI9nYnAJttUCQD"...>>,
  <<"*****">>}]
[ns_server:debug,2021-04-19T20:01:49.607Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
cluster_compat_version ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{6,63786080749}}]},4,6]
[ns_server:debug,2021-04-19T20:01:49.607Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
drop_request_memory_threshold_mib ->
undefined
[ns_server:debug,2021-04-19T20:01:49.608Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
email_alerts ->
[{recipients,["root@localhost"]},
 {sender,"couchbase@localhost"},
 {enabled,false},
 {email_server,[{user,[]},
                {pass,"*****"},
                {host,"localhost"},
                {port,25},
                {encrypt,false}]},
 {alerts,[auto_failover_node,auto_failover_maximum_reached,
          auto_failover_other_nodes_down,auto_failover_cluster_too_small,
          auto_failover_disabled,ip,disk,overhead,ep_oom_errors,
          ep_item_commit_failed,audit_dropped_events,indexer_ram_max_usage,
          ep_clock_cas_drift_threshold_exceeded]}]
[ns_server:debug,2021-04-19T20:01:49.608Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
fts_memory_quota ->
512
[ns_server:debug,2021-04-19T20:01:49.608Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
goxdcr_upgrade ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080749}}]}|
 '_deleted']
[ns_server:debug,2021-04-19T20:01:49.608Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
index_aware_rebalance_disabled ->
false
[ns_server:debug,2021-04-19T20:01:49.608Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
max_bucket_count ->
10
[ns_server:debug,2021-04-19T20:01:49.608Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
memcached ->
[]
[ns_server:debug,2021-04-19T20:01:49.608Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
memory_quota ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080757}}]}|300]
[ns_server:debug,2021-04-19T20:01:49.608Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
nodes_wanted ->
['ns_1@127.0.0.1']
[ns_server:debug,2021-04-19T20:01:49.609Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
otp ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080748}}]},
 {cookie,{sanitized,<<"igGdfqmbza2bbcUGcHlgLfqDrDSw4MuqpdcFvTedqb0=">>}}]
[ns_server:debug,2021-04-19T20:01:49.609Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
read_only_user_creds ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080749}}]}|null]
[ns_server:debug,2021-04-19T20:01:49.609Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
remote_clusters ->
[]
[error_logger:info,2021-04-19T20:01:49.609Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_node_disco_sup}
             started: [{pid,<0.254.0>},
                       {name,ns_config_rep},
                       {mfargs,{ns_config_rep,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:49.609Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
replication ->
[{enabled,true}]
[ns_server:debug,2021-04-19T20:01:49.609Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
rest ->
[{port,8091}]
[error_logger:info,2021-04-19T20:01:49.609Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.247.0>},
                       {name,ns_node_disco_sup},
                       {mfargs,{ns_node_disco_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2021-04-19T20:01:49.609Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
rest_creds ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{2,63786080757}}]}|
 {"Administrator",{password,"*****"}}]
[ns_server:debug,2021-04-19T20:01:49.609Z,ns_1@127.0.0.1:ns_config_rep<0.254.0>:ns_config_rep:do_push_keys:321]Replicating some config keys ([alert_limits,audit,auto_failover_cfg,
                               autocompaction,buckets,cert_and_pkey,
                               cluster_compat_version,
                               drop_request_memory_threshold_mib,email_alerts,
                               fts_memory_quota,goxdcr_upgrade,
                               index_aware_rebalance_disabled,
                               max_bucket_count,memcached,memory_quota,
                               nodes_wanted,otp,read_only_user_creds,
                               remote_clusters,replication,rest,rest_creds,
                               roles_definitions,server_groups,
                               set_view_update_daemon,uuid,
                               {couchdb,max_parallel_indexers},
                               {couchdb,max_parallel_replica_indexers},
                               {local_changes_count,
                                   <<"360fb3d3641e00b1f4f22714c24e2a2a">>},
                               {metakv,<<"/indexing/settings/config">>},
                               {request_limit,capi},
                               {request_limit,rest},
                               {service_map,fts},
                               {service_map,index},
                               {service_map,n1ql},
                               {node,'ns_1@127.0.0.1',audit},
                               {node,'ns_1@127.0.0.1',capi_port},
                               {node,'ns_1@127.0.0.1',compaction_daemon},
                               {node,'ns_1@127.0.0.1',config_version},
                               {node,'ns_1@127.0.0.1',fts_http_port},
                               {node,'ns_1@127.0.0.1',indexer_admin_port},
                               {node,'ns_1@127.0.0.1',indexer_http_port},
                               {node,'ns_1@127.0.0.1',indexer_scan_port},
                               {node,'ns_1@127.0.0.1',indexer_stcatchup_port},
                               {node,'ns_1@127.0.0.1',indexer_stinit_port},
                               {node,'ns_1@127.0.0.1',indexer_stmaint_port},
                               {node,'ns_1@127.0.0.1',is_enterprise},
                               {node,'ns_1@127.0.0.1',isasl},
                               {node,'ns_1@127.0.0.1',ldap_enabled},
                               {node,'ns_1@127.0.0.1',membership},
                               {node,'ns_1@127.0.0.1',memcached},
                               {node,'ns_1@127.0.0.1',memcached_config},
                               {node,'ns_1@127.0.0.1',memcached_defaults},
                               {node,'ns_1@127.0.0.1',moxi},
                               {node,'ns_1@127.0.0.1',ns_log},
                               {node,'ns_1@127.0.0.1',port_servers},
                               {node,'ns_1@127.0.0.1',projector_port},
                               {node,'ns_1@127.0.0.1',query_port},
                               {node,'ns_1@127.0.0.1',rest},
                               {node,'ns_1@127.0.0.1',services},
                               {node,'ns_1@127.0.0.1',ssl_capi_port},
                               {node,'ns_1@127.0.0.1',
                                   ssl_proxy_downstream_port},
                               {node,'ns_1@127.0.0.1',ssl_proxy_upstream_port},
                               {node,'ns_1@127.0.0.1',ssl_query_port}]..)
[ns_server:debug,2021-04-19T20:01:49.610Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
roles_definitions ->
[{admin,[],
        [{name,<<"Admin">>},
         {desc,<<"Can manage ALL cluster features including security.">>}],
        [{[],all}]},
 {ro_admin,[],
           [{name,<<"Read Only Admin">>},
            {desc,<<"Can view ALL cluster features.">>}],
           [{[{bucket,any},password],none},
            {[{bucket,any},data],none},
            {[admin,security],[read]},
            {[admin],none},
            {[],[read]}]},
 {cluster_admin,[],
                [{name,<<"Cluster Admin">>},
                 {desc,<<"Can manage all cluster features EXCEPT security.">>}],
                [{[admin],none},{[],all}]},
 {bucket_admin,[bucket_name],
               [{name,<<"Bucket Admin">>},
                {desc,<<"Can manage ALL bucket features for specified buckets (incl. start/stop XDCR)">>}],
               [{[{bucket,bucket_name},xdcr],[read,execute]},
                {[{bucket,bucket_name}],all},
                {[{bucket,any},settings],[read]},
                {[{bucket,any}],none},
                {[xdcr],none},
                {[admin],none},
                {[],[read]}]},
 {bucket_sasl,[bucket_name],
              [],
              [{[{bucket,bucket_name},data],all},
               {[{bucket,bucket_name},views],all},
               {[{bucket,bucket_name}],[read,flush]},
               {[pools],[read]}]},
 {views_admin,[bucket_name],
              [{name,<<"Views Admin">>},
               {desc,<<"Can manage views for specified buckets">>}],
              [{[{bucket,bucket_name},views],all},
               {[{bucket,bucket_name},data],[read]},
               {[{bucket,any},settings],[read]},
               {[{bucket,any}],none},
               {[xdcr],none},
               {[admin],none},
               {[],[read]}]},
 {replication_admin,[],
                    [{name,<<"Replication Admin">>},
                     {desc,<<"Can manage ONLY XDCR features (cluster AND bucket level)">>}],
                    [{[{bucket,any},xdcr],all},
                     {[{bucket,any},data],[read]},
                     {[{bucket,any},settings],[read]},
                     {[{bucket,any}],none},
                     {[xdcr],all},
                     {[admin],none},
                     {[],[read]}]}]
[ns_server:debug,2021-04-19T20:01:49.611Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
server_groups ->
[[{uuid,<<"0">>},{name,<<"Group 1">>},{nodes,['ns_1@127.0.0.1']}]]
[ns_server:debug,2021-04-19T20:01:49.611Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
set_view_update_daemon ->
[{update_interval,5000},
 {update_min_changes,5000},
 {replica_update_min_changes,5000}]
[ns_server:debug,2021-04-19T20:01:49.611Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
uuid ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080757}}]}|
 <<"819b5f49755d4c5571ba2861d6185103">>]
[ns_server:debug,2021-04-19T20:01:49.611Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{couchdb,max_parallel_indexers} ->
4
[ns_server:debug,2021-04-19T20:01:49.611Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{couchdb,max_parallel_replica_indexers} ->
2
[ns_server:debug,2021-04-19T20:01:49.611Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{local_changes_count,<<"360fb3d3641e00b1f4f22714c24e2a2a">>} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{14,63786081264}}]}]
[ns_server:debug,2021-04-19T20:01:49.611Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{metakv,<<"/indexing/settings/config">>} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{6,63786081264}}]}|
 <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.log_level\":\"info\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\""...>>]
[ns_server:debug,2021-04-19T20:01:49.612Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{request_limit,capi} ->
undefined
[ns_server:debug,2021-04-19T20:01:49.612Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{request_limit,rest} ->
undefined
[ns_server:debug,2021-04-19T20:01:49.612Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{service_map,fts} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080749}}]}]
[ns_server:debug,2021-04-19T20:01:49.612Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{service_map,index} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{2,63786080759}}]},
 'ns_1@127.0.0.1']
[ns_server:debug,2021-04-19T20:01:49.612Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{service_map,n1ql} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{2,63786080759}}]},
 'ns_1@127.0.0.1']
[ns_server:debug,2021-04-19T20:01:49.612Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',audit} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}]
[ns_server:debug,2021-04-19T20:01:49.613Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',capi_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|8092]
[error_logger:info,2021-04-19T20:01:49.613Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.262.0>},
                       {name,vbucket_map_mirror},
                       {mfargs,{vbucket_map_mirror,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:49.613Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',compaction_daemon} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
 {check_interval,30},
 {min_db_file_size,131072},
 {min_view_file_size,20971520}]
[ns_server:debug,2021-04-19T20:01:49.613Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',config_version} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|{4,5}]
[ns_server:debug,2021-04-19T20:01:49.614Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',fts_http_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|8094]
[ns_server:debug,2021-04-19T20:01:49.614Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',indexer_admin_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|9100]
[ns_server:debug,2021-04-19T20:01:49.614Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',indexer_http_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|9102]
[ns_server:debug,2021-04-19T20:01:49.614Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',indexer_scan_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|9101]
[ns_server:debug,2021-04-19T20:01:49.614Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',indexer_stcatchup_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|9104]
[ns_server:debug,2021-04-19T20:01:49.615Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',indexer_stinit_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|9103]
[ns_server:debug,2021-04-19T20:01:49.615Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',indexer_stmaint_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|9105]
[ns_server:debug,2021-04-19T20:01:49.615Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',is_enterprise} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|true]
[ns_server:debug,2021-04-19T20:01:49.615Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',isasl} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
 {path,"/opt/couchbase/var/lib/couchbase/isasl.pw"}]
[ns_server:debug,2021-04-19T20:01:49.615Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ldap_enabled} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|true]
[ns_server:debug,2021-04-19T20:01:49.615Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',membership} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
 active]
[ns_server:debug,2021-04-19T20:01:49.616Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',memcached} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
 {port,11210},
 {dedicated_port,11209},
 {ssl_port,11207},
 {admin_user,"_admin"},
 {admin_pass,"*****"},
 {engines,[{membase,[{engine,"/opt/couchbase/lib/memcached/ep.so"},
                     {static_config_string,"failpartialwarmup=false"}]},
           {memcached,[{engine,"/opt/couchbase/lib/memcached/default_engine.so"},
                       {static_config_string,"vb0=true"}]}]},
 {config_path,"/opt/couchbase/var/lib/couchbase/config/memcached.json"},
 {audit_file,"/opt/couchbase/var/lib/couchbase/config/audit.json"},
 {log_path,"/opt/couchbase/var/lib/couchbase/logs"},
 {log_prefix,"memcached.log"},
 {log_generations,20},
 {log_cyclesize,10485760},
 {log_sleeptime,19},
 {log_rotation_period,39003}]
[ns_server:debug,2021-04-19T20:01:49.616Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',memcached_config} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
 {[{interfaces,
    {memcached_config_mgr,omit_missing_mcd_ports,
     [{[{host,<<"*">>},{port,port},{maxconn,maxconn}]},
      {[{host,<<"*">>},
        {port,dedicated_port},
        {maxconn,dedicated_port_maxconn}]},
      {[{host,<<"*">>},
        {port,ssl_port},
        {maxconn,maxconn},
        {ssl,
         {[{key,
            <<"/opt/couchbase/var/lib/couchbase/config/memcached-key.pem">>},
           {cert,
            <<"/opt/couchbase/var/lib/couchbase/config/memcached-cert.pem">>}]}}]}]}},
   {ssl_cipher_list,{"~s",[ssl_cipher_list]}},
   {ssl_minimum_protocol,{memcached_config_mgr,ssl_minimum_protocol,[]}},
   {connection_idle_time,connection_idle_time},
   {breakpad,
    {[{enabled,breakpad_enabled},
      {minidump_dir,{memcached_config_mgr,get_minidump_dir,[]}}]}},
   {extensions,
    [{[{module,<<"/opt/couchbase/lib/memcached/stdin_term_handler.so">>},
       {config,<<>>}]},
     {[{module,<<"/opt/couchbase/lib/memcached/file_logger.so">>},
       {config,
        {"cyclesize=~B;sleeptime=~B;filename=~s/~s",
         [log_cyclesize,log_sleeptime,log_path,log_prefix]}}]}]},
   {admin,{"~s",[admin_user]}},
   {verbosity,verbosity},
   {audit_file,{"~s",[audit_file]}},
   {dedupe_nmvb_maps,dedupe_nmvb_maps}]}]
[ns_server:debug,2021-04-19T20:01:49.616Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',memcached_defaults} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
 {maxconn,30000},
 {dedicated_port_maxconn,5000},
 {ssl_cipher_list,"HIGH"},
 {connection_idle_time,0},
 {verbosity,0},
 {breakpad_enabled,true},
 {breakpad_minidump_dir_path,"/opt/couchbase/var/lib/couchbase/crash"},
 {dedupe_nmvb_maps,false}]
[ns_server:debug,2021-04-19T20:01:49.616Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',moxi} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
 {port,11211},
 {verbosity,[]}]
[ns_server:debug,2021-04-19T20:01:49.616Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ns_log} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
 {filename,"/opt/couchbase/var/lib/couchbase/ns_log"}]
[ns_server:debug,2021-04-19T20:01:49.617Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',port_servers} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}]
[ns_server:debug,2021-04-19T20:01:49.617Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',projector_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|9999]
[ns_server:debug,2021-04-19T20:01:49.617Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',query_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|8093]
[ns_server:debug,2021-04-19T20:01:49.617Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',rest} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]},
 {port,8091},
 {port_meta,global}]
[ns_server:debug,2021-04-19T20:01:49.617Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',services} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080757}}]},
 index,kv,n1ql]
[ns_server:debug,2021-04-19T20:01:49.617Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ssl_capi_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|18092]
[ns_server:debug,2021-04-19T20:01:49.617Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ssl_proxy_downstream_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|11214]
[ns_server:debug,2021-04-19T20:01:49.617Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ssl_proxy_upstream_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|11215]
[ns_server:debug,2021-04-19T20:01:49.617Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ssl_query_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|18093]
[ns_server:debug,2021-04-19T20:01:49.617Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',ssl_rest_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|18091]
[ns_server:debug,2021-04-19T20:01:49.617Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',stop_xdcr} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{2,63786080749}}]}|
 '_deleted']
[ns_server:debug,2021-04-19T20:01:49.618Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',uuid} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|
 <<"360fb3d3641e00b1f4f22714c24e2a2a">>]
[ns_server:debug,2021-04-19T20:01:49.618Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{node,'ns_1@127.0.0.1',xdcr_rest_port} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{1,63786080741}}]}|9998]
[error_logger:info,2021-04-19T20:01:49.618Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.264.0>},
                       {name,bucket_info_cache},
                       {mfargs,{bucket_info_cache,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:49.618Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.267.0>},
                       {name,ns_tick_event},
                       {mfargs,{gen_event,start_link,[{local,ns_tick_event}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:49.619Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.268.0>},
                       {name,buckets_events},
                       {mfargs,
                           {gen_event,start_link,[{local,buckets_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:49.624Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_mail_sup}
             started: [{pid,<0.270.0>},
                       {name,ns_mail_log},
                       {mfargs,{ns_mail_log,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:49.624Z,ns_1@127.0.0.1:ns_log_events<0.246.0>:ns_mail_log:init:44]ns_mail_log started up
[error_logger:info,2021-04-19T20:01:49.624Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.269.0>},
                       {name,ns_mail_sup},
                       {mfargs,{ns_mail_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T20:01:49.625Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.271.0>},
                       {name,ns_stats_event},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_stats_event}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:49.628Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.272.0>},
                       {name,samples_loader_tasks},
                       {mfargs,{samples_loader_tasks,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:49.637Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_heart_sup}
             started: [{pid,<0.274.0>},
                       {name,ns_heart},
                       {mfargs,{ns_heart,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:49.637Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_heart_sup}
             started: [{pid,<0.277.0>},
                       {name,ns_heart_slow_updater},
                       {mfargs,{ns_heart,start_link_slow_updater,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:49.637Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.273.0>},
                       {name,ns_heart_sup},
                       {mfargs,{ns_heart_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2021-04-19T20:01:49.642Z,ns_1@127.0.0.1:ns_heart<0.274.0>:ns_heart:grab_latest_stats:259]Ignoring failure to grab "@system" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,117}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,255}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,249}]},
                 {ns_heart,update_current_status,1,
                           [{file,"src/ns_heart.erl"},{line,186}]},
                 {ns_heart,handle_info,2,
                           [{file,"src/ns_heart.erl"},{line,118}]}]}}

[ns_server:debug,2021-04-19T20:01:49.643Z,ns_1@127.0.0.1:ns_heart<0.274.0>:ns_heart:grab_latest_stats:259]Ignoring failure to grab "@system-processes" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-processes-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,117}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,255}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,249}]},
                 {ns_heart,update_current_status,1,
                           [{file,"src/ns_heart.erl"},{line,186}]}]}}

[error_logger:info,2021-04-19T20:01:49.645Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_doctor_sup}
             started: [{pid,<0.280.0>},
                       {name,ns_doctor_events},
                       {mfargs,
                           {gen_event,start_link,[{local,ns_doctor_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:49.660Z,ns_1@127.0.0.1:<0.278.0>:restartable:start_child:98]Started child process <0.279.0>
  MFA: {ns_doctor_sup,start_link,[]}
[error_logger:info,2021-04-19T20:01:49.660Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_doctor_sup}
             started: [{pid,<0.281.0>},
                       {name,ns_doctor},
                       {mfargs,{ns_doctor,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:49.661Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.278.0>},
                       {name,ns_doctor_sup},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_doctor_sup,start_link,[]},infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2021-04-19T20:01:49.697Z,ns_1@127.0.0.1:ns_heart<0.274.0>:ns_heart:grab_index_status:373]ignoring failure to get index status: {exit,
                                       {noproc,
                                        {gen_server,call,
                                         ['index_status_keeper-index',
                                          get_status,2000]}}}
[{gen_server,call,3,[{file,"gen_server.erl"},{line,188}]},
 {ns_heart,grab_index_status,0,[{file,"src/ns_heart.erl"},{line,370}]},
 {ns_heart,current_status_slow_inner,0,[{file,"src/ns_heart.erl"},{line,280}]},
 {ns_heart,current_status_slow,1,[{file,"src/ns_heart.erl"},{line,249}]},
 {ns_heart,update_current_status,1,[{file,"src/ns_heart.erl"},{line,186}]},
 {ns_heart,handle_info,2,[{file,"src/ns_heart.erl"},{line,118}]},
 {gen_server,handle_msg,5,[{file,"gen_server.erl"},{line,604}]},
 {proc_lib,init_p_do_apply,3,[{file,"proc_lib.erl"},{line,239}]}]
[error_logger:info,2021-04-19T20:01:49.707Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.286.0>},
                       {name,disk_log_sup},
                       {mfargs,{disk_log_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T20:01:49.708Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.287.0>},
                       {name,disk_log_server},
                       {mfargs,{disk_log_server,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:49.728Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.284.0>},
                       {name,remote_clusters_info},
                       {mfargs,{remote_clusters_info,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:49.728Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.290.0>},
                       {name,master_activity_events},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,master_activity_events}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:49.743Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.291.0>},
                       {name,xdcr_ckpt_store},
                       {mfargs,{simple_store,start_link,[xdcr_ckpt_data]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:49.743Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.292.0>},
                       {name,metakv_worker},
                       {mfargs,{work_queue,start_link,[metakv_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:49.744Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.293.0>},
                       {name,index_events},
                       {mfargs,{gen_event,start_link,[{local,index_events}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:49.755Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.295.0>},
                       {name,index_settings_manager},
                       {mfargs,{index_settings_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T20:01:49.773Z,ns_1@127.0.0.1:ns_couchdb_port<0.181.0>:ns_port_server:log:210]ns_couchdb<0.181.0>: working as port

[error_logger:info,2021-04-19T20:01:49.775Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.298.0>},
                       {name,menelaus_ui_auth},
                       {mfargs,{menelaus_ui_auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:49.783Z,ns_1@127.0.0.1:ns_heart<0.274.0>:goxdcr_rest:get_from_goxdcr:163]Goxdcr is temporary not available. Return empty list.
[error_logger:info,2021-04-19T20:01:49.786Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.300.0>},
                       {name,menelaus_local_auth},
                       {mfargs,{menelaus_local_auth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:49.796Z,ns_1@127.0.0.1:ns_heart<0.274.0>:cluster_logs_collection_task:maybe_build_cluster_logs_task:43]Ignoring exception trying to read cluster_logs_collection_task_status table: error:badarg
[error_logger:info,2021-04-19T20:01:49.805Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.302.0>},
                       {name,menelaus_web_cache},
                       {mfargs,{menelaus_web_cache,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:49.817Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.303.0>},
                       {name,menelaus_stats_gatherer},
                       {mfargs,{menelaus_stats_gatherer,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:49.817Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.304.0>},
                       {name,json_rpc_events},
                       {mfargs,
                           {gen_event,start_link,[{local,json_rpc_events}]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T20:01:49.827Z,ns_1@127.0.0.1:menelaus_sup<0.297.0>:menelaus_pluggable_ui:validate_plugin_spec:117]Loaded pluggable UI specification for fts

[ns_server:info,2021-04-19T20:01:49.828Z,ns_1@127.0.0.1:menelaus_sup<0.297.0>:menelaus_pluggable_ui:validate_plugin_spec:117]Loaded pluggable UI specification for n1ql

[error_logger:info,2021-04-19T20:01:49.829Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.305.0>},
                       {name,menelaus_web},
                       {mfargs,{menelaus_web,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:49.829Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.277.0>:ns_heart:grab_latest_stats:259]Ignoring failure to grab "@system" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,117}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,255}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,249}]},
                 {ns_heart,slow_updater_loop,0,
                           [{file,"src/ns_heart.erl"},{line,243}]},
                 {proc_lib,init_p_do_apply,3,
                           [{file,"proc_lib.erl"},{line,239}]}]}}

[ns_server:debug,2021-04-19T20:01:49.830Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.277.0>:ns_heart:grab_latest_stats:259]Ignoring failure to grab "@system-processes" stats:
{'EXIT',{badarg,[{ets,last,['stats_archiver-@system-processes-minute'],[]},
                 {stats_archiver,latest_sample,2,
                                 [{file,"src/stats_archiver.erl"},{line,117}]},
                 {ns_heart,grab_latest_stats,1,
                           [{file,"src/ns_heart.erl"},{line,255}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,'-current_status_slow_inner/0-lc$^0/1-0-',1,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow_inner,0,
                           [{file,"src/ns_heart.erl"},{line,276}]},
                 {ns_heart,current_status_slow,1,
                           [{file,"src/ns_heart.erl"},{line,249}]},
                 {ns_heart,slow_updater_loop,0,
                           [{file,"src/ns_heart.erl"},{line,243}]}]}}

[ns_server:debug,2021-04-19T20:01:49.830Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.277.0>:ns_heart:grab_index_status:373]ignoring failure to get index status: {exit,
                                       {noproc,
                                        {gen_server,call,
                                         ['index_status_keeper-index',
                                          get_status,2000]}}}
[{gen_server,call,3,[{file,"gen_server.erl"},{line,188}]},
 {ns_heart,grab_index_status,0,[{file,"src/ns_heart.erl"},{line,370}]},
 {ns_heart,current_status_slow_inner,0,[{file,"src/ns_heart.erl"},{line,280}]},
 {ns_heart,current_status_slow,1,[{file,"src/ns_heart.erl"},{line,249}]},
 {ns_heart,slow_updater_loop,0,[{file,"src/ns_heart.erl"},{line,243}]},
 {proc_lib,init_p_do_apply,3,[{file,"proc_lib.erl"},{line,239}]}]
[ns_server:debug,2021-04-19T20:01:49.833Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.277.0>:goxdcr_rest:get_from_goxdcr:163]Goxdcr is temporary not available. Return empty list.
[ns_server:debug,2021-04-19T20:01:49.834Z,ns_1@127.0.0.1:ns_heart_slow_status_updater<0.277.0>:cluster_logs_collection_task:maybe_build_cluster_logs_task:43]Ignoring exception trying to read cluster_logs_collection_task_status table: error:badarg
[error_logger:info,2021-04-19T20:01:49.835Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.328.0>},
                       {name,menelaus_event},
                       {mfargs,{menelaus_event,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:49.842Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.329.0>},
                       {name,hot_keys_keeper},
                       {mfargs,{hot_keys_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:49.849Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.330.0>},
                       {name,menelaus_web_alerts_srv},
                       {mfargs,{menelaus_web_alerts_srv,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:49.856Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,menelaus_sup}
             started: [{pid,<0.331.0>},
                       {name,menelaus_cbauth},
                       {mfargs,{menelaus_cbauth,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[user:info,2021-04-19T20:01:49.864Z,ns_1@127.0.0.1:ns_server_sup<0.237.0>:menelaus_sup:start_link:46]Couchbase Server has started on web port 8091 on node 'ns_1@127.0.0.1'. Version: "4.6.0-3573-enterprise".
[error_logger:info,2021-04-19T20:01:49.864Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.297.0>},
                       {name,menelaus},
                       {mfargs,{menelaus_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T20:01:49.864Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.335.0>},
                       {name,ns_ports_setup},
                       {mfargs,{ns_ports_setup,start,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:49.869Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_agent_sup}
             started: [{pid,<0.338.0>},
                       {name,service_agent_children_sup},
                       {mfargs,
                           {supervisor,start_link,
                               [{local,service_agent_children_sup},
                                service_agent_sup,child]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T20:01:49.869Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,service_agent_sup}
             started: [{pid,<0.339.0>},
                       {name,service_agent_worker},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<service_agent_sup.0.29791682>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:49.870Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.337.0>},
                       {name,service_agent_sup},
                       {mfargs,{service_agent_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T20:01:49.892Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.341.0>},
                       {name,ns_memcached_sockets_pool},
                       {mfargs,{ns_memcached_sockets_pool,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:49.892Z,ns_1@127.0.0.1:ns_audit_cfg<0.342.0>:ns_audit_cfg:write_audit_json:158]Writing new content to "/opt/couchbase/var/lib/couchbase/config/audit.json" : [{auditd_enabled,
                                                                                false},
                                                                               {disabled,
                                                                                []},
                                                                               {log_path,
                                                                                "/opt/couchbase/var/lib/couchbase/logs"},
                                                                               {rotate_interval,
                                                                                86400},
                                                                               {rotate_size,
                                                                                20971520},
                                                                               {sync,
                                                                                []},
                                                                               {version,
                                                                                1},
                                                                               {descriptors_path,
                                                                                "/opt/couchbase/etc/security"}]
[ns_server:debug,2021-04-19T20:01:49.909Z,ns_1@127.0.0.1:ns_ports_setup<0.335.0>:ns_ports_manager:set_dynamic_children:54]Setting children [memcached,moxi,projector,indexer,query,saslauthd_port,
                  goxdcr,xdcr_proxy]
[ns_server:debug,2021-04-19T20:01:49.922Z,ns_1@127.0.0.1:ns_audit_cfg<0.342.0>:ns_audit_cfg:handle_info:107]Instruct memcached to reload audit config
[error_logger:info,2021-04-19T20:01:49.922Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.342.0>},
                       {name,ns_audit_cfg},
                       {mfargs,{ns_audit_cfg,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:warn,2021-04-19T20:01:49.923Z,ns_1@127.0.0.1:<0.344.0>:ns_memcached:connect:1307]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[ns_server:debug,2021-04-19T20:01:49.929Z,ns_1@127.0.0.1:memcached_config_mgr<0.346.0>:memcached_config_mgr:init:44]waiting for completion of initial ns_ports_setup round
[error_logger:info,2021-04-19T20:01:49.929Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.346.0>},
                       {name,memcached_config_mgr},
                       {mfargs,{memcached_config_mgr,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:info,2021-04-19T20:01:49.935Z,ns_1@127.0.0.1:<0.347.0>:ns_memcached_log_rotator:init:28]Starting log rotator on "/opt/couchbase/var/lib/couchbase/logs"/"memcached.log"* with an initial period of 39003ms
[error_logger:info,2021-04-19T20:01:49.936Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.347.0>},
                       {name,ns_memcached_log_rotator},
                       {mfargs,{ns_memcached_log_rotator,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:49.942Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.348.0>},
                       {name,memcached_clients_pool},
                       {mfargs,{memcached_clients_pool,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:49.948Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.349.0>},
                       {name,proxied_memcached_clients_pool},
                       {mfargs,{proxied_memcached_clients_pool,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:49.949Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.350.0>},
                       {name,xdc_lhttpc_pool},
                       {mfargs,
                           {lhttpc_manager,start_link,
                               [[{name,xdc_lhttpc_pool},
                                 {connection_timeout,120000},
                                 {pool_size,200}]]}},
                       {restart_type,{permanent,1}},
                       {shutdown,10000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:49.954Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.351.0>},
                       {name,ns_null_connection_pool},
                       {mfargs,
                           {ns_null_connection_pool,start_link,
                               [ns_null_connection_pool]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:49.965Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {<0.352.0>,xdcr_sup}
             started: [{pid,<0.353.0>},
                       {name,xdc_stats_holder},
                       {mfargs,
                           {proc_lib,start_link,
                               [xdcr_sup,link_stats_holder_body,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:49.970Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {<0.352.0>,xdcr_sup}
             started: [{pid,<0.354.0>},
                       {name,xdc_replication_sup},
                       {mfargs,{xdc_replication_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2021-04-19T20:01:49.976Z,ns_1@127.0.0.1:xdc_rep_manager<0.355.0>:ns_couchdb_api:wait_for_doc_manager:298]Start waiting for doc manager
[error_logger:info,2021-04-19T20:01:49.976Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {<0.352.0>,xdcr_sup}
             started: [{pid,<0.355.0>},
                       {name,xdc_rep_manager},
                       {mfargs,{xdc_rep_manager,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,30000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:49.984Z,ns_1@127.0.0.1:xdcr_doc_replicator<0.357.0>:ns_couchdb_api:wait_for_doc_manager:298]Start waiting for doc manager
[ns_server:debug,2021-04-19T20:01:49.984Z,ns_1@127.0.0.1:xdc_rdoc_replication_srv<0.358.0>:ns_couchdb_api:wait_for_doc_manager:298]Start waiting for doc manager
[error_logger:info,2021-04-19T20:01:49.984Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {<0.352.0>,xdcr_sup}
             started: [{pid,<0.357.0>},
                       {name,xdc_rdoc_replicator},
                       {mfargs,{doc_replicator,start_link_xdcr,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:49.985Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {<0.352.0>,xdcr_sup}
             started: [{pid,<0.358.0>},
                       {name,xdc_rdoc_replication_srv},
                       {mfargs,{doc_replication_srv,start_link_xdcr,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:49.989Z,ns_1@127.0.0.1:<0.352.0>:xdc_rdoc_manager:start_link_remote:42]Starting xdc_rdoc_manager on 'couchdb_ns_1@127.0.0.1' with following links: [<0.357.0>,
                                                                             <0.358.0>,
                                                                             <0.355.0>]
[ns_server:debug,2021-04-19T20:01:49.996Z,ns_1@127.0.0.1:xdcr_doc_replicator<0.357.0>:ns_couchdb_api:wait_for_doc_manager:301]Received doc manager registration from <11633.250.0>
[ns_server:debug,2021-04-19T20:01:49.996Z,ns_1@127.0.0.1:xdc_rdoc_replication_srv<0.358.0>:ns_couchdb_api:wait_for_doc_manager:301]Received doc manager registration from <11633.250.0>
[ns_server:debug,2021-04-19T20:01:49.997Z,ns_1@127.0.0.1:xdc_rep_manager<0.355.0>:ns_couchdb_api:wait_for_doc_manager:301]Received doc manager registration from <11633.250.0>
[error_logger:info,2021-04-19T20:01:49.997Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {<0.352.0>,xdcr_sup}
             started: [{pid,<11633.250.0>},
                       {name,xdc_rdoc_manager},
                       {mfargs,
                           {xdc_rdoc_manager,start_link_remote,
                               ['couchdb_ns_1@127.0.0.1']}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:49.997Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.352.0>},
                       {name,xdcr_sup},
                       {mfargs,{xdcr_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T20:01:50.002Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.360.0>},
                       {name,xdcr_dcp_sockets_pool},
                       {mfargs,{xdcr_dcp_sockets_pool,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:50.006Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_worker_sup}
             started: [{pid,<0.362.0>},
                       {name,ns_bucket_worker},
                       {mfargs,{work_queue,start_link,[ns_bucket_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:50.011Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_sup}
             started: [{pid,<0.364.0>},
                       {name,buckets_observing_subscription},
                       {mfargs,{ns_bucket_sup,subscribe_on_config_events,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:50.011Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_bucket_worker_sup}
             started: [{pid,<0.363.0>},
                       {name,ns_bucket_sup},
                       {mfargs,{ns_bucket_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T20:01:50.012Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.361.0>},
                       {name,ns_bucket_worker_sup},
                       {mfargs,{ns_bucket_worker_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T20:01:50.019Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.365.0>},
                       {name,system_stats_collector},
                       {mfargs,{system_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:50.022Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.369.0>},
                       {name,{stats_archiver,"@system"}},
                       {mfargs,{stats_archiver,start_link,["@system"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:50.027Z,ns_1@127.0.0.1:xdcr_doc_replicator<0.357.0>:doc_replicator:loop:64]doing replicate_newnodes_docs
[error_logger:info,2021-04-19T20:01:50.033Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.371.0>},
                       {name,{stats_reader,"@system"}},
                       {mfargs,{stats_reader,start_link,["@system"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:50.069Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.372.0>},
                       {name,{stats_archiver,"@system-processes"}},
                       {mfargs,
                           {stats_archiver,start_link,["@system-processes"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:50.070Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.374.0>},
                       {name,{stats_reader,"@system-processes"}},
                       {mfargs,
                           {stats_reader,start_link,["@system-processes"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:50.132Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.375.0>},
                       {name,{stats_archiver,"@query"}},
                       {mfargs,{stats_archiver,start_link,["@query"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:50.132Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.377.0>},
                       {name,{stats_reader,"@query"}},
                       {mfargs,{stats_reader,start_link,["@query"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:50.138Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.378.0>},
                       {name,query_stats_collector},
                       {mfargs,{query_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:50.190Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.380.0>},
                       {name,{stats_archiver,"@global"}},
                       {mfargs,{stats_archiver,start_link,["@global"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:50.190Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.382.0>},
                       {name,{stats_reader,"@global"}},
                       {mfargs,{stats_reader,start_link,["@global"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:50.198Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.383.0>},
                       {name,global_stats_collector},
                       {mfargs,{global_stats_collector,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:50.203Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.385.0>},
                       {name,goxdcr_status_keeper},
                       {mfargs,{goxdcr_status_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:50.204Z,ns_1@127.0.0.1:goxdcr_status_keeper<0.385.0>:goxdcr_rest:get_from_goxdcr:163]Goxdcr is temporary not available. Return empty list.
[ns_server:debug,2021-04-19T20:01:50.206Z,ns_1@127.0.0.1:goxdcr_status_keeper<0.385.0>:goxdcr_rest:get_from_goxdcr:163]Goxdcr is temporary not available. Return empty list.
[error_logger:info,2021-04-19T20:01:50.223Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_stats_sup}
             started: [{pid,<0.389.0>},
                       {name,index_stats_children_sup},
                       {mfargs,
                           {supervisor,start_link,
                               [{local,index_stats_children_sup},
                                index_stats_sup,child]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T20:01:50.230Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_status_keeper_sup}
             started: [{pid,<0.391.0>},
                       {name,index_status_keeper_worker},
                       {mfargs,
                           {work_queue,start_link,
                               [index_status_keeper_worker]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:50.230Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_status_keeper_sup}
             started: [{pid,<0.392.0>},
                       {name,index_status_keeper},
                       {mfargs,{indexer_gsi,start_keeper,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:50.253Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_status_keeper_sup}
             started: [{pid,<0.395.0>},
                       {name,index_status_keeper_fts},
                       {mfargs,{indexer_fts,start_keeper,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:50.254Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_stats_sup}
             started: [{pid,<0.390.0>},
                       {name,index_status_keeper_sup},
                       {mfargs,{index_status_keeper_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T20:01:50.254Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_stats_sup}
             started: [{pid,<0.398.0>},
                       {name,index_stats_worker},
                       {mfargs,
                           {erlang,apply,
                               [#Fun<index_stats_sup.0.21142793>,[]]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:50.255Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.388.0>},
                       {name,index_stats_sup},
                       {mfargs,{index_stats_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:error,2021-04-19T20:01:50.270Z,ns_1@127.0.0.1:index_status_keeper_worker<0.391.0>:index_rest:get_json:42]Request to (indexer) http://127.0.0.1:9102/getIndexStatus failed: {error,
                                                                   {econnrefused,
                                                                    [{lhttpc_client,
                                                                      send_request,
                                                                      1,
                                                                      [{file,
                                                                        "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                       {line,
                                                                        220}]},
                                                                     {lhttpc_client,
                                                                      execute,
                                                                      9,
                                                                      [{file,
                                                                        "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                       {line,
                                                                        169}]},
                                                                     {lhttpc_client,
                                                                      request,
                                                                      9,
                                                                      [{file,
                                                                        "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                       {line,
                                                                        92}]}]}}
[error_logger:info,2021-04-19T20:01:50.291Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_stats_children_sup}
             started: [{pid,<0.401.0>},
                       {name,{indexer_gsi,index_stats_collector}},
                       {mfargs,
                           {index_stats_collector,start_link,[indexer_gsi]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:50.321Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.405.0>},
                       {name,compaction_daemon},
                       {mfargs,{compaction_daemon,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:50.380Z,ns_1@127.0.0.1:<0.408.0>:new_concurrency_throttle:init:113]init concurrent throttle process, pid: <0.408.0>, type: kv_throttle# of available token: 1
[ns_server:debug,2021-04-19T20:01:50.389Z,ns_1@127.0.0.1:compaction_new_daemon<0.406.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2021-04-19T20:01:50.389Z,ns_1@127.0.0.1:compaction_new_daemon<0.406.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T20:01:50.390Z,ns_1@127.0.0.1:compaction_new_daemon<0.406.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_views. Rescheduling compaction.
[error_logger:info,2021-04-19T20:01:50.389Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.406.0>},
                       {name,compaction_new_daemon},
                       {mfargs,{compaction_new_daemon,start_link,[]}},
                       {restart_type,{permanent,4}},
                       {shutdown,86400000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:50.390Z,ns_1@127.0.0.1:compaction_new_daemon<0.406.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T20:01:50.390Z,ns_1@127.0.0.1:compaction_new_daemon<0.406.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_master. Rescheduling compaction.
[ns_server:debug,2021-04-19T20:01:50.391Z,ns_1@127.0.0.1:compaction_new_daemon<0.406.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_master too soon. Next run will be in 3600s
[error_logger:info,2021-04-19T20:01:50.396Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_stats_children_sup}
             started: [{pid,<0.404.0>},
                       {name,{indexer_gsi,stats_archiver,"@index"}},
                       {mfargs,{stats_archiver,start_link,["@index"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:50.397Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,index_stats_children_sup}
             started: [{pid,<0.410.0>},
                       {name,{indexer_gsi,stats_reader,"@index"}},
                       {mfargs,{stats_reader,start_link,["@index"]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:50.405Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,cluster_logs_sup}
             started: [{pid,<0.412.0>},
                       {name,ets_holder},
                       {mfargs,
                           {cluster_logs_collection_task,
                               start_link_ets_holder,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:50.406Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.411.0>},
                       {name,cluster_logs_sup},
                       {mfargs,{cluster_logs_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T20:01:50.417Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.413.0>},
                       {name,remote_api},
                       {mfargs,{remote_api,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:50.426Z,ns_1@127.0.0.1:<0.414.0>:mb_master:check_master_takeover_needed:141]Sending master node question to the following nodes: []
[ns_server:debug,2021-04-19T20:01:50.426Z,ns_1@127.0.0.1:<0.414.0>:mb_master:check_master_takeover_needed:143]Got replies: []
[ns_server:debug,2021-04-19T20:01:50.427Z,ns_1@127.0.0.1:<0.414.0>:mb_master:check_master_takeover_needed:149]Was unable to discover master, not going to force mastership takeover
[user:info,2021-04-19T20:01:50.428Z,ns_1@127.0.0.1:mb_master<0.416.0>:mb_master:init:86]I'm the only node, so I'm the master.
[ns_server:debug,2021-04-19T20:01:50.461Z,ns_1@127.0.0.1:mb_master_sup<0.418.0>:misc:start_singleton:1097]start_singleton(gen_server, ns_tick, [], []): started as <0.419.0> on 'ns_1@127.0.0.1'

[error_logger:info,2021-04-19T20:01:50.462Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.419.0>},
                       {name,ns_tick},
                       {mfargs,{ns_tick,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,10},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:50.479Z,ns_1@127.0.0.1:ns_orchestrator_sup<0.420.0>:misc:start_singleton:1097]start_singleton(gen_fsm, ns_orchestrator, [], []): started as <0.421.0> on 'ns_1@127.0.0.1'

[error_logger:info,2021-04-19T20:01:50.480Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_sup}
             started: [{pid,<0.421.0>},
                       {name,ns_orchestrator},
                       {mfargs,{ns_orchestrator,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:50.492Z,ns_1@127.0.0.1:<0.423.0>:auto_failover:init:147]init auto_failover.
[ns_server:debug,2021-04-19T20:01:50.492Z,ns_1@127.0.0.1:ns_orchestrator_sup<0.420.0>:misc:start_singleton:1097]start_singleton(gen_server, auto_failover, [], []): started as <0.423.0> on 'ns_1@127.0.0.1'

[ns_server:debug,2021-04-19T20:01:50.492Z,ns_1@127.0.0.1:<0.414.0>:restartable:start_child:98]Started child process <0.416.0>
  MFA: {mb_master,start_link,[]}
[error_logger:info,2021-04-19T20:01:50.492Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_orchestrator_sup}
             started: [{pid,<0.423.0>},
                       {name,auto_failover},
                       {mfargs,{auto_failover,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:50.494Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,mb_master_sup}
             started: [{pid,<0.420.0>},
                       {name,ns_orchestrator_sup},
                       {mfargs,{ns_orchestrator_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T20:01:50.494Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.414.0>},
                       {name,mb_master},
                       {mfargs,
                           {restartable,start_link,
                               [{mb_master,start_link,[]},infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T20:01:50.494Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.424.0>},
                       {name,master_activity_events_ingress},
                       {mfargs,
                           {gen_event,start_link,
                               [{local,master_activity_events_ingress}]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:50.494Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.425.0>},
                       {name,master_activity_events_timestamper},
                       {mfargs,
                           {master_activity_events,start_link_timestamper,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[error_logger:info,2021-04-19T20:01:50.496Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.426.0>},
                       {name,master_activity_events_pids_watcher},
                       {mfargs,
                           {master_activity_events_pids_watcher,start_link,
                               []}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:50.533Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.155.0>:one_shot_barrier:notify:27]Notifying on barrier menelaus_barrier
[ns_server:debug,2021-04-19T20:01:50.533Z,ns_1@127.0.0.1:menelaus_barrier<0.157.0>:one_shot_barrier:barrier_body:62]Barrier menelaus_barrier got notification from <0.155.0>
[error_logger:info,2021-04-19T20:01:50.533Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_sup}
             started: [{pid,<0.427.0>},
                       {name,master_activity_events_keeper},
                       {mfargs,{master_activity_events_keeper,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,brutal_kill},
                       {child_type,worker}]

[ns_server:debug,2021-04-19T20:01:50.533Z,ns_1@127.0.0.1:ns_server_nodes_sup<0.155.0>:one_shot_barrier:notify:32]Successfuly notified on barrier menelaus_barrier
[ns_server:debug,2021-04-19T20:01:50.534Z,ns_1@127.0.0.1:<0.154.0>:restartable:start_child:98]Started child process <0.155.0>
  MFA: {ns_server_nodes_sup,start_link,[]}
[error_logger:info,2021-04-19T20:01:50.534Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_nodes_sup}
             started: [{pid,<0.237.0>},
                       {name,ns_server_sup},
                       {mfargs,{ns_server_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[ns_server:debug,2021-04-19T20:01:50.534Z,ns_1@127.0.0.1:<0.2.0>:child_erlang:child_loop:116]97: Entered child_loop
[error_logger:info,2021-04-19T20:01:50.534Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
          supervisor: {local,ns_server_cluster_sup}
             started: [{pid,<0.154.0>},
                       {name,ns_server_nodes_sup},
                       {mfargs,
                           {restartable,start_link,
                               [{ns_server_nodes_sup,start_link,[]},
                                infinity]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

[error_logger:info,2021-04-19T20:01:50.534Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]
=========================PROGRESS REPORT=========================
         application: ns_server
          started_at: 'ns_1@127.0.0.1'

[ns_server:warn,2021-04-19T20:01:50.925Z,ns_1@127.0.0.1:<0.344.0>:ns_memcached:connect:1307]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[ns_server:debug,2021-04-19T20:01:51.082Z,ns_1@127.0.0.1:ns_ports_setup<0.335.0>:ns_ports_setup:set_children:72]Monitor ns_child_ports_sup <11632.72.0>
[ns_server:debug,2021-04-19T20:01:51.083Z,ns_1@127.0.0.1:memcached_config_mgr<0.346.0>:memcached_config_mgr:init:46]ns_ports_setup seems to be ready
[ns_server:debug,2021-04-19T20:01:51.117Z,ns_1@127.0.0.1:memcached_config_mgr<0.346.0>:memcached_config_mgr:find_port_pid_loop:119]Found memcached port <11632.79.0>
[ns_server:debug,2021-04-19T20:01:51.154Z,ns_1@127.0.0.1:memcached_config_mgr<0.346.0>:memcached_config_mgr:init:77]wrote memcached config to /opt/couchbase/var/lib/couchbase/config/memcached.json. Will activate memcached port server
[ns_server:debug,2021-04-19T20:01:51.177Z,ns_1@127.0.0.1:memcached_config_mgr<0.346.0>:memcached_config_mgr:init:80]activated memcached port server
[stats:error,2021-04-19T20:01:51.469Z,ns_1@127.0.0.1:query_stats_collector<0.378.0>:base_stats_collector:handle_info:109](Collector: query_stats_collector) Exception in stats collector: {error,
                                                                  {badmatch,
                                                                   {error,
                                                                    {econnrefused,
                                                                     [{lhttpc_client,
                                                                       send_request,
                                                                       1,
                                                                       [{file,
                                                                         "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                        {line,
                                                                         220}]},
                                                                      {lhttpc_client,
                                                                       execute,
                                                                       9,
                                                                       [{file,
                                                                         "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                        {line,
                                                                         169}]},
                                                                      {lhttpc_client,
                                                                       request,
                                                                       9,
                                                                       [{file,
                                                                         "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                        {line,
                                                                         92}]}]}}},
                                                                  [{query_rest,
                                                                    send,3,
                                                                    [{file,
                                                                      "src/query_rest.erl"},
                                                                     {line,
                                                                      64}]},
                                                                   {query_rest,
                                                                    do_get_stats,
                                                                    0,
                                                                    [{file,
                                                                      "src/query_rest.erl"},
                                                                     {line,
                                                                      43}]},
                                                                   {base_stats_collector,
                                                                    handle_info,
                                                                    2,
                                                                    [{file,
                                                                      "src/base_stats_collector.erl"},
                                                                     {line,
                                                                      89}]},
                                                                   {gen_server,
                                                                    handle_msg,
                                                                    5,
                                                                    [{file,
                                                                      "gen_server.erl"},
                                                                     {line,
                                                                      604}]},
                                                                   {proc_lib,
                                                                    init_p_do_apply,
                                                                    3,
                                                                    [{file,
                                                                      "proc_lib.erl"},
                                                                     {line,
                                                                      239}]}]}

[ns_server:error,2021-04-19T20:01:51.471Z,ns_1@127.0.0.1:index_stats_collector-index<0.401.0>:index_rest:get_json:42]Request to (indexer) http://127.0.0.1:9102/stats?async=true failed: {error,
                                                                     {econnrefused,
                                                                      [{lhttpc_client,
                                                                        send_request,
                                                                        1,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          220}]},
                                                                       {lhttpc_client,
                                                                        execute,
                                                                        9,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          169}]},
                                                                       {lhttpc_client,
                                                                        request,
                                                                        9,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          92}]}]}}
[ns_server:warn,2021-04-19T20:01:51.518Z,ns_1@127.0.0.1:<0.435.0>:ns_memcached:connect:1307]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[ns_server:debug,2021-04-19T20:01:51.860Z,ns_1@127.0.0.1:json_rpc_connection-projector-cbauth<0.438.0>:json_rpc_connection:init:74]Observed revrpc connection: label "projector-cbauth", handling process <0.438.0>
[ns_server:debug,2021-04-19T20:01:51.860Z,ns_1@127.0.0.1:menelaus_cbauth<0.331.0>:menelaus_cbauth:handle_cast:87]Observed json rpc process {"projector-cbauth",<0.438.0>} started
[error_logger:error,2021-04-19T20:01:51.860Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.438.0>,{ok,<0.438.0>}}

[ns_server:debug,2021-04-19T20:01:51.874Z,ns_1@127.0.0.1:json_rpc_connection-projector-cbauth<0.438.0>:json_rpc_connection:handle_call:157]sending jsonrpc call:{[{jsonrpc,<<"2.0">>},
                       {id,0},
                       {method,<<"AuthCacheSvc.UpdateDB">>},
                       {params,
                        [{[{specialUser,<<"@projector-cbauth">>},
                           {nodes,
                            [{[{host,<<"127.0.0.1">>},
                               {user,<<"_admin">>},
                               {password,"*****"},
                               {ports,
                                [8091,18091,9100,9101,9102,9103,9104,9105,
                                 18092,8092,11207,9999,11210,11211,8093,
                                 18093]},
                               {local,true}]}]},
                           {buckets,[]},
                           {authCheckURL,<<"http://127.0.0.1:8091/_cbauth">>},
                           {permissionCheckURL,
                            <<"http://127.0.0.1:8091/_cbauth/checkPermission">>},
                           {ldapEnabled,true},
                           {permissionsVersion,125619376},
                           {admin,
                            {[{user,<<"Administrator">>},
                              {salt,<<"HwppMSHwWqqMMQC+Y570Cg==">>},
                              {mac,
                               <<"qvTNNsy5tPU9CAZI+HQuF+FPP5Y=">>}]}}]}]}]}
[ns_server:debug,2021-04-19T20:01:51.878Z,ns_1@127.0.0.1:json_rpc_connection-projector-cbauth<0.438.0>:json_rpc_connection:handle_info:93]got response: [{<<"id">>,0},{<<"result">>,true},{<<"error">>,null}]
[ns_server:warn,2021-04-19T20:01:51.927Z,ns_1@127.0.0.1:<0.344.0>:ns_memcached:connect:1307]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[ns_server:debug,2021-04-19T20:01:52.048Z,ns_1@127.0.0.1:json_rpc_connection-index-cbauth<0.443.0>:json_rpc_connection:init:74]Observed revrpc connection: label "index-cbauth", handling process <0.443.0>
[ns_server:debug,2021-04-19T20:01:52.049Z,ns_1@127.0.0.1:menelaus_cbauth<0.331.0>:menelaus_cbauth:handle_cast:87]Observed json rpc process {"index-cbauth",<0.443.0>} started
[error_logger:error,2021-04-19T20:01:52.050Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.443.0>,{ok,<0.443.0>}}

[ns_server:debug,2021-04-19T20:01:52.049Z,ns_1@127.0.0.1:json_rpc_connection-index-cbauth<0.443.0>:json_rpc_connection:handle_call:157]sending jsonrpc call:{[{jsonrpc,<<"2.0">>},
                       {id,0},
                       {method,<<"AuthCacheSvc.UpdateDB">>},
                       {params,
                        [{[{specialUser,<<"@index-cbauth">>},
                           {nodes,
                            [{[{host,<<"127.0.0.1">>},
                               {user,<<"_admin">>},
                               {password,"*****"},
                               {ports,
                                [8091,18091,9100,9101,9102,9103,9104,9105,
                                 18092,8092,11207,9999,11210,11211,8093,
                                 18093]},
                               {local,true}]}]},
                           {buckets,[]},
                           {authCheckURL,<<"http://127.0.0.1:8091/_cbauth">>},
                           {permissionCheckURL,
                            <<"http://127.0.0.1:8091/_cbauth/checkPermission">>},
                           {ldapEnabled,true},
                           {permissionsVersion,125619376},
                           {admin,
                            {[{user,<<"Administrator">>},
                              {salt,<<"HwppMSHwWqqMMQC+Y570Cg==">>},
                              {mac,
                               <<"qvTNNsy5tPU9CAZI+HQuF+FPP5Y=">>}]}}]}]}]}
[ns_server:debug,2021-04-19T20:01:52.053Z,ns_1@127.0.0.1:json_rpc_connection-index-cbauth<0.443.0>:json_rpc_connection:handle_info:93]got response: [{<<"id">>,0},{<<"result">>,true},{<<"error">>,null}]
[ns_server:debug,2021-04-19T20:01:52.209Z,ns_1@127.0.0.1:json_rpc_connection-cbq-engine-cbauth<0.450.0>:json_rpc_connection:init:74]Observed revrpc connection: label "cbq-engine-cbauth", handling process <0.450.0>
[error_logger:error,2021-04-19T20:01:52.209Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.450.0>,{ok,<0.450.0>}}

[ns_server:debug,2021-04-19T20:01:52.209Z,ns_1@127.0.0.1:menelaus_cbauth<0.331.0>:menelaus_cbauth:handle_cast:87]Observed json rpc process {"cbq-engine-cbauth",<0.450.0>} started
[ns_server:debug,2021-04-19T20:01:52.210Z,ns_1@127.0.0.1:json_rpc_connection-cbq-engine-cbauth<0.450.0>:json_rpc_connection:handle_call:157]sending jsonrpc call:{[{jsonrpc,<<"2.0">>},
                       {id,0},
                       {method,<<"AuthCacheSvc.UpdateDB">>},
                       {params,
                        [{[{specialUser,<<"@cbq-engine-cbauth">>},
                           {nodes,
                            [{[{host,<<"127.0.0.1">>},
                               {user,<<"_admin">>},
                               {password,"*****"},
                               {ports,
                                [8091,18091,9100,9101,9102,9103,9104,9105,
                                 18092,8092,11207,9999,11210,11211,8093,
                                 18093]},
                               {local,true}]}]},
                           {buckets,[]},
                           {authCheckURL,<<"http://127.0.0.1:8091/_cbauth">>},
                           {permissionCheckURL,
                            <<"http://127.0.0.1:8091/_cbauth/checkPermission">>},
                           {ldapEnabled,true},
                           {permissionsVersion,125619376},
                           {admin,
                            {[{user,<<"Administrator">>},
                              {salt,<<"HwppMSHwWqqMMQC+Y570Cg==">>},
                              {mac,
                               <<"qvTNNsy5tPU9CAZI+HQuF+FPP5Y=">>}]}}]}]}]}
[ns_server:debug,2021-04-19T20:01:52.212Z,ns_1@127.0.0.1:json_rpc_connection-cbq-engine-cbauth<0.450.0>:json_rpc_connection:handle_info:93]got response: [{<<"id">>,0},{<<"result">>,true},{<<"error">>,null}]
[ns_server:debug,2021-04-19T20:01:52.228Z,ns_1@127.0.0.1:json_rpc_connection-saslauthd-saslauthd-port<0.454.0>:json_rpc_connection:init:74]Observed revrpc connection: label "saslauthd-saslauthd-port", handling process <0.454.0>
[error_logger:error,2021-04-19T20:01:52.229Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.454.0>,{ok,<0.454.0>}}

[ns_server:error,2021-04-19T20:01:52.463Z,ns_1@127.0.0.1:index_stats_collector-index<0.401.0>:index_rest:get_json:42]Request to (indexer) http://127.0.0.1:9102/stats?async=true failed: {error,
                                                                     {econnrefused,
                                                                      [{lhttpc_client,
                                                                        send_request,
                                                                        1,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          220}]},
                                                                       {lhttpc_client,
                                                                        execute,
                                                                        9,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          169}]},
                                                                       {lhttpc_client,
                                                                        request,
                                                                        9,
                                                                        [{file,
                                                                          "/home/couchbase/jenkins/workspace/watson-unix/couchdb/src/lhttpc/lhttpc_client.erl"},
                                                                         {line,
                                                                          92}]}]}}
[ns_server:debug,2021-04-19T20:01:52.509Z,ns_1@127.0.0.1:json_rpc_connection-goxdcr-cbauth<0.462.0>:json_rpc_connection:init:74]Observed revrpc connection: label "goxdcr-cbauth", handling process <0.462.0>
[error_logger:error,2021-04-19T20:01:52.509Z,ns_1@127.0.0.1:error_logger<0.6.0>:ale_error_logger_handler:do_log:203]Supervisor received unexpected message: {ack,<0.462.0>,{ok,<0.462.0>}}

[ns_server:debug,2021-04-19T20:01:52.509Z,ns_1@127.0.0.1:menelaus_cbauth<0.331.0>:menelaus_cbauth:handle_cast:87]Observed json rpc process {"goxdcr-cbauth",<0.462.0>} started
[ns_server:debug,2021-04-19T20:01:52.509Z,ns_1@127.0.0.1:json_rpc_connection-goxdcr-cbauth<0.462.0>:json_rpc_connection:handle_call:157]sending jsonrpc call:{[{jsonrpc,<<"2.0">>},
                       {id,0},
                       {method,<<"AuthCacheSvc.UpdateDB">>},
                       {params,
                        [{[{specialUser,<<"@goxdcr-cbauth">>},
                           {nodes,
                            [{[{host,<<"127.0.0.1">>},
                               {user,<<"_admin">>},
                               {password,"*****"},
                               {ports,
                                [8091,18091,9100,9101,9102,9103,9104,9105,
                                 18092,8092,11207,9999,11210,11211,8093,
                                 18093]},
                               {local,true}]}]},
                           {buckets,[]},
                           {authCheckURL,<<"http://127.0.0.1:8091/_cbauth">>},
                           {permissionCheckURL,
                            <<"http://127.0.0.1:8091/_cbauth/checkPermission">>},
                           {ldapEnabled,true},
                           {permissionsVersion,125619376},
                           {admin,
                            {[{user,<<"Administrator">>},
                              {salt,<<"HwppMSHwWqqMMQC+Y570Cg==">>},
                              {mac,
                               <<"qvTNNsy5tPU9CAZI+HQuF+FPP5Y=">>}]}}]}]}]}
[ns_server:debug,2021-04-19T20:01:52.510Z,ns_1@127.0.0.1:json_rpc_connection-goxdcr-cbauth<0.462.0>:json_rpc_connection:handle_info:93]got response: [{<<"id">>,0},{<<"result">>,true},{<<"error">>,null}]
[ns_server:warn,2021-04-19T20:01:52.520Z,ns_1@127.0.0.1:<0.435.0>:ns_memcached:connect:1307]Unable to connect: {error,{badmatch,{error,econnrefused}}}, retrying.
[stats:warn,2021-04-19T20:01:53.525Z,ns_1@127.0.0.1:<0.383.0>:base_stats_collector:latest_tick:69](Collector: global_stats_collector) Dropped 2 ticks
[ns_server:debug,2021-04-19T20:01:58.381Z,ns_1@127.0.0.1:ns_config_rep<0.254.0>:ns_config_rep:do_push_keys:321]Replicating some config keys ([{local_changes_count,
                                   <<"360fb3d3641e00b1f4f22714c24e2a2a">>},
                               {metakv,<<"/indexing/settings/config">>}]..)
[ns_server:debug,2021-04-19T20:01:58.381Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{metakv,<<"/indexing/settings/config">>} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{7,63786081718}}]}|
 <<"{\"indexer.settings.compaction.days_of_week\":\"Sunday,Monday,Tuesday,Wednesday,Thursday,Friday,Saturday\",\"indexer.settings.compaction.interval\":\"00:00,00:00\",\"indexer.settings.log_level\":\"info\",\"indexer.settings.persisted_snapshot.interval\":5000,\"indexer.settings.compaction.compaction_mode\":\"circular\",\"indexer.settings.compaction.min_frag\":30,\"indexer.settings.inmemory_snapshot.interval\""...>>]
[ns_server:debug,2021-04-19T20:01:58.382Z,ns_1@127.0.0.1:ns_config_log<0.150.0>:ns_config_log:log_common:145]config change:
{local_changes_count,<<"360fb3d3641e00b1f4f22714c24e2a2a">>} ->
[{'_vclock',[{<<"360fb3d3641e00b1f4f22714c24e2a2a">>,{15,63786081718}}]}]
[ns_server:debug,2021-04-19T20:01:58.382Z,ns_1@127.0.0.1:<0.519.0>:ns_audit:put:248]Audit modify_index_storage_mode: [{storageMode,<<"memory_optimized">>},
                                  {real_userid,
                                      {[{source,ns_server},
                                        {user,<<"Administrator">>}]}},
                                  {remote,
                                      {[{ip,<<"127.0.0.1">>},{port,37166}]}},
                                  {timestamp,<<"2021-04-19T20:01:58.381Z">>}]
[ns_server:debug,2021-04-19T20:02:20.390Z,ns_1@127.0.0.1:compaction_new_daemon<0.406.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2021-04-19T20:02:20.390Z,ns_1@127.0.0.1:compaction_new_daemon<0.406.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T20:02:20.390Z,ns_1@127.0.0.1:compaction_new_daemon<0.406.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2021-04-19T20:02:20.390Z,ns_1@127.0.0.1:compaction_new_daemon<0.406.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T20:02:50.391Z,ns_1@127.0.0.1:compaction_new_daemon<0.406.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_kv. Rescheduling compaction.
[ns_server:debug,2021-04-19T20:02:50.391Z,ns_1@127.0.0.1:compaction_new_daemon<0.406.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_kv too soon. Next run will be in 30s
[ns_server:debug,2021-04-19T20:02:50.392Z,ns_1@127.0.0.1:compaction_new_daemon<0.406.0>:compaction_new_daemon:process_scheduler_message:1309]No buckets to compact for compact_views. Rescheduling compaction.
[ns_server:debug,2021-04-19T20:02:50.392Z,ns_1@127.0.0.1:compaction_new_daemon<0.406.0>:compaction_scheduler:schedule_next:60]Finished compaction for compact_views too soon. Next run will be in 30s
